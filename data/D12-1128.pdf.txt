Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c©2012 Association for Computational Linguistics
Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation
Roberto Navigli and Simone Paolo Ponzetto
Dipartimento di Informatica
Sapienza Universita` di Roma
{navigli,ponzetto}@di.uniroma1.it
Abstract
We present a multilingual joint approach
to Word Sense Disambiguation (WSD). Our
method exploits BabelNet, a very large mul-
tilingual knowledge base, to perform graph-
based WSD across different languages, and
brings together empirical evidence from these
languages using ensemble methods. The re-
sults show that, thanks to complementing
wide-coverage multilingual lexical knowledge
with robust graph-based algorithms and com-
bination methods, we are able to achieve the
state of the art in both monolingual and multi-
lingual WSD settings.
1 Introduction
Nowadays the textual information needed by a user
accessing websites for content such as news re-
ports, commentaries and encyclopedic knowledge
is provided in an increasingly wide range of lan-
guages. For example, even though English is still
the majority language of the Web, the Chinese and
Spanish languages are moving fast to capture their
“juicy share”, and more languages are about to join
them in the near future. This language explosion
clearly forces researchers to focus on the challeng-
ing problem of being able to analyze and under-
stand text written in any language. However, it also
opens up novel perspectives for multilingual Natural
Language Processing (NLP) such as, for instance,
the development of approaches aimed at “joining
forces” and taking advantage of the lexico-semantic
knowledge provided in the different languages to
improve text understanding. These two aspects are
strongly intertwined: on the one hand, enabling
language-independent text understanding would al-
low for the harvesting of more knowledge in arbi-
trary languages, while, on the other hand, bringing
together the lexical and semantic information avail-
able in different languages would improve the qual-
ity of text understanding in arbitrary languages.
However, these two goals have hitherto never
been achieved, as is attested to by the fact that re-
search in a core language understanding task such as
Word Sense Disambiguation (Navigli, 2009, WSD)
has always been focused mostly on English. His-
torically, English became established as the lan-
guage used and understood by the scientific com-
munity and, consequently, most resources were de-
veloped for it, including large-scale computational
lexicons like WordNet (Fellbaum, 1998) and sense-
tagged corpora like SemCor (Miller et al., 1993).
As a result WSD in other languages was hindered
by a lack of resources, which in turn led to poor re-
sults or low involvement on the part of the research
community (Magnini et al., 2004; Ma`rquez et al.,
2004; Orhan et al., 2007; Okumura et al., 2010).
Nonetheless, already in the 1990s it had been re-
marked that WSD could be improved by means of
multilingual information: a recurring idea proposed
by several researchers was that plausible transla-
tions of a word in context would restrict its pos-
sible senses to a manageable subset of meanings
(Dagan et al., 1991; Gale et al., 1992; Resnik and
Yarowsky, 1999). While the lack of resources at that
time hampered the development of effective multi-
lingual approaches to WSD, recently this idea has
been revamped with the organization of SemEval
tasks dealing with cross-lingual WSD (Lefever and
Hoste, 2010) and cross-lingual lexical substitution
(Mihalcea et al., 2010). At the same time, new re-
1399
search on the topic has been done, including the use
of statistical translations of sentences into many lan-
guages as features for supervised models (Banea and
Mihalcea, 2011; Lefever et al., 2011), and the pro-
jection of monolingual knowledge onto another lan-
guage (Khapra et al., 2011).
Yet the above two goals, i.e., disambiguating in
an arbitrary language and using lexical and seman-
tic knowledge from many languages in a joint way
to improve the WSD task, have not hitherto been
attained. In this paper, we address both objectives
and propose a graph-based approach to multilingual
joint Word Sense Disambiguation. Our proposal
brings together the lexical knowledge from differ-
ent languages by exploiting empirical evidence for
disambiguation from each of them, and then com-
bining this information in a synergistic way: each
language provides a piece of sense evidence for the
meaning of a target word in context, and subsequent
integration of these various pieces enables them to
(soft) constrain each other. The results show that
this way we are able to improve over previous, high-
performing graph-based methods in both a monolin-
gual and multilingual setting, thus showing for the
first time the beneficial effects of exploiting multi-
lingual knowledge in a joint fashion.
2 Related Work
Parallel corpora have been used in the literature
for the automatic creation of a sense-tagged dataset
for supervised WSD in different languages (Gale
et al., 1992; Chan and Ng, 2005; Zhong and Ng,
2009). Other approaches include the use of a coher-
ence index for identifying the tendency to lexicalize
senses differently across languages (Ide, 2000) and
the clustering of source words which translate into
the same target word, then used to perform WSD
using a similarity measure (Diab, 2003). A histori-
cal approach (Brown et al., 1991) uses bilingual cor-
pora to perform unsupervised word alignment and
determine the most appropriate translation for a tar-
get word from a set of contextual features.
All the above approaches to multilingual or cross-
lingual WSD rely on bilingual corpora, including
those which exploit existing multilingual WordNet-
like resources (Ide et al., 2002), or use automatically
induced multilingual co-occurrence graphs (Silberer
and Ponzetto, 2010). However, this requirement is
often very hard to satisfy, especially if we need wide
coverage. To overcome this limitation, in this work
we make use of BabelNet (Navigli and Ponzetto,
2010), a very large multilingual lexical knowledge
base. This resource – complementary in nature
to other recent efforts presented by de Melo and
Weikum (2010), Nastase et al. (2010) and Meyer and
Gurevych (2012), inter alia – provides a truly multi-
lingual semantic network by combining Wikipedia’s
multilinguality with the output of a state-of-the-art
machine translation system to achieve high cover-
age for all languages. The key insight here is that
Word Sense Disambiguation and Machine Transla-
tion (MT) are highly intertwined tasks, as previously
shown by Carpuat and Wu (2007) and Chan et al.
(2007), who successfully used sense information to
boost state-of-the-art statistical MT. In this work we
focus instead on the benefits of using multilingual
information for WSD by exploiting the structure of
a multilingual semantic network.
3 Multilingual Joint WSD
We present our methodology for multilingual WSD:
we first introduce BabelNet, the resource used in our
work (Section 3.1) and then present our algorithm
for multilingual joint WSD (Section 3.2), including
its main components, namely graph-based WSD, en-
semble methods and translation weighting (sections
3.3, 3.4 and 3.5).
3.1 BabelNet
BabelNet (Navigli and Ponzetto, 2010) follows the
structure of a traditional lexical knowledge base and,
accordingly, consists of a labeled directed graph
whose nodes represent concepts and named entities,
and whose edges express semantic relations between
them. Concepts and relations are harvested from
the largest available semantic lexicon of English,
i.e., WordNet, and a wide-coverage collaboratively-
edited encyclopedia, i.e., Wikipedia1, thus making
BabelNet a multilingual ‘encyclopedic dictionary’
which combines lexicographic information with en-
cyclopedic knowledge on the basis of an unsuper-
vised mapping framework. In addition to a core
1http://www.wikipedia.org. In the following, we
refer to Wikipedia pages and senses using SMALL CAPS.
1400
semantic network, BabelNet provides a multilin-
gual lexical dimension. Each of its nodes, called
Babel synsets, contains a set of lexicalizations of
the concept for different languages, e.g., { bankENn ,
BankDEn , bancaITn , . . . , bancoESn }2. Multilin-
gual lexicalizations for all concepts are collected
from Wikipedia’s inter-language links (e.g., the En-
glish Wikipedia page BANK links to the Italian
BANCA), as well as by acquiring missing trans-
lations by means of a statistical machine transla-
tion system applied to sense-tagged data from Sem-
Cor and Wikipedia itself – for instance, most oc-
currences of bank1n in SemCor3 are translated into
German and Italian as Ufer and riva, respectively.
As a result of combining human-edited translations
from Wikipedia and automatically generated ones
from sense-labeled data, BabelNet is able to achieve
wide coverage for all its languages (Catalan, En-
glish, French, German, Italian and Spanish): accord-
ingly, we chose it to perform graph-based WSD in
a multilingual setting since it is specifically focused
on lexical knowledge. In addition, BabelNet is avail-
able for any language required to perform standard
SemEval cross-lingual disambiguation tasks (e.g.,
Spanish, in order to perform cross-lingual lexical
substitution). Since previous work in knowledge-
based WSD shows the benefits of using rich lexical
resources (Navigli and Lapata, 2010; Ponzetto and
Navigli, 2010), BabelNet is a suitable choice for per-
forming graph-based multilingual WSD.
3.2 Exploiting multilingual information in a
knowledge-based WSD framework
We present a multilingual approach to WSD
which exploits three main factors:
i) the fact that translations of a target word pro-
vide complementary information on the range
of its candidate senses in context;
ii) the wide-coverage, multilingual lexical knowl-
edge stored in BabelNet;
iii) the support for disambiguation from different
languages in a synergistic, unified way.
2BabelNet senses are referred to with wlp, namely the sense
of a word w in a language l with part of speech p.
3We denote WordNet senses with wip, namely the i-th sense
of a word w with part of speech p.
Algorithm 1 Multilingual joint WSD
Input: a word sequence ? = (w1, . . . , wn)
a target word w ? ?
BabelNet BN
an ensemble method M
Output: a distribution of scores for the senses of w
( indicates a comment)
1: S ? SynsetsBN (w)
2: T ? {w}
3: for each s ? S
4: T ? T ? getTranslations(s)
5: ctx? ? ? {w}
6:  LScore := {lScorei,j}i=1,...,|T |, j=1,...,|S|
7: for each ti ? T
8: ?? ? {ti} ? ctx
9:  Gi := (Vi, Ei)
10: Gi ? createGraph(??, BN)
11: for each sj ? S ? Vi
12: lScorei,j ? score(Gi, sj)
13:  Score := (score1, . . . , score|S|)
14: Score?M(LScore)
15: return Score
We call this approach multilingual joint WSD,
since disambiguation is performed by exploiting dif-
ferent languages together at the same time. To this
end, we first perform graph-based WSD using the
target word in context as input, and then combine
sense evidence from its translations using an ensem-
ble method. The key idea of our joint approach is
that sense evidence from different translations pro-
vides complementary views for the senses of a tar-
get word in context. Therefore, combining such ev-
idence should produce more accurate sense predic-
tions. We view WSD as a sense ranking problem.
Given a word sequence ? = (w1, . . . , wn), we dis-
ambiguate a target word w ? ? by scoring each of
its senses and selecting the highest-ranking one:
sˆ = argmax
s ? SynsetsBN (w)
score(s) , (1)
where SynsetsBN (w) is the set of Babel synsets con-
taining the different senses for w.4 We score these
4Babel synsets unambiguously identify different senses
of the target word, e.g., { bankENn , BankDEn , bancoESn . . . ,
bancaITn } corresponds to the ‘financial institute’ sense of
bankENn (i.e., bank2n in WordNet).
1401
synsets using Algorithm 1, which we illustrate in
the following by means of the example sentence
‘bank bonuses are paid in stock’, where we focus on
bankENn as the target word and { bonusENn , payENv ,
stockENn } as its context. The following steps are
performed:
Initialization. We start by gathering the data re-
quired for disambiguation (lines 1–5). First, we
collect in line 1 the set S of Babel synsets corre-
sponding to the different senses of the target word w
– namely, the synsets containing the ‘financial in-
stitution’, ‘money container’, ‘building’ senses of
bankENn , among others. Next, we obtain the multi-
lingual lexicalizations of the target word: to this end,
we first include in T the word w itself (line 2), and
then iterate through each synset s ? S to collect the
translations of each of its senses in the languages of
interest (lines 3–4). For instance, given the English
word bankENn , we collect its sense-specific German,
Italian and Spanish translations and obtain a set of
multilingual terms T = { bankENn , . . . , BankDEn ,
Sparbu¨chseDEn , Bankgeba¨udeDEn , . . . , bancaITn ,
salvadanaioITn , . . . , bancoESn , huchaESn }. Finally,
we create a disambiguation context ctx by taking the
word sequence ? and removing w from it (line 5, as
a result, e.g., ctx = { bonusENn , payENv , stockENn }).
Collecting sense distributions. In the next phase
(lines 6–12), we collect a scoring distribution over
the different synsets S of w for each term ti ? T .
Each distribution quantifies the empirical support for
the different senses of the target word, obtained us-
ing ti and the context ctx: we store this informa-
tion in a |T | × |S| matrix LScore, where each cell
lScorei,j quantifies the support for synset sj ? S,
computed using the term in ti ? T . We calculate the
scores as follows:
- We select at each step an element ti from T (line
7), for instance bancoESn .
- Next, we create a multilingual context ?? by com-
bining ti with the words in ctx (line 8, e.g., we set
?? = { bancoESn , bonusENn , payENv , stockENn }.
- We use ?? to build a graph Gi = (Vi, Ei) by
computing the paths in BabelNet which connect
the synsets of ti with those of the other words
in ?? (line 10, see Section 3.3 for details on the
createGraph function). Note that by selecting at
each step a different element from T we create a
new graph where different sets of Babel synsets
get activated by the context words in ctx. In our
example, Figures 1(a)–(c) show the graphs ob-
tained by setting at different steps ti to bankENn ,
bancoESn and BankDEn , respectively (we show ex-
cerpts by using only stockENn as context word for
ease of readability).
- Finally, we compute the support from term ti for
each synset sj ? S of the target word by applying
a graph connectivity measure to Gi and store the
result in lScorei,j (lines 11–12). For instance, us-
ing degree as graph measure, we can compute the
following scores from the graph in Figure 1(b):
bank2n bank8n bank9n
bancoESn 2 0 1
By repeating the process for each term in T (lines 7–
12) we compute all values in the matrixLScore. For
instance, given T = {bankENn , bancoESn , BankDEn },
we create the set of graphs in Figures 1(a)–(c), and
compute from each of them the following scores
(again, using degree as scoring measure):
LScore =
bank2n bank8n bank9n
bankENn
?
?
2 2 1
?
?bancoESn 2 0 1
BankDEn 2 0 0
Combining sense distributions. In the last step
(line 14) we aggregate the scores associated with
each term of T using an ensemble method M (see
Section 3.4 for details). For instance, M could sim-
ply consist of summing the scores associated with
each sense over all distributions and thus return a
score of 6, 2, and 2 for bank2n, bank8n and bank9n,
respectively. As a result of the execution of Al-
gorithm 1, the combined scoring distribution is re-
turned (line 15). This sense distribution in turn can
be used to select the best sense using Equation 1.
The main hunch behind our approach is that using
information from different languages improves dis-
ambiguation performance, as in the example of Fig-
ure 1 where more accurate disambiguation is per-
formed by combining scores computed from trans-
lations in different languages, as opposed to using
1402
(a) Disambiguation graph using the target word bankENn .
bank2nBankDEbancoESbancaIT
bank8nSparbu¨chseDEhuchaESsalvadanaioIT
bank9nBankgeba¨udeDEbancoES bancaIT
stock1nAktienDEaccionesESazioniIT
stock4nAktienzertifikatDEaccionesES azioniIT
stock17nViehDEganadoESbestiameIT
commercial
bank
investment
banking
stock
broker trader
piggy
bank pig
building abattoir
(b) Disambiguation graph using bancoESn as translation.
bank2nBankDEbancoESbancaIT
bench1nBankDEbancoESpanchinaIT
bank8nSparbu¨chseDEhuchaESsalvadanaioIT
bank9nBankgeba¨udeDEbancoES bancaIT
stock1nAktienDEaccionesESazioniIT
stock4nAktienzertifikatDEaccionesES azioniIT
stock17nViehDEganadoESbestiameIT
commercial
bank
investment
banking
stock
broker trader
piggy
bank pig
building abattoir
(c) Disambiguation graph using BankDEn as translation.
bank2nBankDEbancoESbancaIT
bench1n BankDEbancoES panchinaIT
bed4n BankDEestratoES lettoIT
bank8nSparbu¨chseDEhuchaESsalvadanaioIT
bank9nBankgeba¨udeDEbancoES bancaIT
stock1nAktienDEaccionesESazioniIT
stock4nAktienzertifikatDEaccionesES azioniIT
stock17nViehDEganadoESbestiameIT
commercial
bank
investment
banking
stock
broker trader
piggy
bank pig
building abattoir
(d) List of corresponding WordNet senses and their glosses
bank2n financial institution that accepts deposits and channels
the money into lending activities
bank8n a container (usually with a slot in the top) for keeping
money at home
bank9n a building in which the business of banking transacted
stock1n the capital raised by a corporation through the issue
of shares entitling holders to an ownership interest
stock4n a certificate documenting the shareholder’s
ownership in the corporation
stock17n any animals kept for use or profit
Figure 1: Multilingual graph construction for the input sentence ‘bank bonuses are paid in stock’. We show excerpts
using only stockENn as context word for ease of readability.
monolingual sense evidence only. Figure 1(a) shows
the graph created to disambiguate the English target
word bankENn in our example sentence. In the graph,
some of the possible senses of this word are acti-
vated, including the correct one (bank2n) but also re-
lated, yet incorrect ones such as bank8n and bank9n.
Figure 1(b) and 1(c) show instead the graphs ob-
tained from replacing the target word with its Span-
ish and German translations, respectively. In these
graphs, different subsets of the senses of bankENn
are activated, together with others pertaining to the
translations only (e.g., the meaning of bancoESn cor-
responding to the English bench1n). However, the
sense that is consistently activated across all graphs
is the correct one – i.e., bankENn as financial insti-
tution – which is in fact the sense selected by our
multilingual approach by means of combining the
scoring distributions from all these graphs.
3.3 Graph-based WSD
We use graph-based algorithms to exploit multilin-
gual knowledge from BabelNet for WSD. These are
a natural choice for our approach, since BabelNet is
a semantic network, and such algorithms have been
shown to achieve high performance across domains
(Agirre et al., 2009; Navigli et al., 2011), as well
as to compete with supervised methods on a vari-
ety of lexical disambiguation tasks (Ponzetto and
Navigli, 2010). To this end, we use the method
of Navigli and Lapata (2010) and construct a di-
rected graphG = (V,E) for an input word sequence
? = (w1, . . . , wn)5 using the lexical and semantic
relations found in BabelNet. The result of this pro-
cedure is a subgraph of BabelNet containing (1) the
senses of the words in context, (2) all edges and in-
termediate senses found in BabelNet along all paths
that connect them. Given G, a target word w ? ?
and its set of senses in BabelNet S ? V , we com-
pute a score distribution (score1, . . . , score|S|) over
S, where scorej refers to the confidence score for
the j-th sense of w, e.g. bank2n, based on some con-
nectivity measure applied to G. In this paper, we
specifically focus on two such measures.
5In our experiments we always take ? to be a single sen-
tence, thus disambiguating on a sentence-by-sentence basis.
1403
Degree Centrality (Degree): The first measure
ranks the senses of a given word in the graph based
on the number of their incident edges, namely:
scorej = |{{sj , v} ? E : v ? V }| .
This standard connectivity measure weights a sense
as more appropriate if it has a higher degree. We
chose context-based Degree since, albeit simple, it
had previously been shown to yield a highly com-
petitive performance on various WSD tasks (Navigli
and Lapata, 2010; Ponzetto and Navigli, 2010).
Inverse path length sum (PLength): We then de-
veloped a graph connectivity measure which scores
each sense by summing over the inverse length of all
paths which connect it to other senses in the graph:
scorej =
?
p? paths(sj)
1
elength(p)?1
,
where paths(sj) is the set of simple paths con-
necting sj to the senses of other context words,
length(p) is the number of edges in the path p and
each path is scored with the exponential inverse de-
cay of the path length. This measure overcomes the
locality of Degree by aggregating over all paths be-
tween a sense of the target word and those of the
context words, thus being able to capture the rich-
ness of the BabelNet subgraph and the semantic den-
sity of the underlying knowledge base.
3.4 Ensemble methods for multilingual WSD
At the core of our algorithm lies the combination of
the scores generated using the different translations
of the target word w. For this purpose, we apply so-
called ensemble methods, which have been shown
to improve the performance of both supervised (Flo-
rian et al., 2002) and unsupervised WSD systems
(Brody et al., 2006). Given |T | lexicalizations and
|S| senses for w, the input to the combination com-
ponent consists of a |T |× |S|matrix LScore, where
each cell lScorei,j quantifies the empirical support
for sense sj from a term ti ? T (see Section 3.2 for
an example). The ensemble method computes from
this translation-sense matrix a combined scoring, ex-
pressing the joint confidence across terms in differ-
ent languages over the set of senses S. In this work,
we use the ‘Probability Mixture’ (PMixture) method
proposed by Brody et al. (2006), which they show
to be the best performing for WSD. This method
takes the scores associated with each term, normal-
izes and combines them by summing across distri-
butions. Formally, it computes the score for the j-th
sense of w as follows:
scorej =
|T |?
i=1
p(si,j), p(si,j) =
lScorei,j
?|S|
s=1 lScorei,s
.
For instance, using the (normalized) sense distribu-
tions from our example, the ensemble distribution
will be the following:
bank2n bank8n bank9n
bankENn 0.40 0.40 0.20
bancoESn 0.67 0.00 0.33
BankDEn 1.00 0.00 0.00
PMixture 2.07 0.40 0.53
3.5 Weighting multilingual sense distribution
Computing a sense distribution for each translation
using the same graph connectivity measure assumes
that all translations are equal. However, a leitmotif
of multilingual WSD research is that translations re-
strict the set of candidate senses of the target word
in the source language. In our example of Figure
1, for instance, BankDEn provides structural support
only for the financial sense of English bank, since
this is the only sense it covers. Within our frame-
work this can potentially lead to skewed sense dis-
tributions when only some senses of the target word
have a translation. In such cases, in fact, scores tend
to be concentrated mostly on the senses covered by
the translations, with the result that sense evidence
for uncovered English senses is disregarded. In or-
der to cope with this issue, we weight the elements
of each sense distribution lScorei for the i-th trans-
lation ti ? T by a factor of 1+log2 cov(ti, w), where
cov(ti, w) is the number of Babel synsets where ti
co-occurs with the target word w – i.e., the number
of senses of w that it covers (we use the log func-
tion to dampen the effect of high coverage values).
This is to say, in order to level off the effects of un-
balanced sense coverage we assume that, all things
being equal, the more senses a translation covers, the
stronger the disambiguation evidence it provides in
context for specific senses. As a result, the contri-
butions of each translation are weighted differently
1404
and we are thus able to dampen the effects of a
highly skewed distribution like, for instance, that of
BankDEn :
bank2n bank8n bank9n
bankENn 1.72 1.72 0.86
bancoESn 1.34 0.00 0.66
BankDEn 1.00 0.00 0.00
Weighted PMixture 4.04 1.70 1.52
4 Experiments
We evaluate our approach in two different settings,
namely a monolingual all-words WSD task in Sec-
tion 4.1, as well as two different cross-lingual dis-
ambiguation gold standards in Section 4.2.
4.1 Monolingual WSD
Experimental setting. We first evaluate the per-
formance of multilingual joint WSD on a standard
monolingual dataset, namely the SemEval-2010 do-
main WSD task 17 (Agirre et al., 2010), since it
provides the latest dataset for fine-grained WSD in
English. We opt for an English all-words task for
two main reasons: first, it is a well-established and
widely-participated task in the WSD community –
thus ensuring a comparison of our method with a
wide range of state-of-the-art approaches, includ-
ing other graph-based techniques (e.g., Personalized
PageRank), as well as weakly-supervised and super-
vised approaches (see Agirre et al. (2010) for de-
tails on the participating systems); second, we want
to assess whether a multilingual approach benefits
lexical disambiguation in all settings, namely even
in a standard monolingual one. We use in our ex-
periments the dataset’s nouns-only subset (1032 in-
stances), since BabelNet currently contains multi-
lingual lexicalizations for nouns only (and thus no
multilingual strategy can be applied to other parts
of speech). We perform graph-based WSD with
BabelNet in two different configurations, namely a
monolingual and multilingual setting. The multi-
lingual system performs WSD by means of the full
joint multilingual approach described in Algorithm
1. The monolingual approach, instead, simply uses
the English input sentence for disambiguation – that
is, we skip lines 3–4 of Algorithm 1. Knowledge-
based systems typically suffer from a low recall –
i.e., they cannot provide an answer if no information
Algorithm P R F1
Monolingual Degree 50.6 45.2 47.7
graph PLength 51.0 47.3 49.1
Multilingual Degree† 53.9 48.6 51.1
ensemble PLength† 54.3 50.2 52.2
SemCor MFS 51.9 51.2 51.5
Random 25.3 25.3 25.3
Table 1: Performance on SemEval-2010 all-words do-
main WSD (nouns only subset). Best results for each
measure are bolded. † indicates statistically significant
differences with respect to the monolingual setting.
can be found with senses of the context words. To
overcome this issue, in both settings we use a type-
based fallback strategy which assigns to the target
word the sense which has been most frequently as-
signed by the system to other instances of the word
in the dataset.
Results and discussion. We report our results in
terms of precision (P), recall (R) and F1 measure in
Table 1, where we compare the monolingual vari-
ant (rows 1–2 of the table) with our multilingual
approach (rows 3–4). Following standard practice,
(1) we benchmark our method against two baselines,
namely a random sense assignment and the most fre-
quent sense (MFS) from SemCor; (2) we test for sta-
tistical significance by computing a 95% confidence
interval on the recall score (i.e., the main evaluation
measure for the WSD task) using bootstrap resam-
pling (Noreen, 1989).
The results show that our multilingual approach
improves over the monolingual one by a substan-
tial (i.e., statistically significant) margin. Combining
multilingual information from different languages
yields a higher precision (+3.3 for both graph algo-
rithms) and recall (+3.4 and +2.9 for Degree and
PLength, respectively). Manual inspection of the
output reveals that these increases in precision are
due to translations in different languages constrain-
ing each other – e.g., an implausible English sense is
‘ruled out’ from the sense distributions of the other
languages (cf. the example in Figure 1). The in-
creases in recall, instead, indicate that using trans-
lations triggers responses in those cases where no
sense of the English target word can be connected
to the senses of the context words – i.e., some trans-
1405
Algorithm P R F1
Monolingual Degree 52.0 51.3 51.6
graph PLength 55.0 54.2 54.6
Multilingual Degree† 61.6 59.5 60.5
ensemble PLength† 62.5 60.4 61.4
CFILT 61.4 59.4 60.4
IIITH 56.4 55.3 55.8
Table 2: Performance on SemEval-2010 all-words do-
main WSD (nouns only subset) using the most frequent
sense assigned by the system as back-off strategy when
no sense assignment is attempted.
lations activate senses in the knowledge base which
are closer to the senses of the context words. The
result is an overall increase in F1 measure of 3.4
and 3.1 points for Degree and PLength, respectively,
which makes it possible for us to beat the MFS
baseline (notably a difficult competitor for WSD
systems). Among the different graph algorithms,
PLength consistently outperforms Degree: however,
the differences are not statistically significant.
In order to better understand the impact of our ap-
proach we follow previous work (e.g., Navigli and
Lapata (2010)) and explore a weakly-supervised set-
ting where the system attempts no sense assignment
if the highest score among those assigned to the
senses of a target word is below a certain threshold.
If this is the case, in order to provide an answer for
all items, we output the most frequent sense assigned
by the system to other instances of the target word,
and fall back to SemCor’s MFS if no assignment has
been attempted. We estimate the optimal value for
the threshold by maximizing F1 on a development
set obtained by combining the Senseval-2 (Palmer et
al., 2001) and Senseval-3 (Snyder and Palmer, 2004)
English all-words datasets. The results for this set-
ting are shown in Table 2, where we also compare
with the top-performing systems from the SemEval
competition, namely CFILT (Kulkarni et al., 2010)
and IIITH (Reddy et al., 2010).
By complementing our multilingual method with
the MFS heuristic we achieve a performance compa-
rable with the state of the art on this task. Again, the
multilingual ensemble approach consistently outper-
forms the monolingual one and enables us to achieve
the best overall results for this dataset: without mul-
tilingual information, in fact, we achieve only aver-
age performance above the MFS level, whereas by
effectively combining sense evidence from multilin-
gual translations we are able to boost the F1 measure
by a 6-8 point margin, and thus outperform the top-
ranking SemEval systems. While differences with
CFILT are not statistically significant, we still take
this to be good news, since our system is general
purpose in nature and, accordingly, does not use any
domain information such as manually-labeled exam-
ples for the most frequent domain words (CFILT) or
a domain-specific sense ranking (IIITH).
4.2 Cross-lingual lexical disambiguation
Using a multilingual lexical resource makes it possi-
ble to perform WSD in any of its languages. Ac-
cordingly, we complement our evaluation on En-
glish texts with a second set of experiments where
we quantify the impact of our approach on a lex-
ical disambiguation task in a multilingual setting.
To this end, we use the SemEval-2010 cross-lingual
lexical substitution (Mihalcea et al., 2010, CL-LS,
henceforth) and WSD (Lefever et al., 2011, CL-
WSD) tasks and evaluate our methodology on per-
forming disambiguation across different languages.
Both cross-lingual WSD tasks cast disambiguation
as a word translation problem: given an English pol-
ysemous noun in context as input, the system dis-
ambiguates it by providing a translation into another
language (translations are deemed correct if they
preserve the meaning of the source word in the target
language). Their main difference, instead, lies in the
range of translations which are assumed to be valid:
that is, while CL-LS assumes no predefined sense in-
ventory (i.e., any translation can be potentially cor-
rect), CL-WSD makes use of a sense inventory built
on the basis of the Europarl corpus (Koehn, 2005).
Our approach to lexical disambiguation involves
two steps: first, given a target word in context, we
disambiguate it as usual to the highest-ranked Ba-
bel synset; next, given the translations in the se-
lected synset, we return the most suitable lexical-
ization in the language of interest. Since the se-
lected synset can contain multiple translations in a
target language for the input English word, we ex-
plore using an unsupervised strategy to select the
most reliable translation from multiple candidates.
To this end, we return for each test instance only the
1406
Algorithm P/R/F1
Baseline 23.80
Monolingual Degree 30.52
graph PLength 30.64
Multilingual Degree 32.21
ensemble PLength 32.47
UBA-T 32.17
Table 3: Performance on SemEval-2010 lexical substitu-
tion (best results are bolded).
most frequent translation found in the Babel synset.
Given that the two tasks make different assumptions
on the sense inventory (no fixed inventory for CL-
LS vs. Europarl-based for CL-WSD), the frequency
of a translation is calculated as either the number
of Babel synsets in which it occurs (CL-LS), or its
frequency of alignment with the target word, as ob-
tained by applying GIZA++ (Och and Ney, 2003) to
Europarl (CL-WSD). To provide an answer for all
instances, we return this most frequent translation
even when no sense assignment is attempted – i.e.,
no sense of the target word is connected to any other
sense of the context words – or a tie occurs.
Results and discussion. We report our results for
CL-LS and CL-WSD in Tables 3 and 4. We evalu-
ate using the nouns-only subset of the CL-LS dataset
and the full CL-WSD dataset, consisting of 300 and
1,000 instances of nouns in context, respectively.
The evaluation scheme is based on the SemEval-
2007 English lexical substitution task (McCarthy
and Navigli, 2009), and consists of an adaptation of
the metrics of precision and recall for the translation
setting. For each task, we compare our monolingual
and multilingual approaches against the best per-
forming SemEval systems for these tasks, namely
UBA-T (Basile and Semeraro, 2010) and UVT-v
(van Gompel, 2010) for CL-LS and CL-WSD, re-
spectively, as well as a recent supervised proposal
that exploits automatically generated multilingual
features from parallel text and translated contexts
(Lefever et al., 2011, Parasense). For each task
we also report its official baseline, namely the first
translation from an online-dictionary6 for CL-LS,
and the most frequent word alignment obtained by
6www.spanishdict.com
applying GIZA++ to the Europarl data for CL-WSD.
Our cross-lingual results confirm all trends of the
English monolingual evaluation, namely that: a) our
joint multilingual approach substantially improves
over the simple monolingual graph-based approach;
b) it enables us to achieve state-of-the-art perfor-
mance for these tasks. In the case of both CL-
LS and CL-WSD, using a rich multilingual knowl-
edge base like BabelNet makes it possible to achieve
a respectable performance already with the simple
monolingual approach, thus indicating the viability
of a knowledge-rich approach to sense-driven word
translation. The use of multilingual ensembles al-
ways improves the monolingual setting for all lan-
guages, and allows us to achieve the best overall re-
sults for both CL-LS and CL-WSD. Similarly to the
case of monolingual WSD, manual inspection of the
output reveals that translations help us rule out in-
correct senses and let the disambiguation algorithm
focus on the more coherent set of senses for the in-
put context in a way similar to the one highlighted
by the example in Figure 1. As a result of this we
are able to improve the performance of both mono-
lingual Degree and PLength, and compete with the
state of the art on all disambiguation tasks.
5 Conclusions
In this paper we presented a multilingual joint ap-
proach to WSD. Key to our methodology is the ef-
fective use of a wide-coverage multilingual knowl-
edge base, BabelNet, which we exploit to perform
graph-based WSD across languages and combine
complementary sense evidence from translations in
different languages using an ensemble method. This
is the first proposal to exploit structured multilingual
information within a joint, knowledge-rich frame-
work for WSD. The APIs to perform multilingual
WSD using BabelNet are freely available for re-
search purposes (Navigli and Ponzetto, 2012b).
Thanks to multilingual joint WSD we achieve
state-of-the-art performance on three different gold
standards. The good news about these results is that
not only can further advances be achieved by using
multilingual lexical knowledge, but, more impor-
tantly, that combining multilingual sense evidence
from different languages at the same time yields
consistent improvements over a monolingual ap-
1407
French German Italian Spanish
P/R/F1 P/R/F1 P/R/F1 P/R/F1
Baseline 21.25 13.16 15.18 19.74
UvT-v N/A N/A N/A 23.39
Parasense 24.54 16.88 18.03 22.80
Monolingual Degree 22.94 17.15 18.03 22.48
graph PLength 23.42 17.72 18.19 22.76
Multilingual Degree 24.02 18.07 18.93 23.51
ensemble PLength 24.61 18.26 19.05 23.65
Table 4: Results on the SemEval-2010 cross-lingual WSD dataset (best results are bolded).
proach in both monolingual and cross-lingual lexical
disambiguation tasks – that is, ‘joining forces pays
off’. Effectively leveraging multilingual knowledge
for WSD helps overcome the shortcomings of the
underlying resource (noise, coverage, etc.), thus in-
dicating that further performance boosts can come
in the future from even better multilingual lexical
resources. Moreover, our methodology is general-
purpose and can be adapted to tasks other than
WSD: in fact, we have already taken the first steps
in this direction by showing the beneficial effects of
a joint multilingual approach to computing semantic
relatedness (Navigli and Ponzetto, 2012a). In ad-
dition, we plan in the very near future to general-
ize our multilingual joint approach and apply it to
high-end tasks such as multilingual textual entail-
ment (Mehdad et al., 2011) and sentiment analysis
(Lu et al., 2011) – so as to provide a general frame-
work for knowledge-rich multilingual NLP.
Acknowledgments
The authors gratefully acknowl-
edge the support of the ERC Start-
ing Grant MultiJEDI No. 259234.
BabelNet and its API are available for download at
http://lcl.uniroma1.it/babelnet.
References
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2009. Knowledge-based WSD on specific domains:
performing better than generic supervised WSD. In
Proceedings of the 21st International Joint Confer-
ence on Artificial Intelligence (IJCAI-09), pages 1501–
1506.
Eneko Agirre, Oier Lo´pez de Lacalle, Christiane Fell-
baum, Shu-Kai Hsieh, Maurizio Tesconi, Monica
Monachini, Piek Vossen, and Roxanne Segers. 2010.
Semeval-2010 task 17: All-words Word Sense Disam-
biguation on a specific domain. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 75–80.
Carmen Banea and Rada Mihalcea. 2011. Word Sense
Disambiguation with multilingual features. In Pro-
ceedings of the 9th International Conference on Com-
putational Semantics (IWCS 2011), pages 25–34.
Pierpaolo Basile and Giovanni Semeraro. 2010. UBA:
Using automatic translation and Wikipedia for cross-
lingual lexical substitution. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 242–247.
Samuel Brody, Roberto Navigli, and Mirella Lapata.
2006. Ensemble methods for unsupervised WSD.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics
(COLING-ACL-06), pages 97–104.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1991. Word-sense dis-
ambiguation using statistical methods. In Proceed-
ings of the 29th Annual Meeting of the Association for
Computational Linguistics (ACL-91), pages 264–270.
Marine Carpuat and Dekai Wu. 2007. Improving Sta-
tistical Machine Translation using Word Sense Dis-
ambiguation. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Language Learning
(EMNLP-CoNLL-07), pages 61–72.
Yee Seng Chan and Hwee Tou Ng. 2005. Scaling up
Word Sense Disambiguation via parallel texts. In Pro-
ceedings of the 20th National Conference on Artificial
Intelligence (AAAI-05), pages 1037–1042.
Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007.
Word Sense Disambiguation improves Statistical Ma-
1408
chine Translation. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics (ACL-07), pages 33–40.
Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two
languages are more informative than one. In Proceed-
ings of the 29th Annual Meeting of the Association for
Computational Linguistics (ACL-91), pages 130–137.
Gerard de Melo and Gerhard Weikum. 2010. MENTA:
Inducing multilingual taxonomies from Wikipedia. In
Proceedings of the 19th ACM Conference on Informa-
tion and Knowledge Management (CIKM-10), pages
1099–1108.
Mona Diab. 2003. Word Sense Disambiguation within a
Multilingual Framework. Ph.D. thesis, University of
Maryland, College Park, Maryland.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Database. MIT Press, Cambridge, MA.
Radu Florian, Silviu Cucerzan, Charles Schafer, and
David Yarowsky. 2002. Combining classifiers for
Word Sense Disambiguation. Natural Language En-
gineering, 8(4):1–14.
William A. Gale, Kenneth Church, and David Yarowsky.
1992. Using bilingual materials to develop Word
Sense Disambiguation methods. In Proceedings of the
Fourth International Conference on Theoretical and
Methodological Issues in Machine Translation, pages
101–112.
Nancy Ide, Tomaz Erjavec, and Dan Tufis¸. 2002. Sense
discrimination with parallel corpora. In Proceedings
of the ACL-02 Workshop on WSD: Recent Successes
and Future Directions, pages 54–60.
Nancy Ide. 2000. Cross-lingual sense determination:
Can it work? Computers and the Humanities, 34:223–
234.
Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee, and
Pushpak Bhattacharyya. 2011. Together we can:
Bilingual bootstrapping for WSD. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics, (ACL-11), pages 561–569.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of Ma-
chine Translation Summit X.
Anup Kulkarni, Mitesh Khapra, Saurabh Sohoney, and
Pushpak Bhattacharyya. 2010. CFILT: Resource
conscious approaches for all-words domain specific
WSD. In Proceedings of the 5th International Work-
shop on Semantic Evaluations (SemEval-2010), pages
421–426.
Els Lefever and Veronique Hoste. 2010. SemEval-2010
task 3: Cross-lingual Word Sense Disambiguation. In
Proceedings of the 5th International Workshop on Se-
mantic Evaluations (SemEval-2010), pages 15–20.
Els Lefever, Ve´ronique Hoste, and Martine De Cock.
2011. Parasense or how to use parallel corpora for
Word Sense Disambiguation. In Proceedings of the
49th Annual Meeting of the Association for Computa-
tional Linguistics, (ACL-11), pages 317–322.
Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin
K. Tsou. 2011. Joint bilingual sentiment classification
with unlabeled parallel corpora. In Proceedings of the
49th Annual Meeting of the Association for Computa-
tional Linguistics, (ACL-11), pages 320–330.
Bernardo Magnini, Danilo Giampiccolo, and Alessan-
dro Vallin. 2004. The Italian lexical sample task at
Senseval-3. In Proceedings of the 3rd International
Workshop on the Evaluation of Systems for the Seman-
tic Analysis of Text (SENSEVAL-3), pages 17–20.
Lluis Ma`rquez, Mariona Taule´, Antonia Mart?´, Nu´ria
Artigas, Mar Garc?´a, Francis Real, and Dani Ferre´s.
2004. Senseval-3: The Spanish lexical sample task.
In Proceedings of the 3rd International Workshop on
the Evaluation of Systems for the Semantic Analysis of
Text (SENSEVAL-3), pages 21–24.
Diana McCarthy and Roberto Navigli. 2009. The En-
glish lexical substitution task. Language Resources
and Evaluation, 43(2):139–159.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using bilingual parallel corpora for cross-
lingual textual entailment. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics, (ACL-11), pages 1336–1345.
Christian M. Meyer and Iryna Gurevych. 2012.
Ontowiktionary – Constructing an ontology from
the collaborative online dictionary Wiktionary. In
Maria Teresa Pazienza and Armando Stellato, edi-
tors, Semi-Automatic Ontology Development: Pro-
cesses and Resources. IGI Global, Hershey, Penn.
Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010.
Semeval-2010 task 2: Cross-lingual lexical substitu-
tion. In Proceedings of the 5th International Work-
shop on Semantic Evaluations (SemEval-2010), pages
9–14.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross Bunker. 1993. A semantic concordance. In Pro-
ceedings of the 3rd DARPA Workshop on Human Lan-
guage Technology, pages 303–308.
Vivi Nastase, Michael Strube, Benjamin Bo¨rschinger,
Caecilia Zirn, and Anas Elghafari. 2010. WikiNet:
A very large scale multi-lingual concept network. In
Proceedings of the 7th International Conference on
Language Resources and Evaluation, (LREC ’10).
Roberto Navigli and Mirella Lapata. 2010. An exper-
imental study on graph connectivity for unsupervised
Word Sense Disambiguation. IEEE Transactions on
Pattern Anaylsis and Machine Intelligence, 32(4):678–
692.
1409
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belNet: Building a very large multilingual semantic
network. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
(ACL-10), pages 216–225.
Roberto Navigli and Simone Paolo Ponzetto. 2012a. Ba-
belRelate! A joint multilingual approach to computing
semantic relatedness. In Proceedings of the 26th Con-
ference on Artificial Intelligence (AAAI-12).
Roberto Navigli and Simone Paolo Ponzetto. 2012b.
Multilingual WSD with just a few lines of code: The
BabelNet API. In Proceedings of the 50th Annual
Meeting of the Association for Computational Linguis-
tics, (ACL-12). System Demonstrations.
Roberto Navigli, Stefano Faralli, Aitor Soroa, Oier Lopez
de Lacalle, and Eneko Agirre. 2011. Two birds with
one stone: Learning semantic models for Text Cate-
gorization and Word Sense Disambiguation. In Pro-
ceedings of the 20th ACM Conference on Informa-
tion and Knowledge Management (CIKM-11), pages
2317–2320.
Roberto Navigli. 2009. Word Sense Disambiguation: A
survey. ACM Computing Surveys, 41(2):1–69.
Eric W. Noreen, editor. 1989. Computer-intensive meth-
ods for testing hypotheses: an introduction. New
York, N.Y.: John Wiley.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Manabu Okumura, Kiyoaki Shirai, Kanako Komiya, and
Hikaru Yokono. 2010. SemEval-2010 task: Japanese
WSD. In Proceedings of the 5th International Work-
shop on Semantic Evaluations (SemEval-2010), pages
69–74.
Zeynep Orhan, Emine C¸elik, and Demirgu¨c¸ Neslihan.
2007. SemEval-2007 task 12: Turkish lexical sample
task. In Proceedings of the 4th International Work-
shop on Semantic Evaluations (SemEval-2007), pages
59–63.
Martha Palmer, Christiane Fellbaum, Scott Cotton, Lau-
ren Delfs, and Hoa Trang Dang. 2001. English tasks:
All-words and verb lexical sample. In Proceedings of
the 2nd International Workshop on Evaluating Word
Sense Disambiguation Systems (SENSEVAL-2), pages
21–24.
Simone Paolo Ponzetto and Roberto Navigli. 2010.
Knowledge-rich Word Sense Disambiguation rivaling
supervised system. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, (ACL-10), pages 1522–1531.
Siva Reddy, Abhilash Inumella, Diana McCarthy, and
Mark Stevenson. 2010. IIITH: Domain specific
Word Sense Disambiguation. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 387–391.
Philip Resnik and David Yarowsky. 1999. Distinguish-
ing systems and distinguishing senses: new evaluation
methods for Word Sense Disambiguation. Journal of
Natural Language Engineering, 5(2):113–133.
Carina Silberer and Simone Paolo Ponzetto. 2010. UHD:
Cross-lingual Word Sense Disambiguation using mul-
tilingual co-occurrence graphs. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 134–137.
Benjamin Snyder and Martha Palmer. 2004. The English
all-words task. In Proceedings of the 3rd International
Workshop on the Evaluation of Systems for the Seman-
tic Analysis of Text (SENSEVAL-3), pages 41–43.
Maarten van Gompel. 2010. UvT-WSD1: A cross-
lingual word sense disambiguation system. In Pro-
ceedings of the 5th International Workshop on Seman-
tic Evaluations (SemEval-2010), pages 238–241.
Zhi Zhong and Hwee Tou Ng. 2009. Word Sense Dis-
ambiguation for all words without hard labor. In Pro-
ceedings of the 21st International Joint Conference on
Artificial Intelligence (IJCAI-09), pages 1616–1622.
1410
