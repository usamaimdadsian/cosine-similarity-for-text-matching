Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 46–50,
Avignon, France, April 23 - 27 2012. c©2012 Association for Computational Linguistics
A Statistical Spoken Dialogue System using Complex User Goals and
Value Directed Compression
Paul A. Crook, Zhuoran Wang, Xingkun Liu and Oliver Lemon
Interaction Lab
School of Mathematical and Computer Sciences (MACS)
Heriot-Watt University, Edinburgh, UK
{p.a.crook, zhuoran.wang, x.liu, o.lemon}@hw.ac.uk
Abstract
This paper presents the first demonstration
of a statistical spoken dialogue system that
uses automatic belief compression to rea-
son over complex user goal sets. Reasoning
over the power set of possible user goals al-
lows complex sets of user goals to be rep-
resented, which leads to more natural dia-
logues. The use of the power set results in a
massive expansion in the number of belief
states maintained by the Partially Observ-
able Markov Decision Process (POMDP)
spoken dialogue manager. A modified form
of Value Directed Compression (VDC) is
applied to the POMDP belief states produc-
ing a near-lossless compression which re-
duces the number of bases required to rep-
resent the belief distribution.
1 Introduction
One of the main problems for a spoken dialogue
system (SDS) is to determine the user’s goal (e.g.
plan suitable meeting times or find a good Indian
restaurant nearby) under uncertainty, and thereby
to compute the optimal next system dialogue ac-
tion (e.g. offer a restaurant, ask for clarification).
Recent research in statistical SDSs has success-
fully addressed aspects of these problems through
the application of Partially Observable Markov
Decision Process (POMDP) approaches (Thom-
son and Young, 2010; Young et al., 2010). How-
ever POMDP SDSs are currently limited by the
representation of user goals adopted to make sys-
tems computationally tractable.
Work in dialogue system evaluation, e.g.
Walker et al. (2004) and Lemon et al. (2006),
shows that real user goals are generally sets of
items, rather than a single item. People like to
explore possible trade offs between the attributes
of items.
Crook and Lemon (2010) identified this as a
central challenge for the field of spoken dialogue
systems, proposing the use of automatic compres-
sion techniques to allow for extended accurate
representations of user goals. This paper presents
a proof of concept of these ideas in the form of a
complete, working spoken dialogue system. The
POMDP dialogue manager (DM) of this demon-
stration system uses a compressed belief space
that was generated using a modified version of the
Value Directed Compression (VDC) algorithm
as originally proposed by Poupart (2005). This
demonstration system extends work presented by
Crook and Lemon (2011) in that it embeds the
compressed complex user goal belief space into a
working system and demonstrates planning (and
acting) in the compressed space.
2 Complex User Goals
The type of SDS task that we focus on is a limited-
domain query-dialogue, also known as a “slot fill-
ing” task. The spoken dialogue system has knowl-
edge about some set of objects where these ob-
jects have attributes and these attributes can take
several values. An object can thus be described
by a conjunction of attribute-value pairs. A di-
alogue progresses with the system obtaining re-
quirements from the user which are specified in
terms of attribute values. The system should even-
tually present objects (search results) based upon
its understanding of the user’s requirement. The
dialogue ends when the user accepts one of the
domain objects.
Prior work on POMDP SDSs has assumed that
a user has a narrowly constrained goal (as speci-
46
User goal: cheap central Thai or expensive French
S: Hello, how can I help you?
U: I’m looking for a cheap central Thai restaurant.
S: You’re looking for budget, city centre, Thai
restaurants. —
U: Or an expensive French restaurant anywhere.
S: You’re looking for non-budget French restaurants.
What —
U: And cheap, city centre, Thai.
S: You’re looking for budget, city centre, Thai
restaurants. What about —
U: (SIGH) And French.
S: You’re looking for budget, city centre, French
restaurants. What about —
U: (HANG UP)
Table 1: Example dialogue using simple user goals.
S=System, U=User. ‘—’ indicates the user barged in.
fied in terms of the domain objects) and thus the
role of the DM is one of reducing uncertainty un-
til its belief is strongly focused on a particular do-
main object. This has the unfortunate effect of
forcing users to select one domain object in order
to progress the dialogue, see Table 1. Note that the
example given is problematic not only because the
user wants two different food types but because
they have different requirements associated with
each, i.e. Thai restaurants should be in the centre
and cheap, while any French restaurants should be
expensive1 and can be located anywhere. To our
knowledge such a combination of goals with dif-
ferent attribute values cannot be straightforwardly
handled by comparable state-of-the-art statistical
SDSs which appear in the literature.
Crook and Lemon (2011) suggest that rather
than the DM assuming that the user has a single
narrowly constrained goal in mind, it should as-
sume that they want any possible sub-set of the
complete set of domain objects. Thus, instead
of maintaining the POMDP belief over individual
domain objects, it should be maintained over the
power set of domain objects. As an example see
Table 3 which is the power set for a domain with
three objects that can take two attributes u, v with
associated values u1, u2, u3 and v1 respectively.
The power set representation allows the
demonstration system to straightforwardly handle
previously problematic dialogues. See Table 2.
Of course this approach significantly expands the
1Interpreted as non-budget by the system since its
database only classifies restaurants as budget or non-budget.
User goal: cheap central Thai or expensive French
S: Hello, how can I help you?
U: I’m looking for a cheap central Thai restaurant.
S: You’re looking for budget, city centre, Thai
restaurants. —
U: Or an expensive French restaurant anywhere.
S: You’re looking for budget, city centre, Thai
restaurants or non-budget French. What about
Chang Thai in Old Town†? Chang Thai’s set lunch
price is £ 7.95 —
U: What alternatives do you have?
S: What about the Plumed Horse in Leith‡? The
Plumed Horse is a Michelin starred French ...
Table 2: Example dialogue using complex user goals.
S=System, U=User. †Old Town is part of the city cen-
tre. ‡Leith is outside the centre.
state space of possible user goals, with the num-
ber of goal sets being equal to 2|domain objects| .
2.1 Automatic Compression
Even considering limited domains, POMDP state
spaces for SDSs grow very quickly. Thus the cur-
rent state-of-the-art in POMDP SDSs uses a vari-
ety of handcrafted compression techniques, such
as making several types of independence assump-
tion as discussed above.
Crook and Lemon (2010) propose replacing
handcrafted compressions with automatic com-
pression techniques. The idea is to use princi-
pled statistical methods for automatically reduc-
ing the dimensionality of belief spaces, but which
preserve useful distributions from the full space,
and thus can more accurately represent real user’s
goals.
2.2 VDC Algorithm
The VDC algorithm (Poupart, 2005) uses Krylov
iteration to compute a reduced state space. It finds
a set of linear basis vectors that can reproduce the
value2 of being in any of the original POMDP
states. Where, if a lossless VDC compression is
possible, the number of basis vectors is less than
the original number of POMDP states.
The intuition here is that if the value of taking
an action in a given state has been preserved then
planning is equally as reliable in the compressed
space as the in full space.
The VDC algorithm requires a fully specified
POMDP, i.e. ?S,A,O, T,?,R? where S is the set
2The sum of discounted future rewards obtained through
following some series of actions.
47
state goal set meaning: user’s goal is
s1 ? (empty set) none of the domain objects
s2 u=u1?v=v1 domain object 1
s3 u=u2?v=v1 domain object 2
s4 u=u3?v=v1 domain object 3
s5 (u=u1?v=v1) ? (u=u2?v=v1) domain objects 1 or 2
s6 (u=u1?v=v1) ? (u=u3?v=v1) domain objects 1 or 3
s7 (u=u2?v=v1) ? (u=u3?v=v1) domain objects 2 or 3
s8 (u=u1?v=v1) ? (u=u2?v=v1) ? (u=u3?v=v1) any of the domain objects
Table 3: Example of complex user goal sets.
of states, A is the set of actions, O is the set of ob-
servations, T conditional transition probabilities,
? conditional observation probabilities, and R is
the reward function. Since it iteratively projects
the rewards associated with each state and action
using the state transition and observation proba-
bilities, the compression found is dependent on
structures and regularities in the POMDP model.
The set of basis vectors found can be used to
project the POMDP reward, transition, and obser-
vation probabilities into the reduced state space
allowing the policy to be learnt and executed in
this state space.
Although the VDC algorithm (Poupart, 2005)
produces compressions that are lossless in terms
of the states’ values, the set of basis vectors found
(when viewed as a transformation matrix) can be
ill-conditioned. This results in numerical instabil-
ity and errors in the belief estimation. The com-
pression used in this demonstration was produced
using a modified VDC algorithm that improves
the matrix condition by approximately selecting
the most independent basis vectors, thus improv-
ing numerical stability. It achieves near-lossless
state value compression while allowing belief es-
timation errors to be minimised and traded-off
against the amount of compression. Details of this
algorithm are to appear in a forthcoming publica-
tion.
3 System Description
3.1 Components
Input and output to the demonstration system is
using standard open source and commercial com-
ponents. FreeSWITCH (Minessale II, 2012) pro-
vides a platform for accepting incoming Voice
over IP calls, routing them (using the Media Re-
source Control Protocol (MRCP)) to a Nuance 9.0
Automatic Speech Recogniser (Nuance, 2012).
Output is similarly handled by FreeSWITCH
routing system responses via a CereProc Text-to-
Speech MRCP server (CereProc, 2012) in order
to respond to the user.
The heart of the demonstration system consists
of a State-Estimator server which estimates the
current dialogue state using the compressed state
space previously produced by VDC, a Policy-
Executor server that selects actions based on
the compressed estimated state, and a template
based Natural Language Generator server. These
servers, along with FreeSWITCH, use ZeroC’s
Internet Communications Engine (Ice) middle-
ware (ZeroC, 2012) as a common communica-
tions platform.
3.2 SDS Domain
The demonstration system provides a restaurant
finder system for the city of Edinburgh (Scot-
land, UK). It presents search results from a real
database of over 600 restaurants. The search
results are based on the attributes specified by
the user, currently; location, food type and
budget/non-budget.
3.3 Interface
The demonstration SDS is typically accessed over
the phone network. For debugging and demon-
stration purposes it is possible to visualise the
belief distribution maintained by the DM as dia-
logues progress. The compressed version of the
belief distribution is not a conventional proba-
bility distribution3 and its visualisation is unin-
formative. Instead we take advantage of the re-
versibility of the VDC compression and project
the distribution back onto the full state space. For
an example of the evolution of the belief distribu-
tion during a dialogue see Figure 1.
3The values associated with the basis vectors are not con-
fined to the range [0? 1].
48
#4096
10?7 10?6 10?5 0.0001 0.001
(a) Initial uniform distribution over the power set.
#2048
#2048
10?7 10?6 10?5 0.0001 0.001
(b) Distribution after user responds to greet.
#512
#3584
10?11 10?9 10?7 10?5 0.001
(c) Distribution after second user utterance.
Figure 1: Evolution of the belief distribution for the
example dialogue in Table 2. The horizontal length of
each bar corresponds to the probability of that com-
plex user goal state. Note that the x-axis uses a log-
arithmic scale to allow low probability values to be
seen. The y-axis is the set of complex user goals or-
dered by probability. Lighter shaded (green) bars indi-
cate complex user goal states corresponding to “cheap,
central Thai” and “cheap, central Thai or expensive
French anywhere” in figures (b) and (c) respectively.
The count ‘#’ indicates the number of states in those
groups.
4 Conclusions
We present a demonstration of a statistical SDS
that uses automatic belief compression to reason
over complex user goal sets. Using the power set
of domain objects as the states of the POMDP
DM allows complex sets of user goals to be rep-
resented, which leads to more natural dialogues.
To address the massive expansion in the number
of belief states, a modified form of VDC is used
to generate a compression. It is this compressed
space which is used by the DM for planning and
acting in response to user utterances. This is the
first demonstration of a statistical SDS that uses
automatic belief compression to reason over com-
plex user goal sets.
VDC and other automated compression tech-
niques reduce the human design load by automat-
ing part of the current POMDP SDS design pro-
cess. This reduces the knowledge required when
building such statistical systems and should make
them easier for industry to deploy.
Such compression approaches are not only ap-
plicable to SDSs but should be equally relevant
for multi-modal interaction systems where sev-
eral modalities are being combined in user-goal
or state estimation.
5 Future Work
The current demonstration system is a proof
of concept and is limited to a small number
of attributes and attribute-values. Part of our
ongoing work involves investigation of scaling.
For example, increasing the number of attribute-
values should produce more regularities across
the POMDP space. Does VDC successfully ex-
ploit these?
We are in the process of collecting corpora
for the Edinburgh restaurant domain mentioned
above with the aim that the POMDP observation
and transition statistics can be derived from data.
As part of this work we have launched a long
term, public facing outlet for testing and data col-
lection, see http:\\www.edinburghinfo.
co.uk. It is planned to make future versions of
the demonstration system discussed in this paper
available via this public outlet.
Finally we are investigating the applicability
of other automatic belief (and state) compression
techniques for SDSs, e.g. E-PCA (Roy and Gor-
don, 2002).
49
Acknowledgments
The research leading to these results was funded
by the Engineering and Physical Sciences Re-
search Council, UK (EPSRC) under project no.
EP/G069840/1 and was partially supported by the
EC FP7 projects Spacebook (ref. 270019) and
JAMES (ref. 270435).
References
CereProc. 2012. http://www.cereproc.com/.
Paul A. Crook and Oliver Lemon. 2010. Representing
uncertainty about complex user goals in statistical
dialogue systems. In proceedings of SIGdial.
Paul A. Crook and Oliver Lemon. 2011. Lossless
Value Directed Compression of Complex User Goal
States for Statistical Spoken Dialogue Systems. In
Proceedings of the Twelfth Annual Conference of
the International Speech Communication Associa-
tion (Interspeech).
Oliver Lemon, Kallirroi Georgila, and James Hender-
son. 2006. Evaluating Effectiveness and Portabil-
ity of Reinforcement Learned Dialogue Strategies
with real users: the TALK TownInfo Evaluation. In
IEEE/ACL Spoken Language Technology.
Anthony Minessale II. 2012. FreeSWITCH. http:
//www.freeswitch.org/.
Nuance. 2012. Nuance Recognizer. http://www.
nuance.com.
P. Poupart. 2005. Exploiting Structure to Efficiently
Solve Large Scale Partially Observable Markov De-
cision Processes. Ph.D. thesis, Dept. Computer Sci-
ence, University of Toronto.
N. Roy and G. Gordon. 2002. Exponential Family
PCA for Belief Compression in POMDPs. In NIPS.
B. Thomson and S. Young. 2010. Bayesian update
of dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562–588.
Marilyn Walker, S. Whittaker, A. Stent, P. Maloor,
J. Moore, M. Johnston, and G. Vasireddy. 2004.
User tailored generation in the match multimodal
dialogue system. Cognitive Science, 28:811–840.
S. Young, M. Gas?ic´, S. Keizer, F. Mairesse, B. Thom-
son, and K. Yu. 2010. The Hidden Information
State model: a practical framework for POMDP
based spoken dialogue management. Computer
Speech and Language, 24(2):150–174.
ZeroC. 2012. The Internet Communications Engine
(Ice). http://www.zeroc.com/ice.html.
50
