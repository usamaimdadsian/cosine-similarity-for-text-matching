Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 196–205,
Honolulu, October 2008. c©2008 Association for Computational Linguistics
Syntactic Constraints on Paraphrases Extracted from Parallel Corpora
Chris Callison-Burch
Center for Language and Speech Processing
Johns Hopkins University
Baltimore, Maryland
ccb cs jhu edu
Abstract
We improve the quality of paraphrases ex-
tracted from parallel corpora by requiring that
phrases and their paraphrases be the same syn-
tactic type. This is achieved by parsing the En-
glish side of a parallel corpus and altering the
phrase extraction algorithm to extract phrase
labels alongside bilingual phrase pairs. In or-
der to retain broad coverage of non-constituent
phrases, complex syntactic labels are intro-
duced. A manual evaluation indicates a 19%
absolute improvement in paraphrase quality
over the baseline method.
1 Introduction
Paraphrases are alternative ways of expressing the
same information. Being able to identify or gen-
erate paraphrases automatically is useful in a wide
range of natural language applications. Recent work
has shown how paraphrases can improve question
answering through query expansion (Riezler et al.,
2007), automatic evaluation of translation and sum-
marization by modeling alternative lexicalization
(Kauchak and Barzilay, 2006; Zhou et al., 2006;
Owczarzak et al., 2006), and machine translation
both by dealing with out of vocabulary words and
phrases (Callison-Burch et al., 2006) and by expand-
ing the set of reference translations for minimum er-
ror rate training (Madnani et al., 2007). While all ap-
plications require the preservation of meaning when
a phrase is replaced by its paraphrase, some addi-
tionally require the resulting sentence to be gram-
matical.
In this paper we examine the effectiveness of
placing syntactic constraints on a commonly used
paraphrasing technique that extracts paraphrases
from parallel corpora (Bannard and Callison-Burch,
2005). The paraphrasing technique employs various
aspects of phrase-based statistical machine transla-
tion including phrase extraction heuristics to obtain
bilingual phrase pairs from word alignments. En-
glish phrases are considered to be potential para-
phrases of each other if they share a common for-
eign language phrase among their translations. Mul-
tiple paraphrases are frequently extracted for each
phrase and can be ranked using a paraphrase proba-
bility based on phrase translation probabilities.
We find that the quality of the paraphrases that
are generated in this fashion improves significantly
when they are required to be the same syntactic type
as the phrase that they are paraphrasing. This con-
straint:
• Eliminates a trivial but pervasive error that
arises from the interaction of unaligned words
with phrase extraction heuristics.
• Refines the results for phrases that can take on
different syntactic labels.
• Applies both to phrases which are linguistically
coherent and to arbitrary sequences of words.
• Results in much more grammatical output
when phrases are replaced with their para-
phrases.
A thorough manual evaluation of the refined para-
phrasing technique finds a 19% absolute improve-
196
ment in the number of paraphrases that are judged
to be correct.
This paper is structured as follows: Section 2
describes related work in syntactic constraints on
phrase-based SMT and work utilizing syntax in
paraphrase discovery. Section 3 details the prob-
lems with extracting paraphrases from parallel cor-
pora and our improvements to the technique. Sec-
tion 4 describes our experimental design and evalu-
ation methodology. Section 5 gives the results of our
experiments, and Section 6 discusses their implica-
tions.
2 Related work
A number of research efforts have focused on em-
ploying syntactic constraints in statistical machine
translation. Wu (1997) introduced the inversion
transduction grammar formalism which treats trans-
lation as a process of parallel parsing of the source
and target language via a synchronized grammar.
The synchronized grammar places constraints on
which words can be aligned across bilingual sen-
tence pairs. To achieve computational efficiency, the
original proposal used only a single non-terminal la-
bel rather than a linguistic grammar.
Subsequent work used more articulated parses
to improve alignment quality by applying cohesion
constraints (Fox, 2002; Lin and Cherry, 2002). If
two English phrases are in disjoint subtrees in the
parse, then the phrasal cohesion constraint prevents
them from being aligned to overlapping sequences
in the foreign sentence. Other recent work has incor-
porated constituent and dependency subtrees into the
translation rules used by phrase-based systems (Gal-
ley et al., 2004; Quirk et al., 2005). Phrase-based
rules have also been replaced with synchronous con-
text free grammars (Chiang, 2005) and with tree
fragments (Huang and Knight, 2006).
A number of techniques for generating para-
phrases have employed syntactic information, either
in the process of extracting paraphrases from mono-
lingual texts or in the extracted patterns themselves.
Lin and Pantel (2001) derived paraphrases based
on the distributional similarity of paths in depen-
dency trees. Barzilay and McKeown (2001) incor-
porated part-of-speech information and other mor-
phosyntactic clues into their co-training algorithm.
They extracted paraphrase patterns that incorporate
this information. Ibrahim et al. (2003) generated
structural paraphrases capable of capturing long-
distance dependencies. Pang et al. (2003) employed
a syntax-based algorithm to align equivalent English
sentences by merging corresponding nodes in parse
trees and compressing them down into a word lat-
tice.
Perhaps the most closely related work is a recent
extension to Bannard and Callison-Burch’s para-
phrasing method. Zhao et al. (2008b) extended the
method so that it is capable of generating richer
paraphrase patterns that include part-of-speech slots,
rather than simple lexical and phrasal paraphrases.
For example, they extracted patterns such as con-
sider NN ? take NN into consideration. To ac-
complish this, Zhao el al. used dependency parses
on the English side of the parallel corpus. Their
work differs from the work presented in this paper
because their syntactic constraints applied to slots
within paraphrase patters, and our constraints apply
to the paraphrases themselves.
3 Paraphrasing with parallel corpora
Bannard and Callison-Burch (2005) extract para-
phrases from bilingual parallel corpora. They give
a probabilistic formation of paraphrasing which nat-
urally falls out of the fact that they use techniques
from phrase-based statistical machine translation:
eˆ2 = argmax
e2:e2 6=e1
p(e2|e1) (1)
where
p(e2|e1) =
?
f
p(f |e1)p(e2|f, e1) (2)
?
?
f
p(f |e1)p(e2|f) (3)
Phrase translation probabilities p(f |e1) and p(e2|f)
are commonly calculated using maximum likelihood
estimation (Koehn et al., 2003):
p(f |e) =
count(e, f)
?
f count(e, f)
(4)
where the counts are collected by enumerating all
bilingual phrase pairs that are consistent with the
197
conseguido
.opportunitiesequalcreatetofailedhasprojecteuropeanthe
oportunidadesdeigualdadlahanoeuropeoproyectoel
Figure 1: The interaction of the phrase extraction heuristic with unaligned English words means that the Spanish
phrase la igualdad aligns with equal, create equal, and to create equal.
word alignments for sentence pairs in a bilingual
parallel corpus. Various phrase extraction heuristics
are possible. Och and Ney (2004) defined consistent
bilingual phrase pairs as follows:
BP (fJ1 , e
I
1, A) = {(f
j+m
j , e
i+n
i ) :
?(i?, j?) ? A : j ? j? ? j +m? i ? i? ? i+ n
??(i?, j?) ? A : j ? j? ? j +m? ? i ? i? ? i+ n}
where fJ1 is a foreign sentence, e
I
1 is an English sen-
tence and A is a set of word alignment points.
The heuristic allows unaligned words to be in-
cluded at the boundaries of the source or target lan-
guage phrases. For example, when enumerating the
consistent phrase pairs for the sentence pair given in
Figure 1, la igualdad would align not only to equal,
but also to create equal, and to create equal. In SMT
these alternative translations are ranked by the trans-
lation probabilities and other feature functions dur-
ing decoding.
The interaction between the phrase extraction
heuristic and unaligned words results in an unde-
sirable effect for paraphrasing. By Bannard and
Callison-Burch’s definition, equal, create equal, and
to create equal would be considered paraphrases be-
cause they are aligned to the same foreign phrase.
Tables 1 and 2 show how sub- and super-phrases can
creep into the paraphrases: equal can be paraphrased
as equal rights and create equal can be paraphrased
as equal. Obviously when e2 is substituted for e1 the
resulting sentence will generally be ungrammatical.
The first case could result in equal equal rights, and
the second would drop the verb.
This problem is pervasive. To test its extent we at-
tempted to generate paraphrases for 900,000 phrases
using Bannard and Callison-Burch’s method trained
on the Europarl corpora (as described in Section 4).
It generated a total of 3.7 million paraphrases for
equal
equal .35 equally .02
same .07 the .02
equality .03 fair .01
equals .02 equal rights .01
Table 1: The baseline method’s paraphrases of equal and
their probabilities (excluding items with p < .01).
create equal
create equal .42 same .03
equal .06 created .02
to create a .05 conditions .02
create .04 playing .02
to create equality .03 creating .01
Table 2: The baseline’s paraphrases of create equal. Most
are clearly bad, and the most probable e2 6= e1 is a sub-
string of e1.
400,000 phrases in the list.1 We observed that 34%
of the paraphrases (excluding the phrase itself) were
super- or sub-strings of the original phrase. The
most probable paraphrase was a super- or sub-string
of the phrase 73% of the time.
There are a number of strategies that might be
adopted to alleviate this problem:
• Bannard and Callison-Burch (2005) rank their
paraphrases with a language model when the
paraphrases are substituted into a sentence.
• Bannard and Callison-Burch (2005) sum over
multiple parallel corpora C to reduce the prob-
lems associated with systematic errors in the
1The remaining 500,000 phrases could not be paraphrased
either because e2 6= e1 or because they were not consistently
aligned to any foreign phrases.
198
word alignments in one language pair:
eˆ2 = argmax
e2
?
c?C
?
f
p(f |e1)p(e2|f) (5)
• We could change the phrase extraction heuris-
tic’s treatment of unaligned words, or we could
attempt to ensure that we have fewer unaligned
items in our word alignments.
• The paraphrase criterion could be changed
from being e2 6= e1 to specifying that e2 is not
sub- or super-string of e1.
In this paper we adopt a different strategy. The
essence of our strategy is to constrain paraphrases
to be the same syntactic type as the phrases that they
are paraphrasing. Syntactic constraints can apply in
two places: during phrase extraction and when sub-
stituting paraphrases into sentences. These are de-
scribed in sections 3.1 and 3.2.
3.1 Syntactic constraints on phrase extraction
When we apply syntactic constraints to the phrase
extraction heuristic, we change how bilingual phrase
pairs are enumerated and how the component proba-
bilities of the paraphrase probability are calculated.
We use the syntactic type s of e1 in a refined ver-
sion of the paraphrase probability:
eˆ2 = argmax
e2:e2 6=e1?s(e2)=s(e1)
p(e2|e1, s(e1)) (6)
where p(e2|e1, s(e1)) can be approximated as:
?
c?C
?
f p(f |e1, s(e1))p(e2|f, s(e1))
|C|
(7)
We define a new phrase extraction algorithm that op-
erates on an English parse tree P along with foreign
sentence fJ1 , English sentence e
I
1, and word align-
ment A. We dub this SBP for syntactic bilingual
phrases:
SBP (fJ1 , e
I
1, A, P ) = {(f
j+m
j , e
i+n
i , s(e
i+n
i )) :
?(i?, j?) ? A : j ? j? ? j +m? i ? i? ? i+ n
??(i?, j?) ? A : j ? j? ? j +m? ? i ? i? ? i+ n
?? subtree ? P with label s spanning words (i, i+ n)}
equal
JJ equal .60 similar .02
same .14 equivalent .01
fair .02
ADJP equal .79 the same .01
necessary .02 equal in law .01
similar .02 equivalent .01
identical .02
Table 3: Syntactically constrained paraphrases for equal
when it is labeled as an adjective or adjectival phrase.
The SBP phrase extraction algorithm produces tu-
ples containing a foreign phrase, an English phrase
and a syntactic label (f, e, s). After enumerating
these for all phrase pairs in a parallel corpus, we can
calculate p(f |e1, s(e1)) and p(e2|f, s(e1)) as:
p(f |e1, s(e1)) =
count(f, e1, s(e1))
?
f count(f, e1, s(e1))
p(e2|f, s(e1)) =
count(f, e2, s(e1))
?
e2 count(f, e2, s(e1))
By redefining the probabilities in this way we parti-
tion the space of possible paraphrases by their syn-
tactic categories.
In order to enumerate all phrase pairs with their
syntactic labels we need to parse the English side of
the parallel corpus (but not the foreign side). This
limits the potential applicability of our refined para-
phrasing method to languages which have parsers.
Table 3 gives an example of the refined para-
phrases for equal when it occurs as an adjective or
adjectival phrase. Note that most of the paraphrases
that were possible under the baseline model (Table
1) are now excluded. We no longer get the noun
equality, the verb equals, the adverb equally, the de-
termier the or the NP equal rights. The paraphrases
seem to be higher quality, especially if one considers
their fidelity when they replace the original phrase in
the context of some sentence.
We tested the rate of paraphrases that were sub-
and super-strings when we constrain paraphrases
based on non-terminal nodes in parse trees. The
percent of the best paraphrases being substrings
dropped from 73% to 24%, and the overall percent
of paraphrases subsuming or being subsumed by the
original phrase dropped from 34% to 12%. How-
ever, the number of phrases for which we were able
199
SBARQ
WHADVP
WRB
How
SQ
VBP
do
NP
PRP
we
VP
VB
create
NP
JJ
equal
NNS
rights
.
?
Figure 2: In addition to extracting phrases that are domi-
nated by a node in the parse tree, we also generate labels
for non-syntactic constituents. Three labels are possible
for create equal.
to generated paraphrases dropped from 400,000 to
90,000, since we limited ourselves to phrases that
were valid syntactic constituents. The number of
unique paraphrases dropped from several million to
800,000.
The fact that we are able to produce paraphrases
for a much smaller set of phrases is a downside to
using syntactic constraints as we have initially pro-
posed. It means that we would not be able to gen-
erate paraphrases for phrases such as create equal.
Many NLP tasks, such as SMT, which could benefit
from paraphrases require broad coverage and may
need to paraphrases for phrases which are not syn-
tactic constituents.
Complex syntactic labels
To generate paraphrases for a wider set of phrases,
we change our phrase extraction heuristic again so
that it produces phrase pairs for arbitrary spans in
the sentence, including spans that aren’t syntactic
constituents. We assign every span in a sentence a
syntactic label using CCG-style notation (Steedman,
1999), which gives a syntactic role with elements
missing on the left and/or right hand sides.
SBP (fJ1 , e
I
1, A, P ) = {(f
j+m
j , e
i+n
i , s) :
?(i?, j?) ? A : j ? j? ? j +m? i ? i? ? i+ n
??(i?, j?) ? A : j ? j? ? j +m? ? i ? i? ? i+ n
??s ? CCG-labels(ei+ni , P )}
The function CCG-labels describes the set of CCG-
labels for the phrase spanning positions i to i+ n in
create equal
VP/(NP/NNS) create equal .92
creating equal .08
VP/(NP/NNS) PP create equal .96
promote equal .03
establish fair .01
VP/(NP/NNS) PP PP create equal .80
creating equal .10
provide equal .06
create genuinely fair .04
VP/(NP/(NP/NN) PP) create equal .83
create a level playing .17
VP/(NP/(NP/NNS) PP) create equal .83
creating equal .17
Table 4: Paraphrases and syntactic labels for the non-
constituent phrase create equal.
a parse tree P . It generates three complex syntactic
labels for the non-syntactic constituent phrase create
equal in the parse tree given in Figure 2:
1. VP/(NP/NNS) – This label corresponds to the in-
nermost circle. It indicates that create equal is
a verb phrase missing a noun phrase to its right.
That noun phrase in turn missing a plural noun
(NNS) to its right.
2. SQ\VBP NP/(VP/(NP/NNS)) – This label corre-
sponds to the middle circle. It indicates that
create equal is an SQ missing a VBP and a NP
to its left, and the complex VP to its right.
3. SBARQ\WHADVP (SQ\VBP NP/(VP/(NP/NNS)))/. –
This label corresponds to the outermost cir-
cle. It indicates that create equal is an SBARQ
missing a WHADVP and the complex SQ to its
left, and a punctuation mark to its right.
We can use these complex labels instead of atomic
non-terminal symbols to handle non-constituent
phrases. For example, Table 4 shows the para-
phrases and syntactic labels that are generated for
the non-constituent phrase create equal. The para-
phrases are significantly better than the paraphrases
generated for the phrase by the baseline method (re-
fer back to Table 2).
The labels shown in the figure are a fraction of
those that can be derived for the phrase in the paral-
lel corpus. Each of these corresponds to a different
200
syntactic context, and each has its own set of associ-
ated paraphrases.
We increase the number of phrases that are para-
phrasable from the 90,000 in our initial definition
of SBP to 250,000 when we use complex CCG la-
bels. The number of unique paraphrases increases
from 800,000 to 3.5 million, which is nearly as
many paraphrases that were produced by the base-
line method for the sample.
3.2 Syntactic constraints when substituting
paraphrases into a test sentence
In addition to applying syntactic constraints to our
phrase extraction algorithm, we can also apply them
when we substitute a paraphrase into a sentence. To
do so, we limit the paraphrases to be the same syn-
tactic type as the phrase that it is replacing, based on
the syntactic labels that are derived from the phrase
tree for a test sentence. Since each phrase normally
has a set of different CCG labels (instead of a sin-
gle non-termal symbol) we need a way of choosing
which label to use when applying the constraint.
There are several different possibilities for choos-
ing among labels. We could simultaneously choose
the best paraphrase and the best label for the phrase
in the parse tree of the test sentence:
eˆ2 = argmax
e2:e2 6=e1
argmax
s?CCG-labels(e1,P )
p(e2|e1, s) (8)
Alternately, we could average over all of the labels
that are generated for the phrase in the parse tree:
eˆ2 = argmax
e2:e2 6=e1
?
s?CCG-labels(e1,P )
p(e2|e1, s) (9)
The potential drawback of using Equations 8 and
9 is that the CCG labels for a particular sentence sig-
nificantly reduces the paraphrases that can be used.
For instance, VP/(NP/NNS) is the only label for the
paraphrases in Table 4 that is compatible with the
parse tree given in Figure 2.
Because the CCG labels for a given sentence are
so specific, many times there are no matches. There-
fore we also investigated a looser constraint. We
choose the highest probability paraphrase with any
label (i.e. the set of labels extracted from all parse
trees in our parallel corpus):
eˆ2 = argmax
e2:e2 6=e1
argmax
s???T in CCCG-labels(e1,T )
p(e2|e1, s) (10)
Equation 10 only applies syntactic constraints dur-
ing phrase extraction and ignores them during sub-
stitution.
In our experiments, we evaluate the quality of the
paraphrases that are generated using Equations 8, 9
and 10. We compare their quality against the Ban-
nard and Callison-Burch (2005) baseline.
4 Experimental design
We conducted a manual evaluation to evaluate para-
phrase quality. We evaluated whether paraphrases
retained the meaning of their original phrases and
whether they remained grammatical when they re-
placed the original phrase in a sentence.
4.1 Training materials
Our paraphrase model was trained using the Eu-
roparl corpus (Koehn, 2005). We used ten par-
allel corpora between English and (each of) Dan-
ish, Dutch, Finnish, French, German, Greek, Ital-
ian, Portuguese, Spanish, and Swedish, with approx-
imately 30 million words per language for a total of
315 million English words. Automatic word align-
ments were created for these using Giza++ (Och and
Ney, 2003). The English side of each parallel corpus
was parsed using the Bikel parser (Bikel, 2002). A
total of 1.6 million unique sentences were parsed.
A trigram language model was trained on these En-
glish sentences using the SRI language modeling
toolkit (Stolcke, 2002).
The paraphrase model and language model for the
Bannard and Callison-Burch (2005) baseline were
trained on the same data to ensure a fair comparison.
4.2 Test phrases
The test set was the English portion of test sets
used in the shared translation task of the ACL-
2007 Workshop on Statistical Machine Translation
(Callison-Burch et al., 2007). The test sentences
were also parsed with the Bikel parser.
The phrases to be evaluated were selected such
that there was an even balance of phrase lengths
(from one word long up to five words long), with
half of the phrases being valid syntactic constituents
and half being arbitrary sequences of words. 410
phrases were selected at random for evaluation. 30
items were excluded from our results subsequent
to evaluation on the grounds that they consisted
201
solely of punctuation and stop words like determin-
ers, prepositions and pronouns. This left a total of
380 unique phrases.
4.3 Experimental conditions
We produced paraphrases under the following eight
conditions:
1. Baseline – The paraphrase probability defined
by Bannard and Callison-Burch (2005). Calcu-
lated over multiple parallel corpora as given in
Equation 5. Note that under this condition the
best paraphrase is the same for each occurrence
of the phrase irrespective of which sentence it
occurs in.
2. Baseline + LM – The paraphrase probability
(as above) combined with the language model
probability calculated for the sentence with the
phrase replaced with the paraphrase.
3. Extraction Constraints – This condition se-
lected the best paraphrase according to Equa-
tion 10. It chooses the single best paraphrase
over all labels. Conditions 3 and 5 only apply
the syntactic constraints at the phrase extraction
stage, and do not require that the paraphrase
have the same syntactic label as the phrase in
the sentence that it is being subtituted into.
4. Extraction Constraints + LM – As above, but
the paraphrases are also ranked with a language
model probability.
5. Substitution Constraints – This condition
corresponds to Equation 8, which selects the
highest probability paraphrase which matches
at least one of the syntactic labels of the phrase
in the test sentence. Conditions 5–8 apply the
syntactic constraints both and the phrase ex-
traction and at the substitution stages.
6. Syntactic Constraints + LM – As above, but
including a language model probability as well.
7. Averaged Substitution Constraints – This
condition corresponds to Equation 9, which av-
erages over all of the syntactic labels for the
phrase in the sentence, instead of choosing the
single one which maximizes the probability.
MEANING
5 All of the meaning of the original phrase is re-
tained, and nothing is added
4 The meaning of the original phrase is retained, al-
though some additional information may be added
but does not transform the meaning
3 The meaning of the original phrase is retained, al-
though some information may be deleted without
too great a loss in the meaning
2 Substantial amount of the meaning is different
1 The paraphrase doesn’t mean anything close to
the original phrase
GRAMMAR
5 The sentence with the paraphrase inserted is per-
fectly grammatical
4 The sentence is grammatical, but might sound
slightly awkward
3 The sentence has an agreement error (such as be-
tween its subject and verb, or between a plural
noun and singular determiner)
2 The sentence has multiple errors or omits words
that would be required to make it grammatical
1 The sentence is totally ungrammatical
Table 5: Annotators rated paraphrases along two 5-point
scales.
8. Averaged Substitution Constraints + LM –
As above, but including a language model
probability.
4.4 Manual evaluation
We evaluated the paraphrase quality through a sub-
stitution test. We retrieved a number of sentences
which contained each test phrase and substituted the
phrase with automatically-generated paraphrases.
Annotators judged whether the paraphrases had the
same meaning as the original and whether the re-
sulting sentences were grammatical. They assigned
two values to each sentence using the 5-point scales
given in Table 5. We considered an item to have
the same meaning if it was assigned a score of 3 or
greater, and to be grammatical if it was assigned a
score of 4 or 5.
We evaluated several instances of a phrase when
it occurred multiple times in the test corpus,
since paraphrase quality can vary based on context
(Szpektor et al., 2007). There were an average of
3.1 instances for each phrase, with a maximum of
6. There were a total of 1,195 sentences that para-
202
phrases were substituted into, with a total of 8,422
judgements collected. Note that 7 different para-
phrases were judged on average for every instance.
This is because annotators judged paraphrases for
eight conditions, and because we collected judg-
ments for the 5-best paraphrases for many of the
conditions.
We measured inter-annotator agreement with the
Kappa statistic (Carletta, 1996) using the 1,391
items that two annotators scored in common. The
two annotators assigned the same absolute score
47% of the time. If we consider chance agreement to
be 20% for 5-point scales, then K = 0.33, which is
commonly interpreted as “fair” (Landis and Koch,
1977). If we instead measure agreement in terms
of how often the annotators both judged an item to
be above or below the thresholds that we set, then
their rate of agreement was 80%. In this case chance
agreement would be 50%, so K = 0.61, which is
“substantial”.
4.5 Data and code
In order to allow other researchers to recreate our re-
sults or extend our work, we have prepared the fol-
lowing materials for download2:
• The complete set of paraphrases generated for
the test set. This includes the 3.7 million para-
phrases generated by the baseline method and
the 3.5 million paraphrases generated with syn-
tactic constraints.
• The code that we used to produce these para-
phrases and the complete data sets (including
all 10 word-aligned parallel corpora along with
their English parses), so that researchers can
extract paraphrases for new sets of phrases.
• The manual judgments about paraphrase qual-
ity. These may be useful as development ma-
terial for setting the weights of a log-linear for-
mulation of paraphrasing, as suggested in Zhao
et al. (2008a).
5 Results
Table 6 summarizes the results of the manual eval-
uation. We can observe a strong trend in the syn-
tactically constrained approaches performing better
2Available from http://cs.jhu.edu/˜ccb/.
correct correct both
meaning grammar correct
Baseline .56 .35 .30
Baseline+LM .46 .44 .36
Extraction Constraints .62 .57 .46
Extraction Const+LM .60 .65 .50
Substitution Constraints .60 .60 .50
Substitution Const+LM .61 .68 .54
Avg Substitution Const .62 .61 .51
Avg Substit Const+LM .61 .68 .55
Table 6: The results of the manual evaluation for each
of the eight conditions. Correct meaning is the percent of
time that a condition was assigned a 3, 4, or 5, and correct
grammar is the percent of time that it was given a 4 or 5,
using the scales from Table 5.
than the baseline. They retain the correct meaning
more often (ranging from 4% to up to 15%). They
are judged to be grammatical far more frequently
(up to 26% more often without the language model,
and 24% with the language model) . They perform
nearly 20% better when both meaning and grammat-
icality are used as criteria.3
Another trend that can be observed is that incor-
porating a language model probability tends to result
in more grammatical output (a 7–9% increase), but
meaning suffers as a result in some cases. When
the LM is applied there is a drop of 12% in correct
meaning for the baseline, but only a slight dip of 1-
2% for the syntactically-constrained phrases.
Note that for the conditions where the paraphrases
were required to have the same syntactic type as the
phrase in the parse tree, there was a reduction in the
number of paraphrases that could be applied. For
the first two conditions, paraphrases were posited for
1194 sentences, conditions 3 and 4 could be applied
to 1142 of those sentences, but conditions 5–8 could
only be applied to 876 sentences. The substitution
constraints reduce coverage to 73% of the test sen-
tences. Given that the extraction constraints have
better coverage and nearly identical performance on
3Our results show a significantly lower score for the base-
line than reported in Bannard and Callison-Burch (2005). This
is potentially due to the facts that in this work we evaluated
on out-of-domain news commentary data, and we randomly se-
lected phrases. In the pervious work the test phrases were drawn
from WordNet, and they were evaluated solely on in-domain
European parliament data.
203
the meaning criterion, they might be more suitable
in some circumstances.
6 Conclusion
In this paper we have presented a novel refinement
to paraphrasing with bilingual parallel corpora. We
illustrated that a significantly higher performance
can be achieved by constraining paraphrases to have
the same syntactic type as the original phrase. A
thorough manual evaluation found an absolute im-
provement in quality of 19% using strict criteria
about paraphrase accuracy when comparing against
a strong baseline. The syntactically enhanced para-
phrases are judged to be grammatically correct over
two thirds of the time, as opposed to the baseline
method which was grammatically correct under half
of the time.
This paper proposed constraints on paraphrases at
two stages: when deriving them from parsed paral-
lel corpora and when substituting them into parsed
test sentences. These constraints produce para-
phrases that are better than the baseline and which
are less commonly affected by problems due to un-
aligned words. Furthermore, by introducing com-
plex syntactic labels instead of solely relying on
non-terminal symbols in the parse trees, we are able
to keep the broad coverage of the baseline method.
Syntactic constraints significantly improve the
quality of this paraphrasing method, and their use
opens the question about whether analogous con-
straints can be usefully applied to paraphrases gen-
erated from purely monolingual corpora. Our im-
provements to the extraction of paraphrases from
parallel corpora suggests that it may be usefully ap-
plied to other NLP applications, such as generation,
which require grammatical output.
Acknowledgments
Thanks go to Sally Blatz, Emily Hinchcliff and
Michelle Bland for conducting the manual evalua-
tion and to Michelle Bland and Omar Zaidan for
proofreading and commenting on a draft of this pa-
per.
This work was supported by the National Science
Foundation under Grant No. 0713448. The views
and findings are the author’s alone.
References
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of ACL.
Regina Barzilay and Kathleen McKeown. 2001. Extract-
ing paraphrases from a parallel corpus. In Proceedings
of ACL.
Dan Bikel. 2002. Design of a multi-lingual, parallel-
processing statistical parsing engine. In Proceedings
of HLT.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine translation
using paraphrases. In Proceedings of HLT/NAACL.
Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,
Christof Monz, and Josh Schroeder. 2007. (Meta-)
evaluation of machine translation. In Proceedings of
the Second Workshop on Statistical Machine Transla-
tion.
Jean Carletta. 1996. Assessing agreement on classifi-
cation tasks: The kappa statistic. Computational Lin-
guistics, 22(2):249–254.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL.
Heidi J. Fox. 2002. Phrasal cohesion and statistical ma-
chine translation. In Proceedings of EMNLP.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In Pro-
ceedings of HLT/NAACL.
Bryant Huang and Kevin Knight. 2006. Relabeling syn-
tax trees to improve syntax-based machine translation
quality. In Proceedings of HLT/NAACL.
Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Extract-
ing structural paraphrases from aligned monolingual
corpora. In Proceedings of the Second International
Workshop on Paraphrasing (ACL 2003).
David Kauchak and Regina Barzilay. 2006. Para-
phrasing for automatic evaluation. In Proceedings of
EMNLP.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of HLT/NAACL.
Philipp Koehn. 2005. A parallel corpus for statistical
machine translation. In Proceedings of MT-Summit,
Phuket, Thailand.
J. Richard Landis and Gary G. Koch. 1977. The mea-
surement of observer agreement for categorical data.
Biometrics, 33:159–174.
Dekang Lin and Colin Cherry. 2002. Word align-
ment with cohesion constraint. In Proceedings of
HLT/NAACL.
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules from text. Natural Language Engineering,
7(3):343–360.
204
Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and
Bonnie Dorr. 2007. Using paraphrases for parame-
ter tuning in statistical machine translation. In Pro-
ceedings of the ACL Workshop on Statistical Machine
Translation.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics, 30(4):417–449.
Karolina Owczarzak, Declan Groves, Josef Van Gen-
abith, and Andy Way. 2006. Contextual bitext-derived
paraphrases in automatic MT evaluation. In Proceed-
ings of the SMT Workshop at HLT-NAACL.
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations: Ex-
tracting paraphrases and generating new sentences. In
Proceedings of HLT/NAACL.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal smt. In Proceedings of ACL.
Stefan Riezler, Alexander Vasserman, Ioannis Tsochan-
taridis, Vibhu Mittal, and Yi Liu. 2007. Statistical
machine translation for query expansion in answer re-
trieval. In Proceedings of ACL.
Mark Steedman. 1999. Alternative quantier scope in ccg.
In Proceedings of ACL.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of the International
Conference on Spoken Language Processing, Denver,
Colorado, September.
Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007.
Instance-based evaluation of entailment rule acquisi-
tion. In Proceedings of ACL.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3).
Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and Sheng
Li. 2008a. Combining multiple resources to improve
SMT-based paraphrasing model. In Proceedings of
ACL/HLT.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008b. Pivot approach for extracting paraphrase
patterns from bilingual corpora. In Proceedings of
ACL/HLT.
Liang Zhou, Chin-Yew Lin, and Eduard Hovy. 2006. Re-
evaluating machine translation results with paraphrase
support. In Proceedings of EMNLP.
205
