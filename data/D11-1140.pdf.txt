Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1512–1523,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics
Lexical Generalization in CCG Grammar Induction for Semantic Parsing
Tom Kwiatkowski?
t.m.kwiatkowksi@sms.ed.ac.uk
Luke Zettlemoyer†
lsz@cs.washington.edu
Sharon Goldwater?
sgwater@inf.ed.ac.uk
Mark Steedman?
steedman@inf.ed.ac.uk
?School of Informatics
University of Edinburgh
Edinburgh, EH8 9AB, UK
†Computer Science & Engineering
University of Washington
Seattle, WA 98195
Abstract
We consider the problem of learning fac-
tored probabilistic CCG grammars for seman-
tic parsing from data containing sentences
paired with logical-form meaning representa-
tions. Traditional CCG lexicons list lexical
items that pair words and phrases with syntac-
tic and semantic content. Such lexicons can
be inefficient when words appear repeatedly
with closely related lexical content. In this
paper, we introduce factored lexicons, which
include both lexemes to model word meaning
and templates to model systematic variation in
word usage. We also present an algorithm for
learning factored CCG lexicons, along with a
probabilistic parse-selection model. Evalua-
tions on benchmark datasets demonstrate that
the approach learns highly accurate parsers,
whose generalization performance benefits
greatly from the lexical factoring.
1 Introduction
Semantic parsers automatically recover representa-
tions of meaning from natural language sentences.
Recent work has focused on learning such parsers
directly from corpora made up of sentences paired
with logical meaning representations (Kate et al.,
2005; Kate and Mooney, 2006; Wong and Mooney,
2006, 2007; Zettlemoyer and Collins, 2005, 2007;
Lu et al., 2008; Kwiatkowski et al., 2010).
For example, in a flight booking domain we
might have access to training examples such as:
Sentence: I want flights from Boston
Meaning: ?x. f light(x)? f rom(x,bos)
and the goal is to learn a grammar that can map new,
unseen, sentences onto their corresponding mean-
ings, or logical forms.
One approach to this problem has developed al-
gorithms for leaning probabilistic CCG grammars
(Zettlemoyer and Collins, 2005, 2007; Kwiatkowski
et al., 2010). These grammars are well-suited to the
task of semantic parsing, as they closely link syn-
tax and semantics. They can be used to model a
wide range of complex linguistic phenomena and are
strongly lexicalized, storing all language-specific
grammatical information directly with the words in
the lexicon. For example, a typical learned lexicon
might include entries such as:
(1) f light `N :?x. f light(x)
(2) f light `N/(S|NP) :? f?x. f light(x)? f (x)
(3) f light `N\N :? f?x. f light(x)? f (x)
(4) f are`N :?x.cost(x)
(5) f are`N/(S|NP) :? f?x.cost(x)? f (x)
(6) f are`N\N :? f?x.cost(x)? f (x)
(7) Boston`NP :bos
(8) Boston`N\N :? f?x. f rom(x,bos)? f (x)
(9) New York `NP :nyc
(10) New York `N\N :? f?x. f rom(x,nyc)? f (x)
Although lexicalization of this kind is useful
for learning, as we will see, these grammars can
also suffer from sparsity in the training data, since
closely related entries must be repeatedly learned for
all members of a certain class of words. For exam-
ple, the list above shows a selection of lexical items
that would have to be learned separately.
In this list, the word “flight” is paired with the
predicate flight in three separate lexical items which
are required for different syntactic contexts. Item
1512
(1) has the standard N category for entries of this
type, item (2) allows the use of the word “flight”
with that-less relative clauses such as “flight depart-
ing Boston”, and item (3) is useful for phrases with
unconventional word order such as “from Boston
flight to New York”. Representing these three lexi-
cal items separately is inefficient, since each word of
this class (such as “fare”) will require three similarly
structured lexical entries differing only in predicate
name. There may also be systemtatic semantic vari-
ation between entries for a certain class of words.
For example, in (6) “Boston” is paired with the con-
stant bos that represents its meaning. However, item
(7) also adds the predicate from to the logical form.
This might be used to analyse somewhat elliptical,
unedited sentences such as “Show me flights Boston
to New York,” which can be challenging for seman-
tic parsers (Zettlemoyer and Collins, 2007).
This paper builds upon the insight that a large pro-
portion of the variation between lexical items for
a given class of words is systematic. Therefore it
should be represented once and applied to a small set
of basic lexical units. 1 We develop a factored lex-
icon that captures this insight by distinguishing lex-
emes, which pair words with logical constants, from
lexical templates, which map lexemes to full lexical
items. As we will see, this can lead to a significantly
more compact lexicon that can be learned from less
data. Each word or phrase will be associated with a
few lexemes that can be combined with a shared set
of general templates.
We develop an approach to learning factored,
probabilistic CCG grammars for semantic pars-
ing. Following previous work (Kwiatkowski et al.,
2010), we make use of a higher-order unification
learning scheme that defines a space of CCG gram-
mars consistent with the (sentence, logical form)
training pairs. However, instead of constructing
fully specified lexical items for the learned grammar,
we automatically generate sets of lexemes and lexi-
cal templates to model each example. This is a dif-
ficult learning problem, since the CCG analyses that
1A related tactic is commonly used in wide-coverage CCG
parsers derived from treebanks, such as work by Hockenmaier
and Steedman (2002) and Clark and Curran (2007). These
parsers make extensive use of category-changing unary rules,
to avoid data sparsity for systematically related categories (such
as those related by type-raising). We will automatically learn to
represent these types of generalizations in the factored lexicon.
are required to construct the final meaning represen-
tations are not explicitly labeled in the training data.
Instead, we model them with hidden variables and
develop an online learning approach that simultane-
ously estimates the parameters of a log-linear pars-
ing model, while inducing the factored lexicon.
We evaluate the approach on the benchmark Atis
and GeoQuery domains. This is a challenging setup,
since the GeoQuery data has complex meaning rep-
resentations and sentences in multiple languages,
while the Atis data contains spontaneous, unedited
text that can be difficult to analyze with a formal
grammar representation. Our approach achieves at
or near state-of-the-art recall across all conditions,
despite having no English or domain-specific infor-
mation built in. We believe that ours is the only sys-
tem of sufficient generality to run with this degree of
success on all of these datasets.
2 Related work
There has been significant previous work on learn-
ing semantic parsers from training sentences la-
belled with logical form meaning representations.
We extend a line of research that has addressed
this problem by developing CCG grammar induc-
tion techniques. Zettlemoyer and Collins (2005,
2007) presented approaches that use hand gener-
ated, English-language specific rules to generate lex-
ical items from logical forms as well as English
specific type-shifting rules and relaxations of the
CCG combinators to model spontaneous, unedited
sentences. Zettlemoyer and Collins (2009) extends
this work to the case of learning in context depen-
dent environments. Kwiatkowski et al. (2010) de-
scribed an approach for language-independent learn-
ing that replaces the hand-specified templates with
a higher-order-unification-based lexical induction
method, but their approach does not scale well to
challenging, unedited sentences. The learning ap-
proach we develop for inducing factored lexicons is
also language independent, but scales well to these
challenging sentences.
There have been a number of other approaches
for learning semantic parsers, including ones based
on machine translation techniques (Papineni et al.,
1997; Ramaswamy and Kleindienst, 2000; Wong
and Mooney, 2006), parsing models (Miller et al.,
1996; Ge and Mooney, 2006; Lu et al., 2008), in-
1513
ductive logic programming algorithms (Zelle and
Mooney, 1996; Thompson and Mooney, 2002; Tang
and Mooney, 2000), probabilistic automata (He and
Young, 2005, 2006), and ideas from string kernels
and support vector machines (Kate and Mooney,
2006; Nguyen et al., 2006).
More recent work has focused on training se-
mantic parsers without supervision in the form of
logical-form annotations. Clarke et al. (2010) and
Liang et al. (2011) replace semantic annotations in
the training set with target answers which are more
easily available. Goldwasser et al. (2011) present
work on unsupervised learning of logical form struc-
ture. However, all of these systems require signifi-
cantly more domain and language specific initializa-
tion than the approach presented here.
Other work has learnt semantic analyses from text
in the context of interactions in computational envi-
ronments (Branavan et al. (2010), Vogel and Juraf-
sky (2010)); text grounded in partial observations of
a world state (Liang et al., 2009); and from raw text
alone (Poon and Domingos, 2009, 2010).
There is also related work that uses the CCG
grammar formalism. Clark and Curran (2003)
present a method for learning the parameters of a
log-linear CCG parsing model from fully annotated
normal–form parse trees. Watkinson and Manand-
har (1999) describe an unsupervised approach for
learning syntactic CCG lexicons. Bos et al. (2004)
present an algorithm for building semantic represen-
tations from CCG parses but requires fully–specified
CCG derivations in the training data.
3 Overview of the Approach
Here we give a formal definition of the problem and
an overview of the learning approach.
Problem We will learn a semantic parser that
takes a sentences x and returns a logical form z repre-
senting its underlying meaning. We assume we have
input data {(xi,zi)|i = 1 . . .n} containing sentences
xi and logical forms zi, for example xi =“Show me
flights to Boston” and zi = ?x. f light(x)? to(x,bos).
Model We will represent the parser as a factored,
probabilistic CCG (PCCG) grammar. A traditional
CCG lexical item would fully specify the syntax and
semantics for a word (reviewed in Section 4). For
example, Boston`NP : bos represents the entry for
the word “Boston” with syntactic category NP and
meaning represented by the constant bos. Where a
lexicon would usually list lexical items such as this,
we instead use a factored lexicon (L,T ) containing:
• A list of lexemes L. Each lexeme pairs a word
or phrase with a list of logical constants that can
be used to construct its meaning. For example,
one lexeme might be (Boston, [bos]).
• A list of lexical templates T . Each template
takes a lexeme and maps it on to a full lexical
item. For example, there is a single template
that can map the lexeme above to the final lex-
ical entry Boston `NP : bos.
We will make central use of this factored repre-
sentation to provide a more compact representation
of the lexicon that can be learned efficiently.
The factored PCCG will also contain a parameter
vector, ? , that defines a log-linear distribution over
the possible parses y, conditioned on the sentence x.
Learning Our approach for learning factored PC-
CGs extends the work of Kwiatkowski et al. (2010),
as reviewed in Section 7. Specifically, we modify
the lexical learning, to produce lexemes and tem-
plates, as well as the feature space of the model, but
reuse the existing parameter estimation techniques
and overall learning cycle, as described in Section 7.
We present the complete approach in three parts
by describing the factored representation of the lex-
icon (Section 5), techniques for proposing potential
new lexemes and templates (Section 6), and finally
a complete learning algorithm (Section 7). How-
ever, the next section first reviews the required back-
ground on semantic parsing with CCG.
4 Background
4.1 Lambda Calculus
We represent the meanings of sentences, words
and phrases with logical expressions that can con-
tain constants, quantifiers, logical connectors and
lambda abstractions. We construct the meanings of
sentences from the meanings of words and phrases
using lambda-calculus operations. We use a version
of the typed lambda calculus (Carpenter, 1997), in
which the basic types include e, for entities; t, for
truth values; and i for numbers. We also have func-
tion types that are assigned to lambda expressions.
1514
The expression ?x. f light(x) takes an entity and re-
turns a truth value, and has the function type ?e, t?.
4.2 Combinatory Categorial Grammar
CCG (Steedman, 1996, 2000) is a linguistic formal-
ism that tightly couples syntax and semantics, and
can be used to model a wide range of language phe-
nomena. A traditional CCG grammar includes a lex-
icon ? with entries like the following:
f lights`N :?x. f light(x)
to` (N\N)/NP :?y.? f .?x. f (x)? to(x,y)
Boston`NP :bos
where each lexical item w`X : h has words w, a syn-
tactic category X , and a logical form h. For the first
example, these are “flights,” N, and ?x. f light(x).
In this paper, we introduce a new way of represent-
ing lexical items as (lexeme, template) pairs, as de-
scribed in section 5.
CCG syntactic categories may be atomic (such
as S or NP) or complex (such as (N\N)/NP)
where the slash combinators encode word order
information. CCG uses a small set of combinatory
rules to build syntactic parses and semantic repre-
sentations concurrently. Two example combinatory
rules are forward (>) and backward (<) application:
X/Y : f Y : g ? X : f (g) (>)
Y : g X\Y : f ? X : f (g) (<)
These rules apply to build syntactic and semantic
derivations under the control of the word order infor-
mation encoded in the slash directions of the lexical
entries. For example, given the lexicon above, the
phrase “flights to Boston” can be parsed to produce:
flights to Boston
N (N\N)/NP NP?x. f light(x) ?y? f?x. f (x)? to(x,y) bos
>
(N\N)? f?x. f (x)? to(x,bos)
<N?x. f light(x)? to(x,bos)
where each step in the parse is labeled with the com-
binatory rule (?> or ?<) that was used.
CCG also includes combinatory rules of forward
(> B) and backward (< B) composition:
X/Y : f Y/Z : g? X/Z : ?x. f (g(x)) (> B)
Y\Z : g X\Y : f ? X\Z : ?x. f (g(x)) (< B)
These rules allow a relaxed notion of constituency
which helps limit the number of distinct CCG lexical
items required.
To the standard forward and backward slashes of
CCG we also add a vertical slash for which the di-
rection of application is underspecified. We shall see
examples of this in Section 10.
4.3 Probabilistic CCGs
Due to ambiguity in both the CCG lexicon and the
order in which combinators are applied, there will
be many parses for each sentence. We discriminate
between competing parses using a log-linear model
which has a feature vector ? and a parameter vector
? . The probability of a parse y that returns logical
form z, given a sentence x is defined as:
P(y,z|x;? ,?) = e
? ·?(x,y,z)
?(y?,z?) e? ·?(x,y?,z?) (1)
Section 8 fully defines the set of features used in the
system presented. The most important of these con-
trol the generation of lexical items from (lexeme,
template) pairs. Each (lexeme, template) pair used
in a parse fires three features as we will see in more
detail later.
The parsing, or inference, problem done at test
time requires us to find the most likely logical form
z given a sentence x, assuming the parameters ? and
lexicon ? are known:
f (x) = argmaxz p(z|x;? ,?) (2)
where the probability of the logical form is found by
summing over all parses that produce it:
p(z|x;? ,?) =?
y
p(y,z|x;? ,?) (3)
In this approach the distribution over parse trees y
is modeled as a hidden variable. The sum over
parses in Eq. 3 can be calculated efficiently using
the inside-outside algorithm with a CKY-style pars-
ing algorithm.
To estimate the parameters themselves, we
use stochastic gradient updates (LeCun et al.,
1998). Given a set of n sentence-meaning pairs
{(xi,zi) : i = 1...n}, we update the parameters ? it-
eratively, for each example i, by following the local
gradient of the conditional log-likelihood objective
1515
Oi = logP(zi|xi;? ,?). The local gradient of the in-
dividual parameter ? j associated with feature ? j and
training instance (xi,zi) is given by:
?Oi
?? j = Ep(y|xi,zi;? ,?)[? j(xi,y,zi)]
?Ep(y,z|xi;? ,?)[? j(xi,y,z)]
(4)
As with Eq. 3, all of the expectations in Eq. 4 are
calculated through the use of the inside-outside al-
gorithm on a pruned parse chart. For a sentence
of length m, each parse chart span is pruned using
a beam width proportional to m 23 , to allow larger
beams for shorter sentences.
5 Factored Lexicons
A factored lexicon includes a set L of lexemes and
a set T of lexical templates. In this section, we for-
mally define these sets, and describe how they are
used to build CCG parses. We will use a set of lex-
ical items from our running example to discuss the
details of how the following lexical items:
(1) f light `N :?x. f light(x)
(2) f light `N/(S|NP) :? f?x. f light(x)? f (x)
. . .
(6) Boston`NP :bos
(7) Boston`N\N :? f?x. f rom(x,bos)? f (x)
are constructed from specific lexemes and templates.
5.1 Lexemes
A lexeme (w,~c) pairs a word sequence w with an
ordered list of logical constants ~c = [c1 . . .cm]. For
example, item (1) and (2) above would come from
a single lexeme (flight, [ f light]). Similar lexemes
would be represented for other predicates, for exam-
ple (fare, [cost]). Lexemes also can contain multiple
constants, for example (cheapest, [argmin,cost]),
which we will see more examples of later.
5.2 Lexical Templates
A lexical template takes a lexeme and produces a
lexical item. Templates have the general form
? (?,~v).[? `X : h~v]
where h~v is a logical expression that contains vari-
ables from the list ~v. Applying this template to the
input lexeme (w,~c) gives the full lexical item w `
X :h where the variable ? has been replaced with the
wordspan w and the logical form h has been created
by replacing each of the variables in~v with the coun-
terpart constant from ~c. For example, the lexical
item (6) above would be constructed from the lex-
eme (Boston, [bos]) using the template ? (?,~v).[? `
NP :v1]. Items (1) and (2) would both be constructed
from the single lexeme (flight, [ f light]) with the two
different templates ? (?,~v).[? ` N : ?x.v1(x)] and
? (?,~v).[? `N/(S|NP) :? f?x.v1(x)? f (x)]
5.3 Parsing with a Factored Lexicon
In general, there can by many different (lexeme,
template) pairs that produce the same lexical item.
For example, lexical item (7) in our running ex-
ample above can be constructed from the lexemes
(Boston, [bos]) and (Boston, [ f rom,bos]), given ap-
propriate templates.
To model this ambiguity, we include the selection
of a (lexeme, template) pair as a decision to be made
while constructing a CCG parse tree. Given the lex-
ical item produced by the chosen lexeme and tem-
plate, parsing continues with the traditional combi-
nators, as reviewed in Section 4.2. This direct inte-
gration allows for features that signal which lexemes
and templates have been used while also allowing
for well defined marginal probabilities, by summing
over all ways of deriving a specific lexical item.
6 Learning Factored Lexicons
To induce factored lexicons, we will make use of two
procedures, presented in this section, that factor lexi-
cal items into lexemes and templates. Section 7 will
describe how this factoring operation is integrated
into the complete learning algorithm.
6.1 Maximal Factorings
Given a lexical item l of the form w `X : h with
words w, a syntactic category X , and a logical form
h, we define the maximal factoring to be the unique
(lexeme, template) pair that can be used to recon-
struct l and includes all of the constants of h in
the lexeme (listed in a fixed order based on an
ordered traversal of h). For example, the maxi-
mal factoring for the lexical item Boston ` NP :
bos is the pair we saw before: (Boston, [bos]) and
? (?,~v).[? ` NP : v1]. Similarly, the lexical item
Boston ` N\N : ? f .?x. f (x)? f rom(x,bos) would
be factored to produce (Boston, [ f rom,bos]) and
? (?,~v).[? ` N\N :? f .?x. f (x)? v1(x,v2)].
As we will see in Section 7, this notion of factor-
1516
ing can be directly incorporated into existing algo-
rithms that learn CCG lexicons. When the original
algorithm would have added an entry l to the lexi-
con, we can instead compute the factoring of l and
add the corresponding lexeme and template to the
factored lexicon.
6.2 Introducing Templates with Content
Maximal factorings, as just described, provide for
significant lexical generalization but do not handle
all of the cases needed to learn effectively. For
instance, the maximal split for the item Boston `
N\N : ? f .?x. f (x) ? f rom(x,bos) would introduce
the lexeme (Boston, [ f rom,bos]), which is subopti-
mal since each possible city would need a lexeme
of this type, with the additional from constant in-
cluded. Instead, we would ideally like to learn the
lexeme (Boston, [bos]) and have a template that in-
troduces the from constant. This would model the
desired generalization with a single lexeme per city.
In order to permit the introduction of extra con-
stants into lexical items, we allow the creation of
templates that contain logical constants through par-
tial factorings. For instance, the template below can
introduce the predicate from
? (?,~v).[? `N\N :? f .?x. f (x)? f rom(x,v1)]
The use of templates to introduce extra semantic
constants into a lexical item is similar to, but more
general than, the English-specific type-shifting rules
used in Zettlemoyer and Collins (2007), which were
introduced to model spontaneous, unedited text.
They are useful, as we will see, in learning to re-
cover semantic content that is implied, but not ex-
plicitly stated, such as our original motivating phrase
“flights Boston to New York.”
To propose templates which introduce semantic
content, during learning, we build on the intuition
that we need to recover from missing words, such
as in the example above. In this scenario, there
should also be other sentences that actually include
the word, in our example this would be something
like “flights from Boston.” We will also assume
that we have learned a good factored lexicon for the
complete example that could produce the parse:
flights from Boston
N (N\N)/NP NP?x. f light(x) ?y? f?x. f (x)? f rom(x,y) bos
>
(N\N)? f?x. f (x)? f rom(x,bos)
<N?x. f light(x)? f rom(x,bos)
Given analyses of this form, we introduce new
templates that will allow us to recover from miss-
ing words, for example if “from” was dropped. We
identify commonly occurring nodes in the best parse
trees found during training, in this case the non-
terminal spanning “from Boston,” and introduce
templates that can produce the nonterminal, even if
one of the words is missing. Here, this approach
would introduce the desired template ? (?,~v).[? `
N\N : ? f .?x. f (x) ? f rom(x,v1)] for mapping the
lexeme (Boston, [bos]) directly to the intermediate
structure.
Not all templates introduced this way will model
valid generalizations. However, we will incorporate
them into a learning algorithm with indicator fea-
tures that can be weighted to control their use. The
next section presents the complete approach.
7 Learning Factored PCCGs
Our Factored Unification Based Learning (FUBL)
method extends the UBL algorithm (Kwiatkowski
et al., 2010) to induce factored lexicons, while also
simultanously estimating the parameters of a log-
linear CCG parsing model. In this section, we first
review the NEW-LEX lexical induction procedure
from UBL, and then present the FUBL algorithm.
7.1 Background: NEW-LEX
NEW-LEX generates lexical items by splitting and
merging nodes in the best parse tree of each training
example. Each parse node has a CCG category X : h
and a sequence of words w that it spans. We will
present an overview of the approach using the run-
ning example with the phrase w =“in Boston” and
the category X : h = S\NP :?x.loc(x,bos), which is
of the type commonly seen during learning. The
splitting procedure is a two step process that first
splits the logical form h, then splits the CCG syn-
tactic category X and finally splits the string w.
The first step enumerates all possible splits of
the logical form h into a pair of new expressions
1517
( f ,g) that can be used to reconstruct h by ei-
ther function application (h = f (g)) or composition
(h = ?x. f (g(x))). For example, one possible split is:
( f = ?y.?x.loc(x,y) , g = bos)
which corresponds to the function application case.
The next two steps enumerate all ways of splitting
the syntactic category X and words w to introduce
two new lexical items which can be recombined with
CCG combinators (application or composition) to
recreate the original parse node X : h spanning w. In
our example, one possibility would be:
(in` (S\NP)/NP :?y.?x.loc(x,y) , Boston`NP :bos)
which could be recombined with the forward appli-
cation combinator from Section 4.2.
To assign categories while splitting, the grammar
used by NEW-LEX only uses two atomic syntac-
tic categories S and NP. This allows NEW-LEX to
make use of a direct mapping from semantic type
to syntactic category when proposing syntactic cate-
gories. In this schema, the standard syntactic cat-
egory N is replaced by the category S|NP which
matches the type ?e, t? and uses the vertical slash in-
troduced in Section 4.2. We will see categories such
as this in the evaluation.
7.2 The FUBL Algorithm
Figure 1 shows the FUBL learning algorithm. We
assume training data {(xi,zi) : i= 1 . . .n}where each
example is a sentence xi paired with a logical form
zi. The algorithm induces a factored PCCG, includ-
ing the lexemes L, templates T , and parameters ? .
The algorithm is online, repeatedly performing
both lexical expansion (Step 1) and a parameter up-
date (Step 2) for each training example. The over-
all approach is closely related to the UBL algo-
rithm (Kwiatkowski et al., 2010), but includes exten-
sions for updating the factored lexicon, as motivated
in Section 6.
Initialization The model is initialized with a fac-
tored lexicon as follows. MAX-FAC is a function
that takes a lexical item l and returns the maximal
factoring of it, that is the unique, maximal (lexeme,
template) pair that can be combined to construct l,
as described in Section 6.1. We apply MAX-FAC to
each of the training examples (xi,zi), creating a sin-
gle way of producing the desired meaning zi from a
Inputs: Training set {(xi,zi) : i = 1 . . .n} where each
example is a sentence xi paired with a logical form
zi. Set of entity name lexemes Le. Number of itera-
tions J. Learning rate parameter ?0 and cooling rate
parameter c. Empty lexeme set L. Empty template
set T .
Definitions: NEW-LEX(y) returns a set of new lex-
ical items from a parse y as described in Sec-
tion 7.1. MAX-FAC(l) generates a (lexeme, tem-
plate) pair from a lexical item l. PART-FAC(y)
generates a set of templates from parse y. Both of
these are described in Section 7.2. The distributions
p(y|x,z;? ,(L,T )) and p(y,z|x;? ,(L,T )) are defined
by the log-linear model described in Section 4.3.
Initialization:
• For i = 1 . . .n
• (?,pi) = MAX-FAC(xi ` S : zi)
• L = L?? , T = T ?pi
• Set L = L?Le.
• Initialize ? using coocurrence statistics, as de-
scribed in Section 8.
Algorithm:
For t = 1 . . .J, i = 1 . . .n :
Step 1: (Add Lexemes and Templates)
• Let y? = argmaxy p(y|xi,zi;? ,(L,T ))
• For l ? NEW-LEX(y?)
• (?,pi) = MAX-FAC(l)
• L = L?? , T = T ?pi
• ?= PART-FAC(y?) , T = T ??
Step 2: (Update Parameters)
• Let ? = ?01+c×k where k = i+ t×n.
• Let ?= Ep(y|xi,zi;? ,(L,T ))[?(xi,y,zi)]
?Ep(y,z|xi;? ,(L,T ))[?(xi,y,z)]
• Set ? = ? + ??
Output: Lexemes L, templates T , and parameters ? .
Figure 1: The FUBL learning algorithm.
lexeme containing all of the words in xi. The lex-
emes and templates created in this way provide the
initial factored lexicon.
Step 1 The first step of the learning algorithm in
Figure 1 adds lexemes and templates to the fac-
tored model given by performing manipulations on
the highest scoring correct parse y? of the current
training example (xi,zi). First the NEW-LEX pro-
cedure is run on y? as described in Section 6.1 to
1518
generate new lexical items. We then use the func-
tion MAX-FAC to create the maximal factorings of
each of these new lexical items as described in Sec-
tion 6 and these are added to the factored represen-
tation of the lexicon. New templates can also be in-
troduced through partial factorings of internal parse
nodes as described in Section 6.2. These templates
are generated by using the function PART-FAC to
abstract over the wordspan and a subset of the con-
stants contained in the internal parse nodes of y?.
This step allows for templates that introduce new
semantic content to model elliptical language, as de-
scribed in Section 6.2.
Step 2 The second step does a stochastic gradient
descent update on the parameters ? used in the pars-
ing model. This update is described in Section 4.3
Discussion The FUBL algorithm makes use of a
direct online approach, where lexemes and tem-
plates are introduced in place while analyzing spe-
cific sentences. In general, this will overgeneralize;
not all ways of combining lexemes and templates
will produce high quality lexical items. However,
the overall approach includes features, presented in
Section 8, that can be used to learn which ones are
best in practice. The complete algorithm iterates be-
tween adding new lexical content and updating the
parameters of the parsing model with each proce-
dure guiding the other.
8 Experimental setup
Data Sets We evaluate on two benchmark seman-
tic parsing datasets: GeoQuery, which is made up of
natural language queries to a database of geograph-
ical information; and Atis, which contains natural
language queries to a flight booking system. The
Geo880 dataset has 880 (English-sentence, logical-
form) pairs split into a training set of 600 pairs and
a test set of 280. The Geo250 data is a subset of
the Geo880 sentences that have been translated into
Japanese, Spanish and Turkish as well as the original
English. We follow the standard evaluation proce-
dure for Geo250, using 10-fold cross validation ex-
periments with the same splits of the data as Wong
and Mooney (2007). The Atis dataset contains 5410
(sentence, logical-form) pairs split into a 4480 ex-
ample training set, a 480 example development set
and a 450 example test set.
Evaluation Metrics We report exact match Re-
call (percentage of sentences for which the correct
logical-form was returned), Precision (percentage of
returned logical-forms that are correct) and F1 (har-
monic mean of Precision and Recall). For Atis we
also report partial match Recall (percentage of cor-
rect literals returned), Precision (percentage of re-
turned literals that are correct) and F1, computed as
described by Zettlemoyer and Collins (2007).
Features We introduce two types of features to
discriminate between parses: lexical features and
logical-form features.
Lexical features fire on the lexemes and templates
used to build the lexical items used in a parse. For
each (lexeme,template) pair used to create a lexi-
cal item we have indicator features ?l for the lex-
eme used, ?t for the template used, and ?(l,t) for the
pair that was used. We assign the features on lexi-
cal templates a weight of 0.1 to prevent them from
swamping the far less frequent but equally informa-
tive lexeme features.
Logical-form features are computed on the
lambda-calculus expression z returned at the root of
the parse. Each time a predicate p in z takes an
argument a with type Ty(a) in position i, it trig-
gers two binary indicator features: ?(p,a,i) for the
predicate-argument relation; and ?(p,Ty(a),i) for the
predicate argument-type relation. Boolean opera-
tor features look at predicates that occurr together
in conjunctions and disjunctions. For each variable
vi that fills argument slot i in two conjoined pred-
icates p1 and p2 we introduce a binary indicator
feature ?con j(i,p1,p2). We introduce similar features?dis j(i,p1,p2) for variables vi that are shared by predi-cates in a disjunction.
Initialization The weights for lexeme features are
initialized according to coocurrance statistics be-
tween words and logical constants. These are esti-
mated with the Giza++ (Och and Ney, 2003) imple-
mentation of IBM Model 1. The initial weights for
templates are set by adding ?0.1 for each slash in
the syntactic category and ?2 if the template con-
tains logical constants. Features on lexeme-template
pairs and all parse features are initialized to zero.
Systems We compare performance to all recently-
published, directly-comparable results. For Geo-
Query, this includes the ZC05, ZC07 (Zettlemoyer
1519
System Exact MatchRec. Pre. F1
ZC07 74.4 87.3 80.4
UBL 65.6 67.1 66.3
FUBL 81.9 82.1 82.0
Table 1: Performance on the Atis development set.
System Exact Match Partial MatchRec. Pre. F1. Rec. Pre. F1
ZC07 84.6 85.8 85.2 96.7 95.1 95.9
HY06 - - - - - 90.3
UBL 71.4 72.1 71.7 78.2 98.2 87.1
FUBL 82.8 82.8 82.8 95.2 93.6 94.6
Table 2: Performance on the Atis test set.
and Collins, 2005, 2007), ? -WASP (Wong and
Mooney, 2007), UBL (Kwiatkowski et al., 2010)
systems and DCS (Liang et al., 2011). For Atis,
we report results from HY06 (He and Young, 2006),
ZC07, and UBL.
9 Results
Tables 1-4 present the results on the Atis and Geo-
query domains. In all cases, FUBL achieves at or
near state-of-the-art recall (overall number of correct
parses) when compared to directly comparable sys-
tems and it significantly outperforms UBL on Atis.
On Geo880 the only higher recall is achieved
by DCS with prototypes - which uses signifi-
cant English-specific resources, including manually
specified lexical content, but does not require train-
ing sentences annotated with logical-forms. On
Geo250, FUBL achieves the highest recall across
languages. Each individual result should be inter-
preted with care, as a single percentage point cor-
responds to 2-3 sentences, but the overall trend is
encouraging.
On the Atis development set, FUBL outperforms
ZC07 by 7.5% of recall but on the Atis test set
FUBL lags ZC07 by 2%. The reasons for this dis-
crepancy are not clear, however, it is possible that
the syntactic constructions found in the Atis test set
do not exhibit the same degree of variation as those
seen in the development set. This would negate the
need for the very general lexicon learnt by FUBL.
Across the evaluations, despite achieving high re-
call, FUBL achieves significantly lower precision
than ZC07 and ? -WASP. This illustrates the trade-
off from having a very general model of proposing
lexical structure. With the ability to skip unseen
System Rec. Pre. F1
Labelled Logical Forms
ZC05 79.3 96.3 87.0
ZC07 86.1 91.6 88.8
UBL 87.9 88.5 88.2
FUBL 88.6 88.6 88.6
Labelled Question Answers
DCS 91.1 - -
Table 3: Exact match accuracy on the Geo880 test set.
System English SpanishRec. Pre. F1 Rec. Pre. F1
? -WASP 75.6 91.8 82.9 80.0 92.5 85.8
UBL 81.8 83.5 82.6 81.4 83.4 82.4
FUBL 83.7 83.7 83.7 85.6 85.8 85.7
System Japanese TurkishRec. Pre. F1 Rec. Pre. F1
? -WASP 81.2 90.1 85.8 68.8 90.4 78.1
UBL 83.0 83.2 83.1 71.8 77.8 74.6
FUBL 83.2 83.8 83.5 72.5 73.7 73.1
Table 4: Exact-match accuracy on the Geo250 data set.
words, FUBL returns a parse for all of the Atis test
sentences, since the factored lexicons we are learn-
ing can produce a very large number of lexical items.
These parses are, however, not always correct.
10 Analysis
The Atis results in Tables 1 and 2 highlight the ad-
vantages of factored lexicons. FUBL outperforms
the UBL baseline by 16 and 11 points respectively
in exact-match recall. Without making any modi-
fication to the CCG grammars or parsing combina-
tors, we are able to induce a lexicon that is general
enough model the natural occurring variations in the
data, for example due to sloppy, unedited sentences.
Figure 2 shows a parse returned by FUBL for
a sentence on which UBL failed. While
the word “cheapest” is seen 208 times in the
training data, in only a handful of these in-
stances is it seen in the middle of an utter-
ance. For this reason, UBL never proposes
the lexical item, cheapest ` NP\(S|NP)/(S|NP) :
? f?g.argmin(?x. f (x)? g(x),?y.cost(y)), which is
used to parse the sentence in Figure 2. In contrast,
FUBL uses a lexeme learned from the same word in
different contexts, along with a template learnt from
similar words in a similar context, to learn to per-
1520
pittsburgh to atlanta the cheapest on july twentieth
NP (S|NP)\NP/NP NP NP\(S|NP)/(S|NP) (S|NP)/NP/NP NP NP
pit ?x?y? z.to(z,x) atl ? f?g.argmin(?x. f (x)?g(x),?y.cost(y)) ?x?y? z.month(z,x) jul 20
? f rom(z,y) ?day(z,y)
> >
(S|NP)\NP (S|NP)/NP?x?y.to(y,atl)? f rom(y,x) ?x?y.month(y, jul)?day(y,x)
< >
(S|NP) (S|NP)?x.to(x,atl)? f rom(x, pit) ?x.month(x, jul)?day(x,20)
>NP\(S|NP)? f .argmin(?x. f (x)?month(x, jul)?day(x,20),?y.cost(y))
<NP
argmin(?x. f rom(x, pit)? to(x,atl)?month(x, jul)?day(x,20),?y.cost(y))
Figure 2: An example learned parse. FUBL can learn this type of analysis with novel combinations of lexemes and
templates at test time, even if the individual words, like “cheapest,” were never seen in similar syntactic constructions
during training, as described in Section 10.
form the desired analysis.
As well as providing a new way to search the lex-
icon during training, the factored lexicon provides a
way of proposing new, unseen, lexical items at test
time. We find that new, non-NP, lexical items are
used in 6% of the development set parses.
Interestingly, the addition of templates that intro-
duce semantic content (as described in Section 6.2)
account for only 1.2% of recall on the Atis develop-
ment set. This is suprising as elliptical constructions
are found in a much larger proportion of the sen-
tences than this. In practice, FUBL learns to model
many elliptical constructions with lexemes and tem-
plates introduced through maximal factorings. For
example, the lexeme (to, [ f rom, to]) can be used
with the correct lexical template to deal with our
motivating example “flights Boston to New York”.
Templates that introduce content are therefore only
used in truly novel elliptical constructions for which
an alternative analysis could not be learned.
Table 5 shows a selection of lexemes and tem-
plates learned for Atis. Examples 2 and 3 show that
morphological variants of the same word must still
be stored in separate lexemes. However, as these
lexemes now share templates, the total number of
lexical variants that must be learned is reduced.
11 Discussion
We argued that factored CCG lexicons, which in-
clude both lexemes and lexical templates, provide
a compact representation of lexical knowledge that
can have advantages for learning. We also described
a complete approach for inducing factored, prob-
abilistic CCGs for semantic parsing, and demon-
Most common lexemes by type of constants in~c.
1 e (Boston, [bos]) (Denver, [den])
2 ?e, t? (flight, [ f light]) (flights, [ f light])
3 ?e, i? (fare, [cost]) (fares, [cost])
4 ?e,?e, t?? (from, [ f rom]) (to, [to])
5 ?e, i?, (cheapest, [argmin,cost])?e, t? (earliest, [argmin,dep time])
6 ?i,?i, t??, (after, [>,dep time])
?e, i? (before, [<,dep time])
Most common templates matching lexemes above.
1 ? (?,~v).? `NP :v1
2 ? (?,~v).? `S|NP :?x.v1(x)
3 ? (?,~v).? `NP|NP :?x.v1(x)
4 ? (?,~v).? `S|NP/NP\(S|NP) :?x?y.v1(x,y)
5 ? (?,~v).? `NP/(S|NP) :? f .v1(?x. f (x),?y,v2(y))
6 ? (?,~v).? `S|NP\(S|NP)/NP :
?x?y? z.v1(v2(z),x)? y(x)
Table 5: Example lexemes and templates learned from
the Atis development set.
strated strong performance across a wider range of
benchmark datasets that any previous approach.
In the future, it will also be important to ex-
plore morphological models, to better model vari-
ation within the existing lexemes. The factored lex-
ical representation also has significant potential for
lexical transfer learning, where we would need to
learn new lexemes for each target application, but
much of the information in the templates could, po-
tentially, be ported across domains.
Acknowledgements
The work was supported in part by EU ERC Ad-
vanced Fellowship 249520 GRAMPLUS, and an
ESPRC PhD studentship. We would like to thank
Yoav Artzi for helpful discussions.
1521
References
Bos, Johan, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-coverage
semantic representations from a CCG parser. In Pro-
ceedings of the International Conference on Computa-
tional Linguistics.
Branavan, S.R.K., Luke Zettlemoyer, and Regina Barzi-
lay. 2010. Reading between the lines: Learning to map
high-level instructions to commands. In Association
for Computational Linguistics (ACL).
Carpenter, Bob. 1997. Type-Logical Semantics. The MIT
Press.
Clark, Stephen and James R. Curran. 2003. Log-linear
models for wide-coverage CCG parsing. In Proceed-
ings of the Conference on Empirical Methods in Natu-
ral Language Processing.
Clark, Stephen and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics
33(4):493–552.
Clarke, James, Dan Goldwasser, Ming-Wei Chang, and
Dan Roth. 2010. Driving semantic parsing from
the world’s response. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL-2010). Uppsala, Sweden,
pages 18–27.
Ge, Ruifang and Raymond J. Mooney. 2006. Discrimina-
tive reranking for semantic parsing. In Proceedings of
the COLING/ACL 2006 Main Conference Poster Ses-
sions.
Goldwasser, Dan, Roi Reichart, James Clarke, and Dan
Roth. 2011. Confidence driven unsupervised semantic
parsing. In Association for Computational Linguistics
(ACL).
He, Yulan and Steve Young. 2005. Semantic processing
using the hidden vector state model. Computer Speech
and Language .
He, Yulan and Steve Young. 2006. Spoken language
understanding using the hidden vector state model.
Speech Communication 48(3-4).
Hockenmaier, Julia and Mark Steedman. 2002. Gener-
ative models for statistical parsing with Combinatory
Categorial Grammar. In Proceedings of the 40th Meet-
ing of the ACL. Philadelphia, PA, pages 335–342.
Kate, Rohit J. and Raymond J. Mooney. 2006. Using
string-kernels for learning semantic parsers. In Pro-
ceedings of the 44th Annual Meeting of the Association
for Computational Linguistics.
Kate, Rohit J., Yuk Wah Wong, and Raymond J. Mooney.
2005. Learning to transform natural to formal lan-
guages. In Proceedings of the National Conference
on Artificial Intelligence.
Kwiatkowski, Tom, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing probabilistic
CCG grammars from logical form with higher-order
unification. In Proceedings of the Conference on Em-
perical Methods in Natural Language Processing.
LeCun, Y., L. Bottou, Y. Bengio, and P. Haffner. 1998.
Gradient-based learning applied to document recogni-
tion. Proceedings of the IEEE 86(11):2278–2324.
Liang, P., M. I. Jordan, and D. Klein. 2009. Learning
semantic correspondences with less supervision. In
Association for Computational Linguistics and Inter-
national Joint Conference on Natural Language Pro-
cessing (ACL-IJCNLP).
Liang, P., M. I. Jordan, and D. Klein. 2011. Learning
dependency-based compositional semantics. In Asso-
ciation for Computational Linguistics (ACL).
Lu, Wei, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettle-
moyer. 2008. A generative model for parsing natural
language to meaning representations. In Proceedings
of The Conference on Empirical Methods in Natural
Language Processing.
Miller, Scott, David Stallard, Robert J. Bobrow, and
Richard L. Schwartz. 1996. A fully statistical approach
to natural language interfaces. In Proc. of the Associ-
ation for Computational Linguistics.
Nguyen, Le-Minh, Akira Shimazu, and Xuan-Hieu Phan.
2006. Semantic parsing with structured SVM ensem-
ble classification models. In Proceedings of the COL-
ING/ACL 2006 Main Conference Poster Sessions.
Och, Franz Josef and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics 29(1):19–51.
Papineni, K. A., S. Roukos, and T. R. Ward. 1997.
Feature-based language understanding. In Proceed-
ings of European Conference on Speech Communica-
tion and Technology.
Poon, Hoifung and Pedro Domingos. 2009. Unsuper-
vised semantic parsing. In Conference on Empirical
Methods in Natural Language Processing (EMNLP).
Poon, Hoifung and Pedro Domingos. 2010. Unsuper-
vised ontology induction from text. In Association for
Computational Linguistics (ACL).
Ramaswamy, Ganesh N. and Jan Kleindienst. 2000. Hier-
archical feature-based translation for scalable natural
language understanding. In Proceedings of Interna-
tional Conference on Spoken Language Processing.
Steedman, Mark. 1996. Surface Structure and Interpre-
tation. The MIT Press.
1522
Steedman, Mark. 2000. The Syntactic Process. The MIT
Press.
Tang, Lappoon R. and Raymond J. Mooney. 2000. Au-
tomated construction of database interfaces: Integrat-
ing statistical and relational learning for semantic pars-
ing. In Proceedings of the Joint Conference on Empiri-
cal Methods in Natural Language Processing and Very
Large Corpora.
Thompson, Cynthia A. and Raymond J. Mooney. 2002.
Acquiring word-meaning mappings for natural lan-
guage interfaces. Journal of Artificial Intelligence Re-
search 18.
Vogel, Adam and Dan Jurafsky. 2010. Learning to follow
navigational directions. In Association for Computa-
tional Linguistics (ACL).
Watkinson, Stephen and Suresh Manandhar. 1999. Un-
supervised lexical learning with categorial grammars
using the LLL corpus. In Proceedings of the 1st Work-
shop on Learning Language in Logic.
Wong, Yuk Wah and Raymond Mooney. 2006. Learning
for semantic parsing with statistical machine transla-
tion. In Proceedings of the Human Language Technol-
ogy Conference of the NAACL.
Wong, Yuk Wah and Raymond Mooney. 2007. Learn-
ing synchronous grammars for semantic parsing with
lambda calculus. In Proceedings of the Association for
Computational Linguistics.
Zelle, John M. and Raymond J. Mooney. 1996. Learn-
ing to parse database queries using inductive logic pro-
gramming. In Proceedings of the National Conference
on Artificial Intelligence.
Zettlemoyer, Luke S. and Michael Collins. 2005. Learn-
ing to map sentences to logical form: Structured clas-
sification with probabilistic categorial grammars. In
Proceedings of the Conference on Uncertainty in Arti-
ficial Intelligence.
Zettlemoyer, Luke S. and Michael Collins. 2007. On-
line learning of relaxed CCG grammars for parsing to
logical form. In Proc. of the Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning.
Zettlemoyer, Luke S. and Michael Collins. 2009. Learn-
ing context-dependent mappings from sentences to
logical form. In Proceedings of The Joint Conference
of the Association for Computational Linguistics and
International Joint Conference on Natural Language
Processing.
1523
