Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 106–110,
Gothenburg, Sweden, April 26-30 2014.
c©2014 Association for Computational Linguistics
Automatic Selection of Reference Pages in Wikipedia
for Improving Targeted Entities Disambiguation
Takuya Makino
Fujitsu Laboratories Ltd.
4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki, Japan
makino.takuya@jp.fujitsu.com
Abstract
In Targeted Entity Disambiguation setting,
we take (i) a set of entity names which be-
long to the same domain (target entities),
(ii) candidate mentions of the given enti-
ties which are texts that contain the tar-
get entities as input, and then determine
which ones are true mentions of “target
entity”. For example, given the names of
IT companies, including Apple, we deter-
mine Apple in a mention denotes an IT
company or not. Prior work proposed a
graph based model. This model ranks all
candidate mentions based on scores which
denote the degree of relevancy to target
entities. Furthermore, this graph based
model could utilize reference pages of tar-
get entities. However, human annotators
must select reference pages in advance.
We propose an automatic method that can
select reference pages. We formalize the
selection problem of reference pages as an
Integer Linear Programming problem. We
show that our model works as well as the
prior work that manually selected refer-
ence pages.
1 Introduction
The enterprise is typically interested in customer’s
opinions. One of the methods to analyze cus-
tomer’s opinions is to collect mentions which con-
tain product names. We would get a noisy mention
collection if we use a simple method which ex-
tracts mentions that contain product names, since
the product names may be used as other meanings.
Wang et al. (2012) proposed a new task which
they referred to as Targeted Entity Disambigua-
tion (TED). In this problem setting, we take (i) a
set of entity names which belong to the same do-
main (target entities), (ii) candidate mentions of
the given entities which are texts that contain the
target entity entities as input, and then determine
which ones are true mentions for the target enti-
ties. TED is different from traditional Word Sense
Disambiguation or Entity Linking. Word Sense
Disambiguation can be viewed as a classification
task in which word senses are the classes (Nav-
igli, 2009) and Entity Linking is the task of link-
ing name in Web text with entities in Wikipedia
(Han et al., 2011). The uniqueness of this prob-
lem is that the entities are all in the same domain
(referred to as the target domain) and not necessar-
ily included in a knowledge base such as DBpedia,
Freebase or YAGO.
Wang et al. (2012) realized TED with a graph
based model. In their graph based method, a target
entity in a mention is regarded as a node, and the
weight of an edge is determined according to con-
text similarity, and a prior score of node that is de-
termined according to the unique number of target
entities in the mention. This graph is called as a
mention graph. Using mention graph, the author-
ity of each mention is calculated with Mention-
Rank which is a variant of PageRank (Page et al.,
1999). This authority denotes a score of how likely
this node is in the target domain. In addition, Men-
tionRank could integrate external knowledge such
as Wikipedia. For each target entity, a reference
page is added as a virtual node to the graph. Since
reference pages can be regarded as true mentions,
the prior scores of virtual nodes are higher than
other mentions. This extended method can prop-
agate the score of the virtual node of each entity
to candidate mentions which are likely true. Al-
though the use of reference pages works well, hu-
man annotators must select these reference pages.
InWord Sense Disambiguation and Entity Link-
ing, there are some collective approaches (Hoffart
et al., 2011; Kulkarni et al., 2009). In this pa-
per, we apply this technique to the selection prob-
lem of reference pages for TED. To select refer-
106
ence pages, we collect candidate reference pages
of target entities from Wikipedia in advance. If
the name of a target entity has a disambiguation
page in Wikipedia, we have two or more candi-
date reference pages. Then we formalize the prob-
lem of reference page selection as an Integer Lin-
ear Programming problem. Our model is going to
maximize the summation of similarities between
selected pages under some constraints. Thus, co-
herent pages are selected as reference pages. Our
method does not require any knowledge except for
names of target entities. We give only target enti-
ties as input to select reference pages. Our method
shows competitive accuracy of the prior method
with manually selected reference pages.
2 Task Definition
Following previous work, we assume that all oc-
currences of a name in a mention refer to the same
entity (e.g., occurrences of the string “Apple” in a
single mention either all refer to the IT company
or all refer to the fruit) (Wang et al., 2012).
TED is defined as follows.
Definition 1 (Targeted Entity Disambiguation).
Given input of a target entity set E = {e
1
, ..., e
n
},
a mention set D = {d
1
, ..., d
n
} and candidate
mentions R = {(e
i
, d
j
)|e
i
? E, d
j
? D}, out-
put score r
ij
? [0, 1] for every candidate mention
(e
i
, d
j
) ? R.
3 Related Work
Wang et al. (2012) proposed MentionRank to ad-
dress TED. MentionRank is similar to PageRank.
This model is based on three hypotheses:
1. Context similarity: The true mentions
across all the entities, across all the mentions
will have more similar contexts than the false
mentions of different entities.
2. Co-Mention: If multiple target entities are
co-mentioned in a mention, they are likely to
be true mentions.
3. Interdependency: If one or more men-
tions among the ones with similar context is
deemed likely to be a true mention, they are
all likely to be true mentions.
In a mention graph, a node (e
i
, d
j
) denotes an
entity e
i
in mention d
j
. The weight of edge be-
tween (e
i
, d
j
) and (e
?
i
, d
?
j
) is denoted as w
ij,i
?
j
?
which is a variable normalized by context similar-
ity µ
ij,i
?
j
?
. Context similarities are normalized to
avoid “false-boost” problem. “false-boost” prob-
lem is boosting ranking score of false mentions in
a false mentions group. The normalized weight of
the edge is defined as follows:
w
ij,i
?
j
?
=
{
z
ij
k
if i = i
?
,
µ
i
?
j
?
,ij
V
i
Z
+
z
ij
k
otherwise.
(1)
z
ij
= 1 ?
?
i
?
?=i
?
j
?
µ
i
?
j
?
,ij
V
i
Z
, (2)
Z = max
i,j
?
i
?
?=i
?
j
?
µ
i
?
j
?
,ij
V
i
, (3)
where, V
i
denotes the number of candidate men-
tions that contain e
i
(i.e. V
i
= |{d
j
|(e
i
, d
j
) ?
R}|). k denotes the number of all candidate men-
tions (i.e. k = |R|). Co-mention is represented
by a prior score. Wang et al. (2012) defined
prior score pi
ij
of (e
i
, d
j
) as the number of unique
names of target entities occurred in d
j
.
The final score of each mention is decided by
its prior score estimation as well as the score of
the other correlated mentions.
r
ij
= ?p
ij
+ (1 ? ?)
?
i
?
,j
?
w
ij,i
?
j
?
r
i
?
j
?
, (4)
where ? is the dumping factor. p
ij
denotes prior
score of (e
i
, d
j
): p
ij
= pi
ij
/
?
i
?
,j
?
pi
i
?
j
?
Although this model works even if only the
names of entities are given as input, we can ex-
tend this model to integrate external knowledge
such as Wikipedia. For example, we can add refer-
ence pages for each entity as virtual nodes. Since
we can assume that the reference page of a tar-
get entity is a true mention with a high confidence,
we assign a high prior score than the other men-
tions. This causes the group of candidate men-
tions which have similar contexts with the refer-
ence pages to get higher scores. One example of
using reference pages is to add a set of reference
pages {a
i
|1 ? i ? n} into the mention graph. a
i
denotes the reference page of entity e
i
.
4 Proposed Method
In this section, we propose our approach for auto-
matic selection of reference pages. In the domain
of Word Sense Disambiguation and Entity Link-
ing, some researches proposed the methods which
107
Figure 1: Article “Apple (disambiguation)” in
Wikipedia
are based on coherence between mentions (Hof-
fart et al., 2011; Kulkarni et al., 2009; Han et al.,
2011). Our method does not require any knowl-
edge except for the names of target entities. We
give only target entities as input. Target entities in
Wikipedia have two characteristics.
• A name of an ambiguous target entity tends
to have a disambiguation page.
• The articles that are in the same domain have
the same categories or contain similar con-
tents.
In Wikipedia, there are disambiguation pages like
Figure 1. “Apple (disambiguation)” contains apple
as a plant, an IT company, a music album, and so
on. To collect candidate reference pages, we use
these disambiguation pages.
Kulkarni et al. (2009) formalized entity linking
as an Integer Linear Programming problem and
then relaxed it as a Linear Programming problem.
They considered a coherence score which takes
higher value if the selected articles have similar
contents. Their framework can be used for entity
linking and word sense disambiguation. In this pa-
per, we use this coherence score to select reference
pages. We show an image of an automatic selec-
tion of reference pages in Figure 2. In Figure 2,
the target entities are Apple, HP and Microsoft.
Although we have only one page for Microsoft,
we have two or more candidate reference pages,
since Apple and HP have disambiguation pages.
Then we need to select reference pages for Ap-
ple and HP. If the name of a target entity is not
in Wikipedia, we have no reference page for that
Figure 2: Automatic selection of reference pages
from disambiguation pages in Wikipedia: selected
pages contains same categories or similar contents
(They are connected by edge).
target entity. The goal of this example is to select
“Apple Inc.” for Apple and “Hewlett-Packard” for
HP (Selecting “Microsoft” for Microsoft is triv-
ial). We regard these selected articles as reference
pages for target entities.
We assume that the number of true reference
page a
i
for target entity e
i
is one and select one
reference page for each target entity. For each tar-
get entity, we select articles which the have same
categories or similar contents from the set of can-
didate reference pages {c
ik
|1 ? k ? l} since we
assume that the articles in the same domain have
the same categories or contain similar contents. In
fact, our model is going to maximize the summa-
tion of similarities between selected pages under
some constraints. We formalize this selection as
follows:
max .
?
i,k
?
i
?
,k
?
e
ik,i
?
k
?
x
ik,i
?
k
?
,
s.t . ?i,
?
k
y
ik
= 1, (5)
y
ik
? x
ik,i
?
k
?
; ?i, k, i
?
, k
?
, (6)
y
i
?
k
?
? x
ik,i
?
k
?
; ?i, k, i
?
, k
?
, (7)
x
ik,i
?
k
?
? {0, 1}; ?i, k, i
?
, k
?
, (8)
y
ik
? {0, 1}; ?i, k, (9)
e
ik,i
?
k
?
denotes the weight of the edge between
candidate reference pages c
ik
and c
i
?
k
?
. x
ik,i
?
k
?
takes 1 if c
ik
is selected, 0 otherwise. y
ik
takes
1 if the edge between c
ik
and c
i
?
k
?
is selected, 0
108
n k #cand %Positive
Car 21 1809 21.5 29.9
Magazine 28 2741 17.9 43.5
Table 1: Datasets: n is # of entities, k is # of can-
didate mentions, #cand is average # of candidate
reference pages for each entity and %Positive is %
of true mentions in all candidate mentions
n=5 Car Magazine
MentionRank 39.74 61.07
MentionRank+manVN 39.14 70.94†
MentionRank+randomVN 37.85† 65.01
Proposed method 44.21 65.86
n=10
MentionRank 49.23 65.90†
MentionRank+manVN 47.21† 70.85
MentionRank+randomVN 45.13† 68.38
Proposed method 50.84 69.81
n=15
MentionRank 46.50† 65.77†
MentionRank+manVN 44.29 69.38
MentionRank+randomVN 39.21† 67.89
Proposed method 42.77 69.02
Table 2: Mean average precision for each dataset
otherwise. Constraint (5) ensures that always one
article is selected for each entity. Constraints (6)
and (7) ensure that when x
ik,i
?
k
?
= 1, y
ik
and y
i
?
k
?
.
In this paper, we defined e
ik,i
?
k
?
as cosine similar-
ity of two vectors of words those weights are tfidf.
5 Experiments
We used weblogs written in Japanese for experi-
ments. Following the previous work, we created
two datasets: Car and Magazine. A summary of
each dataset is shown in Table 1.
• Car: Target entities include car names such
as Prius and Harrier.
• Magazine: Target entities include magazine
names such as MORE and LEE.
We randomly selected 5, 10 or 15 entities from
each target entities for 10 times and conducted
experiment for each dataset with parameter ?
= 0.15. We conducted significance test using
Wilcoxon signed-rank test. Table 2 lists the
experimental results on these datasets. In Ta-
ble 2, MentionRank+manVN denotes Mention-
Rank with virtual nodes that are selected manually
(Wang et al., 2012). MentionRank+randomVN
denotes MentionRank with virtual nodes that are
selected randomly from candidate reference pages
in Wikipedia. Proposed method denotes the Men-
tionRank with virtual nodes that are selected auto-
matically using ILP. Values with †in Table 2 indi-
cate that there are significant differences between
mean average precision of proposed method and
the others. Five results of proposed methods are
better than those of MentionRank, there are signif-
icant differences on two results. Furthermore, all
the results of proposed method is better than those
of MentionRank+randomVN and there are signif-
icant differences on three results. Four results of
proposed method is worse than those of Mention-
Rank+manVN, however there is a significant dif-
ference on only one of those results. From these
results, we can see that use of reference pages
automatically selected by our method improves
mean average precision. In Magazine, several en-
tities are not ambiguous and we could get true ref-
erence pages easily. Therefore, we think proposed
method did not show any significant differences
compared with MentionRank+randomVN. Also,
in Car, several entities are not ambiguous but these
reference pages belong to domains other than Car
domain. As a result, we think that some results
are worse than MentionRank. For example, entity
“86” which is a kind of car have only one reference
page that belongs to number domain.
6 Conclusion
In this paper, we proposed an automatic selec-
tion method of reference pages for Target En-
tity Disambiguation. Our method that uses au-
tomatically selected reference pages showed bet-
ter performance than MentionRank without ref-
erence pages and competitive mean average pre-
cision with MentionRank with manually selected
reference pages.
Since our framework always selects one refer-
ence page for each target entity even if a reference
page does not exist in Wikipedia or one or more
reference pages exist in Wikipedia, we need to re-
fine our framework in future work. An another im-
provement would be to assign prior scores for vir-
tual nodes according to coherence score between
the other virtual nodes.
109
References
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective
entity linking in web text: a graph-based method. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, SIGIR ’11, pages 765–774, New
York, NY, USA. ACM.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc Span-
iol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ’11, pages 782–792, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. 2009. Collective annota-
tion of Wikipedia entities in web text. In Proceed-
ings of the 15th ACM SIGKDD international con-
ference on Knowledge discovery and data mining,
KDD ’09, pages 457–466, New York, NY, USA.
ACM.
Roberto Navigli. 2009. Word sense disambiguation:
A survey. ACM Comput. Surv., 41(2):10:1–10:69,
February.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical Report
1999-66, Stanford InfoLab, November.
Chi Wang, Kaushik Chakrabarti, Tao Cheng, and Sura-
jit Chaudhuri. 2012. Targeted disambiguation of
ad-hoc, homogeneous sets of named entities. In
Proceedings of the 21st international conference on
World Wide Web, WWW ’12, pages 719–728, New
York, NY, USA. ACM.
110
