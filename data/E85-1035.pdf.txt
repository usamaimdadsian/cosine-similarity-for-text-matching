AUTOMATED SPEECH RECOGNITION:  
A FRAMEWORK FOR RESEARCH 
Anne Johnstone 
Department  of Ar t i f i c ia l  Inte l l igence 
Ed inburgh Un ivers i ty  
Hope Park Square, Meadow Lane 
Ed inburgh EHB 9LL. (GB) 
ABSTRACT 
This paper ref lects  the v iew that the 
decod ing of speech, e i ther by computer  
systems or people, must to a large extent  
be determined by the ways in which the 
speaker has encoded the in format ion  
necessary  for its comprehension.  We 
therefore  place great emphasis  on the use 
of psycho l ingu is t i cs  as a tool for the 
const ruct ion  of models  essent ia l  to the 
character i sa t ion  of the speech 
understand ing  task. 
We are pr imar i ly  concerned with the 
interact ions  between the var ious levels at 
which a f ragment of speech can be 
descr ibed (e.g. acoust ic -phonet ic ,  
lexical, syntact ic,  etc), and the ways in 
which the knowledge bases assoc ia ted  with 
each of these "levels" contr ibute  towards 
a final in terpretat ion  of an utterance.  We 
propose to use the Chart  Parser  as a 
general  computat iona l  f ramework for 
s imulat ing such interact ions,  s ince its 
f lex ib i l i ty  a l lows var ious models to be 
implemented and evaluated. 
With in  this general  f ramework we 
discuss problems of in format ion f low and 
search st rategy in combin ing ev idence 
across levels of descr ip t ion  and across 
time, dur ing the extens ion of an 
hypothesis .  We stress the importance of 
both psycholog ica l  and computat iona l  
theory in deve lop ing a par t icu lar  control  
strategy which could be implemented with in  
the framework. 
In t roduct ion  
The decoding of speech, e i ther by 
computer  systems or people, must to a 
large extent be determined by the ways in 
which the speaker has encoded the 
in format ion  necessary  for its 
comprehension.  Such a view is supported by 
a large body of exper imenta l  ev idence 
concern ing the ways in which var ious 
factors (eg. p red ic tab i l i ty  from context) 
af fect  both the acoust ic  c lar i ty  with 
which a speaker  pronounces an utterance,  
and the strategy the hearer appears to use 
in ident i fy ing  it. The task of the 
Gerry A l tmann 
Depar tment  of L ingu is t ics  
Ed inburgh Un ivers i ty  
George Square 
Ed inburgh EHB 9LL. (GB) 
compu-£er system is to mimic, though 
pre ferab ly  model, this strategy. In order  
to do so, one should presumably  draw on 
both computat iona l  and psycho log ica l  
theor ies of process. Such a dual approach  
has been shown to be feasible, and indeed 
desirable,  by research into ear ly v isual  
p rocess ing  (eg. Marr  1976) which has shown 
that there can come a point  when 
psycho log ica l  and computat iona l  
descr ip t ions  become bare ly  
d is t ingu ishab le .  This ana logy with ear ly  
v isual  process ing is s ign i f i cant  because 
centra l  to the deve lopment  of the v is ion  
research was the not ion of 'model l ing':  
one can argue that a s ign i f i cant  
d i f fe rence  between the so-ca l led  '4th 
Generat ion'  and '5th Genera£ion'  
techno log ies  is that with the former ad- 
hoc a lgor i thms are appl ied to of ten 
incomplete  and unre l iab le  data, whi le  with 
5th Generat ion  systems, a lgor i thms are 
dev ised by f i rst  const ruct ing  qua l i ta t ive  
models  sui ted to the task domain. 
We propose to use psycho l ingu is t i cs  
as a tool for the const ruct ion  of models  
essent ia l  to the character i sa t ion  of the 
speech unders tand ing  task. We bel ieve that 
this approach is essent ia l  to the 
deve lopment  of automated speech 
recogn i t ion  systems, and wil l  a lso prove 
benef ic ia l  to psycho log ica l  models  of 
human speech processing,  the major i ty  of 
which are underdetermined  from a 
computat iona l  point of view. Rumelhar t  and 
McCle l land  have recent ly  adopted a s imi lar  
approach to account  for the major f indings 
in the psycho log ica l  l i terature  on letter  
percept ion.  By const ruct ing  a deta i led  
computat iona l  model  of the processes  
involved they were able to give an 
a l te rnat ive  descr ip t ion  of the recogn i t ion  
of certa in letter strings, which was 
supported by subsequent  psycho l ingu is t i c  
exper iments.  Rumelhar t  and McCle l land  
emphas ise  the point  that their  resul ts  
were not pred ic tab le  'on paper', but were 
the outcome of cons iderab le  
exper imentat ion  with the computat iona l  
model. 
239 
Requirements of the Computat ional  
Framework 
The experience of the ARPA speech 
project, which resulted in the design of a 
number of speech recognit ion systems, has 
demonstrated that the task of control l ing 
the interactions between the knowledge 
bases which make up the system is at least 
as problematic as that of def ining the 
knowledge bases. Major inadequacies in 
the systems developed during the ARPA 
project can be attr ibuted to an early 
commitment in one or more areas of design 
which were not apparent until final 
testing and evaluation of the complete 
system began. An architecture is 
required, therefore, which will permit the 
development in parallel and relat ively 
independently of component knowledge bases 
and methods of deploying them 
computationally. It should also permit 
the evaluation and testing of solutions 
with partial ly specif ied or simulated 
components. This will ensure that the 
design of one component will not inf luence 
unduly the design of any other component, 
possibly to the detr iment of both. In 
addition, we should have the abi l i ty to 
determine the consequences of component 
design decisions by testing their 
contributions to the overall  goals of 
speech recognition. 
In order to fulfi l l  these 
requirements we propose to use the active 
chart parser (e.g. Thompson & Ritchie, 
1984). This was specif ical ly designed as 
a flexible framework for the 
implementation (both serial and para l le l )  
of di f ferent rule systems, and the 
evaluation of strategies for using these 
rule systems. It is described below in 
more detail. 
The Computational Model 
The problem in designing optimal 
control or search strategies lies in 
combining evidence across dif ferent levels 
of descr ipt ion (e.g. acoustic-phonetic,  
morpho-phonemic, syntactic, etc.), and 
across time during the extension of a 
hypothesis, such that promising 
interpretations are given priority and the 
right one wins. In this section we shall 
consider just a few of the issues 
concerning this flow of information. 
Automated speech systems, in 
particular those implemented during the 
ARPA-SUR project, have been forced to 
confront the errorful l  and ambiguous 
nature of speech, and to devise methods of 
control l ing the very large search space of 
partial interpretations generated during 
processing. Although the problem was 
exacerbated by the poor performance of the 
acoust ic-phonetic processing used in these 
systems, the experimental  evidence 
suggests that the solution will not be 
found simply by improving techniques for 
low-level feature detection. The 
situation appears to be analogous to that 
of visual processing, where "s ign i f i cant"  
features may be absent. If present, their 
s igni f icance may also be open to a number 
of interpretations. 
Combining evidence across di f ferent 
levels of descr ipt ion requires the 
speci f icat ion of information flow between 
these levels. Within the psychological  
l iterature, there is a growing tendency 
away from "strong" (or "instructive") 
interactions towards "weak" (or 
"selective") interactions. With the 
latter, the only permissible flow of 
information involves the f i l tering out, by 
one component, of a l ternat ives produced by 
other components (cf. Mars len-Wi lson & 
Tyler, 1980; Crain & Steedman, 1982; 
Altmann & Steedman, forthcoming), so in 
hierarchical  terms no component determines 
what is produced by any other component 
beneath it. A strong interaction, on the 
other hand, al lows one component to 
direct, or guide, @ctively a second 
component in the pursuit  of a part icular 
hypothesis. Within the computat ional  
l iterature, weak interact ions are also 
argued for on "aesthetic" grounds such as 
Marr's pr inciples of modular i ty and least 
commitment (Mart, 1982). 
The strongly interact ive 
heterarchical  and blackboard models 
implemented in HWIM and Hearsay II 
respect ively have been cr i t ic ised for the 
extremely complex control strategies which 
they required. Problems arise with the 
heterarchical  model "because of the 
di f f icult ies of generating each of the 
separate interfaces and, more importantly, 
because of the necessity of specifying the 
expl icit  control scheme." (Reddy & Erman, 
1975). Similar problems arise with 
exist ing blackboard models. Their 
information flow allows strong top-down 
direct ion of components, result ing once 
again in highly complex control 
strategies. Hierarchical  models have 
other problems, in that they al low too 
little interact ion between the knowledge 
sources: within a str ict ly hierarchical  
system, one cannot "interleave" the 
processes associated with each dif ferent 
level of knowledge, and hence one cannot 
al low the very early f i l tering out by 
higher- level  components of what might only 
be partial analyses at lower levels. This 
situation (considered disadvantageous for 
reasons of speed and efficiency) arises 
because of the lack of any common 
workspace over which the separate 
components can operate. There is, 
however, much to be said for h ierarchical  
systems in terms of the relat ive 
240 
s impl ic i ty  of the control  s t rategies  
needed to manage them, a cons iderat ion  
which is fundamenta l  to the des ign of any 
speech recogn i t ion  system. 
The model current ly  being deve loped 
embodies a weak h ierarch ica l  interact ion,  
s ince this seems most promis ing on both 
psycho log ica l  and computat iona l  grounds. 
Unl ike ex ist ing h ierarch ica l  or 
assoc iat ive  models, it uses a un i form 
global data structure,  a "chart". 
Assoc iated with this s t ructure  is the 
act ive chart parser. 
The act ive chart  parser consists  of 
the fo l lowing: -  
I) A un i form global  data st ructure  (the 
Chart), represents  compet ing pathways 
through a search space, at d i f fe rent  
levels of descr ipt ion,  and at d i f fe rent  
stages of analysis.  Complete  descr ip t ions  
are marked by " inact ive" paths, cal led 
edges, spanning tempora l ly  def ined 
port ions of the utterance. These inact ive 
edges have pointers to the lower level 
descr ipt ions  which support  them. Part ia l  
descr ipt ions  are marked by "active" edges 
which carry representat ions  of the data 
needed to complete them. For example, a 
syntact ic  edge, such as a noun phrase, may 
span any complete descr ip t ions  that 
part ia l ly  support  it, such as a determiner  
or adject ive.  In addit ion,  it wi l l  carry 
a descr ipt ion  of the syntact ic  propert ies  
(e.g. noun) any inact ive lexical  edge must 
have to count both as add i t iona l  ev idence 
for this syntact ic  descr ip t ion  and as 
just i f icat ion for its extens ion or 
complet ion. The type and complex i ty  of 
the descr ipt ions  are determined by the 
rule based knowledge systems used by the 
parser, and are not determined by the 
parser itself. 
2) A mul t i - leve l  task queueing st ructure  
(the Agenda), which is used to order the 
ways in which the descr ip t ions  wil l  be 
extended, through time and level of 
abstract ion,  and thus to control  the size 
and d i rect ion of the search space. This 
order ing on the agenda is contro l led  by 
spec i f ica l ly  des igned search st rategies  
which determine the min imum amount  of 
search compat ib le  with a low rate of error 
in descr ipt ion.  The power  and f lex ib i l i ty  
of this approach in tack l ing complex 
system bui ld ing tasks is well  set out in 
Bobrow et al. 1976). 
3) An a lgor i thm which automat ica l ly  
schedules addi t ions  to the Chart  onto the 
Agenda for subsequent  process ing wherever  
such extens ions are possible.  That is to 
say, whenever a descr ip t ion  which is 
complete at some level (an inact ive  edge) 
can be used to extend a part ia l  
descr ip t ion  at some higher level (an 
act ive edge). The knowledge bases def ine 
what extens ions  are possible,  not the 
parser. 
To summarize,  the chart  is used to 
represent  and extend pathways, through 
t ime and level of abstract ion,  through a 
search space. With in  the chart, there are 
d i f ferent  types of path cor respond ing  to 
d i f fe rent  levels of descr ipt ion,  each of 
which is assoc ia ted  with a par t icu lar  
knowledge source. To the extent that 
knowledge spec i f ic  rules speci fy  what  
counts as const i tuent  pathways at the 
d i f fe rent  levels of abstract ion,  a 
h ierarch ica l  f low in in format ion  is 
mainta ined.  The weak in teract ion  ar ises 
because a l te rnat ive  pathways at one level 
of descr ip t ion  can be f i l tered through 
attempts  to bui ld pathways at the next 
"higher" level. This model  d i f fers  from 
s t ra ight fo rward  h ierarch ica l  models, but 
resembles  assoc ia t ive  models, in that 
knowledge sources cont r ibute  to process ing  
wi thout  each source necessar i l y  
cor respond ing  to a d is t inct  stage of 
analys is  in the process ing  sequence. 
Having sketched the const ruct ion  of 
the search space we must  now dec ide upon a 
st rategy for exp lor ing  that space. Most 
current  psycho log ica l  theor ies  appear  to 
assume str ict  " le f t - to- r ight"  processing,  
a l though this requires  tack l ing  st retches 
of sound immediatedly which are of poor 
acoust ic  qual ity,  and which are re la t ive ly  
unconst ra ined  by higher level knowledge.  
The major i ty  of systems deve loped dur ing 
the ARPA pro ject  found it necessary  to use 
later occurr ing in format ion  to 
d i sambiguate  ear l ier  parts of an 
utterance. Moreover,  there is 
psycho l ingu is t i c  ev idence that the 
" inte l l ig ib i l i ty"  of a par t icu lar  s t retch 
of sound increases with add i t iona l  
ev idence from later "r ightward" s t retches 
of sound (Pol lack & Pickett, 1963; Warren 
& Warren, 1970). We propose to adopt  a 
system using a form of le f t - to - r ight  
analys is  which could approx imate  to the 
power of midd le -out  analys is  (used in HWIM 
and Hearsay II) but w i thout  requ i r ing  the 
const ruct ion  of d is t inct  " is lands" and 
with less computat iona l  expense. This 
more prec ise method of using "r ight- 
context  ef fects" depends on the pr ior i ty  
scores ass igned to paths. Such scores can 
be thought  of, for present  purposes, as 
some measure  of "goodness of fit". The 
score on a spanning pathway (that is, a 
pathway which spans other pathways 
"beneath" it) is determined by the scores 
on its const i tuents,  and so is part ly  
determined by scores towards its r ight-  
hand end. By v i r tue of a f fec t ing  the 
"spanning score", a score on one sub-path  
can af fect  the probab i l i ty  that another  
sub-path to its left (as well  as to its 
241 
right) will f inally be chosen as the best 
descript ion for the acoustic segment it 
represents. We will use psychol inguist ic  
techniques to interrogate the "expert" 
(i.e. stat ist ical ly rel iable experiments 
with human listeners), in order to 
determine both when such leftwards flowing 
information is most often used for the 
disambiguation of poor quality areas, and 
what sets of paths it will affect. It 
will be extremely useful to know whether 
people regularly rely on information from 
the right to disambiguate preceding 
stretches of sound, or whether this 
happens only at the beginning of 
utterances as the HWIM strategy suggests. 
Pollack and Pickett claim that there is no 
effect on intel l ig ibi l i ty of a word's 
position within a stimulus, but 
unfortunately they offer no inferential  
statistics to back this claim. 
This is only one of the many issues 
in speech recognit ion which are 
experimental ly addressable. The results of 
such experiments are obviously of 
relevance to computational systems since 
they can indicate where and when sources 
of information are most l ikely to 
contribute towards identi f icat ion of an 
utterance. Conversely, the attempt to 
build a working model of at least some 
parts of the process, will highl ight many 
areas where further experimental data is 
needed. 
Conc lud ing  Remark  
We hope that this sketch of part of 
the proposed system has given a feel for 
the combined approach taken here. It 
developed through a re-examination of a 
number of issues which arose during the 
ARPA speech project, and a reconsiderat ion 
of these issues in the light of recent 
computational and psychol inguist ic  
advances. Given the success of these 
recent advancements in the contr ibuting 
fields of research, we feel that the time 
is right for the evaluation of a speech 
recognit ion system along the lines laid 
down here. 
ACKNOWLEDGEMENTS 
This is a summary of a paper (Johnstone & 
Altmann, 1984) written as a result of 
discussions held in the University of 
Edinburgh School of Epistemics research 
workshop on Lexical Access and Speech 
Perception. We would like to thank the 
members of that workshop, in particular 
Dr. El len Bard and Dr. Henry Thompson. 
The proposals contained therein have been 
adopted by the Edinburgh contr ibut ion to 
the Plessey Consort ium's Alvey Large Scale 
Demonstrator Project on Machine Assisted 
Speech Transcription. 
REFERENCES 
Altmann, G.T. & Steedman, M.J. 
Forthcoming. The Garden Path in 
Context: Reference and the Resolut ion of 
Local Syntactic Ambiguity. 
Bard, E.G. & Anderson,  A.H. 1983. The 
unintel l ig ib i l i ty  of speech to children. 
Journal of Child Lanuuaqe 10, 265-292 
Crain, S. & Steedman, M.J. 1982. On not 
being led up the garden path: the use of 
context by the psychological  parser. In 
(eds.) Dowty, D., Kartunnen, L., & 
Zwicky, A.  Natural Lanaua~e Parsinu: 
psycholouical, co~putational, and 
theoretical  perspectives. In press. 
Johnstone, A.M. & Altmann, G.T. 1984. 
Automated Speech Recognition: A 
Framework for Research. Department of 
Art i f ic ial  Intell igence, University uf 
Edinburgh, Research Paper No. 233. 
Also appears as Speech Input Project, 
University of Edinburgh, Research Report 
No. 2. 
Marr, D. 1976. Early Processing of 
Visual Information. Proc. Roy. $9c., 
275.b 
Marslen-Wilson, W.D. & Tyler, L.K. 1980. 
The Temporal Structure of Spoken 
Language Understanding. Cognition, 8, 
1-71. 
McClelland, J .L & Rumelhart ,  D.E. 1981. 
An Interactive Act ivat ion Model of 
Context Effects in Letter Perception: 
Part I. An Account of Basic Findings. 
In Psvcholouical  Review, 88, 375-407. 
Pollack, I. & Pickett, J.M. 1963. The 
intel l ig ibi l i ty of excerpts from 
Conversation. Language add Speech, 6, 
165-171. 
Reddy, D.R. & Ermann, L.D. 1975. 
Tutorial on System Organisat ion for 
Speech Understanding. In D.R. Reddy 
(ed) Speech Recognition, Academic Press. 
Rumelhart, D.E. & McClelland, J.L. 1982. 
An Interactive Act ivat ion Model of 
Context Effects in Letter Perception: 
Part II. The Contextual Enhancement 
Effect. Some Tests and Extensions of 
the Model. In Psychological  Review, 89, 
60-94. 
242 
Thompson, H.S. & Ritchie, G.D. 1984. 
Techniques for Parsing Natural Language: 
Two Examples. In M. Eisenstadt & T. 
O'Shea (eds.) Art i f ic ial  Intel l iqence 
Skills. Harper & Row. 
Warren, R.M. & Warren, R.P. 1970. 
Auditory Confusions and Illusions. 
Scientif ic American, 223, 30-36. 
243 
