Automatic Acronym Recognition
Dana Danne´lls
Computational Linguistics, Department of Linguistics and
Department of Swedish Language
Go¨teborg University
Go¨teborg, Sweden
cl2ddoyt@cling.gu.se
Abstract
This paper deals with the problem
of recognizing and extracting acronym-
definition pairs in Swedish medical texts.
This project applies a rule-based method
to solve the acronym recognition task and
compares and evaluates the results of dif-
ferent machine learning algorithms on the
same task. The method proposed is based
on the approach that acronym-definition
pairs follow a set of patterns and other
regularities that can be usefully applied
for the acronym identification task. Su-
pervised machine learning was applied to
monitor the performance of the rule-based
method, using Memory Based Learning
(MBL). The rule-based algorithm was
evaluated on a hand tagged acronym cor-
pus and performance was measured using
standard measures recall, precision and f-
score. The results show that performance
could further improve by increasing the
training set and modifying the input set-
tings for the machine learning algorithms.
An analysis of the errors produced indi-
cates that further improvement of the rule-
based method requires the use of syntactic
information and textual pre-processing.
1 Introduction
There are many on-line documents which contain
important information that we want to understand,
thus the need to extract glossaries of domain-
specific names and terms increases, especially in
technical fields such as biomedicine where the vo-
cabulary is quickly expanding. One known phe-
nomenon in biomedical literature is the growth of
new acronyms.
Acronyms are a subset of abbreviations and
are generally formed with capital letters from the
original word or phrase, however many acronyms
are realized in different surface forms i.e. use
of Arabic-numbers, mixed alpha-numeric forms,
low-case acronyms etc.
Several approaches have been proposed for au-
tomatic acronym extraction, with the most com-
mon tools including pattern-matching techniques
and machine learning algorithms. Considering the
large variety in the Swedish acronym-definition
pairs it is practical to use pattern-matching tech-
niques. These will enable to extract relevant in-
formation of which a suitable set of schema will
give a representation valid to present the different
acronym pairs.
This project presents a rule-based algorithm to
process and automatically detect different forms of
acronym-definition pairs. Since machine learning
techniques are generally more robust, can easily
be retrained for a new data and successfully clas-
sify unknown examples, different algorithms were
tested. The acronym pair candidates recognized
by the rule-based algorithm were presented as fea-
ture vectors and were used as the training data for
the supervised machine learning system.
This approach has the advantage of using ma-
chine learning techniques without the need for
manual tagging of the training data. Several ma-
chine learning algorithms were tested and their re-
sults were compared on the task.
2 Related work
The task of automatically extracting acronym-
definition pairs from biomedical literature has
been studied, almost exclusively for English, over
the past few decades using technologies from Nat-
ural Language Processing (NLP). This section
167
presents a few approaches and techniques that
were applied to the acronym identification task.
Taghva and Gilbreth (1999) present the
Acronyms Finding Program (AFP), based on
pattern matching. Their program seeks for
acronym candidates which appear as upper case
words. They calculate a heuristic score for each
competing definition by classifying words into:
(1) stop words (”the”, ”of”, ”and”), (2) hyphen-
ated words (3) normal words (words that don’t
fall into any of the above categories) and (4) the
acronyms themselves (since an acronym can
sometimes be a part of the definition). The AFP
utilizes the Longest Common Subsequence (LCS)
algorithm (Hunt and Szymanski, 1977) to find all
possible alignments of the acronym to the text,
followed by simple scoring rules which are based
on matches. The performance reported from their
experiment are: recall of 86% at precision of 98%.
An alternative approach to the AFP was pre-
sented by Yeates (1999). In his program, Three
Letters Acronyms (TLA), he uses more complex
methods and general heuristics to match charac-
ters of the acronym candidate with letters in the
definition string, Yeates reported f-score of 77.8%.
Another approach recognizes that the align-
ment between an acronym and its definition of-
ten follows a set of patterns (Park and Byrd,
2001), (Larkey et al., 2000). Pattern-based meth-
ods use strong constraints to limit the number of
acronyms respectively definitions recognized and
ensure reasonable precision.
Nadeau and Turney (2005) present a machine
learning approach that uses weak constraints to re-
duce the search space of the acronym candidates
and the definition candidates, they reached recall
of 89% at precision of 88%.
Schwartz and Hearst (2003) present a simple al-
gorithm for extracting abbreviations from biomed-
ical text. The algorithm extracts acronym candi-
dates, assuming that either the acronym or the def-
inition occurs between parentheses and by giving
some restrictions for the definition candidate such
as length and capital letter initialization. When an
acronym candidate is found the algorithm scans
the words in the right and left side of the found
acronym and tries to match the shortest definition
that matches the letters in the acronym. Their ap-
proach is based on previous work (Pustejovsky et
al., 2001), they achieved recall of 82% at precision
of 96%.
It should be emphasized that the common char-
acteristic of previous approaches in the surveyed
literature is the use of parentheses as indication for
the acronym pairs, see Nadeau and Turney (2005)
table 1. This limitation has many drawbacks
since it excludes the acronym-definition candi-
dates which don’t occur within parentheses and
thereby don’t provide a complete coverage for all
the acronyms formation.
3 Methods and implementation
The method presented in this section is based on
a similar algorithm described by Schwartz and
Hearst (2003). However it has the advantage of
recognizing acronym-definition pairs which are
not indicated by parentheses.
3.1 Finding Acronym-Definition Candidates
A valid acronym candidate is a string of alpha-
betic, numeric and special characters such as ’-’
and ’/’. It is found if the string satisfies the condi-
tions (i) and (ii) and either (iii) or (iv):
(i) The string contains at least two charac-
ters. (ii) The string is not in the list of rejected
words1. (iii) The string contains at least one capi-
tal letter. (iv) The strings’ first or last character is
lower case letter or numeric.
When an acronym is found, the algorithm
searches the words surrounding the acronym for a
definition candidate string that satisfies the follow-
ing conditions (all are necessary in conjunction):
(i) At least one letter of the words in the string
matches the letter in the acronym. (ii) The string
doesn’t contain a colon, semi-colon, question
mark or exclamation mark. (iii) The maximum
length of the string is min(|A|+5,|A|*2), where
|A| is the acronym length (Park and Byrd, 2001).
(iv) The string doesn’t contain only upper case let-
ters.
3.2 Matching Acronyms with Definitions
The process of extracting acronym-definition pairs
from a raw text, according to the constraints de-
scribed in Section 3.1 is divided into two steps:
1. Parentheses matching. In practice, most of
the acronym-definition pairs come inside paren-
theses (Schwartz and Hearst, 2003) and can cor-
respond to two different patterns: (i) defini-
tion (acronym) (ii) acronym (definition). The
1The rejected word list contains frequent acronyms which
appear in the corpus without their definition, e.g. ’USA’,
’UK’, ’EU’.
168
algorithm extracts acronym-definition candidates
which correspond to one of these two patterns.
2. Non parentheses matching. The algorithm
seeks for acronym candidates that follow the con-
straints, described in Section 3.1 and are not en-
closed in parentheses. Once an acronym candidate
is found it scans the previous and following con-
text, where the acronymwas found, for a definition
candidate. The search space for the definition can-
didate string is limited to four words multiplied by
the number of letters in the acronym candidate.
The next step is to choose the correct substring
of the definition candidate for the acronym can-
didate. This is done by reducing the definition
candidate string as follows: the algorithm searches
for identical characters between the acronym and
the definition starting from the end of both strings
and succeeds in finding a correct substring for
the acronym candidate if it satisfies the follow-
ing conditions: (i) at least one character in the
acronym string matches with a character in the
substring of the definition; (ii) the first character
in the acronym string matches the first character
of the leftmost word in the definition substring, ig-
noring upper/lower case letters.
3.3 Machine Learning Approach
To test and compare different supervised learn-
ing algorithms, Tilburg Memory-Based Learner
(TiMBL)2 was used. In memory-based learning
the training set is stored as examples for later eval-
uation. Features vectors were calculated to de-
scribe the acronym-definition pairs. The ten fol-
lowing (numeric) features were chosen: (1) the
acronym or the definition is between parenthe-
ses (0-false, 1-true), (2) the definition appears be-
fore the acronym (0-false, 1-true), (3) the dis-
tance in words between the acronym and the
definition, (4) the number of characters in the
acronym, (5) the number of characters in the def-
inition, (6) the number of lower case letters in the
acronym, (7) the number of lower case letters in
the definition, (8) the number of upper case let-
ters in the acronym, (9) the number of upper case
letters in the definition and (10) the number of
words in the definition. The 11th feature is the
class to predict: true candidate (+), false candi-
date (-). An example of the acronym-definition
pair ?”vCJD”, ”variant CJD”? represented as
a feature vector is: 0,1,1,4,11,1,7,3,3,2,+.
2http://ilk.uvt.nl
4 Evaluation and Results
4.1 Evaluation Corpus
The data set used in this experiment consists of
861 acronym-definition pairs. The set was ex-
tracted from Swedish medical texts, the MEDLEX
corpus (Kokkinakis, 2006) and was manually an-
notated using XML tags. For the majority of the
cases there exist one acronym-definition pair per
sentence, but there are cases where two or more
pairs can be found.
4.2 Experiment and Results
The rule-based algorithm was evaluated on the un-
tagged MEDLEX corpus samples. Recall, pre-
cision and F-score were used to calculate the
acronym-expansion matching. The algorithm rec-
ognized 671 acronym-definition pairs of which 47
were incorrectly identified. The results obtained
were 93% precision and 72.5% recall, yielding F-
score of 81.5%.
A closer look at the 47 incorrect acronym pairs
that were found showed that the algorithm failed
to make a correct match when: (1) words that
appear in the definition string don’t have a corre-
sponding letter in the acronym string, (2) letters
in the acronym string don’t have a corresponding
word in the definition string, such as ”PGA” from
”glycol alginate lo¨sning”, (3) letters in the defini-
tion string don’t match the letters in the acronym
string.
The error analysis showed that the reasons for
missing 190 acronym-definition pairs are: (1) let-
ters in the definition string don’t appear in the
acronym string, due to a mixture of a Swedish
definition with an acronym written in English,
(2) mixture of Arabic and Roman numerals, such
as ”USH3” from ”Usher typ III”, (3) position of
numbers/letters, (4) acronyms of three characters
which appear in lower case letters.
4.3 Machine Learning Experiment
The acronym-definition pairs recognized by the
rule-based algorithm were used as the training ma-
terial in this experiment. The 671 pairs were pre-
sented as feature vectors according to the features
described in Section 3.3. The material was di-
vided into two data files: (1) 80% training data;
(2) 20% test data. Four different algorithms were
used to create models. These algorithms are: IB1,
IGTREE, TRIBL and TRIBL2. The results ob-
tained are given in Table 1.
169
Algorithm Precision Recall F-score
IB1 90.6 % 97.1 % 93.7 %
IGTREE 95.4 % 97.2 % 96.3 %
TRIBL 92.0 % 96.3 % 94.1 %
TRIBL2 92.8 % 96.3 % 94.5 %
Table 1: Memory-Based algorithm results.
5 Conclusions
The approach presented in this paper relies on
already existing acronym pairs which are seen
in different Swedish texts. The rule-based algo-
rithm utilizes predefined strong constraints to find
and extract acronym-definition pairs with differ-
ent patterns, it has the advantage of recognizing
acronyms and definitions which are not indicated
by parentheses. The recognized pairs were used
to test and compare several machine learning al-
gorithms. This approach does not requires manual
tagging of the training data.
The results given by the rule-based algorithm
are as good as reported from earlier experiments
that have dealt with the same task for the English
language. The algorithm uses backward search al-
gorithm and to increase recall it is necessary to
combine it with forward search algorithm.
The variety of the Swedish acronym pairs is
large and includes structures which are hard to de-
tect, for example: ?”V F”, ”kammarflimmer”?
and ?”CT”, ”datortomografi”?, the acronym
is in English while the extension is written in
Swedish. These structures require a dictio-
nary/database lookup3, especially because there
are also counter examples in the Swedish text
where both the acronym and the definition are in
English. Another problematic structure is three
letter acronyms which consist of only lowercase
letters since there are many prepositions, verbs and
determinates that correspond to this structure. To
solve this problem it may be suitable to combine
textual pre-processing such as part-of-speech an-
notation or/and parsing with the exiting code.
The machine learning experiment shows that
the best results were given by the IGTREE algo-
rithm4. Performance can further improve by mod-
ifying the input settings e.g test different feature
weighting schemes, such as Shared Variance and
3Due to short time available and the lack of resources this
feature was not used in the experiment.
4The IGTREE algorithm uses information gain in a com-
pressed decision tree structure.
Gain Ratio and combine different values of k for
the k-nearest neighbour classifier5.
On-going work aim to improve the rule-based
method and combine it with a supervised machine
learning algorithm. The model produced will later
be used for making prediction on a new data.
Acknowledgements
Project funded in part by the SematicMining EU
FP6 NoE 507505. This research has been car-
ried out thanks to Lars Borin and Dimitrios Kokki-
nakis. I thank Torbjo¨rn Lager for his guidance
and encouragement. I would like to thank Walter
Daelemans, Ko van der Sloot Antal van den Bosch
and Robert Andersson for their help and support.
References
Ariel S. Schwartz and Marti A. Hearst. 2003. A simple
algorithm for identifying abbreviation definitions in
biomedical texts. Proc. of the Pacific Symposium on
Biocomputing. University of California, Berkeley.
David Nadeau and Peter Turney. 2005. A Supervised
Learning Approach to Acronym Identification. In-
formation Technology National Research Council,
Ottawa, Ontario, Canada.
Dimitrios Kokkinakis. 2006. Collection, Encoding
and Linguistic Processing of a Swedish Medical
Corpus: The MEDLEX Experience. Proc. of the 5th
LREC. Genoa, Italy.
James W. Hunt and Thomas G. Szymanski. 1977. A
fast algorithm for computing longest common sub-
sequences. Commun. of the ACM, 20(5):350-353.
James Pustejovsky, Jose´ Castan¨o, Brent Cochran, Ma-
ciej Kotecki and Michael Morrella. 2001. Au-
tomation Extraction of Acronym-MeaningPairs from
Medline Databases. In Proceedings of Medinfo.
Kazen Taghva and Jeff Gilbreth. 1999. Technical Re-
port. Recognizing Acronyms and their Definitions.
University of Nevada, Las Vegas.
Leah S. Larkey, Paul Ogilvie, Andrew M. Price and
Brenden Tamilio. 2000. Acrophile: An Automated
Acronym Extractor and Server. University of Mas-
sachusetts, Dallas TX.
Stuart Yeates. 1999. Automatic extraction of acronyms
from text. Proc. of the Third New Zealand Computer
Science Research Students’ Conference. University
of Waikato, New Zealand.
Youngja Park and Roy J. Byrd. 2001. Hybrid Text Min-
ing for Finding Abbreviations and Their Definitions.
IMB Thomas J. Watson Research Center, NY, USA.
5In the machine learning experiment default value is used,
k=1.
170
