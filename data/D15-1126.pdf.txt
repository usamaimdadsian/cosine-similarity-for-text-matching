Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1079–1083,
Lisbon, Portugal, 17-21 September 2015.
c©2015 Association for Computational Linguistics.
Supervised Phrase Table Triangulation with Neural Word Embeddings
for Low-Resource Languages
Tomer Levinboim and David Chiang
Department of Computer Science and Engineering
University of Notre Dame
{levinboim.1,dchiang}@nd.edu
Abstract
In this paper, we develop a supervised
learning technique that improves noisy
phrase translation scores obtained by
phrase table triangulation. In particular,
we extract word translation distributions
from small amounts of source-target bilin-
gual data (a dictionary or a parallel corpus)
with which we learn to assign better scores
to translation candidates obtained by trian-
gulation. Our method is able to gain im-
provement in translation quality on two
tasks: (1) On Malagasy-to-French transla-
tion via English, we use only 1k dictionary
entries to gain +0.5 Bleu over triangula-
tion. (2) On Spanish-to-French via English
we use only 4k sentence pairs to gain +0.7
Bleu over triangulation interpolated with
a phrase table extracted from the same 4k
sentence pairs.
1 Introduction
Phrase-based statistical machine translation sys-
tems require considerable amounts of source-
target parallel data to produce good quality trans-
lation. However, large amounts of parallel data are
available for only a fraction of language pairs, and
mostly when one of the languages is English.
Phrase table triangulation (Utiyama and Isa-
hara, 2007; Cohn and Lapata, 2007; Wu and
Wang, 2007) is a method for generating source-
target phrase tables without having access to any
source-target parallel data. The intuition behind
triangulation (and pivoting techniques in general)
is the transitivity of translation: if a source lan-
guage phrase s translates to a pivot language
phrase p which in turn translates to a target lan-
guage phrase t, then s should likely translate to t.
Following this intuition, a triangulated source-
target phrase table
ˆ
T can be composed from a
source-pivot and pivot-target phrase table (§2).
However, the resulting triangulated phrase table
ˆ
T contains many spurious phrase pairs and noisy
probability estimates. Therefore, early triangula-
tion work (Wu and Wang, 2007) already realis-
tically assumed access to a limited source-target
parallel data from which a relatively high-quality
source-target phrase table T can be directly esti-
mated. The two phrase tables were then combined,
resulting in a higher quality phrase table that pro-
poses translations for many source phrases not
found in T . Wu and Wang (2007) report that in-
terpolation of the two phrase tables T and
ˆ
T leads
to higher quality translations. However, the trian-
gulated phrase table
ˆ
T is obtained without using
the source-target bilingual data, which suggests
that the source-target data is not used as fully as
it could be.
In this paper, we develop a supervised learning
algorithm that corrects triangulated word transla-
tion probabilities by relying on word translation
distributions w
sup
derived from the limited source-
target data. In particular, we represent source and
target words using word embeddings (Mikolov
et al., 2013) and learn a transformation between
the two embedding spaces in order to approxi-
mate w
sup
, thus down-weighting incorrect trans-
lation candidates proposed by triangulation (§3).
By representing words as embeddings, our model
can generalize the information contained in the
source-target data (as encoded in the distributions
w
sup
) to a much larger vocabulary, and can as-
sign lexical-weighting probabilities to most of the
phrase pairs in
ˆ
T .
Fixing English as the pivot language (the
most realistic pivot language choice), on a low-
resource Spanish-to-French translation task our
model gains +0.7 Bleu on top of standard phrase
table interpolation. On Malagasy-to-French trans-
lation, our model gains +0.5 Bleu on top of tri-
angulation when using only 1k Malagasy-French
dictionary entries (§4).
1079
2 Preliminaries
Let s, p, t denote words and s,p, t denote phrases
in the source, pivot, and target languages, respec-
tively. Also, let T denote a phrase table estimated
over a parallel corpus and
ˆ
T denote a triangu-
lated phrase table. We use similar notation for their
respective phrase translation features ?, lexical-
weighting features lex, and the word translation
probabilities w.
2.1 Triangulation (weak baseline)
In phrase table triangulation, a source-target
phrase table T
st
is constructed by combining a
source-pivot and pivot-target phrase table T
sp
,T
pt
,
each estimated on its respective parallel data. For
each resulting phrase pair (s, t), we can also com-
pute an alignment
ˆ
a as the most frequent align-
ment obtained by combining source-pivot and
pivot-target alignments a
sp
and a
pt
across all pivot
phrases p as follows: {(s, t) | ?p : (s, p) ? a
sp
?
(p, t) ? a
pt
}.
The triangulated source-to-target lexical
weights, denoted
?
lex
st
, are approximated in two
steps: First, word translation scores wˆ
st
are ap-
proximated by marginalizing over the pivot words:
wˆ
st
(t | s) =
?
p
w
sp
(p | s) · w
pt
(t | p). (1)
Next, given a (triangulated) phrase pair (s, t) with
alignment
ˆ
a, let
ˆ
a
s,:
= {t | (s, t) ?
ˆ
a}; the lexical-
weighting probability is (Koehn et al., 2003):
?
lex
st
(t | s, ˆa) =
?
s?s
1
|
ˆ
a
s,:
|
?
t?
ˆ
a
s,:
wˆ
st
(t | s). (2)
The triangulated phrase translation scores, de-
noted
ˆ
?
st
, are computed by analogy with Eq. 1.
We also compute these scores in the reverse
direction by swapping the source and target lan-
guages.
2.2 Interpolation (strong baseline)
Given access to source-target data, an ordinary
source-target phrase table T
st
can be estimated di-
rectly. Wu and Wang (2007) suggest interpolating
phrase pairs entries that occur in both tables:
T
interp
= ?T
st
+ (1 ? ?)
ˆ
T
st
. (3)
Phrase pairs appearing in only one phrase table are
added as-is. We refer to the resulting table as the
interpolated phrase table.
3 Supervised Word Translations
While interpolation (Eq. 3) may help correct some
of the noisy triangulated scores, its effect is lim-
ited to phrase pairs appearing in both phrase ta-
bles. Here, we suggest a discriminative supervised
learning method that can affect all phrase pairs.
Our idea is to regard word translation distri-
butions derived from source-target bilingual data
(through word alignments or dictionary entries)
as the correct translation distributions, and use
them to learn discriminately: correct target words
should become likely translations, and incorrect
ones should be down-weighted. To generalize be-
yond the vocabulary of the source-target data, we
appeal to word embeddings.
We present our formulation in the source-to-
target direction. The target-to-source direction is
obtained simply by swapping the source and tar-
get languages.
3.1 Model
Let c
sup
st
denote the number of times source word
s was aligned to target word t (in word alignment,
or in the dictionary). We define the word transla-
tion distributions w
sup
(t | s) = c
sup
st
/c
sup
s
, where
c
sup
s
=
?
t
c
sup
st
. Furthermore, let q(t | s) denote the
word translation probabilities we wish to learn and
consider maximizing the log-likelihood function:
arg max
q
L(q) = arg max
q
?
(s,t)
c
sup
st
log q(t | s).
Clearly, the solution q(· | s) := w
sup
(· | s) maxi-
mizes L. However, we would like a solution that
generalizes to source words s beyond those ob-
served in the source-target corpus – in particular,
those source words that appear in the triangulated
phrase table
ˆ
T , but not in T .
In order to generalize, we abstract from words
to vector representations of words. Specifically,
we constrain q to the following parameterization:
q(t | s) =
1
Z
s
exp
(
v
T
s
Av
t
+ f
T
st
h
)
Z
s
=
?
t?T (s)
exp
(
v
T
s
Av
t
+ f
T
st
h
)
.
Here, the vectors v
s
and v
t
represent monolingual
features and the vector f
st
represents bilingual fea-
tures. The parameters A and h are to be learned.
In this work, we use monolingual word embed-
dings for v
s
and v
t
, and set the vector f
st
to con-
tain only the value of the triangulated score, such
1080
that f
st
:= wˆ
st
. Therefore, the matrix A is a lin-
ear transformation between the source and target
embedding spaces, and h (now a scalar) quantifies
how the triangulated scores wˆ are to be trusted.
In the normalization factor Z
s
, we let t range
only over possible translations of s suggested by
either w
sup
or the triangulated word probabilities.
That is:
T (s) = {t | w
sup
(t | s) > 0 ? wˆ(t | s) > 0}.
This restriction makes efficient computation pos-
sible, as otherwise the normalization term would
have to be computed over the entire target vocab-
ulary.
Under this parameterization, our goal is to solve
the following maximization problem:
max
A,h
L(A, h) = max
A,h
?
s,t
c
sup
st
log q(t | s). (4)
3.2 Optimization
The objective function in Eq. 4 is concave in both
A and h. This is because after taking the log, we
are left with a weighted sum of linear and concave
(negative log-sum-exp) terms in A and h. We can
therefore reach the global solution of the problem
using gradient descent.
Taking derivatives, the gradient is
?L
?A
=
?
s,t
m
st
v
s
v
T
t
?L
?h
=
?
s,t
m
st
f
st
where the scalar m
st
= c
sup
st
? c
sup
s
q(t | s) for the
current value of q.
For quick results, we limited the number of gra-
dient steps to 200 and selected the iteration that
minimized the total variation distance to w
sup
over
a held out dev set:
?
s
||q(· | s) ? w
sup
(· | s)||
1
. (5)
We obtained better convergence rate by us-
ing a batch version of the effective and easy-
to-implement Adagrad technique (Duchi et al.,
2011). See Figure 1.
3.3 Re-estimating lexical weights
Having learned the model (A and h), we can now
use q(t | s) to estimate the lexical weights (Eq. 2)
of any aligned phrase pairs (s, t, ˆa), assuming it is
composed of embeddable words.
0 50 100 150 200Iteration
0
10
20
30
40
50
60
70
80
Erro
r (To
tal V
aria
tion
 x 1
00)
French to Spanish
train, with adagraddev, with adagradtrain, no adagraddev, no adagrad
Figure 1: The (target-to-source) objective function
per iteration. Applying batch Adagrad (blue) sig-
nificantly accelerates convergence.
However, we found the supervised word trans-
lation scores q to be too sharp, sometimes assign-
ing all probability mass to a single target word. We
therefore interpolated q with the triangulated word
translation scores wˆ:
q
?
= ?q + (1 ? ?)wˆ. (6)
To integrate the lexical weights induced by q
?
(Eq. 2), we simply appended them as new features
in the phrase table in addition to the existing lexi-
cal weights. Following this, we can search for a ?
value that maximizes Bleu on a tuning set.
3.4 Summary of method
In summary, to improve upon a triangulated or in-
terpolated phrase table, we:
1. Learn word translation distributions q by super-
vision against distributions w
sup
derived from
the source-target bilingual data (§3.1).
2. Smooth the learned distributions q by interpo-
lating with triangulated word translation scores
wˆ (§3.3).
3. Compute new lexical weights and append them
to the phrase table (§3.3).
4 Experiments
To test our method, we conducted two low-
resource translation experiments using the
phrase-based MT system Moses (Koehn et al.,
2007).
1081
4.1 Data
Fixing the pivot language to English, we applied
our method on two data scenarios:
1. Spanish-to-French: two related languages
used to simulate a low-resource setting. The
baseline is phrase table interpolation (Eq. 3).
2. Malagasy-to-French: two unrelated languages
for which we have a small dictionary, but no
parallel corpus (aside from tuning and testing
data). The baseline is triangulation alone (there
is no source-target model to interpolate with).
Table 1 lists some statistics of the bilin-
gual data we used. European-language bitexts
were extracted from Europarl (Koehn, 2005). For
Malagasy-English, we used the Global Voices par-
allel data available online.
1
The Malagasy-French
dictionary was extracted from online resources
2
and the small Malagasy-French tune/test sets were
extracted
3
from Global Voices.
lines of data
language pair train tune test
sp-fr 4k 1.5k 1.5k
mg-fr 1.1k 1.2k 1.2k
sp-en 50k – –
mg-en 100k – –
en-fr 50k – –
Table 1: Bilingual datasets. Legend: sp=Spanish,
fr=French, en=English, mg=Malagasy.
Table 2 lists token statistics of the monolin-
gual data used. We used word2vec
4
to generate
French, Spanish and Malagasy word embeddings.
The French and Spanish embeddings were (in-
dependently) estimated over their combined to-
kenized and lowercased Gigaword
5
and Leipzig
news corpora.
6
The Malagasy embeddings were
similarly estimated over data form Global Voices,
7
the Malagasy Wikipedia and the Malagasy Com-
mon Crawl.
8
In addition, we estimated a 5-gram
French language model over the French monolin-
gual data.
1
http://www.ark.cs.cmu.edu/global-voices
2
http://motmalgache.org/bins/homePage
3
https://github.com/vchahun/gv-crawl
4
https://radimrehurek.com/gensim/models/word2vec.html
5
http://catalog.ldc.upenn.edu
6
http://corpora.uni-leipzig.de/download.html
7
http://www.isi.edu/˜qdou/downloads.html
8
https://commoncrawl.org/the-data/
language words
French 1.5G
Spanish 1.4G
Malagasy 58M
Table 2: Size of monolingual corpus per language
as measured in number of tokens.
4.2 Spanish-French Results
To produce w
sup
, we aligned the small Spanish-
French parallel corpus in both directions, and
symmetrized using the intersection heuristic. This
was done to obtain high precision alignments (the
often-used grow-diag-final-and heuristic is opti-
mized for phrase extraction, not precision).
We used the skip-gram model to estimate the
Spanish and French word embeddings and set the
dimension to d = 200 and context window to
w = 5 (default). Subsequently, to run our method,
we filtered out source and target words that either
did not appear in the triangulation, or, did not have
an embedding. We took words that appeared more
than 10 times in the parallel corpus for the training
set (?690 words), and between 5–9 times for the
held out dev set (?530 words). This was done in
both source-target and target-source directions.
In Table 3 we show that the distributions learned
by our method are much better approximations of
w
sup
compared to those obtained by triangulation.
Method source?target target?source
triangulation 71.6% 72.0%
our scores 30.2% 33.8%
Table 3: Average total variation distance (Eq. 5)
to the dev set portion of w
sup
(computed only over
words whose translations in w
sup
appear in the tri-
angulation). Using word embeddings, our method
is able to better generalize on the dev set.
We then examined the effect of appending our
supervised lexical weights. We fixed the word
level interpolation ? := 0.95 (effectively assigning
very little mass to triangulated word translations
wˆ) and searched for ? ? {0.9, 0.8, 0.7, 0.6} in Eq. 3
to maximize Bleu on the tuning set.
Our MT results are reported in Table 4. While
interpolation improves over triangulation alone by
+0.8 Bleu, our method adds another +0.7 Bleu on
top of interpolation, a statistically significant gain
(p < 0.01) according to a bootstrap resampling
significance test (Koehn, 2004).
1082
Method ? tune test
source-target – 26.8 25.3
triangulation – 29.2 28.4
interpolation 0.7 30.2 29.2
interpolation+our scores 0.6 30.8 29.9
Table 4: Spanish-French Bleu scores. Append-
ing lexical weights obtained by supervision over
a small source-target corpus significantly out-
performs phrase table interpolation (Eq. 3) by
+0.7 Bleu.
4.3 Malagasy-French Results
For Malagasy-French, the w
sup
distributions used
for supervision were taken to be uniform distri-
butions over the dictionary translations. For each
training direction, we used a 70%/30% split of the
dictionary to form the train and dev sets.
Having significantly less Malagasy monolin-
gual data, we used d = 100 dimensional embed-
dings and a w = 3 context window to estimate both
Malagasy and French words.
As before, we added our supervised lexical
weights as new features in the phrase table. How-
ever, instead of fixing ? = 0.95 as above, we
searched for ? ? {0.9, 0.8, 0.7, 0.6} in Eq. 6 to max-
imize Bleu on a small tune set. We report our re-
sults in Table 5. Using only a dictionary, we are
able to improve over triangulation by +0.5 Bleu, a
statistically significant difference (p < 0.01).
Method ? tune test
triangulation – 12.2 11.1
triangulation+our scores 0.6 12.4 11.6
Table 5: Malagasy-French Bleu. Supervision with
a dictionary significantly improves upon simple
triangulation by +0.5 Bleu.
5 Conclusion
In this paper, we argued that constructing a trian-
gulated phrase table independently from even very
limited source-target data (a small dictionary or
parallel corpus) underutilizes that parallel data.
Following this argument, we designed a super-
vised learning algorithm that relies on word trans-
lation distributions derived from the parallel data
as well as a distributed representation of words
(embeddings). The latter enables our algorithm to
assign translation probabilities to word pairs that
do not appear in the source-target bilingual data.
We then used our model to generate new lexi-
cal weights for phrase pairs appearing in a trian-
gulated or interpolated phrase table and demon-
strated improvements in MT quality on two tasks.
This is despite the fact that the distributions (w
sup
)
we fit our model to were estimated automatically,
or even na¨?vely as uniform distributions.
Acknowledgements
The authors would like to thank Daniel Marcu and
Kevin Knight for initial discussions and a sup-
portive research environment at ISI, as well as the
anonymous reviewers for their helpful comments.
This research was supported in part by a Google
Faculty Research Award to Chiang.
References
Trevor Cohn and Mirella Lapata. 2007. Machine
translation by triangulation: Making effective use of
multi-parallel corpora. In Proc. ACL, pages 728–
735.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. J. Machine Learning
Research, 12:2121–2159, July.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
NAACL HLT, pages 48–54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?rej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proc. ACL, Interactive Poster and Demon-
stration Sessions, pages 177–180.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proc. EMNLP,
pages 388–395.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. MT Summit,
pages 79–86.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In Proc. ICLR, Workshop
Track.
Masao Utiyama and Hitoshi Isahara. 2007. A com-
parison of pivot methods for phrase-based statistical
machine translation. In Proc. HLT-NAACL, pages
484–491.
Hua Wu and Haifeng Wang. 2007. Pivot language ap-
proach for phrase-based statistical machine transla-
tion. In Proc. ACL, pages 856–863.
1083
