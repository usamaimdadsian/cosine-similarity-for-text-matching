Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 148–153,
Gothenburg, Sweden, April 26-30 2014.
c©2014 Association for Computational Linguistics
Integrating an Unsupervised Transliteration Model into
Statistical Machine Translation
Nadir Durrani
University of Edinburgh
dnadir@inf.ed.ac.uk
Hieu Hoang Philipp Koehn
University of Edinburgh
hieu.hoang,pkoehn@inf.ed.ac.uk
Hassan Sajjad
Qatar Computing Research Institute
hsajjad@@qf.org.qa
Abstract
We investigate three methods for integrat-
ing an unsupervised transliteration model
into an end-to-end SMT system. We in-
duce a transliteration model from parallel
data and use it to translate OOV words.
Our approach is fully unsupervised and
language independent. In the methods
to integrate transliterations, we observed
improvements from 0.23-0.75 (? 0.41)
BLEU points across 7 language pairs. We
also show that our mined transliteration
corpora provide better rule coverage and
translation quality compared to the gold
standard transliteration corpora.
1 Introduction
All machine translation (MT) systems suffer from
the existence of out-of-vocabulary (OOV) words,
irrespective of the amount of data available for
training. OOV words are mostly named entities,
technical terms or foreign words that can be trans-
lated to the target language using transliteration.
Much work (Al-Onaizan and Knight, 2002;
Zhao et al., 2007; Kashani et al., 2007; Habash,
2009) has been done on transliterating named enti-
ties and OOVs, and transliteration has been shown
to improve MT quality. Transliteration has also
shown to be useful for translating closely related
language pairs (Durrani et al., 2010; Nakov and
Tiedemann, 2012), and for disambiguation (Her-
mjakob et al., 2008; Azab et al., 2013). How-
ever, despite its utility, a transliteration module
does not exist in the commonly used MT toolk-
its, such as Moses (Koehn et al., 2007). One of the
main reasons is that the training data, a corpus of
transliteration pairs, required to build a translitera-
tion system, is not readily available for many lan-
guage pairs. Even if such a training data is avail-
able, mechanisms to integrate transliterated words
into MT pipelines are unavailable in these toolkits.
Generally, a supervised transliteration system is
trained separately outside of an MT pipeline, and
a na¨?ve approach, to replace OOV words with their
1-best transliterations in the post/pre-processing
step of decoding is commonly used.
In this work i) we use an unsupervised model
based on Expectation Maximization (EM) to in-
duce transliteration corpus from word aligned par-
allel data, which is then used to train a translitera-
tion model, ii) we investigate three different meth-
ods for integrating transliteration during decoding,
that we implemented within the Moses toolkit. To
the best of our knowledge, our work is the fore-
most attempt to integrate unsupervised translitera-
tion model into SMT.
This paper is organized as follows. Section 2
describes the unsupervised transliteration mining
system, which automatically mines transliteration
pairs from the same word-aligned parallel corpus
as used for training the MT system. Section 3 de-
scribes the transliteration model that is trained us-
ing the automatically extracted pairs. Section 4
presents three methods for incorporating translit-
eration into the MT pipeline, namely: i) replac-
ing OOVs with the 1-best transliteration in a post-
decoding step, ii) selecting the best translitera-
tion from the list of n-best transliterations using
transliteration and language model features in a
post-decoding step, iii) providing a transliteration
phrase-table to the decoder on the fly where it
can consider all features to select the best translit-
eration of OOV words. Section 5 presents re-
sults. Our integrations achieved an average im-
provement of 0.41 BLEU points over a competi-
tive baseline across 7 language pairs (Arabic, Ben-
gali, Farsi, Hindi, Russian, Telugu and Urdu-into-
English). An additional experiment showed that
our system provides better rule coverage as op-
posed to another built from gold standard translit-
eration corpus and produces better translations.
148
2 Transliteration Mining
The main bottleneck in building a transliteration
system is the lack of availability of translitera-
tion training pairs. It is, however, fair to assume
that any parallel data would contain a reasonable
number of transliterated word pairs. Transliter-
ation mining can be used to extract such word
pairs from the parallel corpus. Most previous
techniques on transliteration mining generally use
supervised and semi-supervised methods (Sherif
and Kondrak, 2007; Jiampojamarn et al., 2010;
Darwish, 2010; Kahki et al., 2012). This con-
strains the mining solution to language pairs for
which training data (seed data) is available. A few
researchers proposed unsupervised approaches to
mine transliterations (Lee and Choi, 1998; Sajjad
et al., 2011; Lin et al., 2011). We adapted the work
of Sajjad et al. (2012) as summarized below.
Model: The transliteration mining model is a
mixture of two sub-models, namely: a translit-
eration and a non-transliteration sub-model. The
idea is that the transliteration model would as-
sign higher probabilities to transliteration pairs
compared to the probabilities assigned by a non-
transliteration model to the same pairs. Consider a
word pair (e, f), the transliteration model prob-
ability for the word pair is defined as follows:
p
tr
(e, f) =
?
a?Align(e,f)
|a|
?
j=1
p(q
j
)
where Align(e, f) is the set of all possible se-
quences of character alignments, a is one align-
ment sequence and q
j
is a character alignment.
The non-transliteration model deals with the
word pairs that have no character relationship be-
tween them. It is modeled by multiplying source
and target character unigram models:
p
ntr
(e, f) =
|e|
?
i=1
p
E
(e
i
)
|f |
?
i=1
p
F
(f
i
)
The transliteration mining model is defined
as an interpolation of the transliteration sub-model
and the non-transliteration sub-model:
p(e, f) = (1? ?)p
tr
(e, f) + ?p
ntr
(e, f)
? is the prior probability of non-transliteration.
The non-transliteration model does not change
during training. We compute it in a pre-processing
step. The transliteration model learns character
alignment using expectation maximization (EM).
See Sajjad et al. (2012) for more details.
3 Transliteration Model
Now that we have transliteration word pairs, we
can learn a transliteration model. We segment the
training corpus into characters and learn a phrase-
based system over character pairs. The translitera-
tion model assumes that source and target charac-
ters are generated monotonically.
1
Therefore we
do not use any reordering models. We use 4 basic
phrase-translation features (direct, inverse phrase-
translation, and lexical weighting features), lan-
guage model feature (built from the target-side of
mined transliteration corpus), and word and phrase
penalties. The feature weights are tuned
2
on a dev-
set of 1000 transliteration pairs.
4 Integration to Machine Translation
We experimented with three methods for integrat-
ing transliterations, described below:
Method 1: involves replacing OOVs in the out-
put with the 1-best transliteration. The success of
Method 1 is solely contingent on the accuracy of
the transliteration model. Also, it ignores con-
text which may lead to incorrect transliteration.
For example, the Arabic word transliterates
to “Bill” when followed by “Clinton” and “Bell”
if preceded by “Alexander Graham”.
Method 2: provides n-best transliterations to
a monotonic decoder that uses a monolingual
language model and a transliteration phrase-
translation table to rescore transliterations. We
carry forward the 4 translation model features used
in the transliteration system to build a transliter-
ation phrase-table. We additionally use an LM-
OOV feature which counts the number of words
in a hypothesis that are unknown to the lan-
guage model. Smoothing methods such as Kneser-
Ney assign significant probability mass to unseen
events, which may cause the decoder to make in-
correct transliteration selection. The LM-OOV
feature acts as a prior to penalize such hypotheses.
Method 3: Method 2 can not benefit from all in-
decoding features and phenomenon like reorder-
ing. It transliterates Urdu compound
(Arabian Sea) to “Sea Arabian”, if is an un-
known word. In method 3, we feed the translitera-
tion phrase-table directly into the first-pass decod-
ing which allows reordering of UNK words. We
1
Mining algorithm also makes this assumption.
2
Tuning data is subtracted from the training corpus while
tuning to avoid over-fitting. After the weights are tuned, we
add it back, retrain GIZA, and estimate new models.
149
use the decoding-graph-backoff option in Moses,
that allows multiple translation phrase tables and
back-off models. As in method 2, we also use the
LM-OOV feature in method 3.
3
5 Evaluation
Data: We experimented with 7 language pairs,
namely: Arabic, Bengali, Farsi, Hindi, Russian,
Telugu and Urdu-into-English. For Arabic
4
and
Farsi, we used the TED talks data (Cettolo et al.,
2012) made available for IWSLT-13, and we used
the dev2010 set for tuning and the test2011 and
test2012 sets for evaluation. For Indian languages
we used the Indic multi-parallel corpus (Post et
al., 2012), and we used the dev and test sets pro-
vided with the parallel corpus. For Russian, we
used WMT-13 data (Bojar et al., 2013), and we
used half of the news-test2012 for tuning and other
half for testing. We also evaluated on the news-
test2013 set. For all, we trained the language
model using the monolingual WMT-13 data. See
Table 1 for data statistics.
Lang Train
tm
Train
tr
Dev Test
1
Test
2
AR 152K 6795 887 1434 1704
BN 24K 1916 775 1000
FA 79K 4039 852 1185 1116
HI 39K 4719 1000 1000
RU 2M 302K 1501 1502 3000
TE 45K 4924 1000 1000
UR 87K 9131 980 883
Table 1: No. of sentences in Training Data and
Mined Transliteration Corpus (Types) (Train
tr
)
Baseline Settings: We trained a Moses system
replicating the settings used in competition-grade
systems (Durrani et al., 2013b; Birch et al., 2013):
a maximum sentence length of 80, GDFA sym-
metrization of GIZA++ alignments (Och and Ney,
2003), an interpolated Kneser-Ney smoothed 5-
gram language model with KenLM (Heafield,
2011) used at runtime, a 5-gram OSM (Dur-
rani et al., 2013a), msd-bidirectional-fe lexical-
3
Method 3 is desirable in cases where the decoder can
translate or transliterate a word. For example Hindi word
can be translated to “Border” and also transliterated
to name “Seema”. Identifying such candidates that can be
translated or transliterated is a challenge. Machine learning
techniques (Goldwasser and Roth, 2008; Kirschenbaum and
Wintner, 2009) and named entity recognizers (Klementiev
and Roth, 2006; Hermjakob et al., 2008) have been used for
this purpose. Though, we only focus on OOV words, method
3 can be used if such a classifier/NE tagger is available.
4
Arabic and Urdu are segmented using MADA (Habash
and Sadat, 2006) and UWS (Durrani and Hussain, 2010).
ized reordering, sparse lexical and domain fea-
tures (Hasler et al., 2012), a distortion limit of
6, 100-best translation options, MBR decoding
(Kumar and Byrne, 2004), Cube Pruning (Huang
and Chiang, 2007), and the no-reordering-over-
punctuation heuristic. We tuned with the k-best
batch MIRA (Cherry and Foster, 2012).
5
Transliteration Miner: The miner extracts
transliterations from a word-aligned parallel cor-
pus. We only used word pairs with 1-to-1 align-
ments.
6
Before feeding the list into the miner, we
cleaned it by removing digits, symbols, word pairs
where source or target is composed from less than
3 characters, and words containing foreign char-
acters that do not belong to this scripts. We ran
the miner with 10 iterations of EM. The number
of transliteration pairs (types) extracted for each
language pair is shown in Table 1 (Train
tr
).
Transliteration System: Before evaluating our
integrations into the SMT system, we performed
an intrinsic evaluation of the transliteration system
that we built from the mined pairs. We formed
test data for Arabic–English (1799 pairs), Hindi–
English (2394 pairs) and Russian–English (1859
pairs) by concatenating the seed data and gold
standard transliteration pairs both provided for the
Shared Task on Transliteration mining (Kumaran
et al., 2010). Table 2 shows precision and recall of
the mined transliteration system (MTS).
AR HI RU
Precision (1-best Accuracy) 20.0% 25.3% 46.1%
Recall (100-best Accuracy) 80.2% 79.3% 87.5%
Table 2: Precision and Recall of MTS
The precision (1-best accuracy) of the translit-
eration model is quite low. This is because the
transliteration corpus is noisy and contains imper-
fect transliteration pairs. For example, the miner
extracted the pair ( , Australasia), while
the correct transliteration is “Australia”. We can
improve the precision by tightening the mining
threshold probability. However, our end goal is to
improve end-to-end MT and not the transliteration
system. We observed that recall is more important
than precision for overall MT quality. We provide
an empirical justification for this when discussing
the final experiments.
5
Retuning the transliteration features was not helpful, de-
fault weights are used.
6
M-N/1-N alignments are less likely to be transliterations.
150
MT Experiments: Table 3 gives a comprehen-
sive evaluation of the three methods of integra-
tion discussed in Section 4 along with the num-
ber
7
of OOV words (types) in different tests. We
report BLEU gains (Papineni et al., 2002) obtained
by each method. Method 1 (M
1
), that replaces
OOV words with 1-best transliteration gave an av-
erage improvement of +0.13. This result can be at-
tributed to the low precision of the transliteration
system (Table 2). Method 2 (M
2
), that translit-
erates OOVs in second pass monotonic decoding,
gave an average improvement of +0.39. Slightly
higher gains were obtained using Method 3 (M
3
),
that integrates transliteration phrase-table inside
decoder on the fly. However, the efficacy of M
3
in
comparison to M
2
is not as apparent, as M
2
pro-
duced better results than M
3
in half of the cases.
Lang Test B
0
M
1
M
2
M
3
OOV
AR iwslt
11
26.75 +0.12 +0.36 +0.25 587
iwslt
12
29.03 +0.10 +0.30 +0.27 682
BN jhu
12
16.29 +0.12 +0.42 +0.46 1239
FA iwslt
11
20.85 +0.10 +0.40 +0.31 559
iwslt
12
16.26 +0.04 +0.20 +0.26 400
HI jhu
12
15.64 +0.21 +0.35 +0.47 1629
RU wmt
12
33.95 +0.24 +0.55 +0.49 434
wmt
13
25.98 +0.25 +0.40 +0.23 799
TE jhu
12
11.04 -0.09 +0.40 +0.75 2343
UR jhu
12
23.25 +0.24 +0.54 +0.60 827
Avg 21.9 +0.13 +0.39 +0.41 950
Table 3: End-to-End MT Evaluation – B
0
=
Baseline, M
1
= Method
1
, M
2
= Method
2
, M
3
=
Method
3
, BLEU gains shown for each method
In an effort to test whether improving translit-
eration precision would improve end-to-end SMT
results, we carried out another experiment. Instead
of building a transliteration system from mined
corpus, we built it using the gold standard corpus
(for Arabic, Hindi and Russian), that we also used
previously to do an intrinsic evaluation. We then
replaced our mined transliteration systems with
the gold standard transliteration systems, in the
best performing SMT systems for these languages.
Table 4 shows a comparison of performances. Al-
though the differences are small, systems using
mined transliteration system (MTS) outperformed
its counterpart that uses gold standard translitera-
tion system (GTS), except in Hindi–English where
7
Note that not all OOVs can be transliterated. This num-
ber is therefore an upper bound what can be transliterated.
both systems were equal.
AR HI RU
iwslt
11
iwslt
12
jhu
12
wmt
12
iwslt
13
MTS 27.11 29.33 16.11 34.50 26.38
GST 26.99 29.20 16.11 34.33 26.22
Table 4: Comparing Gold Standard Transliteration
(GST) and Mined Transliteration Systems
In the error analysis we found that the GST
system suffered from sparsity and did not pro-
vide enough coverage of rules to produce right
transliterations. For example, Arabic drops the
determiner (al), but such additions were not
observed in gold transliteration pairs. Arabic
word (Gigapixel) is therefore translit-
erated to “algegabksl”. Similarly the GST system
learned no transliteration pairs to account for the
rule “b ? p” and therefore erroneously translit-
erated (Spurlock) to “Sbrlok”. Similar
observations were true for the case of Russian–
English. The rules “a? u” and “y? ” were not
observed in the gold set, and hence
(hurricane) was transliterated to “herricane” and
(Talbot) to “Talboty”. This shows that
better recall obtained from the mined pairs led to
overall improvement.
6 Conclusion
We incorporated unsupervised transliteration min-
ing model into standard MT pipeline to automati-
cally transliterate OOV words without needing ad-
ditional resources. We evaluated three methods
for integrating transliterations on 7 language pairs
and showed improvements ranging from 0.23-0.75
(? 0.41) BLEU points. We also showed that our
mined transliteration corpus provide better recall
and overall translation quality compared to the
gold standard transliteration corpus. The unsu-
pervised transliteration miner and its integration
to SMT has been made available to the research
community via the Moses toolkit.
Acknowledgments
We wish to thank the anonymous reviewers and
Kareem Darwish for their valuable feedback on
an earlier draft of this paper. The research lead-
ing to these results has received funding from
the European Union Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
n
?
287658. This publication only reflects the au-
thors’ views.
151
References
Yaser Al-Onaizan and Kevin Knight. 2002. Translat-
ing Named Entities Using Monolingual and Bilin-
gual Resources. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics.
Mahmoud Azab, Houda Bouamor, Behrang Mohit, and
Kemal Oflazer. 2013. Dudley North visits North
London: Learning When to Transliterate to Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 439–444, Atlanta, Georgia, June. Association
for Computational Linguistics.
Alexandra Birch, Nadir Durrani, and Philipp Koehn.
2013. Edinburgh SLT and MT System Description
for the IWSLT 2013 Evaluation. In Proceedings
of the 10th International Workshop on Spoken Lan-
guage Translation, pages 40–48, Heidelberg, Ger-
many, December.
Ondrej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut,
and Lucia Specia. 2013. Findings of the 2013
Workshop on Statistical Machine Translation. In
Eighth Workshop on Statistical Machine Transla-
tion, WMT-2013, pages 1–44, Sofia, Bulgaria.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. WIT
3
: Web Inventory of Transcribed
and Translated Talks. In Proceedings of the 16
th
Conference of the European Association for Ma-
chine Translation (EAMT), pages 261–268, Trento,
Italy, May.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427–436, Montr´eal, Canada, June. Associa-
tion for Computational Linguistics.
Kareem Darwish. 2010. Transliteration Mining with
Phonetic Conflation and Iterative Training. In Pro-
ceedings of the 2010 Named Entities Workshop, Up-
psala, Sweden.
Nadir Durrani and Sarmad Hussain. 2010. Urdu Word
Segmentation. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 528–536, Los Angeles, California,
June. Association for Computational Linguistics.
Nadir Durrani, Hassan Sajjad, Alexander Fraser, and
Helmut Schmid. 2010. Hindi-to-Urdu Machine
Translation through Transliteration. In Proceedings
of the 48th Annual Conference of the Association for
Computational Linguistics, Uppsala, Sweden.
Nadir Durrani, Alexander Fraser, Helmut Schmid,
Hieu Hoang, and Philipp Koehn. 2013a. Can
Markov Models Over Minimal Translation Units
Help Phrase-Based SMT? In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, Sofia, Bulgaria, August. Asso-
ciation for Computational Linguistics.
Nadir Durrani, Barry Haddow, Kenneth Heafield, and
Philipp Koehn. 2013b. Edinburgh’s Machine Trans-
lation Systems for European Language Pairs. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria, August. As-
sociation for Computational Linguistics.
Dan Goldwasser and Dan Roth. 2008. Active Sam-
ple Selection for Named Entity Transliteration. In
Proceedings of ACL-08: HLT, Short Papers, pages
53–56, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Nizar Habash and Fatiha Sadat. 2006. Arabic Pre-
processing Schemes for Statistical Machine Transla-
tion. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Companion Vol-
ume: Short Papers, pages 49–52, New York City,
USA, June. Association for Computational Linguis-
tics.
Nizar Habash. 2009. REMOOV: A Tool for Online
Handling of Out-of-Vocabulary Words in Machine
Translation. In Proceedings of the Second Interna-
tional Conference on Arabic Language Resources
and Tools, Cairo, Egypt, April. The MEDAR Con-
sortium.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2012.
Sparse Lexicalised Features and Topic Adaptation
for SMT. In Proceedings of the seventh Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 268–275.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187–197, Edinburgh, Scotland, United King-
dom, 7.
Ulf Hermjakob, Kevin Knight, and Hal Daum´e III.
2008. Name Translation in Statistical Machine
Translation - Learning When to Transliterate. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, Columbus, Ohio.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 144–151, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Sittichai Jiampojamarn, Kenneth Dwyer, Shane
Bergsma, Aditya Bhargava, Qing Dou, Mi-Young
Kim, and Grzegorz Kondrak. 2010. Transliteration
152
Generation and Mining with Limited Training Re-
sources. In Proceedings of the 2010 Named Entities
Workshop, Uppsala, Sweden.
Ali El Kahki, Kareem Darwish, Ahmed Saad El Din,
and Mohamed Abd El-Wahab. 2012. Transliter-
ation Mining Using Large Training and Test Sets.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ’12.
Mehdi M. Kashani, Eric Joanis, Roland Kuhn, George
Foster, and Fred Popowich. 2007. Integration of
an Arabic Transliteration Module into a Statistical
Machine Translation System. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, Prague, Czech Republic.
Amit Kirschenbaum and Shuly Wintner. 2009. Lightly
Supervised Transliteration for Machine Translation.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), pages 433–
441, Athens, Greece, March. Association for Com-
putational Linguistics.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proceedings of the
Human Language Technology Conference of the
NAACL, Main Conference, pages 82–88, New York
City, USA, June. Association for Computational
Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics, Demon-
stration Program, Prague, Czech Republic.
Shankar Kumar and William J. Byrne. 2004. Mini-
mum Bayes-Risk Decoding for Statistical Machine
Translation. In HLT-NAACL, pages 169–176.
A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010.
Whitepaper of news 2010 shared task on transliter-
ation mining. In Proceedings of the 2010 Named
Entities Workshop, pages 29–38, Uppsala, Sweden,
July. Association for Computational Linguistics.
Jae-Sung Lee and Key-Sun Choi. 1998. English
to Korean Statistical Transliteration for Information
Retrieval. Computer Processing of Oriental Lan-
guages, 12(1):17–37.
Wen-Pin Lin, Matthew Snover, and Heng Ji. 2011.
Unsupervised Language-Independent Name Trans-
lation Mining from Wikipedia Infoboxes. In Pro-
ceedings of the First workshop on Unsupervised
Learning in NLP, pages 43–52, Edinburgh, Scot-
land, July. Association for Computational Linguis-
tics.
Preslav Nakov and J¨org Tiedemann. 2012. Com-
bining Word-Level and Character-Level Models for
Machine Translation Between Closely-Related Lan-
guages. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 301–305, Jeju
Island, Korea, July. Association for Computational
Linguistics.
Franz J. Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Mod-
els. Computational Linguistics, 29(1).
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, ACL ’02, pages 311–318, Mor-
ristown, NJ, USA.
Matt Post, Chris Callison-Burch, and Miles Osborne.
2012. Constructing Parallel Corpora for Six Indian
Languages via Crowdsourcing. In Proceedings of
the Seventh Workshop on Statistical Machine Trans-
lation, pages 401–409, Montr´eal, Canada, June. As-
sociation for Computational Linguistics.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2011. An Algorithm for Unsupervised Translitera-
tion Mining with an Application to Word Alignment.
In Proceedings of the 49th Annual Conference of
the Association for Computational Linguistics, Port-
land, USA.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2012. A Statistical Model for Unsupervised and
Semi-supervised Transliteration Mining. In Pro-
ceedings of the 50th Annual Conference of the Asso-
ciation for Computational Linguistics, Jeju, Korea.
Tarek Sherif and Grzegorz Kondrak. 2007. Bootstrap-
ping a Stochastic Transducer for Arabic-English
Transliteration Extraction. In Proceedings of the
45th Annual Meeting of the Association for Compu-
tational Linguistics, Prague, Czech Republic.
Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-
gel. 2007. A Log-Linear Block Transliteration
Model based on Bi-Stream HMMs. In Human
Language Technologies 2007: The Conference of
the North American Chapter of the Association for
Computational Linguistics, Rochester, New York.
153
