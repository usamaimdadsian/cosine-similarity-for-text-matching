The Turing Test: Verbal Behavior as the Hallmark of Intelligence
Stuart Shieber (editor)
(Harvard University)
Cambridge, MA: The MIT Press, 2004,
xiii+346 pp; paperbound, ISBN
0-262-69293-7, $30.00, £19.95
Reviewed by
William J. Rapaport
State University of New York at Buffalo
This eagerly awaited anthology, while surely not the last word on the Turing Test,
equally surely deserves to become the principal source of information on the test. It
includes not only Turing’s classic paper, but a fine selection of the main replies to date,
all tied together by an engaging and penetrating essay by the editor.
Stuart M. Shieber’s name is well known to computational linguists for his research
and to computer scientists more generally for his debate on the Loebner Turing Test
competition, which appeared a decade earlier in Communications of the ACM (Shieber
1994a, 1994b; Loebner 1994).1 With this collection, I expect it to become equally well
known to philosophers.
The collection begins with historical “precursors” to Turing’s paper: two pieces
by Descartes—his Discourse on the Method, Chap. V (1637), and his “Letter to the
Marquess of Newcastle”—followed by selections from La Mettrie’s Machine Man
(1748).
The second part contains the centerpiece: Turing’s 1950 paper from Mind, “Com-
puting Machinery and Intelligence,” accompanied by three “ephemera”: two early
(1951) and difficult-to-find articles by Turing—“Intelligent Machinery, a Heretical The-
ory” and “Can Digital Computers Think?”—and a transcript of a 1952 BBC radio
interview with Turing, M. H. A. Newman, Sir Geoffrey Jefferson, and R. B. Braithwaite,
“Can automatic Calculating Machines Be Said to Think?” Shieber’s presentation of the
pie`ce de re´sistance (Turing 1950) devotes great attention to the sanctity of the text and
is replete with scholarly paraphernalia comparing his carefully edited reprint with the
original (which, by the way, is now available online, courtesy of JSTOR.org).
The third, and final, part contains the immediate reactions to Turing’s Mind
paper as they appeared in that journal, followed by now-classic responses and some
more-recent, important papers, some arranged chronologically, others logically. The
first published response was Leonard Pinsky’s early (1951)—and satirical—“Do Ma-
chines Think about Machines Thinking?” for which Shieber offers a brief, wry
introduction. Next we have a quartet consisting of Keith Gunderson’s important “The
Imitation Game” (1964), Richard Purtill’s response (“Beating the Imitation Game,”
1971), and Geoffrey Sampson’s (“In Defence of Turing”) and P. H. Millar’s (“On the
Point of the Imitation Game”) 1973 replies to Purtill. Jumping ahead a couple of decades
comes Robert M. French’s 1990 “Subcognition and the Limits of the Turing Test.”
Next, in more of a logical than a chronological order, comes a trio consisting of John
1 Interestingly, neither Loebner nor his competition are mentioned by name, or even discussed,
in the book under review, though there is a citation to Shieber 1994a.
Computational Linguistics Volume 31, Number 3
R. Searle’s almost equally classic “Minds, Brains, and Programs” (1980), Ned Block’s
important “Psychologism and Behaviorism” (1981), and Daniel C. Dennett’s “Can
Machines Think?” (1985). Skipping back in time a bit, we next have a debate between
James H. Moor (his excellent “An Analysis of the Turing Test,” 1976) and Douglas F.
Stalker (“Why Machines Can’t Think: A Reply to James Moor,” 1978), with Moor’s reply
to Stalker (“Explaining Computer Behavior,” 1978). A gift closes the book: a previously
unpublished essay by Noam Chomsky, “Turing on the ‘Imitation Game.’”
Meandering through these delicacies are Shieber’s introductory remarks to each,
which, taken together, constitute an extended essay on the Turing Test, the issues it
raises, and its significance. Shieber begins his introduction with an analogy that makes
the Turing Test seem as clear and plausible as possible:
How do you tell if something is a meter long? You compare it with an object postulated
to be a meter long. If the two are indistinguishable with regard to the pertinent property,
their length, then you can conclude that the tested object is the given length.
Now, how do you tell if something is intelligent? You compare it with an entity
postulated to be intelligent. If the two are indistinguishable with regard to the pertinent
properties, then you can conclude that the tested entity is intelligent. (page 1)
Shieber observes that the “pertinent property” for “indistinguishability” according to
Turing is “verbal behavior” (in the sense of spoken behavior). This phrase does not
appear in Turing 1950; “behavio[u]r” does, but it is not immediately obvious that it
always means verbal behavior. The phrase brings to mind, of course, B. F. Skinner’s
(1957) famous book of that name, though Shieber ascribes the notion to Descartes
(page 4). Shieber does note that the two cases (meter-measuring and thinking) are not
perfectly parallel:
[U]nlike the case of meter measurement, the identification of the pertinent properties for
intelligence are [sic] subtle, and ramifies widely in the foundation of the philosophy of
mind. (page 1)
That length is the pertinent property for determining meter-hood is uncontroversial. But
exactly what the pertinent property or properties are for assessing intelligence, and whether
verbal behavior in particular is the one, has become the key issue regarding the Turing
Test. (page 8)
This raises what Shieber calls “the Big Question”: “Is passing a Turing Test criterial
for intelligence?” (page 8) or “. . . for thinking” (page 11), where ‘intelligence’ is to be
understood as meaning “being capable of thought” (page 6, note 2).
In the sections called “The Beˆte Machine” and “If Animals Could Talk,” Shieber
discusses the history of “mechanistic marvels” (page 18), beginning with timekeep-
ing devices and how they make “the question of whether real animals are purely
mechanistic” (page 18) a plausible one, leading up to a discussion and analysis
of Descartes’s “beˆte machine” (beast—i.e., animal—machine) and “linguistic test for
distinguishing between human and machine” (page 21), an anticipation of the Turing
Test, in his Discourse.
Further analysis of Descartes appears in the section on “The Homme Machine”
(man—i.e., human—machine), where Shieber shows that many of the responses to
Descartes were empirical attempts to build a machine that was indistinguishable
(in relevant respects) from a living creature (e.g., de Vaucauson’s duck [page 39]).
408
Book Reviews
Compare (at least one of) the goal(s) of modern artificial intelligence, namely, to build a
machine that is indistinguishable (in relevant respects) from a living cognitive agent!
Shieber discusses La Mettrie’s extension of Descartes’s argument to the conclusion
that, in fact, machines can be made indistinguishable from humans, since we humans
are already nothing but machines. Shieber notes that it was only practical limitations
of mechanics (e.g., those due to friction) that prevented further implementations,
many of which limitations have now been transcended by modern electronics.
Obviously, many critics believe that there are theoretical limitations that will never be
transcended, but I wonder if any physical limitations of contemporary electronic devices
might someday be overcome in their turn by some new engineering tricks (such as
optical or quantum computers?).
In “Computer Technology,” the section introducing Turing 1950, Shieber suggests
that Turing played the role with respect to electronic computers that Descartes played
with respect to mechanical devices, asking the same questions, only about different
technology. Here, he also raises “the question of whether the Test is intended as
definitional of the concept of intelligence or substitutive for it” (pages 61– 62). The
rest of this section is devoted to a discussion of the textual differences between this
reprinting and the original. Because of Shieber’s careful scholarly work, it seems to
me that this reprint should become the standard version, possibly even superseding
the original!
Next comes “The Ephemera,” a useful reprinting of the two speeches and the
radio interview that originally appeared shortly after Turing 1950. Shieber’s discussion
focuses on the sidebar issues of when the test might be passed and on the role of gender.
On the former, Shieber takes issue with the famous understanding of Turing 1950 as
having predicted passage by the year 2000; rather, all that Turing predicted would
happen by then was passage of a weaker test. But one of the ephemera gives a figure of
“at least 100 years” (pages 100, 119), that is, no earlier than 2050 (though this still seems
somewhat optimistic to me, and I’m a fan both of “strong AI” and of the Turing Test).
As for the latter, Shieber explores in some depth the question of the confusing roles
of man and woman in the original Imitation Game and whether they are essential in
some way to the human–computer Turing Test (with copious references to the literature
on the topic), noting that the ephemera side with the non-gendered version. (See also
Colby et al. 1972, page 202, and Argamon et al. 2003 for two relevant articles not cited
by Shieber.)
In “The Immediate Responses,” Shieber offers “the Turing syllogism,” an argu-
ment from passing the Turing Test to being intelligent (page 136):
1. Humans are intelligent.
2. The conversational verbal behavior of humans reveals that (human)
intelligence.
3. If an agent has behavior of a type that can reveal intelligence and that is
indistinguishable from that of an intelligent agent, the former agent is
itself intelligent.
4. Any agent that passes the Turing Test has conversational verbal behavior
indistinguishable from that of humans.
Therefore, any agent that passes the Turing Test is intelligent.
409
Computational Linguistics Volume 31, Number 3
This syllogism “is implicitly assumed by all philosophers investigating the ramifi-
cations of the Turing Test beyond” Turing’s limitation that it is intended to replace
the “meaningless” conclusion (pages 136–137). Shieber goes on to consider whether
the Turing Test is a necessary or a sufficient condition of thinking. That intelligent
agents can pass the Turing Test does not follow from premises 1– 4 because of the
possibility of “incidental distinctions” that might prevent an intelligent agent from
passing (page 137). Shieber notes that French’s contribution argues that the Turing
Test is a test of chauvinistically human intelligence, not necessarily of intelligence
simpliciter (see below). As to whether the Test is a sufficient condition of thinking,
Shieber focuses on the circumstantial evidence cited in premise 3 as the weak link
(if an entity walks like a duck, talks like a duck, and is otherwise indistinguishable
from a duck, then is it really a duck?). He notes that there is an easy counterexample
to this premise: the celebrated case of the monkeys and the typewriter (an infinite
number of monkeys working for an infinite amount of time eventually producing the
complete works of Shakespeare). Other counterexamples can be found in Block’s and
Searle’s contributions.
In “The Wedge and the Spark,” Shieber introduces Gunderson’s objection that “net
results” (pages 147, 154) are not enough to decide whether something can think, because
there might be a property that is essential for thought that people, but not machines,
have. (This is an attack on premise 3.) Such a machine is, in Shieber’s terminology,
a “wedge” (page 148) driven between “passing the Turing Test” and “being capa-
ble of thought.” The essential property is a “spark” that would otherwise cause the
wedge to be able to think. Gunderson also argues that it is too easy to pass the Turing
Test, but Shieber argues that this is not the case, based on the difficulties that com-
putational linguists have faced in their investigations of natural-language-processing
tasks.
In subsequent sections, Shieber (1) dismisses Purtill’s chapter for trying to show
that, if computers do think, then perhaps people don’t, citing Sampson’s objection
that “redefining . . . ‘think’ is not” an “option” (page 163); (2) introduces French’s
argument that passing the Turing Test might be so hard that only humans could pass
it, not even other “intelligent beings” (page 182); (3) points out that, according to
Searle’s Chinese Room Argument, the “missing spark” is intentionality (or, perhaps,
consciousness; see page 199, note 1); (4) summarizes Dennett’s original Behavioral
and Brain Sciences reply to Searle; and (5) quotes a long passage by I. J. Good that
presents Turing’s views on consciousness (Turing may have believed that, for a
human to retain consciousness after having parts of his or her brain replaced by elec-
tronic devices, he or she might require at least 1 cubic inch of “original brain tissue”
[page 200]).
If the missing spark isn’t intentionality, perhaps it is “richness of information
processing.” Shieber discusses Block’s move from actually passing a Turing Test
to “the capacity [italics added] to pass” as “a sufficient condition for intelligence”
(page 225), which “vitiates the monkeys and typewriters example” (page 225, note 1).
But how? Presumably, monkeys and typewriters that actually pass the test thereby
also have the capacity to pass it. Block’s Aunt Bertha machine uses a gigantic ta-
ble lookup to pass the test, thus lacking “the richness of information processing”
of a real human. But as Shieber notes, this notion of “richness” is vague. (And
arguably table lookup is computational, hence perhaps cognitive; see Rapaport,
forthcoming.)
In the section introducing Dennett’s supportive view of the test, Shieber cites an
early paper of Turing’s (1947) that mentions an early version of the Turing Test that
410
Book Reviews
Turing may have actually carried out and that contains a hint of Dennett’s intentional
stance (that what counts as “intelligent” may be [partly] in the eye of the observer).
The Moor–Stalker debate is introduced in the only section that mentions Shieber’s
own contribution to the literature. Moor claimed that passing the Turing Test is evidence
of intelligence; the test is neither a definition nor a sufficient condition of intelligence.
In particular, it is good inductive “evidence for Block’s . . . [capacity-]conception of
intelligence” (page 293); that is, it is a statistical proof in the sense of contemporary
“interactive proofs,” about which Shieber has written in a forthcoming essay that I
hope will be included in any future edition of the present book.2 Or possibly, follow-
ing Stalker, it is abductive evidence, that is, an inference to the best explanation; if so, then
(according to Stalker) there is a better explanation, namely, that the entity that passes
is a nonthinking machine. Moor replies in the negative that such a purely mechanical
explanation would apply, in neurophysiological form, to humans, too.
In “Dumping the Big Question,” Shieber presents Dennett’s analysis that Turing
was uninterested in what thinking is but was interested in finding behavior that we
would all agree was thinking and then trying to devise machines that could produce
that behavior. Chomsky’s new essay makes essentially this point.
In conclusion, Shieber observes of the Turing Test that “perhaps like all philo-
sophical quandaries, its role is not as part of an answer but as part of the continual
search for one” (page 323), a view congenial to one that this reviewer once proposed
on how there can be progress in philosophy (Rapaport 1982).
This volume compiles all of the historically important papers surrounding the
Turing Test.3 Like the essay that it celebrates, it is destined to become a classic.
References
Akman, Varol and Patrick Blackburn,
editors. 2000. Alan Turing and artificial
intelligence (special issue). Journal of Logic,
Language and Information, 9(4).
Argamon, Shlomo, Moshe Koppel, Jonathan
Fine, and Anat Rachel Shimoni. 2003.
Gender, genre, and writing style in formal
written texts. Text, 23(3):321–346.
Colby, Kenneth Mark, Franklin Dennis Hilf,
Sylvia Weber, and Helena C. Kraemer.
1972. Turing-like indistinguishability tests
for the validation of a computer simulation
of paranoid processes. Artificial Intelligence,
3:199–221.
Loebner, Hugh Gene. 1994. In response [to
Shieber 1994a]. Communications of the
ACM, 37(6):79–82.
Moor, James H., editor. 2000–2001. The
Turing Test: Past, present and future
(special issues). Minds and Machines, 10(4)
and 11(1).
Moor, James H., (editor). 2003. The
Turing Test: The Elusive Standard of
Artificial Intelligence. Kluwer Academic,
Dordrecht.
Rapaport, William J. 1982. Unsolvable
problems and philosophical progress.
American Philosophical Quarterly
19:289–298.
Rapaport, William J. Forthcoming. The
Turing Test. In The Encyclopedia of Language
and Linguistics, second edition. Oxford:
Elsevier.
Shieber, Stuart M. 1994a. Lessons from a
restricted Turing Test. Communications of
the ACM, 37(6):70–78.
Shieber, Stuart M. 1994b. On Loebner’s
lessons. Communications of the ACM,
37(6):83–84.
Shieber, Stuart M. Forthcoming. The Turing
Test as interactive proof. Nouˆs.
Skinner, B. F. 1957. Verbal Behavior.
Appleton-Century-Crofts, New York.
2 “[A]n interactive proof is a protocol between two parties in which one party, called the prover, tries to
prove a certain fact to the other party, called the verifier. An interactive proof usually takes the form of a
challenge–response protocol, in which the prover and the verifier exchange messages and the verifier
outputs either ”accept” or ”reject” at the end of the protocol” (RSA Laboratories FAQ
[http://www.rsasecurity.com/rsalabs/node.asp?id=2178]).
3 Readers interested in more recent articles can consult several anthologies that celebrated the 50-year
mark: Akman and Blackburn 2000, Moor 2000–2001, and Moor 2003.
411
Computational Linguistics Volume 31, Number 3
Turing, Alan M. 1947. Intelligent machinery.
Machine Intelligence 5:3–23.
Turing, Alan M. 1950. Computing machinery
and intelligence. Mind 59:433–460.
William J. Rapaport is an associate professor in the Department of Computer Science and Engi-
neering, an adjunct professor in the Department of Philosophy, and a member of the Center for
Cognitive Science, all at SUNY Buffalo. His current research is in computational contextual vo-
cabulary acquisition and philosophy of computer science. He has been review editor of Minds and
Machines and on the editorial boards of Computational Linguistics and other journals in philosophy,
computational linguistics, and cognitive science. Rapaport’s address is Department of Computer
Science & Engineering, SUNY Buffalo, Buffalo, NY 14260-2000; e-mail: rapaport@cse.buffalo.edu.
412
