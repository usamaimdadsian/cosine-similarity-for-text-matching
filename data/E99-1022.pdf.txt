Proceedings of EACL '99 
Selective Magic HPSG Parsing 
Guido Minnen* 
Cognitive and Computing Sciences, University of Sussex 
Falmer, Brighton BN1 9QH 
United Kingdom 
Guido.Minnen@cogs.susx.ac.uk 
www.cogs.susx.ac.uk/lab/nlp/minnen/minnen.html 
Abstract 
We propose a parser for constraint- 
logic grammars implementing HPSG 
that combines the advantages of dy- 
namic bottom-up and advanced top- 
down control. The parser allows the 
user to apply magic compilation to spe- 
cific constraints in a grammar which as 
a result can be processed dynamically 
in a bottom-up and goal-directed fash- 
ion. State of the art top-down process- 
ing techniques are used to deal with the 
remaining constraints. We discuss vari- 
ous aspects concerning the implementa- 
tion of the parser as part of a grammar 
development system. 
1 Introduction 
In case of large grammars the space requirements 
of dynamic parsing often outweigh the benefit of 
not duplicating sub-computations. We propose a 
parser that avoids this drawback through combin- 
ing the advantages of dynamic bottom-up and ad- 
vanced top-down control. 1 The underlying idea is 
to achieve faster parsing by avoiding tabling on 
sub-computations which are not expensive. The 
so-called selective magic parser allows the user to 
apply magic compilation to specific constraints in
a grammar which as a result can be processed y- 
namically in a bottom-up and goal-directed fash- 
ion. State of the art top-down processing tech- 
niques are used to deal with the remaining con- 
straints. 
Magic is a compilation technique originally de- 
veloped for goal-directed bottom-up rocessing of 
logic programs. See, among others, (Ramakrish- 
nan et al. 1992). As shown in (Minnen, 1996) 
*The presented research was carried out at the Uni- 
versity of Tfibingen, Germany, as part of the Sonder- 
forschungsbereich 340. 
1A more detailed iscussion of various aspects of 
the proposed parser can be found in (Minnen, 1998). 
magic is an interesting technique with respect o 
natural language processing as it incorporates fil- 
tering into the logic underlying the grammar and 
enables elegant control independent filtering im- 
provements. In this paper we investigate the se- 
lective application of magic to typed feature gram- 
mars a type of constraint-logic grammar based on 
Typed Feature Logic (Tgv£:; GStz, 1995). Typed 
feature grammars can be used as the basis for 
implementations of Head-driven Phrase Structure 
Grammar (HPSG; Pollard and Sag, 1994) as dis- 
cussed in (GStz and Meurers, 1997a) and (Meur- 
ers and Minnen, 1997). Typed feature grammar 
constraints that are inexpensive to resolve are 
dealt with using the top-down interpreter of the 
ConTroll grammar development system (GStz and 
Meurers, 1997b) which uses an advanced search 
function, an advanced selection function and in- 
corporates a coroutining mechanism which sup- 
ports delayed interpretation. 
The proposed parser is related to the so-called 
Lemma Table deduction system (Johnson and 
DSrre, 1995) which allows the user to specify 
whether top-down sub-computations are to be 
tabled. In contrast to Johnson and DSrre's deduc- 
tion system, though, the selective magic parsing 
approach combines top-down and bottom-up con- 
trol strategies. As such it resembles the parser 
of the grammar development system Attribute 
Language Engine (ALE) of (Carpenter and Penn, 
1994). Unlike the ALE parser, though, the selec- 
tive magic parser does not presuppose a phrase 
structure backbone and is more flexible as to 
which sub-computations are tabled/filtered. 
Bottom-up Interpretation of 
Magic-compiled Typed Feature 
Grammars 
We describe typed feature grammars and discuss 
their use in implementing HPSG grammars. Sub- 
sequently we present magic compilation of typed 
165 
Proceedings of EACL '99 
feature grammars on the basis of an example and 
introduce a dynamic bottom-up interpreter that 
can be used for goM-directed interpretation of 
magic-compiled typed feature grammars. 
2.1 Typed Feature  Grammars  
A typed feature grammar consists of a signa- 
ture and a set of definite clauses over the con- 
straint language of equations o fTY£  (GStz, 1995) 
terms (HShfeld and Smolka, 1988) which we will 
refer to as Torz: definite clauses. Equations over 
TJr£ terms can be solved using (graph) unifica- 
tion provided they are in normal form. (GStz, 
1994) describes a normal form for ir~r£ terms, 
where typed feature structures are interpreted as 
satisfiable normal form T~r£: terms. 2 The signa- 
ture consists of a type hierarchy and a set of ap- 
propriateness conditions. 
Example  1 The signature specified in figure 1 
and 2 and the T~r£: definite clauses in figure 3 
constitute an example of a typed feature gram- 
mar. We write T~r£ terms in normal form, i. e., 
relation 
Figure 2: Example of a typed feature grammar 
signature (part 2) 
as typed feature structures. In addition, uninfor- 
mative feature specifications are ignored and typ- 
ing is left implicit when immaterial to the example 
at hand. Equations between typed feature struc- 
tures are removed by simple substitution or tags 
indicating structure sharing. Notice that we also 
use non-numerical tags such as ~ and ~ .  In 
general all boxed items indicate structure sharing. 
For expository reasons we represent he ARGn 
features of the append relation as separate argu- 
ments. 
Typed feature grammars can be used as the 
basis for implementations of Head-driven Phrase 
Structure Grammar (Pollard and Sag, 1994). 3 
(Meurers and Minnen, 1997) propose a compi- 
lation of lexical rules into T~r/: definite clauses 
2This view of typed feature structures differs from 
the perspective on typed feature structures as mod- 
ehng partial information as in (Carpenter, 1992). 
Typed feature structures as normal form ir~'~E terms 
are merely syntactic objects. 
aSee (King, 1994) for a discussion of the appro- 
priateness of T~-£: for HPSG and a comparison with 
other feature logic approaches designed for HPSG. 
(1) constituent( \[PHON ):- 
LSEM 
PHON 
constituent( \[ AGR )' 
I_Sr~M 
teAT° 1 
constituent( |AGR )' 
append(\[~,\[~,\[~). 
rCAT °, \] 
(2) constituent( \[PHON ( ,,,,y ) /xGR ,h.~-,,.~\] )" 
(3) constituent( |PHON (,leCp,) 
/AGR ,h,.~-.,.~ I ). LSEM sleep J 
(4) append((), F'~' ~)"  (5) append( 3 | 
a.ppend(F'x- ~,~,  ~Y's\])- 
Figure 3: Example of a set of T:7:£ definite clauses 
which are used to restrict lexical entries. (GStz 
and Meurers, 1997b) describe a method for com- 
piling implicational constraints into typed feature 
grammars and interleaving them with relational 
constraints. 4 Because of space limitations we have 
to refrain from an example. The ConTroll gram- 
mar development system as described in (GStz 
and Meurers, 1997b) implements the above men- 
tioned techniques for compiling an HPSG theory 
into typed feature grammars. 
2.2 Magic Compi la t ion  
Magic is a compilation technique for goal-directed 
bottom-up processing of logic programs. See, 
among others, (Ramakrishnan et al. 1992). Be- 
cause magic compilation does not refer to the spe- 
cific constraint language adopted, its application 
is not limited to logic programs/grammars: It can 
be applied to relational extensions of other con- 
straint languages such as typed feature grammars 
without further adaptions. 
Due to space limitations we discuss magic com- 
pilation by example only. The interested reader 
is referred to (Nilsson and Maluszynski, 1995) for 
an introduction. 
Example  2 We illustrate magic compilation of 
typed feature grammars with respect to definite 
4 (GStz, 1995) proves that this compilation method 
is sound in the general case and defines the large class 
of type constraints for which it is complete. 
166 
Proceedings of EACL '99 
T 
\ ~ ~ IPHON list \[ 
• k ~ . IAGR agr\[ 
mary / / relation / liY~st elist /g r  ~ r - 
/ ~  nelistk~ "st\[ th+d-sing mary If sleep~_LIBJ sem--\] 
s np v 
Figure h Example of a typed feature grammar signature (part 1) 
clause 1 in figure 3. Consider the TJ:£ definite 
clause in figure 4. As a result of magic compi- 
+\] constituent~ IP"O. ):- \[SZM 
magic_constituent ~) ,  
PHON constituent( \[AGR )' 
I.Sr,~ FEAT" \] 
constituent( \[AGR )' 
LsE \[suBJ Ell 
appendG,D,Vl). 
Figure 4: Magic variant of definite clause 1 in fig- 
ure 3 
lation a magic literal is added to the right-hand 
side of the original definite clause. Intuitively un- 
derstood, this magic literal "guards" the applica- 
tion of the definite clause. The clause is applied 
only when there exists a fact that unifies with this 
magic l iteral) The resulting definite clause is also 
referred to as the magic variant of the original def- 
inite clause. 
The definite clause in figure 5 is the so-called 
seed which is used to make the bindings as pro- 
vided by the initial goal available for bottom-up 
processing. In this case the seed corresponds to 
the initial goal of parsing the string 'mary sleeps'. 
Intuitively understood, the seed makes available 
the bindings of the initial goal to the magic vari- 
SA fact can be a unit clause, i. e., a TJr£ definite 
clause without right-hand side literals, from the gram- 
mar or derived using the rules in the grammar. In the 
latter case one also speaks of a passive dge. 
CAT s 1 magic_constituent( IPHON (m~r~,sl,ep,)). 
\[SZM ,,~ J 
Figure 5: Seed corresponding tothe initial goal of 
parsing the string 'mary sleeps' 
ants of the definite clauses defining a particular 
initial goal; in this case the magic variant of the 
definite clause defining a constituent of category 
's'. Only when their magic literal unifies with the 
seed are these clauses applied. 6
The so-cMled magic rules in figure 6 are derived 
in order to be able to use the bindings provided by 
the seed to derive new facts that provide the bind- 
ings which allow for a goal-directed application of 
the definite clauses in the grammar not directly 
defining the initial goal. Definite clause 3, for 
example, can be used to derive a magic_append 
fact which percolates the relevant bindings of the 
seed/initial goal to restrict the application of the 
magic variant of definite clauses 4 and 5 in figure 3 
(which are not displayed). 
2.3 Semi-naive Bot tom-up In terpretat ion  
Magic-compiled logic programs/grammars can be 
interpreted in a bottom-up fashion without losing 
any of the goal-directedness normally associated 
with top-down interpretation using a so-called 
semi-naive bottom-up interpreter: A dynamic in- 
terpreter that tables only complete intermediate 
results, i. e., facts or passive edges, and uses 
an agenda to avoid redundant sub-computations. 
The Prolog predicates in figure 7 implement a
~The creation of the seed can be postponed until 
run  time, such that the grammar does not need to be 
compiled for every possible initial goal. 
167 
Proceedings of EACL '99 
CAT ~p \] 
(i) magic_constituent( |AGR|PEON agr|list ):_ 
LSEM sere A
\[c T , \] 
magic_constituent(|PHON z.,, ). 
\[sEg ,era 1
/PHON 
(2) magic_constituent( /AGR ):- 
Ls~g \[S,BJ \[7\]\] 
magic_constituent( |PEON ), 
\[SEM 
I PHON constituent( AGR )' .SEM 
(3) magic_append (\[~1,\[~\],\[~\]) :- 
magic_constituent(/PEON ), 
tszg 
PEON 
constituent( I AGR ), 
I.SZg 
PHON 
constituent( \]AGR )" 
Figure 6: Magic rules resulting from applying 
magic compilation to definite clause 1 in figure 3 
semi-naive bottom-up interpreter. 7 In this inter- 
preter both the table and the agenda are repre- 
sented using lists, s The agenda keeps track of the 
facts that have not yet been used to update the 
table. It is important o notice that in order to 
use the interpreter for typed feature grammars it
has to be adapted to perform graph unification. 9 
We refrain from making the necessary adaptions 
to the code for expository reasons. 
The table is initialized with the facts from the 
grammar. Facts are combined using a operation 
called match. The match operation unifies all but 
one of the right-hand side literals of a definite 
clause in the grammar with facts in the table. The 
7Definite clauses serving as data are en- 
coded using the predicate definite_clause/l: 
definite_clause((Lhs :-B/Is))., where Khs is a 
(possibly empty) list of literals. 
SThere are various other--more fficient--ways to
implement a dynamic ontrol strategy in Prolog. See, 
for example, (Shieber et el., 1995). 
9A term encoding of typed feature structures would 
enable the use of term unification instead. See, for 
example, (Gerdemann, 1995). 
remaining right-hand side literal is unified with a 
newly derived fact, i. e., a fact from the agenda. 
By doing this, repeated erivation of facts from 
the same earlier derived facts is avoided. 
semi_naive_interpret (Goal):- 
initialization(Agenda,TableO), 
updat e_t able (Agenda, Table0, Table), 
member (edge (Goal, \[\] ) ,Table) . 
update_table ( \[\] ,Table ,Table). 
update_table(\[EdgelAgenda0\],Table0,Table):- 
update_table_w_edge(Edge,Edges, 
TableO,Tablel), 
append(Edges,Agenda0,Agenda), 
update_table(Agenda,Tablel,Table). 
update_tableJ_edge(Edge,Edges,Table0,Table):- 
findall( NewEdge, 
matah(Edge,NewEdge,Table0), 
Edges), 
store(Edges,Table0,Table). 
store(\[\],Table,Table):- 
store(\[EdgelEdges\],TableO,Table):- 
member(GenEdge,Table0), 
\+ subsumes(GemEdge,Edge), 
store(Edges,\[EdgelTable0\] ,Table). 
store(\[_lEdges\],TableO,Table):- 
store(Edges,Table0,Table). 
initialization(Edges,Edges):- 
findall( edge(Head, \[\] ), 
definite_clause((Head:- \[\])), 
Edges). 
completion(Edge,edge(Goal,\[\]),Table):- 
definite_clause((Goal :- Body)), 
Edge = edge(F,\[\]), 
select(F,Body,R), 
edges(R,Table). 
edges(\[\],_). 
edges(\[Lit\[Lits\],Table):- 
member(edge(Lit,\[\]),Table), 
edges(Lits,Table). 
Figure 7: Semi-naive bottom-up interpreter 
3 Selective Magic HPSG Parsing 
In case of large grammars the huge space require- 
ments of dynamic processing often nullify the ben- 
efit of tabling intermediate r sults. By combin- 
ing control strategies and allowing the user to 
specify how to process particular constraints in 
the grammar the selective magic parser avoids 
this problem. This solution is based on the ob- 
servation that there are sub-computations that 
are relatively cheap and as a result do not need 
tabling (Johnson and D6rre, 1995; van Noord, 
1997). 
3.1 Parse Type  Specif ication 
Combining control strategies depends on a way 
to differentiate between types of constraints. For 
168 
Proceedings of EACL '99 
example, the ALE parser (Carpenter and Penn, 
1994) presupposes a phrase structure backbone 
which can be used to determine whether a con- 
straint is to be interpreted bottom-up or top- 
down. In the case of selective magic parsing we 
use so-called parse types which allow the user to 
specify how constraints in the grammar are to be 
interpreted. A literal (goal) is considered a parse 
lype literal (goal) if it has as its single argument 
a typed feature structure of a type specified as a 
parse type. 1° 
All types in the type hierarchy can be used 
as parse types. This way parse type specifica- 
tion supports a flexible filtering component which 
allows us to experiment with the role of filter- 
ing. However, in the remainder we will concen- 
trate on a specific class of parse types: We as- 
sume the specification of type sign and its sub- 
types as parse types. 11 This choice is based on 
the observation that the constraints on type sign 
and its sub-types play an important guiding role 
in the parsing process and are best interpreted 
bottom-up given the lexical orientation of I-IPSG. 
The parsing process corresponding tosuch a parse 
type specification is represented schematically in
figure 8. Starting from the lexical entries, i. e., 
word word word 
Figure 8: Schematic representation ofthe selective 
magic parsing process 
the :r~'L definite clauses that specify the word 
objects in the grammar, phrases are built bottom- 
up by matching the parse type literals of the def- 
inite clauses in the grammar against he edges in 
the table. The non-parse type literals are pro- 
cessed according to the top-down control strategy 
1°The notion of a parse type literal is closely related 
to that of a memo literal as in (Johnson and DSrre, 
1995). 
l~When a type is specified as a parse type, all its 
sub-types are considered as parse types as well. This is 
necessary as otherwise there may e.xist magic variants 
of definite clauses defining a parse type goal for which 
no magic facts can be derived which means that the 
magic literal of these clauses can be interpreted nei- 
ther top-down nor bottom-up. 
described in section 3.3. 
3.2 Select ive Magic  Compi la t ion  
In order to process parse type goals according to a 
semi-naive magic control strategy, we apply magic 
compilation selectively. Only the T~-L definite 
clauses in a typed feature grammar which define 
parse type goals are subject to magic compilation. 
The compilation applied to these clauses is iden- 
tical to the magic compilation illustrated in sec- 
tion 2.1 except hat we derive magic rules only for 
the right-hand side literals in a clause which are of 
a parse type. The definite clauses in the grammar 
defining non-parse type goals are not compiled as 
they will be processed using the top-down inter- 
preter described in the next section. 
3.3 Advanced Top-down Control  
Non-parse type goals are interpreted using the 
standard interpreter of the ConTroll grammar de- 
velopment system (G5tz and Meurers, 1997b) as 
developed and implemented by Thilo GStz. This 
advanced top-down interpreter uses a search func- 
tion that allows the user to specify the information 
on which the definite clauses in the grammar are 
indexed. An important advantage of deep multi- 
ple indexing is that the linguist does not have to 
take into account of processing criteria with re- 
spect to the organization of her/his data as is the 
case with a standard Prolog search function which 
indexes on the functor of the first argument. 
Another important feature of the top-down in- 
terpreter is its use of a selection function that 
interprets deterministic goals, i. e., goals which 
unify with the left-hand side literal of exactly 
one definite clause in the grammar, prior to non- 
deterministic goals. This is often referred to as 
incorporating delerministic closure (DSrre, 1993). 
Deterministic losure accomplishes a reduction of 
the number of choice points that need to be set 
during processing to a minimum. Furthermore, it
leads to earlier failure detection. 
Finally, the used top-down interpreter imple- 
ments a powerful coroutining mechanism: 12 At 
run time the processing of a goal is postponed 
in case it is insufficiently instantiated. Whether 
or not a goal is sufficiently instantiated is deter- 
mined on the basis of so-called delay palierns. 13 
These are specifications provided by the user that 
12Coroutining appears under many different guises, 
like for example, suspension, residuation, (goal) freez- 
ing, and blocking. See also (Colmerauer, 1982; Naish, 
1986). 
13In the literature delay patterns are sometimes also 
referred to as wait declarations or .block statements. 
169 
Proceedings ofEACL '99 
indicate which restricting information has to be 
available before a goal is processed. 
3.4 Adapted Semi-naive Bottom-up 
Interpretat ion 
The definite clauses resulting from selective magic 
transformation are interpreted using a semi-naive 
bottom-up interpreter that is adapted in two re- 
spects. It ensures that non-parse type goals are 
interpreted using the advanced top-down inter- 
preter, and it allows non-parse type goals that 
remain delayed locally to be passed in and out 
of sub-computations i  a similar fashion as pro- 
posed by (Johnson and DSrre, 1995). In order 
to accommodate these changes the adapted semi- 
naive interpreter enables the use of edges which 
specify delayed goals. 
Figure 9 illustrates the adapted match op- 
eration. The first defining clause of match/3 
match(Edge,edge(Goal,Delayed),Table):- 
definite_clause((Goal :- Body)), 
select(Lit,Body,Lits), 
parse_type(Lit), 
Edge = edge(Lit,DelayedO), 
edges(Lit,Table,DelayedO,TopDown), 
advancechtd_interpret(TopDown,Delayed). 
match(Edge,edge(Goal,Delayed),Table):- 
definite~lause((Goal :- TopDown)), 
advanced_td_interpret(TopDown,Delayed). 
Figure 9: Adapted efinition of mat, oh/3 
passes delayed and non-parse type goals of the 
definite clause under consideration to the ad- 
vanced top-down interpreter via the call to 
advanced_td_interpret/2 as the list of goals 
TopDown. 14 The second efining clause of match/3 
is added to ensure all right-hand side literals are 
directly passed to the advanced top-down inter- 
preter if none of them are of a parse type. 
Allowing edges which specify delayed goals 
necessitates the adaption of the definition of 
edges/3. When a parse type literal is matched 
against an edge in the table, the delayed goals 
specified by that edge need to be passed to the 
top-down interpreter. Consider the definition of 
the predicate dges in figure 11. The third argu- 
ment of the definition of edges/4 is used to collect 
delayed goals. When there are no more parse type 
literals in the right-hand side of the definite clause 
under consideration, the second defining clause 
of edges/4 appends the collected delayed goals 
Z4The definition of match/3 assumes that there ex- 
ists a strict ordering of the right-hand side literals in 
the definite clauses in the grammar, i. e., parse type 
literals always preced enon-parse type literals. 
edges(\[Lit\[Lits\],Table,Delayed0,TopDown):- 
parse_type(Lit), 
member(edge(Lit,Delayedl),Table), 
append(Delayed0,Delayedl,Delayed). 
edges(Lit,Table,Delayed,TopDown). 
edges(\[\],_,Delayed,TopDown):- 
append(Delayed,Lit,TopDown). 
Figure lh  Adapted efinition of edges/4 
to the remaining non-parse type literals. Subse- 
quently, the resulting list of literals is passed up 
again for advanced top-down interpretation. 
4 Imp lementat ion  
The described parser was implemented aspart of 
the ConTroll grammar development system (GStz 
and Meurers, 1997b). Figure 10 shows the over- 
all setup of the ConTroll magic component. The 
Controll magic component presupposes a parse 
type specification and a set of delay patterns to 
determine when non-parse type constraints are to 
be interpreted. At run-time the goal-directedness 
of the selective magic parser is further increased 
by means of using the phonology of the natural 
language xpression to be parsed as specified by 
the initial goal to restrict he number of facts that 
are added to the table during initialization. Only 
those facts in the grammar corresponding to lex- 
ical entries that have a value for their phonology 
feature that appears as part of the input string 
are used to initialize the table. 
The ConTroll magic omponent was tested with 
a larger (> 5000 lines) HPSG grammar of a size- 
able fragment of German. This grammar provides 
an analysis for simple and complex verb-second, 
verb-first and verb-last sentences with scrambling 
in the mittelfeld, extraposition phenomena, wh- 
movement and topicalization, integrated verb-first 
parentheticals, and an interface to an illocution 
theory, as well as the three kinds of infinitive con- 
structions, nominal phrases, and adverbials (Hin- 
richs et al., 1997). 
As the test grammar combines sub-strings in a 
non-concatenative fashion, a preprocessor is used 
that chunks the input string into linearization do- 
mains. This way the standard ConTroll inter- 
preter (as described in section 3.3) achieves pars- 
ing times of around 1-5 seconds for 5 word sen- 
tences and 10-60 seconds for 12 word sentences) s 
The use of magic compilation on all grammar 
constraints, i.e., tabling of all sub-computations, 
lSParsing with such a grammar is difficult in any 
system as it does neither have nor allow the extraction 
of a phrase structure backbone. 
170 
Proceedings of EACL '99 
i nput :  
I magic compilation I 
on p~rse  type 
c laoses  
preselection I 
of re levant  
lex ica l  entries 
extended se~-na£ve  
bot tom-up ~nterpreta~ion 
of parse type c lauses  
combined with advanced 
top-doom interpreta=ion 
Figure 10: Setup of the ConTroll magic omponent 
leads to an vast increase of parsing times. The 
selective magic HPSG parser, however, exhibits a 
significant speedup in many cases. For example, 
parsing with the module of the grammar imple- 
menting the analysis of nominal phrases is up to 
nine times faster. At the same time though se- 
lective magic HPSG parsing is sometimes signifi- 
cantly slower. For example, parsing of particular 
sentences exhibiting adverbial subordinate clauses 
and long extraction is sometimes more than nine 
times slower. We conjecture that these ambigu- 
ous results are due to the use of coroutining: As 
the test grammar was implemented using the stan- 
dard ConTroll interpreter, the delay patterns used 
presuppose a data-flow corresponding to advanced 
top-down control and are not fine-tuned with re- 
spect to the data-flow corresponding to the selec- 
tive magic parser. 
Coroutining is a flexible and powerful facility 
used in many grammar development systems and 
it will probably remain indispensable in dealing 
with many control problems despite its various 
disadvantages) 6 The test results discussed above 
indicate that the comparison of parsing strategies 
can be seriously hampered by fine-tuning parsing 
using delay patterns. We believe therefore that 
further research into the systematics underlying 
coroutining would be desirable. 
5 Conc lud ing  Remarks  
We described a selective magic parser for typed 
feature grammars implementing HPSG that com- 
bines the advantages of dynamic bottom-up and 
advanced top-down control. As a result the parser 
avoids the efficiency problems resulting from the 
huge space requirements of storing intermediate 
results in parsing with large grammars. The 
parser allows the user to apply magic compilation 
to specific constraints in a grammar which as a 
16Coroutining has a significant run-time overhead 
caused by the necessity to check the instantiation sta- 
tus of a literal/goal. In addition, it demands the pro- 
cedural annotation of an otherwise declarative gram- 
mar. Finally, coroutining presupposes that a grammar 
writer possesses substantial processing expertise. 
171 
Proceedings of EACL '99 
result can be processed ynamically in a bottom- 
up and goal-directed fashion. State of the art 
top-down processing techniques are used to deal 
with the remaining constraints. We discussed var- 
ious aspects concerning the implementation f the 
parser which was developed as part of the gram- 
mar development system ConTroll. 
Acknowledgments 
The author gratefully acknowledges the support 
of the SFB 340 project B4 "From Constraints to 
Rules: Efficient Compilation of ttPSG" funded by 
the German Science Foundation and the project 
"PSET: Practical Simplification of English Text", 
a three-year project funded by the UK Engi- 
neering and Physical Sciences Research Council 
(GR/L53175), and Apple Computer Inc.. The au- 
thor wishes to thank Dale Gerdemann and Erhard 
Hinrichs and the anonymous reviewers for com- 
ments and discussion. Of course, the author is 
responsible for all remaining errors. 
References 
Bob Carpenter and Gerald Penn. 1994. ALE - 
The Attribute Logic Engine, User's guide, ver- 
sion 2.0.2. Technical report, Carnegie Mellon 
University, Pittsburgh, Pennsylvania, USA. 
Bob Carpenter. 1992. The Logic of Typed Fea- 
ture Structures - With Applications to Unifica- 
tion Grammars, Logic Programs and Constraint 
Resolution. Cambridge University Press, New 
York, USA. 
Alain Colmerauer. 1982. PrologII: Manuel de 
r@f~rence t module th@orique. Technical re- 
port, Groupe d'Intelligence Artificielle, Facult~ 
de Sciences de Luminy, Marseille, France. 
Jochen DSrre. 1993. Generalizing Earley Deduc- 
tion for Constraint-based Grammars. In Jochen 
DSrre and Michael Dorna (eds.), 1993. Compu- 
tational Aspects of Constraint-Based Linguistic 
Description L DYANA-2, Deliverable R1.2.A. 
Dale Gerdemann. 1995. Term Encoding of 
Typed Feature Structures. In Proceedings of 
the Fourth International Workshop on Parsing 
Technologies, Prague, Czech Republic. 
Thilo GStz and Detmar Meurers. 1997a. In- 
terleaving Universal Principles and Relational 
Constraints over Typed Feature Logic. In 
A CL/EACL Proceedings, Madrid, Spain. 
Thilo GStz and Detmar Meurers. 1997b. The 
ConTroll System as Large Grammar Develop- 
ment Platform. In Proceedings of the ACL 
Workshop on Computational Environments for 
Grammar Development and Linguistic Engi- 
neering, Madrid, Spain. 
Thilo GStz. 1994. A Normal Form for Typed 
Feature Structures. Technical report SFB 340 
nr. 40, University of Tfibingen, Germany. 
Thilo GStz. 1995. Compiling HPSG Constraint 
Grammars into Logic Programs. In Proceedings 
of the Workshop on Computational Logic for 
Natural Language Processing, Edinburgh, UK. 
Erhard Hinrichs, Detmar Meurers, Frank Richter, 
Manfred Sailer, and Heike Winhart. 1997. Ein 
HPSG-fragment des Deutschen, Tell 1: Theo- 
rie. Technical report SFB 340 95, University of 
Tiibingen, Germany. 
Markus HShfeld and Gert Smolka. 1988. Definite 
Relations over Constraint Languages. Technical 
Report 53, IBM, Germany. 
Mark Johnson and Jochen DSrre. 1995. Memo- 
ization of Coroutined Constraints. In A CL Pro- 
ceedings, Cambridge, Massachusetts, USA. 
Paul King. 1994. Typed Feature Structures as 
Descriptions. In Proceedings of of the 15th Con- 
ference on Computational Linguistics, Kyoto, 
Japan. 
Detmar Meurers and Guido Minnen. 1997. A 
Computational Treatment of Lexical Rules in 
HPSG as Covariation in Lexical Entries. Com- 
putational Linguistics, 23(4). 
Guido Minnen. 1996. Magic for Filter Optimiza- 
tion in Dynamic Bottom-up Processing. In ACL 
Proceedings, Santa Cruz, California, USA. 
Guido Minnen. 1998. Off-line Compilation for Ef- 
ficient Processing with Constraint-logic Gram- 
mars. Ph.D. thesis, University of Tfibingen, 
Germany. Technical report SFB 340 nr. 130. 
Lee Naish. 1986. Negation and Control in Prolog. 
Springer-Verlag, Berlin, Germany. 
Ulf Nilsson and Jan Matuszynski. 1995. Logic, 
Programming and Prolog. John Wiley  Sons, 
Chichester, UK, 2nd edition. 
Carl Pollard and Ivan Sag. 1994. Head-Driven 
Phrase Structure Grammar. University of 
Chicago Press, Chicago, Illinois, USA. 
Raghu Ramakrishnan, Divesh Srivastava, and 
S. Sudarshan. 1992.  Efficient Bottom-up 
Evaluation of Logic Programs. In Joos Van- 
dewalle (ed.), 1992. The State of the Art in 
Computer Systems and Software Engineering. 
Kluwer Academic Publishers. 
Stuart Shieber, Yves Schabes, and Fernando 
Pereira. 1995. Principles and Implementation 
of Deductive Parsing. Journal of Logic Pro- 
gramming, 24(1-2). 
Gertjan van Noord. 1997. An Efficient Imple- 
mentation of the Head-corner Parser. Compu- 
tational Linguistics, 23(3). 
172 
