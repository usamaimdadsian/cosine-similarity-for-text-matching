Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 63–68,
Avignon, France, April 23 - 27 2012. c©2012 Association for Computational Linguistics
Fluid Construction Grammar:
The New Kid on the Block
Remi van Trijp1, Luc Steels1,2, Katrien Beuls3, Pieter Wellens3
1Sony Computer Science 2ICREA Institute for 3 VUB AI Lab
Laboratory Paris Evolutionary Biology (UPF-CSIC) Pleinlaan 2
6 Rue Amyot PRBB, Dr Aiguidar 88 1050 Brussels (Belgium)
75005 Paris (France) 08003 Barcelona (Spain) katrien|pieter@
remi@csl.sony.fr steels@ai.vub.ac.be ai.vub.ac.be
Abstract
Cognitive linguistics has reached a stage
of maturity where many researchers are
looking for an explicit formal grounding
of their work. Unfortunately, most current
models of deep language processing incor-
porate assumptions from generative gram-
mar that are at odds with the cognitive
movement in linguistics. This demonstra-
tion shows how Fluid Construction Gram-
mar (FCG), a fully operational and bidi-
rectional unification-based grammar for-
malism, caters for this increasing demand.
FCG features many of the tools that were
pioneered in computational linguistics in
the 70s-90s, but combines them in an inno-
vative way. This demonstration highlights
the main differences between FCG and re-
lated formalisms.
1 Introduction
The “cognitive linguistics enterprise” (Evans
et al., 2007) is a rapidly expanding research dis-
cipline that has so far avoided rigorous formal-
izations. This choice was wholly justified in the
70s-90s when the foundations of this scientific
movement were laid (Rosch, 1975; Lakoff, 1987;
Langacker, 1987), and it remained so during the
past two decades while the enterprise worked on
getting its facts straight through empirical stud-
ies in various subfields such as language acqui-
sition (Tomasello, 2003; Goldberg et al., 2004;
Lieven, 2009), language change and grammati-
calization (Heine et al., 1991; Barðdal and Chel-
liah, 2009), and corpus research (Boas, 2003; Ste-
fanowitsch and Gries, 2003). However, with nu-
merous textbooks on the market (Lee, 2001; Croft
and Cruse, 2004; Evans and Green, 2006), cogni-
tive linguistics has by now established itself as a
serious branch in the study of language, and many
cognitive linguists are looking for ways of explic-
itly formalizing their work through computational
models (McClelland, 2009).
Unfortunately, it turns out to be very difficult
to adequately formalize a cognitive linguistic ap-
proach to grammar (or “construction grammar”)
using the tools for precision-grammars developed
in the 70s-90s such as unification (Kay, 1979;
Carpenter, 1992), because these tools are typi-
cally incorporated in a generative grammar (such
as HPSG; Ginzburg and Sag, 2000) whose as-
sumptions are incompatible with the foundations
of construction grammar. First, cognitive linguis-
tics blurs the distinction between ‘competence’
and ‘performance’, which means giving up the
sharp distinction between declarative and proce-
dural representations. Next, construction gram-
marians argue for a usage-based approach (Lan-
gacker, 2000), so the constraints on features may
change and features may emerge or disappear
from a grammar at any given time.
This demonstration introduces Fluid Construc-
tion Grammar (FCG; Steels, 2011, 2012a), a
novel unification-based grammar formalism that
addresses these issues, and which is available as
open-source software at www.fcg-net.org.
After more than a decade of development, FCG
is now ready to handle sophisticated linguistic
issues. FCG revisits many of the technologies
developed by computational linguists and intro-
duces several key innovations that are of inter-
est to anyone working on deep language process-
ing. The demonstration illustrates these innova-
tions through FCG’s interactive web interface.
63
semantic 
pole
syntactic 
pole
transient structure
semantic 
pole
syntactic 
pole
construction
matching phase
first 
merging 
phase
second 
merging 
phase
semantic 
pole
syntactic 
pole
transient structure
semantic 
pole
syntactic 
pole
construction
second
merging
phase
first 
merging 
phase
matching phase
Figure 1: FCG allows the implementation of efficient and strongly reversible grammars. Left: In production,
conditional units of the semantic pole of a construction are matched against a transient structure, before additional
semantic constraints and the syntactic pole are merged with the structure. Right: In parsing, the same algorithm
applies but in the opposite direction.
2 Strong and Efficient Reversibility
Reversible or bidirectional grammar formalisms
can achieve both production and parsing (Strza-
lkowski, 1994). Several platforms, such as the
LKB (Copestake, 2002), already achieve bidirec-
tionality, but they do so through separate algo-
rithms for parsing and production (mainly for effi-
ciency reasons). One problem with this approach
is that there may be a loss of coherence in gram-
mar engineering. For instance, the LKB parser
can handle a wider variety of structures than its
generator.
FCG uses one core engine that handles both
parsing and production with a single linguistic
inventory (see Figure 1). When processing, the
FCG-system builds a transient structure that con-
tains all the information concerning the utterance
that the system has to parse or produce, divided
into a semantic and syntactic pole (both of whom
are feature structures). Grammar rules or “con-
structions” are coupled feature structures as well
and thus contain a semantic and syntactic pole.
When applying constructions, the FCG-system
goes through three phases. In production, FCG
first matches all feature-value pairs of the seman-
tic pole of a construction with the semantic pole
of the transient structure, except fv-pairs that are
marked for being attributed by the construction
(De Beule and Steels, 2005). Matching is a more
strict form of unification that resembles a sub-
sumption test (see Steels and De Beule, 2006).
If matching is successful, all the marked fv-pairs
of the semantic pole are merged with the tran-
sient structure in a first merge phase, after which
the whole syntactic pole is merged in a second
phase. FCG-merge is equivalent to “unification”
in other formalisms. The same three-phase algo-
rithm is applied in parsing as well, but this time in
the opposite direction: if the syntactic pole of the
construction matches with the transient structure,
the attributable syntactic fv-pairs and the seman-
tic pole are merged.
3 WYSIWYG Grammar Engineering
Most unification grammars use non-directional
linguistic representations that are designed to be
independent of any model of processing (Sag
and Wasow, 2011). Whereas this may be de-
sirable from a ‘mathematical’ point-of-view, it
puts the burden of efficient processing on the
shoulders of computational linguists, who have to
find a balance between faithfulness to the hand-
written theory and computational efficiency (Mel-
nik, 2005). For instance, there is no HPSG imple-
mentation, but rather several platforms that sup-
port the implementation of ‘HPSG-like’ gram-
mars: ALE (Carpenter and Penn, 1995), ALEP
(Schmidt et al., 1996), CUF (Dörre and Dorna,
64
top
cxn-applied
top
nominal-adjectival-cxn
sem-subunits  
footprints  
args  
sem-cat  
nominal-adjectival-phrase-1
(word-ballon-1 
word-rouge-1)
(nominal-adjectival-cxn)
(red-ball-15 context-19)
((sem-function 
identifier))
word-
ballon-
1
word-
rouge-
1
word-le-1
sem syn
form  
syn-subunits  
syn-cat  
footprints  
nominal-adjectival-phrase-1
((meets 
word-ballon-1 
word-rouge-1))
(word-ballon-1 
word-rouge-1)
((number singular) 
(gender masculine) 
(syn-function nominal))
(nominal-adjectival-cxn)
word-
rouge-
1
word-
ballon-
1
word-le-1
Figure 2: FCG comes equipped with an interactive web interface for inspecting the linguistic inventory, con-
struction application and search. This Figure shows an example construction where two units are opened up for
closer inspection of their feature structures.
1993), LIGHT (Ciortuz, 2002), LKB (Copestake,
2002), ProFIT (Erbach, 1995), TDL (Krieger and
Schäfer, 1994), TFS (Emele, 1994), and others
(see Bolc et al., 1996, for a survey). Unfortu-
nately, the optimizations and technologies devel-
oped within these platforms are often considered
by theoretical linguists as engineering solutions
rather than scientific contributions.
FCG, on the other hand, adheres to the cogni-
tive linguistics assumption that linguistic perfor-
mance is equally important as linguistic compe-
tence, hence processing becomes a central notion
in the formalism. FCG representations therefore
offer a ‘what you see is what you get’ approach
to grammar engineering where the representations
have a direct impact on processing and vice versa.
For instance, a construction’s division between a
semantic and syntactic pole is informative with re-
spect to how the construction is applied.
Some grammarians may object that this design
choice forces linguists to worry about process-
ing, but that is entirely the point. It has already
been demonstrated in other unification-based for-
malisms that different grammar representations
have a significant impact on processing efficiency
(Flickinger, 2000). Moreover, FCG-style repre-
sentations can be directly implemented and tested
without having to compromise on either faithful-
ness to a theory or computational efficiency.
Since writing grammars is highly complex,
however, FCG also features a ‘design level’ on top
of its operational level (Steels, 2012b). On this
level, grammar engineers can use templates that
build detailed constructions. The demonstration
shows how to write a grammar in FCG, switch-
ing between its design level, its operational level
and its interactive web interface (see Figure 2).
The web interface allows FCG-users to inspect the
linguistic inventory, the search tree in processing,
and so on.
4 Robustness and Learning
Unification-based grammars have the reputation
of being brittle when it comes to processing nov-
elty or ungrammatical utterances (Tomuro, 1999).
Since cognitive linguistics adheres to a usage-
based view on language (Langacker, 2000), how-
ever, an adequate formalization must be robust
and open-ended.
A first requirement is that there can be differ-
ent degrees of ‘entrenchment’ in the grammar:
while some features might still be emergent, oth-
ers are already part of well-conventionalized lin-
guistic patterns. Moreover, new features and con-
structions may appear (or disappear) from a gram-
mar at any given time. These requirements are
hard to reconcile with the type hierarchy approach
of other formalisms, so FCG does not imple-
ment typed feature structures. The demonstra-
tion shows how FCG can nevertheless prevent
over-licensing of linguistic structures through its
matching phase and how it captures generaliza-
tions through its templates – two benefits typically
associated with type hierarchies.
Secondly, FCG renders linguistic processing
fluid and robust through a meta-level architec-
ture, which consists of two layers of processing,
as shown in Figure 3 (Beuls et al., 2012). There
is a routine layer in which constructional process-
ing takes place. At the same time, a meta-layer
65
!"!"
routine processing 
diagnostic 
problem repair 
diagnostic diagnostic diagnostic 
problem 
repair meta-layer processing 
Figure 3: There are two layers of processing in FCG. On the routine level, constructional processing takes place.
At the same time, a meta-layer of diagnostics and repairs try to detect and solve problems that occur in the routine
layer.
is active that runs diagnostics for detecting prob-
lems in routine processing, and repairs for solving
those problems. The demonstration shows how
the meta-layer is used for solving common prob-
lems such as missing lexical entries and coercion
(Steels and van Trijp, 2011), and how its archi-
tecture offers a uniform way of implementing the
various solutions for robustness already pioneered
in the aforementioned grammar platforms.
5 Efficiency
Unification is computationally expensive, and
many technical solutions have been proposed for
efficient processing of rich and expressive fea-
ture structures (Tomuro, 1999; Flickinger, 2000;
Callmeier, 2001). In FCG, however, research
on efficiency takes a different dimension because
performance is considered to be an integral part of
the linguistic theory that needs to be operational-
ized. The demonstration allows conference par-
ticipants to inspect the following research results
on the interplay between grammar and efficiency:
• In line with construction grammar, there is
no distinction between the lexicon and the
grammar. Based on language usage, the lin-
guistic inventory can nevertheless organize
itself in the form of dependency networks
that regulate which construction should be
considered when in processing (Wellens and
De Beule, 2010; Wellens, 2011).
• There is abundant psycholinguistic evidence
that language usage contains many ready-
made language structures. FCG incorporates
a chunking mechanism that is able to cre-
ate such canned phrases for faster processing
(Stadler, 2012).
• Morphological paradigms, such as the Ger-
man case system, can be represented in the
form of ‘feature matrices’, which reduce
syntactic and semantic ambiguity and hence
speed up processing efficiency and reliability
(van Trijp, 2011).
• Many linguistic domains, such as spatial lan-
guage, are known for their high degree of
polysemy. By distinguishing between actual
and potential values, such polysemous struc-
tures can be processed smoothly (Spranger
and Loetzsch, 2011).
6 Conclusion
With many well-developed unification-based
grammar formalisms available to the community,
one might wonder whether any ‘new kid on the
block’ can still claim relevance today. With this
demonstration, we hope to show that Fluid Con-
struction Grammar allows grammar engineers to
unchart new territory, most notably in the relation
between linguistic competence and performance,
and in modeling usage-based approaches to lan-
guage.
66
References
Johanna Barðdal and Shobhana Chelliah, edi-
tors. The Role of Semantic, Pragmatic and
Discourse Factors in the Development of Case.
John Benjamins, Amsterdam, 2009.
Katrien Beuls, Remi van Trijp, and Pieter
Wellens. Diagnostics and repairs in Fluid Con-
struction Grammar. In Luc Steels, editor, Com-
putational Issues in Fluid Construction Gram-
mar. Springer Verlag, Berlin, 2012.
Hans C. Boas. A Constructional Approach to Re-
sultatives. Stanford Monograph in Linguistics.
CSLI, Stanford, 2003.
Leonard Bolc, Krzysztof Czuba, Anna
Kups´c´, Malgorzata Marciniak, Agnieszka
Mykowiecka, and Adam Przepiórkowski. A
survey of systems for implementing HPSG
grammars. Research Report 814 of IPI
PAN (Institute of Computer Science, Polish
Academy of Sciences), 1996.
Ulrich Callmeier. Efficient parsing with large-
scale unification grammars. Master’s thesis,
Universität des Saarlandes, 2001.
Bob Carpenter. The Logic of Typed Feature Struc-
tures. Cambridge UP, Cambridge, 1992.
Bob Carpenter and Gerald Penn. The Attribute
Logic Engine (Version 2.0.1). Pittsburgh, 1995.
Liviu Ciortuz. LIGHT – a constraint language and
compiler system for typed-unification gram-
mars. In Proceedings of The 25th German Con-
ferences on Artificial Intelligence (KI 2002),
volume 2479 of LNAI, pages 3–17, Berlin,
2002. Springer-Verlag.
Ann Copestake. Implementing Typed Feature
Structure Grammars. CSLI Publications, Stan-
ford, 2002.
William Croft and D. Alan Cruse. Cognitive Lin-
guistics. Cambridge Textbooks in Linguistics.
Cambridge University Press, Cambridge, 2004.
J. De Beule and L. Steels. Hierarchy in fluid con-
struction grammar. In U. Furbach, editor, Pro-
ceedings of the 28th Annual German Confer-
ence on Artificial Intelligence, volume 3698 of
Lecture Notes in Artificial Intelligence, pages
1–15, Berlin, Germany, 2005. Springer Verlag.
Jochen Dörre and Michael Dorna. CUF – a
formalism for linguistic knowledge represen-
tation. In Jochen Dörre, editor, Computa-
tional Aspects of Constraint Based Linguistic
Descriptions, volume I, pages 1–22. DYANA-2
Project, Amsterdam, 1993.
Martin C. Emele. The typed feature structure rep-
resentation formalism. In Proceedings of the
International Workshop on Sharable Natural
Language Resources, Ikoma, Nara, 1994.
Gregor Erbach. ProFIT: Prolog with features,
inheritance and templates. In Proceedings of
EACL-95, 1995.
Vyvyan Evans and Melanie Green. Cognitive Lin-
guistics: An Introduction. Lawrence Erlbaum
Associates / Edinburgh University Press, Hills-
dale, NJ/Edinburgh, 2006.
Vyvyan Evans, Benjamin K. Bergen, and Jörg
Zinken. The cognitive linguistics enterprise:
An overview. In V. Evans, B.K. Bergen, and
J. Zinken, editors, The Cognitive Linguistics
Reader. Equinox Publishing, London, 2007.
Daniel P. Flickinger. On building a more efficient
grammar by exploiting types. Natural Lan-
guage Engineering, 6(1):15–28, 2000.
Jonathan Ginzburg and Ivan A. Sag. Interroga-
tive Investigations: the Form, the Meaning, and
Use of English Interrogatives. CSLI Publica-
tions, Stanford, 2000.
Adele E. Goldberg, Devin M. Casenhiser, and
Nitya Sethuraman. Learning argument struc-
ture generalizations. Cognitive Linguistics, 15
(3):289–316, 2004.
Bernd Heine, Ulrike Claudi, and Friederike Hün-
nemeyer. Grammaticalization: A Concep-
tual Framework. University of Chicago Press,
Chicago, 1991.
Martin Kay. Functional grammar. In Proceedings
of the Fifth Annual Meeting of the Berkeley Lin-
guistics Society, pages 142–158. Berkeley Lin-
guistics Society, 1979.
Hans-Ulrich Krieger and Ulrich Schäfer. TDL –
a type description language for HPSG. part 1:
Overview. In Proceedings of the 15th Interna-
tional Conference on Computational Linguis-
tics, pages 893–899, Kyoto, 1994.
George Lakoff. Women, Fire, and Danger-
ous Things: What Categories Reveal about
the Mind. The University of Chicago Press,
Chicago, 1987.
67
Ronald W. Langacker. Foundations of Cognitive
Grammar: Theoretical Prerequisites. Stanford
University Press, Stanford, 1987.
Ronald W. Langacker. A dynamic usage-based
model. In Michael Barlow and Suzanne Kem-
mer, editors, Usage-Based Models of Lan-
guage, pages 1–63. Chicago University Press,
Chicago, 2000.
David Lee. Cognitive Linguistics: An Introduc-
tion. Oxford University Press, Oxford, 2001.
Elena Lieven. Developing constructions. Cogni-
tive Linguistics, 20(1):191–199, 2009.
James L. McClelland. The place of modeling in
cognitive science. Topics in Cognitive Science,
1:11–38, 2009.
Nurit Melnik. From “hand-written” to computa-
tionally implemented HPSG theories. In Ste-
fan Müller, editor, Proceedings of the HPSG05
Conference, Stanford, 2005. CSLI Publica-
tions.
Eleanor Rosch. Cognitive representations of se-
mantic categories. Journal of Experimental
Psychology: General, 104:192–233, 1975.
Ivan A. Sag and Thomas Wasow. Performance-
compatible competence grammar. In Robert D.
Borsley and Kersti Börjars, editors, Non-
Transformational Syntax: Formal and Explicit
Models of Grammar, pages 359–377. Wiley-
Blackwell, 2011.
Paul Schmidt, Sibylle Rieder, Axel Theofilidis,
and Thierry Declerck. Lean formalisms, lin-
guistic theory, and applications. grammar de-
velopment in ALEP. In Proceedings of the
16th International Conference on Computa-
tional Linguistics (COLING-96), pages 286–
291, Copenhagen, 1996.
Michael Spranger and Martin Loetzsch. Syntac-
tic indeterminacy and semantic ambiguity: A
case study for German spatial phrases. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar. John Benjamins, Amster-
dam, 2011.
Kevin Stadler. Chunking constructions. In
Luc Steels, editor, Computational Issues in
Fluid Construction Grammar. Springer Verlag,
Berlin, 2012.
Luc Steels, editor. Design Patterns in Fluid Con-
struction Grammar. John Benjamins, Amster-
dam, 2011.
Luc Steels, editor. Computational Issues in
Fluid Construction Grammar. Springer, Berlin,
2012a.
Luc Steels. Design methods for Fluid Construc-
tion Grammar. In Luc Steels, editor, Computa-
tional Issues in Fluid Construction Grammar.
Springer Verlag, Berlin, 2012b.
Luc Steels and Joachim De Beule. Unify and
merge in Fluid Construction Grammar. In
P. Vogt, Y. Sugita, E. Tuci, and C. Nehaniv,
editors, Symbol Grounding and Beyond., LNAI
4211, pages 197–223, Berlin, 2006. Springer.
Luc Steels and Remi van Trijp. How to make con-
struction grammars fluid and robust. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar, pages 301–330. John Ben-
jamins, Amsterdam, 2011.
Anatol Stefanowitsch and Stefan Th. Gries. Col-
lostructions: Investigating the interaction of
words and constructions. International Journal
of Corpus Linguistics, 2(8):209–243, 2003.
Tomek Strzalkowski, editor. Reversible Grammar
in Natural Language Processing. Kluwer Aca-
demic Publishers, Boston, 1994.
Michael Tomasello. Constructing a Language. A
Usage Based Theory of Language Acquisition.
Harvard University Press, 2003.
Noriko Tomuro. Left-Corner Parsing Algorithm
for Unification Grammars. PhD thesis, DePaul
University, Chicago, 1999.
Remi van Trijp. Feature matrices and agree-
ment: A case study for German case. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar, pages 205–236. John Ben-
jamins, Amsterdam, 2011.
Pieter Wellens. Organizing constructions in net-
works. In Luc Steels, editor, Design Patterns in
Fluid Construction Grammar. John Benjamins,
Amsterdam, 2011.
Pieter Wellens and Joachim De Beule. Prim-
ing through constructional dependencies: A
case study in Fluid Construction Grammar.
In A. Smith, M. Schouwstra, Bart de Boer,
and K. Smith, editors, The Evolution of Lan-
guage (EVOLANG8), pages 344–351, Singa-
pore, 2010. World Scientific.
68
