Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 6–10,
Avignon, France, April 23 - 27 2012. c©2012 Association for Computational Linguistics
 
 
Harnessing NLP Techniques in the Processes of  
Multilingual Content Management 
 
 
Anelia Belogay Diman Karagyozov 
Tetracom IS Ltd. Tetracom IS Ltd. 
anelia@tetracom.com diman@tetracom.com 
Svetla Koeva Cristina Vertan 
Institute for Bulgarian Language Universitaet Hamburg 
svetla@dcl.bass.bg cristina.vertan@uni-hamburg.de 
Adam Przepiórkowski Polivios Raxis 
Instytut Podstaw Informatyki Polskiej 
Akademii Nauk 
Atlantis Consulting SA 
adamp@ipipan.waw.pl raxis@atlantisresearch.gr 
Dan Cristea  
Universitatea Alexandru Ioan Cuza  
dcristea@info.uaic.ro  
 
 
Abstract 
The emergence of the WWW as the main 
source of distributing content opened the 
floodgates of information. The sheer 
volume and diversity of this content 
necessitate an approach that will reinvent 
the way it is analysed. The quantitative 
route to processing information which 
relies on content management tools 
provides structural analysis. The 
challenge we address is to evolve from 
the process of streamlining data to a level 
of understanding that assigns value to 
content. 
We present an open-source multilingual 
platform ATALS that incorporates 
human language technologies in the 
process of multilingual web content 
management. It complements a content 
management software-as-a-service 
component i-Publisher, used for creating, 
running and managing dynamic content-
driven websites with a linguistic 
platform. The platform enriches the 
content of these websites with revealing 
details and reduces the manual work of 
classification editors by automatically 
categorising content. The platform 
ASSET supports six European languages. 
We expect ASSET to serve as a basis for 
future development of deep analysis tools 
capable of generating abstractive 
summaries and training models for 
decision making systems. 
Introduction 
The advent of the Web revolutionized the way in 
which content is manipulated and delivered. As a 
result, digital content in various languages has 
become widely available on the Internet and its 
sheer volume and language diversity have 
presented an opportunity for embracing new 
methods and tools for content creation and 
distribution. Although significant improvements 
have been made in the field of web content 
management lately, there is still a growing 
demand for online content services that 
incorporate language-based technology. 
Existing software solutions and services such 
as Google Docs, Slingshot and Amazon 
implement some of the linguistic mechanisms 
addressed in the platform. The most used open-
source multilingual web content management 
6
  
systems (Joomla, Joom!Fish, TYPO3, Drupal)1 
offer low level of multilingual content 
management,   providing abilities for building 
multilingual sites. However, the available 
services are narrowly focused on meeting the 
needs of very specific target groups, thus leaving 
unmet the rising demand for a comprehensive 
solution for multilingual content management 
addressing the issues posed by the growing 
family of languages spoken within the EU. 
We are going to demonstrate the open-source 
content management platform ATLAS and as 
proof of concept, a multilingual library i-
librarian, driven by the platform. The 
demonstration aims to prove that people reading 
websites powered by ATLAS can easily find 
documents, kept in order via the automatic 
classification, find context-sensitive content, find 
similar documents in a massive multilingual data 
collection, and get short summaries in different 
languages that help the users to discern essential 
information with unparalleled clarity. 
The “Technologies behind the system” chapter 
describes the implementation and the integration 
approach of the core linguistic processing 
framework and its key sub-components – the 
categorisation, summarisation and machine-
translation engines. The chapter “i-Librarian – a 
case study” outlines the functionalities of an 
intelligent web application built with our system 
and the benefits of using it. The chapter 
“Evaluation” briefly discusses the user 
evaluation of the new system. The last chapter 
“Conclusion and Future Work” summarises the 
main achievements of the system and suggests 
improvements and extensions. 
Technologies behind the system 
The linguistic framework ASSET employs 
diverse natural language processing (NLP) tools 
technologically and linguistically in a platform, 
based on UIMA 2 . The UIMA pluggable 
component architecture and software framework 
are designed to analyse content and to structure 
it. The ATLAS core annotation schema, as a 
uniform representation model, normalizes and 
harmonizes the heterogeneous nature of the NLP 
tools3. 
                                                          
1 http://www.joomla.org/, http://www.joomfish.net/, 
http://typo3.org/, http://drupal.org/ 
2 http://uima.apache.org/ 
3 The system exploits heterogeneous NLP tools, for 
the supported natural languages, implemented in Java, 
C++ and Perl. Examples are: 
The processing of text in the system is split 
into three sequentially executed tasks. 
Firstly, the text is extracted from the input 
source (text or binary documents) in the “pre-
processing” phase.  
Secondly, the text is annotated by several NLP 
tools, chained in a sequence in the “processing” 
phase. The language processing tools are 
integrated in a language processing chain (LPC), 
so that the output of a given NLP tool is used as 
an input for the next tool in the chain. The 
baseline LPC for each of the supported languages 
includes a sentence and paragraph splitter, 
tokenizer, part of speech tagger, lemmatizer, 
word sense disambiguation, noun phrase chunker 
and named entity extractor (Cristea and Pistiol, 
2008). The annotations produced by each LPC 
along with additional statistical methods are 
subsequently used for detection of keywords and 
concepts, generation of summary of text, multi-
label text categorisation and machine translation.  
Finally, the annotations are stored in a fusion 
data store, comprising of relational database and 
high-performance Lucene4 indexes. 
The architecture of the language processing 
framework is depicted in Figure 1. 
 
 
 
Figure 1. Architecture and communication channels in 
our language processing framework. 
 
The system architecture, shown in Figure 2, is 
based on asynchronous message processing 
                                                                                        
OpenNLP (http://incubator.apache.org/opennlp/), 
RASP (http://ilexir.co.uk/applications/rasp/), 
Morfeusz (http://sgjp.pl/morfeusz/),  Panterra 
(http://code.google.com/p/pantera-tagger/), ParsEst 
(http://dcl.bas.bg/), TnT Tagger (http://www.coli.uni-
saarland.de/~thorsten/tnt/). 
4 http://lucene.apache.org/ 
7
  
patterns (Hohpe and Woolf, 2004) and thus 
allows the processing framework to be easily 
scaled horizontally. 
 
 
 
Figure 2. Top-level architecture of our CMS and its 
major components. 
Text Categorisation 
We implemented a language independent text 
categorisation tool, which works for user-defined 
and controlled classification hierarchies. The 
NLP framework converts the texts to a series of 
natural numbers, prior sending the texts to the 
categorisation engine. This conversion allows 
high level compression of the feature space. The 
categorisation engine employs different 
algorithms, such as Naïve Bayesian, relative 
entropy, Class-Feature Centroid (CFC) (Guan et. 
al., 2009), and SVM. New algorithms can be 
easily integrated because of the chosen OSGi-
based architecture (OSGi Alliance, 2009). A 
tailored voting system for multi-label multi-class 
tasks consolidates the results of each of the 
categorisation algorithms. 
Summarisation (prototype phase) 
The chosen implementation approach for 
coherent text summarisation combines the well-
known LexRank algorithm (Erkan and Radev, 
2004) and semantic graphs and word-sense 
disambiguation techniques (Plaza and Diaz, 
2011). Furthermore, we have automatically built 
thesauri for the top-level domains in order to 
produce domain-focused extractive summaries. 
Finally, we apply clause-boundaries splitting in 
order to truncate the irrelevant or subordinating 
clauses in the sentences in the summary.  
Machine Translation (prototype phase) 
The machine translation (MT) sub-component 
implements the hybrid MT paradigm, combining 
an example-based (EBMT) component and a 
Moses-based statistical approach (SMT). Firstly, 
the input is processed by the example-based MT 
engine and if the whole or important chunks of it 
are found in the translation database, then the 
translation equivalents are used and if necessary 
combined (Gavrila, 2011). In all other cases the 
input is processed by the categorisation sub-
component in order to select the top-level 
domain and respectively, the most appropriate 
SMT domain- and POS-translation model 
(Niehues and Waibel, 2010). 
The translation engine in the system, based on 
MT Server Land (Federmann and Eisele, 2010),  
is able to accommodate and use different third 
party translation engines, such as the Google, 
Bing, Lusy or Yahoo translators. 
Case Study: Multilingual Library  
i-Librarian5  is a free online library that assists 
authors, students, young researchers, scholars, 
librarians and executives to easily create, 
organise and publish various types of documents 
in English, Bulgarian, German, Greek, Polish 
and Romanian. Currently, a sample of the 
publicly available library contains over 20 000 
books in English. 
On uploading a new document to i-Librarian, 
the system automatically provides the user with 
an extraction of the most relevant information 
(concepts and named entities, keywords). Later 
on, the retrieved information is used to generate 
suggestions for classification in the library 
catalogue, containing 86 categories, as well as a 
list of similar documents. Finally, the system 
compiles a summary and translates it in all 
supported languages. Among the supported 
formats are Microsoft Office documents, PDF, 
OpenOffice documents, books in various 
electronic formats, HTML pages and XML 
documents. Users have exclusive rights to 
manage content in the library at their discretion.   
The current version of the system supports 
English and Bulgarian. In early 2012 the Polish, 
Greek, German and Romanian languages will be 
in use. 
                                                          
5 i-Librarian web site is available at http://www.i-
librarian.eu/. One can access the i-Librarian demo content 
using “demo@i-librarian.eu” for username and “sandbox” 
for password. 
8
  
Evaluation 
The technical quality and performance of the 
system is being evaluated as well as its appraisal 
by prospective users. The technical evaluation 
uses indicators that assess the following key 
technical elements: 
? overall quality and performance 
attributes (MTBF6, uptime, response 
time); 
? performance of specific functional 
elements (content management, machine 
translation, cross-lingual content 
retrieval, summarisation, text 
categorisation).  
The user evaluation assesses the level of 
satisfaction with the system. We measure non 
functional elements such as: 
? User friendliness and satisfaction, clarity 
in responses and ease of use; 
? Adequacy and completeness of the 
provided data and functionality; 
? Impact on certain user activities and the 
degree of fulfilment of common tasks. 
We have planned for three rounds of user 
evaluation; all users are encouraged to try online 
the system, freely, or by following the provided 
base-line scenarios and accompanying exercises. 
The main instrument for collecting user feedback 
is an online interactive electronic questionnaire7. 
The second round of user evaluation is 
scheduled for Feb-March 2012, while the first 
round took place in Q1 2011, with the 
participation of 33 users. The overall user 
impression was positive and the Mean value of 
each indicator (in a 5-point Likert scale) was 
measured on AVERAGE or ABOVE 
AVERAGE.  
 
 
Figure 3. User evaluation – UI friendliness and ease 
of use. 
                                                          
6 Mean Time Between Failures 
7 The electronic questionnaire is available at 
http://ue.atlasproject.eu 
 
Figure 4. User evaluation – user satisfaction with the 
available functionalities in the system. 
 
 
Figure 5. User evaluation – users productivity 
incensement. 
Acknowledgments 
ATLAS (Applied Technology for Language-
Aided CMS) is a European project funded under 
the CIP ICT Policy Support Programme, Grant 
Agreement 250467. 
Conclusion and Future Work 
The abundance of knowledge allows us to widen 
the application of NLP tools, developed in a 
research environment. The tailor made voting 
system maximizes the use of the different 
categorisation algorithms. The novel summary 
approach adopts state of the art techniques and 
the automatic translation is provided by a cutting 
edge hybrid machine translation system. 
The content management platform and the 
linguistic framework will be released as open-
source software. The language processing chains 
for Greek, Romanian, Polish and German will be 
fully implemented by the end of 2011. The 
summarisation engine and machine translation 
tools will be fully integrated in mid 2012. 
We expect this platform to serve as a basis for 
future development of tools that directly support 
decision making and situation awareness. We 
will use categorical and statistical analysis in 
order to recognise events and patterns, to detect 
opinions and predictions while processing 
The user interface is friendly and 
easy to use 
Excellent
28%
Good 
35%
Average
28%
Below 
Average
9%
Poor
Below Average
Average
Good 
Excellent
I am satisfied with the functionalities 
Below 
Average
3%
Average
38%
Excellent
31%
Good 
28%
Poor
Below
Average
Average
Good 
Excellent
The system increases y ur 
productivity 
Excellent
13%
Below 
Averag
9%
Average
31%
Good 
47%
Poor
Below
Average
Average
Good 
Excellent
9
  
extremely large volumes of disparate data 
resources. 
Demonstration websites 
The multilingual content management platform is 
available for testing at http://i-
publisher.atlasproject.eu/atlas/i-publisher/demo . 
One can access the CMS demo content using 
“demo” for username and “sandbox2” for 
password. 
The multilingual library web site is available 
at http://www.i-librarian.eu/. One can access the 
i-Librarian demo content using “demo@i-
librarian.eu” for username and “sandbox” for 
password. 
References  
Dan Cristea and Ionut C. Pistol, 2008. Managing 
Language Resources and Tools using a Hierarchy 
of Annotation Schemas. In the proceedings of 
workshop 'Sustainability of Language Resources 
and Tools for Natural Language Processing', 
LREC, 2008 
Gregor Hohpe and Bobby Woolf. 2004. Enterprise 
Integration Patterns: Designing, Building, and 
Deploying Messaging Solutions. Addison-Wesley 
Professional. 
Hu Guan, Jingyu Zhou and Minyi Guo. A Class-
Feature-Centroid Classifier for Text 
Categorization. 2009. WWW 2009 Madrid, Track: 
Data Mining / Session: Learning, p201-210. 
OSGi Alliance. 2009. OSGi Service Platform, Core 
Specification, Release 4, Version 4.2. 
Gunes Erkan and Dragomir R. Radev. 2004. 
LexRank: Graph-based Centrality as Salience in 
Text Summarization. Journal of Artificial 
Intelligence Research 22 (2004), p457–479. 
Laura Plaza and Alberto Diaz. 2011. Using Semantic 
Graphs and Word Sense Disambiguation 
Techniques to Improve Text Summarization. 
Procesamiento del Lenguaje Natural, Revista nº 47 
septiembre de 2011 (SEPLN 2011), pp 97-105. 
Monica Gavrila. 2011. Constrained Recombination in 
an Example-based Machine Translation System, In 
the Proceedings of the EAMT-2011: the 15th 
Annual Conference of the European Association 
for Machine Translation, 30-31 May 2011, Leuven, 
Belgium, p. 193-200 
 Jan Niehues and Alex Waibel. 2010. Domain 
adaptation in statistical machine translation using 
factored translation models. EAMT 2010: 
Proceedings of the 14th Annual conference of the 
European Association for Machine Translation, 27-
28 May 2010, Saint-Raphaël, France. 
Christian Federmann and Andreas Eisele. 2010. MT 
Server Land: An Open-Source MT Architecture. 
The Prague Bulletin of Mathematical Linguistics. 
NUMBER 94, 2010, p57–66 
10
