Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 486–496,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics
A Word Reordering Model for Improved Machine Translation
Karthik Visweswariah
IBM Research India
Bangalore, India
v-karthik@in.ibm.com
Rajakrishnan Rajkumar
Dept. of Linguistics
Ohio State University
raja@ling.osu.edu
Ankur Gandhe
IBM Research India
Bangalore, India
ankugand@in.ibm.com
Ananthakrishnan Ramanathan
IBM Research India
Bangalore, India
aramana2@in.ibm.com
Jiri Navratil
IBM T.J. Watson Research Center
Yorktown Heights, New York
jiri@us.ibm.com
Abstract
Preordering of source side sentences has
proved to be useful in improving statistical
machine translation. Most work has used a
parser in the source language along with rules
to map the source language word order into
the target language word order. The require-
ment to have a source language parser is a ma-
jor drawback, which we seek to overcome in
this paper. Instead of using a parser and then
using rules to order the source side sentence
we learn a model that can directly reorder
source side sentences to match target word or-
der using a small parallel corpus with high-
quality word alignments. Our model learns
pairwise costs of a word immediately preced-
ing another word. We use the Lin-Kernighan
heuristic to find the best source reordering ef-
ficiently during training and testing and show
that it suffices to provide good quality reorder-
ing.
We show gains in translation performance
based on our reordering model for translating
from Hindi to English, Urdu to English (with
a public dataset), and English to Hindi. For
English to Hindi we show that our technique
achieves better performance than a method
that uses rules applied to the source side En-
glish parse.
1 Introduction
Languages differ in the way they order words to pro-
duce sentences representing the same meaning. Ma-
chine translation systems need to reorder words in
the source sentence to produce fluent output in the
target language that preserves the meaning of the
source sentence.
Current phrase based machine translation systems
can capture short range reorderings via the phrase
table. Even the capturing of these local reordering
phenomena is constrained by the amount of training
data available. For example, if adjectives precede
nouns in the source language and follow nouns in the
target language we still need to see a particular ad-
jective noun pair in the parallel corpus to handle the
reordering via the phrase table. Phrase based sys-
tems also rely on the target side language model to
produce the right target side order. This is known
to be inadequate (Al-Onaizan and Papineni, 2006),
and this inadequacy has spurred various attempts to
overcome the problem of handling differing word
order in languages.
One approach is through distortion models, that
try to model which reorderings are more likely
than others. The simplest models just penalize
long jumps in the source sentence when producing
the target sentence. These models have also been
generalized (Al-Onaizan and Papineni, 2006; Till-
man, 2004) to allow for lexical dependencies on the
source. While these models are simple, and can
be integrated with the decoder they are insufficient
to capture long-range reordering phenomena espe-
cially for language pairs that differ significantly.
The weakness of these simple distortion models
has been overcome using syntax of either the source
or target sentence (Yamada and Knight, 2002; Gal-
ley et al., 2006; Liu et al., 2006; Zollmann and Venu-
gopal, 2006). While these methods have shown to
be useful in improving machine translation perfor-
486
mance they generally involve joint parsing of the
source and target language which is significantly
more computationally expensive when compared to
phrase based translation systems. Another approach
that overcomes this weakness, is to to reorder the
source sentence based on rules applied on the source
parse (either hand written or learned from data) both
when training and testing (Collins et al., 2005; Gen-
zel, 2010; Visweswariah et al., 2010).
In this paper we propose a novel method for deal-
ing with the word order problem that is efficient and
does not rely on a source or target side parse being
available. We cast the word ordering problem as a
Traveling Salesman Problem (TSP) based on previ-
ous work on word-based and phrased-based statis-
tical machine translation (Tillmann and Ney, 2003;
Zaslavskiy et al., 2009). Words are the cities in the
TSP and the objective is to learn the distance be-
tween words so that the shortest tour corresponds to
the ordering of the words in the source sentence in
the target language. We show that the TSP distances
for reordering can be learned from a small amount
of high-quality word alignment data by means of
pairwise word comparisons and an informative fea-
ture set involving words and part-of-speech (POS)
tags adapted and extended from prior work on de-
pendency parsing (McDonald et al., 2005b). Ob-
taining high-quality word alignments that we require
for training is fairly easy compared with obtaining a
treebank required to obtain parses for use in syntax
based methods.
We show experimentally that our reordering
model, even when used to reorder sentences for
training and testing (rather than being used as an
additional score in the decoder) improves machine
translation performance for: Hindi ? English, En-
glish?Hindi, and Urdu? English. Although Urdu
is similar to Hindi from the point of reordering phe-
nomena we include it in our experiments since there
are publicly available datasets for Urdu-English. For
English ? Hindi we obtained better machine trans-
lation performance with our reordering model as
compared to a method that uses reordering rules ap-
plied to the source side parse.
The rest of the paper is organized as follows. Sec-
tion 2 reviews related work and places our work in
context. Section 3 outlines reordering issues due
to syntactic differences between Hindi and English.
Section 4 presents our reordering model, Section 5
presents experimental results and Section 6 presents
our conclusions and possible future work.
2 Related work
There have been several studies demonstrating im-
proved machine translation performance by reorder-
ing source side sentences based on rules applied to
the source side parse during training and decoding.
Much of this work has used hand written rules and
several language pairs have been studied e.g German
to English (Collins et al., 2005), Chinese to English
(Wang et al., 2007), English to Hindi (Ramanathan
et al., 2009), English to Arabic (Badr et al., 2009)
and Japanese to English (Lee et al., 2010). There
have also been some studies where the rules are
learned from the data (Genzel, 2010; Visweswariah
et al., 2010; Xia and McCord, 2004). In addition
there has been work (Yamada and Knight, 2002;
Zollmann and Venugopal, 2006; Galley et al., 2006;
Liu et al., 2006) which uses source and/or target
side syntax in a Context Free Grammar framework
which results in machine translation decoding being
considered as a parsing problem. In this paper we
propose a model that does not require either source
or target side syntax while also preserving the effi-
ciency of reordering techniques based on rules ap-
plied to the source side parse.
In work that is closely related to ours, (Tromble
and Eisner, 2009) formulated word reordering as a
Linear Ordering Problem (LOP), an NP-hard permu-
tation problem. They learned LOP model weights
capable of assigning a score to every possible per-
mutation of the source language sentence from an
aligned corpus by using a averaged perceptron learn-
ing model. The key difference between our model
and the model in (Tromble and Eisner, 2009) is that
while they learn costs of a word wi appearing any-
where before wj , we learn costs of wi immediately
preceding wj . This results in more compact models
and (as we show in Section 5) better models.
Our model results in us having to solve a TSP
instance. The relation between the TSP and ma-
chine translation decoding has been explored before.
(Knight, 1999) showed that TSP is a sub-class ofMT
decoding and thus established that the latter is NP-
hard. (Zaslavskiy et al., 2009) casts phrase-based
487
decoding as a TSP and they show favorable speed
performance trade-offs compared with Moses, an
existing state-of-the-art decoder. In (Tillmann and
Ney, 2003), a beam-search algorithm used for TSP
is adapted to work with an IBM-4 word-based model
and phrase-based model respectively. As opposed
to calculating TSP distances from existing machine
translation components ( viz. the translation, dis-
tortion and language model probabilities) we learn
model weights to reorder source sentences to match
target word order using an informative feature set
adapted from graph-based dependency parsing (Mc-
Donald et al., 2005a).
3 Hindi-English reordering issues
This section provides a brief survey of constructions
that the two languages in question differ as well as
have in common. (Ramanathan et al., 2009) notes
the following divergences:
• English follows SVO order while Hindi follows
SOV order
• English uses prepositions while Hindi uses
post-positions
• Hindi allows greater word order freedom
• Hindi has a relatively richer case-marking sys-
tem
In addition to these differences, (Visweswariah et
al., 2010) mention the similarity in word order in
the case of adjective noun sequences (some books
vs. kuch kitab).
4 Reordering model
Consider a source sentence w consisting of a se-
quence of n words w1, w2, ... wn that we would
like to reorder into the target language order. Given
a permutation pi of the indices 1..n, let the candi-
date reordering be wpi1 , wpi2 , ..., wpin . Thus, pii de-
notes the index of the word in the source sentence
that maps to position i in the candidate reordering.
Clearly there are n! such permutations. Our reorder-
ing model assigns costs to candidate permutations
as:
C(pi|w) =
?
i
c(pii?1, pii).
The cost c(m,n) can be thought of as the cost of the
word at index m immediately preceding the word
with index n in the candidate reordering. In this pa-
per, we parametrize the costs as:
c(m,n) = ?T?(w,m, n),
where ? is a learned vector of weights and ? is a
vector of feature functions.
Given a source sentence w we reorder it accord-
ing to the permutation pi that minimizes the cost
C(pi|w). Thus, we would like our cost function
C(pi|w) to be such that the correct reordering pi? has
the lowest cost of all possible reorderings pi. In Sec-
tion 4.1 we describe the features ? that we use, and
in Section 4.2 we describe how we train the weights
? to obtain a good reordering model.
Given our model structure, the minimization
problem that we need to solve is identical to solving
a Asymmetric Traveling Salesman Problem (ATSP)
with each word corresponding to a city, and the costs
c(m,n) representing the pairwise distances between
the cities. Consider the following example:
English input: John eats apples
Hindi: John seba(apples) khaataa hai(eats)
Desired reordered English: John apples eats
The ATSP that we need to solve is represented
pictorially in Figure 1 with sample costs. Note that
we have one extra node numbered 0. We start and
end the tour at node 0, and this determines the first
word in the reordered sentence. In this example the
minimum cost tour is:
Start ? John ? apple ? eats
recovering the right reordering for translation into
Hindi.
Solving the ATSP (which is a well known NP hard
problem) efficiently is crucial for the efficiency of
our reordering model. To solve the ATSP, we first
convert the ATSP to a symmetric TSP and then use
the Lin-Kernighan heuristic as implemented in Con-
corde, a state-of-the-art TSP solver (Applegate et al.,
2005). We also experimented with using the exact
TSP solver in Concorde but since it was slower and
did not improve performance we preferred using the
Lin-Kernighan heuristic. To convert the ATSP to
a symmetric TSP we double the size of the orig-
inal problem creating a node N ? for every node
N in the original graph. Following (Hornik and
488
3apples
2eats1John
0Start
c(2,3)=3c(3,2)=1
c(0,3)=5c(3,0)=2
c(0,1)=-1c(1,0)= 5 c(1,3)=0
c(0,2)=5
c(1,2)=3c(2,1)=5
c(3,1)=5
c(2,0)=-2
Figure 1: Example of an ATSP for reordering the sen-
tence: John eats apples.
Hahsler, 2009), we then set new costs as follows:
c?(A,B) = ?, c?(A,B?) = c?(B? , A) = c(A,B)
and C(A,A?) = ??. Even with this doubling of
the number of nodes, we observed that solving the
TSPs with the Lin-Kernighan heuristic is very fast,
taking roughly 10 milliseconds per sentence on av-
erage. Overall, this means that our reordering model
is as fast as parsing and hence our model is compara-
ble in performance to techniques based on applying
rules to the parse tree.
4.1 Features
Since we would like to model reordering phenomena
which are largely related to analyzing the syntax of
the source sentence, we chose to use features based
on those that have in the past been used for parsing
(McDonald et al., 2005a). A subset of the features
we use was also used for reordering in (Tromble and
Eisner, 2009).
To be able to generalize from relatively small
amounts of data, we use features that in addition to
depending on the words in the input sentence w de-
pend on the part-of-speech (POS) tags of the words
in the input sentence. All features ?(w, i, j) we use
are binary features, that fire based on the identities
of the words and POS tags at or surrounding posi-
tions i and j in the source sentence. The first set of
feature templates we use are given in Table 1. These
features depend only on the identities of the word
and POS tag of the two positions i and j and we call
wi pi wj pj
× × × ×
×
×
×
×
× ×
× ×
× ×
× ×
× ×
× ×
× × ×
Table 1: Bigram feature templates used to calculate the
cost that word at position i immediately precedes word at
position j in the target word order. wi (pi) denotes the
word (POS tag) at position i in the source sentence. Each
of the templates is also conjoined with i-j the signed dis-
tance between the two words in the source sentence.
these Bigram features.
The second set of feature templates we use are
given in Table 2. These features, in addition to ex-
amining positions i and j examine the surround-
ing positions. We instantiate these feature templates
separately for the POS tag sequence and for the
word sequence. We call these two feature sets Con-
textPOS and ContextWord respectively. When in-
stantiated with POS tags, the first row of Table 2
looks at all POS tags between positions i and j.
(Tromble and Eisner, 2009) use Bigram and Con-
textPOS features, while we extend their feature set
with the use of ContextWord features. Since Hindi
is verb final, in Hindi sentences with multiple verb
groups it is rare for words with a verb in between
to be placed together in the reordering to match En-
glish. Looking at the POS tags of words between
positions i and j allows us to penalize such reorder-
ings.
Each of the templates described in Table 1 and
Table 2 is also conjoined with i-j the signed dis-
tance between the two words in the source sentence.
The values of i-j between 5 and 10, and greater than
10 are quantized (negative values are similarly quan-
tized).
In Section 5.2 we report on experiments showing
the relative performance of these different feature
489
oi?1 oi oi+1 ob oj?1 oj oj+1
× × ×
× × × ×
× × ×
× × ×
× × ×
× × ×
× × × ×
× × ×
× × ×
× × ×
× × ×
× × × ×
× × ×
× × ×
× × × ×
× × ×
× × ×
Table 2: Context feature templates used to calculate the
cost that word at position i immediately precedes word
at position j in the target word order. oi denotes the ob-
servation at position i in the source sentence and ob de-
notes an observation at a position between i and j (i.e
i + 1 ? b ? j ? 1). Each of the templates is instan-
tiated with the observation sequence o taken to be the
word sequence w and the POS tag sequence p. Each of
the templates is also conjoined with i-j the signed dis-
tance between the two positions in the source sentence.
types for the task of reordering Hindi sentences to
be in English word order.
4.2 Training
To train the weights ? in our model, we need a
collection of sentences, where we have the desired
reference reordering pi?(x) for each input sentence
x. To obtain these reference reorderings we use
word aligned source-target sentence pairs. The qual-
ity and consistency of these reference reorderings
will depend on the quality of the word alignments
that we use. Given word aligned source and tar-
get sentences, we drop the source words that are not
aligned. Let mi be the mean of the target word po-
sitions that the source word at index i is aligned to.
We then sort the source indices in increasing order
of mi. If mi = mj (for example, because wi and wj
are aligned to the same set of words) we keep them
in the same order that they occurred in the source
sentence. Obtaining the target ordering in this man-
ner, is certainly not the only possible way and we
would like to explore better treatment of this in fu-
ture work.
We used the single best Margin Infused Re-
laxed Algorithm (MIRA) ((McDonald et al., 2005b),
(Crammer and Singer, 2003)) with the online up-
dates to our parameters being given by
?i+1 = argmin
?
||? ? ?i||
s.t. C(pi?|w) < C(pˆi|w)? L(pi?, pˆi).
In the equation above,
pˆi = argmin
pi
C(pi|x)
is the best reordering based on the current parameter
value and L is a loss function. We take the loss of
a reordering to be the number of words for which
the preceding word is wrong relative to the reference
target order.
We also experimented with the averaged percep-
tron algorithm (Collins, 2002), but found single best
MIRA to work slightly better and hence used MIRA
for all our experiments.
5 Experiments
In this section we report on experiments to evalu-
ate our reordering model. The first method we use
for evaluation (monolingual BLEU) is by generat-
ing the desired reordering of the source sentence (as
described in Section 4.2) and compare the reordered
output to this desired reordered sentence using the
BLEU metric. In addition, to these monolingual
BLEU results, we also evaluate (in Section 5.5) the
reordering by its effect on eventual machine transla-
tion performance.
We note that our reordering techniques uses POS
information for the input sentence. The POS taggers
used in this paper are Maximum Entropy Markov
models trained using manually annotated POS cor-
pora. For Hindi, we used roughly fifty thousand
words with twenty six tags from the corpus de-
scribed in (Dalal et al., 2007). For Urdu we used
roughly fifty thousand words and forty six tags from
the CRULP corpus (Hussain, 2008) and for English
we used the Wall Street Journal section of the Penn
Treebank.
490
5.1 Reordering model training data and
alignment quality
To train our reordering models we need training data
where we have the input source language sentence
and the desired reordering in the target language.
As described in Section 4.2 we derive the refer-
ence reordered sentence using word alignments. Ta-
ble 3 presents our monolingual BLEU results for
Hindi to English reordering as the source of the
word alignments is varied. All results in Table 3
are with Bigram and ContextPOS features. We have
word alignments from three sources: A small set
of hand aligned sentences, HMM alignments (Vo-
gel et al., 1996) and alignments obtained using a su-
pervised Maximum Entropy aligner (Ittycheriah and
Roukos, 2005) trained on the hand alignments. The
F-measure for the HMM alignments were 65% and
78% for the Maximum Entropy model alignments.
We see that the quality of the alignments is an im-
portant determiner of reordering performance. Row
1 shows the BLEU for unreordered (baseline) Hindi
compared with the Hindi sentences reordered in En-
glish Order. Using just HMM alignments to train
our model we do worse than unreordered Hindi. Al-
though using the Maximum Entropy alignments is
better than using HMM alignments, we do not im-
prove upon a small number of hand alignments by
using all the Maximum Entropy alignments.
To improve upon the model trained with only
hand alignments we selected a small number of snip-
pets of sentences from our Maximum Entropy align-
ments. The goal was to pick parts of sentences
where the alignment is reliable enough to use for
training. The heuristic we used in the selection of
snippets was to pick maximal snippets of at least
7 consecutive Hindi words with all Hindi words
aligned to a consecutive span of English words,
with no unaligned English words in the span and no
English words aligned to Hindi words outside the
span. Adding snippets selected with this heuristic
improves the reordering performance of our model
as seen in the last row of Table 3.
5.2 Feature set comparison
In this section we report on experiments to deter-
mine the performance of the different classes of fea-
tures (Bigram, ContextPos and ContextWord) dis-
HMM MaxEnt Hand BLEU
- - - 35.9
220K - - 35.4
- 220K - 47.0
- 220K 6K 48.4
- - 6K 49.0
- Good 17K 6K 51.3
Table 3: Monolingual BLEU scores for Hindi to English
reordering using models trained on different alignment
types and tested on a development set of 280 Hindi sen-
tences (5590 tokens).
Feature template
Bigram ContextPOS ContextWord BLEU
- - - 35.9
× - - 43.8
× × - 49.0
× × × 51.3
Table 4: Monolingual BLEU scores for Hindi to En-
glish reordering using models trained with different fea-
ture sets and tested on a development set of 280 Hindi
sentences (5590 tokens).
cussed in Section 4.1. Table 4 shows monolingual
BLEU results for training with different features sets
for Hindi to English reordering. In all cases, we
use a set of 6000 sentence pairs which were hand
aligned to generate the training data. It is clear that
all three sets of features contribute to performance of
the reordering model, however the number of Con-
textWord features is larger than the number of Bi-
gram and ContextPOS features put together, and it
may be desirable to select from this set of features
especially when training on large amounts of data.
5.3 Monolingual reordering comparisons
Table 5 compares our reordering model with a reim-
plementation of the reordering model proposed in
(Tromble and Eisner, 2009). Both the models use
exactly the same features (bigram features and Con-
textPOS features) and are trained on the same data.
To generate our training data, for Hindi to English
and English to Hindi we use a set of 6000 hand
aligned sentences, for Urdu to English we use a set
of 8500 hand aligned sentences and for English to
French we use a set of 10000 hand aligned sentences
(a subset of Europarl and Hansards corpus). Our
491
Language pair Monolingual BLEU
Source Target Unreordered LOP TSP
Hindi English 35.9 36.6 49.0
English Hindi 34.4 48.4 56.7
Urdu English 35.6 39.5 49.9
English French 64.4 78.2 81.2
Table 5: Monolingual BLEU scores comparing the orig-
inal source order with desired target reorder without re-
ordering, and reordering using our model (TSP) and the
model proposed in (Tromble and Eisner, 2009) (LOP).
test data consisted of 280 sentences for Hindi to En-
glish and 400 sentences for all other language pairs
generated from hand aligned sentences. We include
English-French here to compare on a fairly similar
language pair with local reordering phenomena (the
main difference being that in French adjectives gen-
erally follow nouns). We note that our model outper-
forms the model proposed in (Tromble and Eisner,
2009) in all cases.
5.4 Analysis of reordering performance
To get a feel for the qualitative performance of our
reordering algorithm and the kind of phenomena it
is able to capture, we analyze the reordering per-
formance in terms of (i) whether the clause restruc-
turing is done correctly – these can be thought of
as medium-to-long range reorderings, (ii) whether
clause boundaries are respected, and (iii) whether lo-
cal (short range) reordering is performed correctly.
The following analysis is for Hindi to English re-
ordering with the best model (this is also the model
used for Machine Translation experiments reported
on in Section 5.5).
• Clause structure: As discussed in Section 3,
the canonical clause order in Hindi is SOV,
while in English it is SVO. However, variations
on this structure are possible and quite frequent
(e.g., clauses with two objects). To evaluate
clause restructuring, we compared sequences
of subjects, objects and verbs in the output and
reference reorderings.
We had a set of 70 sentences annotated with
subject, direct object, indirect object and verb
information – these annotations were made on
the head word of each phrase, and the compar-
isons were on sequences of these words alone
and not the entire constituent phrase. 52 sen-
tences were reordered by the model to match
the order of the corresponding reference. Eight
sentences were ordered correctly but differently
from the reference, because the reference was
expressed in non-canonical fashion (e.g., in the
passive) – note that these cases negatively im-
pact the monolingual BLEU score. The follow-
ing example shows a sentence being reordered
correctly, where, however, the reference is ex-
pressed differently (note the position of the
subject “policy” (niiti) in the reference and the
reordered output) 1:
Input: aba1 (now) taka2 (till) aisii3 (this) niiti4
(policy) kabhii5 (ever) nahii6 (not) rahii7 (has)
hai8 (been)
Reordered: taka2 (till) aba1 (now) aisii3 (this)
niiti4 (policy) hai8 (been) kabhii5 (ever) nahii6
(not) rahii7 (has)
Reference: taka2 (till) aba1 (now) aisii3 (this)
kabhii5 (ever) nahii6 (not) rahii7 (has) hai8
(been) niiti4 (policy)
English: Till now this never has been the policy
The remaining ten sentences were reordered in-
correctly. These errors are largely in clauses
which deviate from the SVO order in some
way – clauses with multiple subjects or objects,
clauses with no object, etc.. For example, the
following sentence with two subjects and ob-
jects corresponding to the verb wearing has not
been reordered correctly.
Input: sabhii1 (all) purusha2 (men) safeda3
(white) evama4 (and) mahilaaen5 (women)
kesariyaa6 (saffron) vastra7 (clothes) dhaarana8
(wear) kiye9 hue10 (-ing) thiin11 (were)
Reordered: sabhii1 (all) purusha2 (men)
safeda3 (white) evama4 (and) mahilaaen5
(women) kesariyaa6 (saffron) vastra7 (clothes)
dhaarana8 (wear) thiin11 (were) kiye9 hue10 (-
ing)
Reference: sabhii1 (all) purusha2 (men)
thiin11 (were) dhaarana8 (wear) kiye9 hue10 (-
1The numeric subscripts in the examples indicate word po-
sitions in the input.
492
ing) safeda3 (white) evama4 (and) mahilaaen5
(women) kesariyaa6 (saffron)
English: All men were wearing white and the
women saffron
The model possibly needs more data with pat-
terns that deviate from the standard SOV order
to learn to reorder them correctly. We could
also add to the model, features pertaining to
subject, object, etc.
• Clause boundaries: Measured on a set of
844 sentences which were marked with clause
boundaries, 37 sentences (4.4 %) had reorder-
ings that violated these boundaries. An exam-
ple of such a clause-boundary violation is be-
low:
Input: main1 (I) sarakaara2 (government) kaa3
(of) dhyaana4 (attention) maananiiya5 (hon-
ourable) pradhaana6 (prime) mantri7 (min-
ister) dvaaraa8 (by) isa9 (this) sabhaa10
(house) me11 (in) kiye12 gaye13 (made) isa14
(this) vaade15 (promise) ki16 ora17 (towards)
dilaanaa18 (to bring) chaahuungaa19 (would
like)
Reordered: main1 (I) chahuungaa19 (would
like) dilaanaa18 (to bring) kii16 ora17 (to-
wards) isa9 (this) vaade15 (promise) kiye12
gaye13 (made) dvaaraa8 (by) maananiiya5
(honourable) mantri7 (minister) pradhaana6
(prime) dhyaana4 (attention) kaa3 (of)
sarakaara2 (government) men11 (in) isa14 (this)
sabhaa10 (house)
Reference: main1 (I) chahuungaa19 (would
like) dilaanaa18 (to bring) dhyaana4 (attention)
kaa3 (of) sarakaara2 (government) kii16 ora17
(towards) isa9 (this) vaade15 (promise) kiye12
gaye13 (made) dvaaraa8 (by) maananiiya5
(honourable) mantri7 (minister) pradhaana6
(prime) men11 (in) isa9 (this) sabhaa10 (house)
English I would like to bring the attention of
the government towards this promise made by
the honourable prime minister in this house.
Note how the italicized clause, which is kept
together in the reference, is split up incorrectly
in the reordered output. The proportion of such
boundary violations is, however, quite low, be-
cause Hindi being a verb-final language, most
clauses end with a verb and it is probably quite
straightforward for the model to keep clauses
separate. A clause boundary detection program
should make it possible to eliminate the re-
maining errors.
• Local reordering: To estimate the short range
reordering performance, we consider how of-
ten different POS bigrams in the input are re-
ordered correctly. Here, we expect the model
to reorder prepositions correctly, and to avoid
any reordering that moves apart nouns and their
adjectival pre-modifiers or components of com-
pound nouns (see Section 3). Table 6 sum-
marizes the reordering performance for these
categories for a set of 280 sentences (same as
the test set used in Section 5.1). Each row
in Table 6 indicates the total number of cor-
rect instances for the pair, i.e., the number of
instances of the pair in the reference (column
titled Total), the number of instances that al-
ready appear in the correct order in the input
(column Input), and the number that are or-
dered correctly by the reordering model (col-
umn Reordered). The first two rows show that
adjective-noun and noun-noun (compounds)
are in most cases correctly retained in the orig-
inal order by the model. The final row shows
that while many prepositions have been moved
into their correct positions, there are still quite a
few mismatches with the reference. An impor-
tant reason why this happens is that nouns mod-
ified by prepositional phrases can often also be
expressed as noun compounds. For example,
vidyuta (electricity) kii (of) aavashyakataaen
(requirements) in Hindi can be expressed either
as “requirements of electricity” or “electricity
requirements”. The latter expression results in
a match with the input (explaining many of the
104 correct orders in the input) and a mismatch
with the model’s reordering. The same problem
in the training data would also adversely impact
the learning of the preposition reordering rule.
493
POS pair Total Input Reordered
adj-noun 234 192 196
noun-noun 46 44 42
prep-noun 436 104 250
Table 6: An analyis of reordering for a few POS bigrams
5.5 Machine translation results
We now present experiments in incorporating the re-
ordering model in machine translation systems. For
all results presented here, we reorder the training and
test data using the single best reordering based on
our reordering model for each sentence. For each of
the language pairs we evaluated, we trained Direct
Translation Model 2 (DTM) systems (Ittycheriah
and Roukos, 2007) with and without reordering and
compared performance on test data. We note that the
DTM system includes features that allow it to model
lexicalized reordering phenomena. The reordering
window size was set to +/-8 words for both the base-
line and our reordered input. In our experiments, we
left the word alignments fixed, i.e we reordered the
existing word alignments rather than realigning the
sentences after reordering. Redoing the word align-
ments with the reordered data could potentially give
further small improvements. We note that we ob-
tained better baseline performance using DTM sys-
tems than the standard Moses/Giza++ pipeline (e.g
we obtained a BLEU of 14.9 for English to Hindi
with a standard Moses/Giza++ pipeline). For all of
our systems we used a combination of HMM (Vo-
gel et al., 1996) and MaxEnt alignments (Ittycheriah
and Roukos, 2005).
For our Hindi-English experiments we use a train-
ing set of roughly 250k sentences (5.5Mwords) con-
sisting of the Darpa-TIDES dataset (Bojar et al.,
2010) and an internal dataset from several domains
but dominated by news. Our test set was roughly
1.2K sentences from the news domain with a sin-
gle reference. To train our reordering model, we
used roughly 6K alignments plus 17K snippets se-
lected from MaxEnt alignments as described in Sec-
tion 5.1 with bigram, ContextPOS and ContextWord
features. The monolingual reordering BLEU (on the
same data reported on in Section 5.3) was 54.0 for
Hindi to English and 60.8 for English to Hindi.
For our Urdu-English experiments we used 70k
Language pair BLEU
Source Target Unreordered Reordered
Hindi English 14.7 16.7
Urdu English 23.3 24.8
English Hindi 20.7 22.5
Table 7: Translation performance without reordering
(baseline) compared with performance after preordering
with our reordering model.
sentences from the NIST MT-08 training corpus
and used the MT-08 eval set for testing. We note
that the MT-08 eval set has four references as com-
pared to one reference for our Hindi-English test
set. This largely explains the improved baseline per-
formance for Urdu-English as compared to Hindi-
English. We present averaged results for the Web
and News part of the test sets. To train the reorder-
ing model we used 9K hand alignments and 11K
snippets extracted from MaxEnt alignments as de-
scribed in Section 5.1 with bigram, ContextPOS and
ContextWord context feature. The monolingual re-
ordering BLEU for the reordering model thus ob-
tained (on the same data reported on in Section 5.3)
was 52.7.
Table 7 shows that for Hindi to English, English
to Hindi and for Urdu to English we see a gain
of 1.5 - 2 BLEU points. For English ? Hindi
we also experimented with a system that uses rules
(learned from the data using the methods described
in (Visweswariah et al., 2010)) applied to a parse to
reorder source side English sentences. This system
had a BLEU score of 21.2, which is an improvement
over the baseline, but our reordering model is better
by 1.3 BLEU points.
An added benefit of our reordering model is that
the decoder can be run with a smaller search space
exploring only a small amount of reordering with-
out losing accuracy but running substantially faster.
Table 8 shows the variation in machine Hindi to En-
glish translation performance with varying skip size
(this parameter sets the maximum number of words
skipped during decoding, lower values are associ-
ated with a restricted decoder search space and in-
creased speed).
494
skip Unreordered Reordered
2 12.2 16.7
4 13.4 16.7
8 14.7 16.4
Table 8: Translation performance with/without reorder-
ing with varying decoder search space.
6 Conclusion and future work
In this paper we presented a reordering model to
reorder source language data to make it resemble
the target language word order without using either
a source or target parser. We showed consistent
gains of up to 2 BLEU points in machine transla-
tion performance using this model to preorder train-
ing and test data. We show better performance com-
pared to syntax based reordering rules for English
to Hindi translation. Our model used only a part of
speech tagger (sometimes trained with fairly small
amounts of data) and a small corpus of word align-
ments. Considering the fact that treebanks required
to build high quality parsers are costly to obtain, we
think that our reordering model is a viable alterna-
tive to using syntax for reordering. We also note,
that with the preordering based on our reordering
model we can achieve the best BLEU scores with
a much tighter search space in the decoder. Even ac-
counting for the cost of finding the best reordering
according to our model, this usually results in faster
processing than if we did not have the reordering in
place.
In future work we plan to explore using more data
from automatic alignments, perhaps by considering
a joint model for aligning and reordering. We would
also like to explore doing away with the requirement
of having a POS tagger, using completely unsuper-
vised methods to class words. We currently only
look at word pairs in calculating the loss function
used in MIRA updates. We would like to investigate
the use of other loss functions and their effect on re-
ordering performance. We also would like to explore
whether the use of scores from our reordering model
directly in machine translation systems can improve
performance relative to using just the single best re-
ordering.
References
Yaser Al-Onaizan and Kishore Papineni. 2006. Dis-
tortion models for statistical machine translation. In
Proceedings of ACL, ACL-44, pages 529–536, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
David L. Applegate, Robert E. Bixby, Vasek Chvatal, and
William J. Cook. 2005. Concorde tsp solver. In
http://www.tsp.gatech.edu/.
Ibrahim Badr, Rabih Zbib, and James Glass. 2009. Syn-
tactic phrase reordering for English-to-Arabic statisti-
cal machine translation. In Proceedings of EACL.
Ondrej Bojar, Pavel Stranak, and Daniel Zeman. 2010.
Data issues in English-to-Hindi machine translation.
In LREC.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova´.
2005. Clause restructuring for statistical machine
translation. In Proceedings of ACL, pages 531–540,
Morristown, NJ, USA. Association for Computational
Linguistics.
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: theory and experi-
ments with perceptron algorithms. In Proceedings of
EMNLP.
K. Crammer and Y. Singer. 2003. Ultraconservative on-
line algorithms for multiclass problems. Journal of
Machine Learning Research.
Aniket Dalal, Kumar Nagaraj, Uma Sawant, Sandeep
Shelke, and Pushpak Bhattacharyya. 2007. Building
feature rich pos tagger for morphologically rich lan-
guages: Experiences in Hindi. In Proceedings of In-
ternational Conference on Natural Language Process-
ing.
M. Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe,
W. Wang, and I. Thayer. 2006. Scalable inference and
training of context-rich syntactic translation models.
In Proceedings of ACL.
D. Genzel. 2010. Automatically learning source-side re-
ordering rules for large scale machine translation. In
Proceedings of the 23rd International Conference on
Computational Linguistics.
Kurt Hornik and Michael Hahsler. 2009. TSP–
infrastructure for the traveling salesperson problem.
Journal of Statistical Software, 23(i02).
Sarmad Hussain. 2008. Resources for Urdu language
processing. In Proceedings of the 6th Workshop on
Asian Language Resources, IJCNLP’08.
Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for Arabic-English ma-
chine translation. In Proceedings of HLT/EMNLP,
HLT ’05, pages 89–96, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
495
Abraham Ittycheriah and Salim Roukos. 2007. Direct
translation model 2. In Proceedings of HLT-NAACL,
pages 57–64.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Comput. Linguist.,
25:607–615, December.
Young-Suk Lee, Bing Zhao, and Xiaoqian Luo. 2010.
Constituent reordering and syntax models for English-
to-Japanese statistical machine translation. In COL-
ING.
Y. Liu, Q. Liu, and S. Lin. 2006. Tree-to-String align-
ment template for statistical machine translation. In
Proceedings of ACL.
R. McDonald, K. Crammer, and F. Pereira. 2005a. On-
line large-margin training of dependency parsers. In
Proceedings of ACL.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic?. 2005b. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings of
HLT.
Ananthakrishnan Ramanathan, Hansraj Choudhary,
Avishek Ghosh, and Pushpak Bhattacharyya. 2009.
Case markers and morphology: addressing the crux
of the fluency problem in English-Hindi smt. In
Proceedings of ACL-IJCNLP.
Christoph Tillman. 2004. A unigram orientation model
for statistical machine translation. In Proceedings of
HLT-NAACL.
Christoph Tillmann and Hermann Ney. 2003. Word re-
ordering and a dynamic programming beam search al-
gorithm for statistical machine translation. Computa-
tional Linguistics, 29(1):97–133.
Roy Tromble and Jason Eisner. 2009. Learning linear or-
dering problems for better translation. In Proceedings
of EMNLP.
Karthik Visweswariah, Jiri Navratil, Jeffrey Sorensen,
Vijil Chenthamarakshan, and Nandakishore Kamb-
hatla. 2010. Syntax based reordering with automat-
ically derived rules for improved statistical machine
translation. In Proceedings of the 23rd International
Conference on Computational Linguistics.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the 16th conference on Com-
putational Linguistics.
Chao Wang, Michael Collins, and Philipp Koehn. 2007.
Chinese syntactic reordering for statistical machine
translation. In Proceedings of EMNLP-CoNLL.
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical MT system with automatically learned rewrite
patterns. In COLING.
Kenji Yamada and Kevin Knight. 2002. A decoder for
syntax-based statistical mt. In Proceedings of ACL.
Mikhail Zaslavskiy, Marc Dymetman, and Nicola Can-
cedda. 2009. Phrase-based statistical machine transla-
tion as a traveling salesman problem. In Proceedings
of ACL-IJCNLP.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
augmented machine translation via chart parsing. In
Proceedings on the Workshop on Statistical Machine
Translation.
496
