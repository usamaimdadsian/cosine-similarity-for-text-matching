Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 908–913,
Seattle, Washington, USA, 18-21 October 2013. c©2013 Association for Computational Linguistics
Online Learning for Inexact Hypergraph Search
Hao Zhang
Google
haozhang@google.com
Liang Huang Kai Zhao
City University of New York
{lhuang@cs.qc,kzhao@gc}.cuny.edu
Ryan McDonald
Google
ryanmcd@google.com
Abstract
Online learning algorithms like the percep-
tron are widely used for structured predic-
tion tasks. For sequential search problems,
like left-to-right tagging and parsing, beam
search has been successfully combined with
perceptron variants that accommodate search
errors (Collins and Roark, 2004; Huang et
al., 2012). However, perceptron training with
inexact search is less studied for bottom-up
parsing and, more generally, inference over
hypergraphs. In this paper, we generalize
the violation-fixing perceptron of Huang et
al. (2012) to hypergraphs and apply it to the
cube-pruning parser of Zhang and McDonald
(2012). This results in the highest reported
scores on WSJ evaluation set (UAS 93.50%
and LAS 92.41% respectively) without the aid
of additional resources.
1 Introduction
Structured prediction problems generally deal with
exponentially many outputs, often making exact
search infeasible. For sequential search problems,
such as tagging and incremental parsing, beam
search coupled with perceptron algorithms that ac-
count for potential search errors have been shown
to be a powerful combination (Collins and Roark,
2004; Daume´ and Marcu, 2005; Zhang and Clark,
2008; Huang et al., 2012). However, sequen-
tial search algorithms, and in particular left-to-right
beam search (Collins and Roark, 2004; Zhang and
Clark, 2008), squeeze inference into a very narrow
space. To address this, Huang (2008) formulated
constituency parsing as approximate bottom-up in-
ference in order to compactly represent an exponen-
tial number of outputs while scoring features of ar-
bitrary scope. This idea was adapted to graph-based
dependency parsers by Zhang and McDonald (2012)
and shown to outperform left-to-right beam search.
Both these examples, bottom-up approximate de-
pendency and constituency parsing, can be viewed
as specific instances of inexact hypergraph search.
Typically, the approximation is accomplished by
cube-pruning throughout the hypergraph (Chiang,
2007). Unfortunately, as the scope of features at
each node increases, the inexactness of search and
its negative impact on learning can potentially be ex-
acerbated. Unlike sequential search, the impact on
learning of approximate hypergraph search – as well
as methods to mitigate any ill effects – has not been
studied. Motivated by this, we develop online learn-
ing algorithms for inexact hypergraph search by gen-
eralizing the violation-fixing percepron of Huang et
al. (2012). We empirically validate the benefit of
this approach within the cube-pruning dependency
parser of Zhang and McDonald (2012).
2 Structured Perceptron for Inexact
Hypergraph Search
The structured perceptron algorithm (Collins, 2002)
is a general learning algorithm. Given training in-
stances (x, yˆ), the algorithm first solves the decod-
ing problem y? = argmaxy?Y(x)w · f(x, y) given
the weight vector w for the high-dimensional fea-
ture representation f of the mapping (x, y), where
y? is the prediction under the current model, yˆ is the
gold output and Y(x) is the space of all valid outputs
for input x. The perceptron update rule is simply:
w? = w + f(x, yˆ) ? f(x, y?).
The convergence of original perceptron algorithm
relies on the argmax function being exact so that
the conditionw ·f(x, y?) > w ·f(x, yˆ) (modulo ties)
always holds. This condition is called a violation
because the prediction y? scores higher than the cor-
rect label yˆ. Each perceptron update moves weights
908
A B C D E F
G H I J
K L
M
N
Figure 1: A hypergraph showing the union of the gold
and Viterbi subtrees. The hyperedges in bold and dashed
are from the gold and Viterbi trees, respectively.
away from y? and towards yˆ to fix such violations.
But when search is inexact, y? could be suboptimal
so that sometimes w · f(x, y?) < w · f(x, yˆ). Huang
et al. (2012) named such instances non-violations
and showed that perceptron model updates for non-
violations nullify guarantees of convergence. To ac-
count for this, they generalized the original update
rule to select an output y? within the pruned search
space that scores higher than yˆ, but is not necessar-
ily the highest among all possibilities, which repre-
sents a true violation of the model on that training
instance. This violation fixing perceptron thus re-
laxes the argmax function to accommodate inexact
search and becomes provably convergent as a result.
In the sequential cases where yˆ has a linear struc-
ture such as tagging and incremental parsing, the
violation fixing perceptron boils down to finding
and updating along a certain prefix of yˆ. Collins
and Roark (2004) locate the earliest position in a
chain structure where yˆpref is worse than y?pref by
a margin large enough to cause yˆ to be dropped
from the beam. Huang et al. (2012) locate the po-
sition where the violation is largest among all pre-
fixes of yˆ, where size of a violation is defined as
w · f(x, y?pref) ? w · f(x, yˆpref).
For hypergraphs, the notion of prefix must be gen-
eralized to subtrees. Figure 1 shows the packed-
forest representation of the union of gold subtrees
and highest-scoring (Viterbi) subtrees at every gold
node for an input. At each gold node, there are
two incoming hyperedges: one for the gold subtree
and the other for the Viterbi subtree. After bottom-
up parsing, we can compute the scores for the gold
subtrees as well as extract the corresponding Viterbi
subtrees by following backpointers. These Viterbi
subtrees need not necessarily to belong to the full
Viterbi path (i.e., the Viterbi tree rooted at node N ).
An update strategy must choose a subtree or a set of
subtrees at gold nodes. This is to ensure that the
model is updating its weights relative to the inter-
section of the search space and the gold path.
Our first update strategy is called single-node
max-violation (s-max). Given a gold tree yˆ, it tra-
verses the gold tree and finds the node n on which
the violation between the Viterbi subtree and the
gold subtree is the largest over all gold nodes. The
violation is guaranteed to be greater than or equal to
zero because the lower bound for the max-violation
on any hypergraph is 0 which happens at the leaf
nodes. Then we choose the subtree pair (yˆn, y?n) and
do the update similar to the prefix update for the se-
quential case. For example, in Figure 1, suppose the
max-violation happens at node K , which covers the
left half of the input x, then the perceptron update
would move parameters to the subtree represented
by nodes B , C , H and K and away from A ,
B , G and K .
Our second update strategy is called parallel max-
violation (p-max). It is based on the observation that
violations on non-overlapping nodes can be fixed
in parallel. We define a set of frontiers as a set
of nodes that are non-overlapping and the union of
which covers the entire input string x. The frontier
set can include up to |x| nodes, in the case where the
frontier is equivalent to the set of leaves. We traverse
yˆ bottom-up to compute the set of frontiers such
that each has the max-violation in the span it cov-
ers. Concretely, for each node n, the max-violation
frontier set can be defined recursively,
ft(n) =
{
n, if n = maxv(n)
?
ni?children(n) ft(ni), otherwise
where maxv(n) is the function that returns the node
with the absolute maximum violation in the subtree
rooted at n and can easily be computed recursively
over the hypergraph. To make a perceptron update,
we generate the max-violation frontier set for the en-
tire hypergraph and use it to choose subtree pairs
?
n?ft(root(x))(yˆn, y
?
n), where root(x) is the root of
the hypergraph for input x. For example, in Figure 1,
if the union of K and L satisfies the definition of
ft, then the perceptron update would move feature
909
weights away from the union of the two Viterbi sub-
trees and towards their gold counterparts.
In our experiments, we compare the performance
of the two violation-fixing update strategies against
two baselines. The first baseline is the standard up-
date, where updates always happen at the root node
of a gold tree, even if the Viterbi tree at the root node
leads to a non-violation update. The second baseline
is the skip update, which also always updates at the
root nodes but skips any non-violations. This is the
strategy used by Zhang and McDonald (2012).
3 Experiments
We ran a number of experiments on the cube-
pruning dependency parser of Zhang and McDonald
(2012), whose search space can be represented as a
hypergraph in which the nodes are the complete and
incomplete states and the hyperedges are the instan-
tiations of the two parsing rules in the Eisner algo-
rithm (Eisner, 1996).
The feature templates we used are a superset of
Zhang and McDonald (2012). These features in-
clude first-, second-, and third-order features and
their labeled counterparts, as well as valency fea-
tures. In addition, we also included a feature tem-
plate from Bohnet and Kuhn (2012). This tem-
plate examines the leftmost child and the rightmost
child of a modifier simultaneously. All other high-
order features of Zhang and McDonald (2012) only
look at arcs on the same side of their head. We
trained the parser with hamming-loss-augmented
MIRA (Crammer et al., 2006), following Martins et
al. (2010). Based on results on the English valida-
tion data, in all the experiments, we trained MIRA
with 8 epochs and used a beam of size 6 per node.
To speed up the parser, we used an unlabeled
first-order model to prune unlikely dependency arcs
at both training and testing time (Koo and Collins,
2010; Martins et al., 2013). We followed Rush and
Petrov (2012) to train the first-order model to min-
imize filter loss with respect to max-marginal filter-
ing. On the English validation corpus, the filtering
model pruned 80% of arcs while keeping the oracle
unlabeled attachment score above 99.50%. During
training only, we insert the gold tree into the hy-
pergraph if it was mistakenly pruned. This ensures
that the gold nodes are always available, which is
required for model updates.
3.1 English and Chinese Results
We report dependency parsing results on the Penn
WSJ Treebank and the Chinese CTB-5 Treebank.
Both treebanks are constituency treebanks. We gen-
erated two versions of dependency treebanks by ap-
plying commonly-used conversion procedures. For
the first English version (PTB-YM), we used the
Penn2Malt1 software to apply the head rules of Ya-
mada and Matsumoto and the Malt label set. For
the second English version (PTB-S), we used the
Stanford dependency framework (De Marneffe et
al., 2006) by applying version 2.0.5 of the Stan-
ford parser. We split the data in the standard way:
sections 2-21 for training; section 22 for validation;
and section 23 for evaluation. We utilized a linear
chain CRF tagger which has an accuracy of 96.9%
on the validation data and 97.3% on the evaluation
data2. For Chinese, we use the Chinese Penn Tree-
bank converted to dependencies and split into train/-
validation/evaluation according to Zhang and Nivre
(2011). We report both unlabeled attachment scores
(UAS) and labeled attachment scores (LAS), ignor-
ing punctuations (Buchholz and Marsi, 2006).
Table 1 displays the results. Our improved
cube-pruned parser represents a significant improve-
ment over the feature-rich transition-based parser of
Zhang and Nivre (2011) with a large beam size. It
also improves over the baseline cube-pruning parser
without max-violation update strategies (Zhang and
McDonald, 2012), showing the importance of up-
date strategies in inexact hypergraph search. The
UAS score on Penn-YM is slightly higher than the
best result known in the literature which was re-
ported by the fourth-order unlabeled dependency
parser of Ma and Zhao (2012), although we did
not utilize fourth-order features. The LAS score on
Penn-YM is on par with the best reported by Bohnet
and Kuhn (2012). On Penn-S, there are not many
existing results to compare with, due to the tradition
of reporting results on Penn-YM in the past. Never-
theless, our result is higher than the second best by
a large margin. Our Chinese parsing scores are the
highest reported results.
1http://stp.lingfil.uu.se//?nivre/research/Penn2Malt.html
2The data was prepared by Andre´ F. T. Martins as was done
in Martins et al. (2013).
910
Penn-YM Penn-S CTB-5
Parser UAS LAS Toks/Sec UAS LAS Toks/Sec UAS LAS Toks/Sec
Zhang and Nivre (2011) 92.9- 91.8- †680 - - - 86.0- 84.4- -
Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 92.96 90.74 500 85.93 84.42 700
Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 93.11 90.84 250 86.05 84.50 360
Koo and Collins (2010) 93.04 - - - - - - - -
Zhang and McDonald (2012) 93.06 91.86 220 - - - 86.87 85.19 -
Rush and Petrov (2012) - - - 92.7- - 4460 - - -
Martins et al. (2013) 93.07 - 740 92.82 - 600 - - -
Qian and Liu (2013) 93.17 - 180 - - - 87.25 - 100
Bohnet and Kuhn (2012) 93.39 92.38 †120 - - - 87.5- 85.9- -
Ma and Zhao (2012) 93.4- - - - - - 87.4- - -
cube-pruning w/ skip 93.21 92.07 300 92.92 90.35 200 86.95 85.23 200
w/ s-max 93.50 92.41 300 93.59 91.17 200 87.78 86.13 200
w/ p-max 93.44 92.33 300 93.64 91.28 200 87.87 86.24 200
Table 1: Parsing results on test sets of the Penn Treebank and CTB-5. UAS and LAS are measured on all tokens except
punctuations. We also include the tokens per second numbers for different parsers whenever available, although the
numbers from other papers were obtained on different machines. Speed numbers marked with † were converted from
sentences per second.
The speed of our parser is around 200-300 tokens
per second for English. This is faster than the parser
of Bohnet and Kuhn (2012) which has roughly the
same level of accuracy, but is slower than the parser
of Martins et al. (2013) and Rush and Petrov (2012),
both of which only do unlabeled dependency pars-
ing and are less accurate. Given that predicting la-
bels on arcs can slow down a parser by a constant
factor proportional to the size of the label set, the
speed of our parser is competitive. We also tried to
prune away arc labels based on observed labels for
each POS tag pair in the training data. By doing so,
we could speed up our parser to 500-600 tokens per
second with less than a 0.2% drop in both UAS and
LAS.
3.2 Importance of Update Strategies
The lower portion of Table 1 compares cube-pruning
parsing with different online update strategies in or-
der to show the importance of choosing an update
strategy that accommodates search errors. The max-
violation update strategies (s-max and p-max) im-
proved results on both versions of the Penn Treebank
as well as the CTB-5 Chinese treebank. It made
a larger difference on Penn-S relative to Penn-YM,
improving as much as 0.93% in LAS against the skip
update strategy. Additionally, we measured the per-
centage of non-violation updates at root nodes. In
the last epoch of training, on Penn-YM, there was
24% non-violations if we used the skip update strat-
egy; on Penn-S, there was 36% non-violations. The
portion of non-violations indicates the inexactness
 92
 92.2
 92.4
 92.6
 92.8
 93
 93.2
 93.4
 93.6
 93.8
 94
 1  2  3  4  5  6  7  8
UA
S
epochs
UAS on Penn-YM dev
s-max
p-max
skip
standard
Figure 2: Constrast of different update strategies on the
validation data set of Penn-YM. The x-axis is the number
of training epochs. The y-axis is the UAS score. s-max
stands for single-node max-violation. p-max stands for
parallel max-violation.
of the underlying search. Search is harder on Penn-S
due to the larger label set. Thus, as expected, max-
violation update strategies improve most where the
search is the hardest and least exact.
Figure 2 shows accuracy per training epoch on the
validation data. It can be seen that bad update strate-
gies are not simply slow learners. More iterations
of training cannot close the gap between strategies.
Forcing invalid updates on non-violations (standard
update) or simply ignoring them (skip update) pro-
duces less accurate models overall.
911
ZN 2011 (reimpl.) skip s-max p-max Best Published†
Language UAS LAS UAS LAS UAS LAS UAS LAS UAS LAS
SPANISH 86.76 83.81 87.34 84.15 87.96 84.95 87.68 84.75 87.48 84.05
CATALAN 94.00 88.65 94.54 89.14 94.58 89.05 94.98 89.56 94.07 89.09
JAPANESE 93.10 91.57 93.40 91.65 93.26 91.67 93.20 91.49 93.72 91.7-
BULGARIAN 93.08 89.23 93.52 89.25 94.02 89.87 93.80 89.65 93.50 88.23
ITALIAN 87.31 82.88 87.75 83.41 87.57 83.22 87.79 83.59 87.47 83.50
SWEDISH 90.98 85.66 90.64 83.89 91.62 85.08 91.62 85.00 91.44 85.42
ARABIC 78.26 67.09 80.42 69.46 80.48 69.68 80.60 70.12 81.12 66.9-
TURKISH 76.62 66.00 76.18 65.90 76.94 66.80 76.86 66.56 77.55 65.7-
DANISH 90.84 86.65 91.40 86.59 91.88 86.95 92.00 87.07 91.86 84.8-
PORTUGUESE 91.18 87.66 91.69 88.04 92.07 88.30 92.19 88.40 93.03 87.70
GREEK 85.63 78.41 86.37 78.29 86.14 78.20 86.46 78.55 86.05 77.87
SLOVENE 84.63 76.06 85.01 75.92 86.01 77.14 85.77 76.62 86.95 73.4-
CZECH 87.78 82.38 86.92 80.36 88.36 82.16 88.48 82.38 90.32 80.2-
BASQUE 79.65 71.03 79.57 71.43 79.59 71.52 79.61 71.65 80.23 73.18
HUNGARIAN 84.71 80.16 85.67 80.84 85.85 81.02 86.49 81.67 86.81 81.86
GERMAN 91.57 89.48 91.23 88.34 92.03 89.44 91.79 89.28 92.41 88.42
DUTCH 82.49 79.71 83.01 79.79 83.57 80.29 83.35 80.09 86.19 79.2-
AVG 86.98 81.55 87.33 81.56 87.76 82.08 87.80 82.14
Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years,
we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi
(2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For
consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is
our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011
reimplementation and different update strategies from this paper.
3.3 CoNLL Results
We also report parsing results for 17 languages from
the CoNLL 2006/2007 shared-task (Buchholz and
Marsi, 2006; Nivre et al., 2007). The parser in
our experiments can only produce projective depen-
dency trees as it uses an Eisner algorithm backbone
to generate the hypergraph (Eisner, 1996). So, at
training time, we convert non-projective trees – of
which there are many in the CoNLL data – to projec-
tive ones through flattening, i.e., attaching words to
the lowest ancestor that results in projective trees. At
testing time, our parser can only predict projective
trees, though we evaluate on the true non-projective
trees.
Table 2 shows the full results. We sort the
languages according to the percentage of non-
projective trees in increasing order. The Spanish
treebank is 98% projective, while the Dutch tree-
bank is only 64% projective. With respect to the
Zhang and Nivre (2011) baseline, we improved UAS
in 16 languages and LAS in 15 languages. The im-
provements are stronger for the projective languages
in the top rows. We achieved the best published
UAS results for 7 languages: Spanish, Catalan, Bul-
garain, Italian, Swedish, Danish, and Greek. As
these languages are typically from the more projec-
tive data sets, we speculate that extending the parser
used in this study to handle non-projectivity will
lead to state-of-the-art models for the majority of
languages.
4 Conclusions
We proposed perceptron update strategies for in-
exact hypergraph search and experimented with
a cube-pruning dependency parser. Both single-
node max-violation and parallel max-violation up-
date strategies signficantly improved parsing results
over the strategy that ignores any invalid udpates
caused by inexactness of search. The update strate-
gies are applicable to any bottom-up parsing prob-
lems such as constituent parsing (Huang, 2008) and
syntax-based machine translation with online learn-
ing (Chiang et al., 2008).
Acknowledgments: We thank Andre´ F. T. Martins
for the dependency converted Penn Treebank with
automatic POS tags from his experiments; the re-
viewers for their useful suggestions; the NLP team
at Google for numerous discussions and comments;
Liang Huang and Kai Zhao are supported in part by
DARPA FA8750-13-2-0041 (DEFT), PSC-CUNY,
and a Google Faculty Research Award.
912
References
B. Bohnet and J. Kuhn. 2012. The best of bothworlds
- a graph-based completion model for transition-based
parsers. In Proc. of EACL.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proc. of EMNLP.
D. Chiang. 2007. Hierarchical phrase-based translation.
Computational Linguistics, 33(2).
M. Collins and B. Roark. 2004. Incremental parsing with
the perceptron algorithm. In Proc. of ACL.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. of ACL.
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive al-
gorithms. Journal of Machine Learning Research.
H. Daume´ and D. Marcu. 2005. Learning as search
optimization: Approximate large margin methods for
structured prediction. In Proc. of ICML.
M. De Marneffe, B. MacCartney, and C.D. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In Proc. of LREC.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: an exploration. In Proc. of COL-
ING.
L. Huang, S. Fayong, and G. Yang. 2012. Structured
perceptron with inexact search. In Proc. of NAACL.
L. Huang. 2008. Forest reranking: Discriminative pars-
ing with non-local features. In Proc. of ACL.
T. Koo and M. Collins. 2010. Efficient third-order de-
pendency parsers. In Proc. of ACL.
X. Ma and H. Zhao. 2012. Fourth-order dependency
parsing. In Proc. of COLING.
A. F. T. Martins, N. Smith, E. P. Xing, P. M. Q. Aguiar,
and M. A. T. Figueiredo. 2010. Turbo parsers: Depen-
dency parsing by approximate variational inference.
In Proc. of EMNLP.
A. F. T. Martins, M. B. Almeida, and N. A. Smith. 2013.
Turning on the turbo: Fast third-order non-projective
turbo parsers. In Proc. of ACL.
J. Nivre, J. Hall, S. Ku¨bler, R. McDonald, J. Nils-
son, S. Riedel, and D. Yuret. 2007. The CoNLL
2007 shared task on dependency parsing. In Proc. of
EMNLP-CoNLL.
X. Qian and Y. Liu. 2013. Branch and bound algo-
rithm for dependency parsing with non-local features.
TACL, Vol 1.
A. Rush and S. Petrov. 2012. Efficient multi-pass depen-
dency pruning with vine parsing. In Proc. of NAACL.
Y. Zhang and S. Clark. 2008. A Tale of Two
Parsers: Investigating and Combining Graph-based
and Transition-based Dependency Parsing. In Proc.
of EMNLP.
H. Zhang and R. McDonald. 2012. Generalized higher-
order dependency parsing with cube pruning. In Proc.
of EMNLP.
Y. Zhang and J. Nivre. 2011. Transition-based depen-
dency parsing with rich non-local features. In Proc. of
ACL-HLT, volume 2.
913
