Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269,
Singapore, 6-7 August 2009. c©2009 ACL and AFNLP
Using Morphological and Syntactic Structures  
for Chinese Opinion Analysis 
 
 
Lun-Wei Ku Ting-Hao Huang Hsin-Hsi Chen 
 
Department of Computer Science and Information Engineering 
National Taiwan University 
No. 1, Sec. 4, Roosevelt Road, Taipei, 10617 Taiwan 
{lwku,thhuang}@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.tw 
 
   
 
 
Abstract 
This paper employs morphological struc-
tures and relations between sentence seg-
ments for opinion analysis on words and 
sentences.  Chinese words are classified 
into eight morphological types by two 
proposed classifiers, CRF classifier and 
SVM classifier.  Experiments show that 
the injection of morphological information 
improves the performance of the word po-
larity detection.  To utilize syntactic struc-
tures, we annotate structural trios to repre-
sent relations between sentence segments.  
Experiments show that considering struc-
tural trios is useful for sentence opinion 
analysis.  The best f-score achieves 0.77 
for opinion word extraction, 0.62 for opin-
ion word polarity detection, 0.80 for opin-
ion sentence extraction, and 0.54 for opin-
ion sentence polarity detection. 
1 Introduction 
Sentiment analysis has attracted much attention 
in recent years because a large scale of subjective 
information is disseminated through various plat-
forms on the web.  Sentiment information can be 
applied to a wide variety of fields, including 
product recommendation, review summarization, 
public polling, and so on. 
Opinion dictionaries are important resources 
for identifying subjective information.  Several 
approaches were proposed to collect such re-
sources.  Wiebe (2000) learned subjective adjec-
tives from corpora.  Takamura et al. (2005) ex-
tracted semantic orientations of words.  Ku et al. 
(2007) measured sentiment degrees of Chinese 
words by averaging the sentiment scores of the 
composing characters.  When the opinion words 
are available, the polarities of sentences and 
documents can be determined by them.  Riloff 
and Wiebe (2003) learned the extraction patterns 
for subjective expressions.  Kim and Hovy (2004) 
found the polarity of subjective expressions.  
Pang et al. (2002) and Dave et al. (2003) ex-
plored various techniques at document level. 
Morphological information has been widely 
used in classifying words, telling the meanings, 
and doing other in-depth analysis (Tzeng and 
Chen, 2002).  However, morphological informa-
tion was seldom applied either in Chinese opin-
ion extraction, or in solving the coverage prob-
lem of opinion dictionary.  Instead of bag-of-
characters approach (Ku et al., 2007), this paper 
employs morphological structures of words to 
extract opinion words.   
Relations between sentence segments are also 
defined by linguistics in the Chinese language.  
These are similar to morphological structures 
between Chinese characters. Based on parsing 
trees of sentences, we identify these relations and 
utilize them for opinion analysis on sentences. 
As the experimental corpus, some researchers 
managed to generate annotated materials and 
gold standards under many constraints.  Ku set a 
standard for generating final answers from anno-
tations of multiple annotators (Ku et al., 2007), 
and Somasundaran annotated discourse informa-
tion from meeting dialogs to train a sentiment 
model (Somasundaran et al., 2007).  For multi-
lingual issues, researchers concerned mainly 
about the applicability of corpus and algorithms 
from the native language to foreign languages 
(Banea et al., 2008; Bautin et al., 2008). 
Several opinion analysis systems have been 
developed so far.  OASYS (Cesarano et al., 2007) 
and CopeOpi (Ku et al., 2007) allow users input 
their queries and select preferred data sources, 
1260
and then track opinions in a time zone.  For both 
systems, extracting opinions is the main focus, 
while holders and targets are identified implicitly 
when retrieving relevant documents.  Carenini’s 
team proposed a graphical user interface for 
evaluative texts (2006), in which color blocks 
were used to present the evaluations for compo-
nents of products.  Fair News Reader, a Japanese 
news Web system, incorporates sentiment infor-
mation insensibly in an interesting way (Kawai 
et al., 2007).   It provides readers “balanced” re-
ports by analyzing the sentiment in news articles 
which readers have read, and suggests them new 
articles according to the analysis results.  It leads 
the application of opinion analysis to the direc-
tion of personalization. 
2 Chinese Morphological Structures 
In the Chinese language, a word is composed of 
one or more Chinese characters, and its meaning 
can be interpreted in terms of its composite char-
acters.  The morphological structures of Chinese 
words are formulated by three major processes in 
linguistics: compounding, affixation, and conver-
sion.  Compounding is a complex word-
formation process.  In most cases, two or more 
morphemes together are formed as a lexical item 
by this process.  Affixation is a morphological 
process, by which grammatical or lexical infor-
mation is added to a base form.  By the conver-
sion process, a word is changed from one part of 
speech into another without the addition or dele-
tion of any morphemes.   
Compounding is the most productive way to 
construct a Chinese word.  Mostly, a Chinese 
character itself carries meanings, so that a mor-
pheme can function as a character and has its 
own part of speech.  In some cases, a Chinese 
morpheme may carry no specific meaning and 
just makes a word more readable.  Cheng and 
Tian (1992) divided Chinese words into five 
morphological types based on the relations be-
tween the morphemes in compounding words.  
(1) Parallel Type: Two morphemes play coordi-
nate roles in a word.  For example, the mor-
phemes “?” (money) and “?” (wealth) are par-
allel in the word “??” (money-wealth). 
 
(2) Substantive-Modifier Type: A modified 
morpheme follows a modifying morpheme.  For 
example, the morpheme “?” (cry) is modified 
by “?” (bitterly) in the word ”??” (bitterly-
cry). 
 
(3) Subjective-Predicate Type: One morpheme 
is an expresser and the other one is described.  
The structure is like a subject-verb sentence con-
densed in one word.  For example, the morpheme 
“?” (heart) is a subject of the predicate “?” 
(hurt) in the word “??” (heart-hurt). 
 
(4) Verb-Object Type: The first morpheme is 
usually a verb which governs the second one, 
making this word similar to a verb followed by 
its object.  For example, the morpheme “?” 
(control) serves as the object of the verb “?” 
(lose) in the word ”??” (lose-control). 
 
(5) Verb-Complement Type: The first mor-
pheme is usually a verb but sometimes can be an 
adjective, and the second morpheme explains the 
first one from different aspects.  For example, the 
morpheme “?” (clearly) expresses the aspects of 
the action “?” (look). 
 
Chinese words constructed by affixation proc-
ess can be one of the two cases – say, morpheme 
and morpheme, or morpheme and non-morpheme.  
In the case of morpheme and morpheme, the af-
fixation word belongs to one of the above 5 types 
if the prefix and the suffix are neither negations 
nor confirmations.  Types 6 and 7 defined below 
represent the affixation words whose prefix or 
suffix is a negation or a confirmation.  The af-
fixation words whose prefix or suffix characters 
are not morphemes are classified into type 8. 
 
(6) Negation Type: There is at least one nega-
tion character in words of this type.  For example, 
the prefix “?” (no) is the negation morpheme in 
the word ”??” (no-method). 
 
(7) Confirmation Type: There is at least one 
confirmation character in words of this type.  For 
example, the prefix  “?” (do) is a confirmation 
in the word “??” (do-depend on). 
 
(8) Others: Those words that do not belong to 
the above seven types are assigned to this type, 
such as words whose meanings are not a function 
of their composite characters, words whose com-
posite characters are not morphemes, such as “?
?” (nephew-suffix) and “??” (peppermint). 
3 Opinion Scores of Chinese Words  
The bag-of-characters approach proposed by Ku 
et al. (2007) considers the observation probabili-
ties of characters in Chinese opinion words.  It 
calculates the observation probabilities of char-
acters from a set of seeds first, then dynamically 
enlarges the set and adjusts their probabilities.  In 
1261
this approach, the opinion score of a word is de-
termined by the combination of the observation 
probabilities of its composite characters defined 
by Formulas (1) and (2). 
 
??
?
==
=
+
= m
i
i
n
i
i
n
i
i
neg,Cf/neg,Cfpos,Cf/pos,Cf
pos,Cf/pos,Cf
posCP
11
1
)()()()(
)()(
),( (1)
??
?
==
=
+
= m
i
i
n
i
i
m
i
i
neg,Cf/neg,Cfpos,Cf/pos,Cf
neg,Cf/neg,Cf
negCP
11
1
)()()()(
)()(
),( (2)
),(),()( negCNposCPCS ?=
 
(3)
)(
1
)...(
1
21 ?
=
=
l
i
il CSl
CCCS
 
(4)
 
where C is an arbitrary Chinese character, f(C, 
polarity) counts the observed frequency of C in a 
set of Chinese words whose opinion polarity is 
positive (pos) or negative (neg); P(C, pos) and 
P(C, neg) denote the observation probabilities of 
C as a positive and a negative character, and n 
and m denote total number of unique characters 
in positive and negative words.  The difference 
of P(C, pos) and P(C, neg) in Formula (3) de-
termines the sentiment score of character C, de-
noted by S(C).  Formula (4) computes the opin-
ion score of a word of l characters C1C2…Cl by 
averaging their scores. 
Instead of counting the weights as in the bag-
of-characters approaches, we consider the word 
structures and propose a scoring function for 
each morphological type.  According to the Fre-
quency Dictionary of Modern Chinese, 96.5% of 
Chinese words are unigrams and bigrams (Chen, 
et al., 1997).  In the following functions, S(C1C2) 
computes the opinion scores of words with char-
acters C1 and C2.  SIGN(s) returns -1 if polarity 
degree s is smaller than 0, i.e., negative, and re-
turns 1 when positive. 
 
(1) Parallel Type: Since the two composite 
characters of a word of this type are homogene-
ous, the opinion score is the average score of two 
characters’ opinion scores.   
 
 
2
)()(
)( 2121
CSCS
CCS
+
=
 (5)
 
 
(2) Substantive-Modifier Type: The first mor-
pheme of a word of this type modifies the second 
one, so that its opinion weight comes from the 
absolute opinion score of the first character, 
while the opinion polarity is determined by the 
occurrence of negative opinion characters.  If at 
least one negative opinion character appears, the 
word is negative, else it is positive.  For example, 
the word “??” (bitterly cry) is composed of 
“?” (bitterly, negative) and “?” (cry, negative).  
Negative characters make this word negative and 
its opinion strength, i.e., the absolute value of the 
score, is decided by the first character for the 
degree of crying. 
 
)()()( else
)( 1- )( else      
 )(  )( then  )0)(  and  0)(( if      
 then)0)(  and  0)(( if
2121
121
12121
21
CSCSCCS
CSCCS
CSCCSCSCS
CSCS
+=
×=
=>>
??
 
(6)
      
 
(3) Subjective-Predicate Type: The first mor-
pheme of a word of this type is a subject and the 
second morpheme is the action it performs, so 
that the action decides the opinion score of the 
word.  If the action is not an opinion or it is neu-
tral, the subject determines the opinion score of 
this word.  For example, the word “??” (mud-
slide, negative) is composed of “?” (mountain, 
non-opinion) and “?” (collapse, negative). Its 
opinion score depends only on the second char-
acter “?” (collapse) since the first character is a 
subject and usually bears no opinions. 
 
)()( else
 )()( then )0)(( if
121
2212
CSCCS
CSCCSCS
=
=?  (7)
 
 
(4) Verb-Object Type: The first morpheme of 
words of this type acts upon the second mor-
pheme.  The effect depends not only on the ac-
tion but on the target.  The weight is determined 
by the action, but the polarity is the multiplica-
tion of the signs of the two morphemes.  For ex-
ample, the word “??” (to go away for the 
summer, positive) is composed of “?” (hide, 
negative) and “?” (hot summer, negative).  Its 
strength depends on the strength of “?” (hide) 
and polarity is positive from the multiplication of 
two negatives.  
 
)()()( else    
))(())(()()(    then  
)0)(  and  0)(( if
2121
21121
21
CSCSCCS
CSSIGNCSSIGNCSCCS
CSCS
+=
××=
??
(8)
 
 
(5) Verb-Complement Type: The scoring func-
tion for words of this type is defined the same as 
that of a Subjective-Predicate type in Formula 
(7).  The complement morpheme is the deciding 
factor of the opinion score.  For example, the 
word “??” (raise, positive) is composed of 
“?” (carry or lift, non-opinion) and “?” (high, 
1262
positive).  The complement morpheme “? ” 
(high) describes the resulting state of the verb 
morpheme “?” (raise), so both strength and po-
larity depend on the morpheme “?” (high). 
 
(6) Negation Type: A negative character speci-
fied in a predefined set NC has a negation effect 
on the opinion score of the other character.  The 
strength depends on the modified morpheme 
while the polarity of the word is the negation of 
the polarity of the modified morpheme. 
 
( )
( ) )(1)( else
 )(1)( then )( if
121
2211
CSCCS
CSCCSNCC
×?=
×?=?  (9)
 
 
(7) Confirmation Type: A positive character 
specified in a predefined set PC ensures that the 
opinion score of a word only comes from the 
other character.  Therefore, the opinion score of 
this word is determined by the modified mor-
pheme. 
 
)()( else )()( then )( if 1212211 CSCCSCSCCSPCC ==?  (10)
 
 
(8) Others: Since words of this type contain no 
clear cues for their morphological structures, we 
postulate that both characters have the same con-
tribution, and adopt Formula (5).  
4 Identification of Morphological Types 
To compute the opinion score of a word accord-
ing to formulae in Section 3, we must know its 
morphological type from the morphological 
structure, i.e., the parts of speech of the compos-
ite morphemes.  Currently, part of speech tag-
ging is performed at the word level rather than 
the morpheme level, and morpheme-tagging cor-
pus is not available.  We consider an on-line 
Chinese dictionary, Dictionary of Chinese Words 
by Ministry of Education, Taiwan (MOEDCW), 
as a corpus, and compute the statistics of each 
morpheme in it. 
Two classifiers, CRF classifier and SVM clas-
sifier are proposed to recognize morphological 
types (1)-(5).  Morphological types (6) to (8) are 
determined by rules such as whether two com-
posite characters are morphemes; whether there 
are confirmation/negation morphemes; and so on. 
4.1 MOEDCW Corpus 
MOEDCW corpus provides possible parts of 
speech for each morpheme by treating it as a uni-
gram word, and possible senses under each part 
of speech.  In each entry, there are a sense defini-
tion and some example words.  Figures 1 and 2 
show the specifications of two morphemes “?” 
and “?”.  The morpheme “?”  has three parts 
of speech (verb, adverb and noun) and includes 3, 
1, and 1 senses.  There are 3, 3, and 2 example 
words listed under the three verb senses. 
We can find the correct parts of speech of the 
composite characters of a word when it is an ex-
ample word in the dictionary.  However, not all 
words are listed in the corpus.  Consider the 
word “??” (sweat, verb).  Figure 1 shows that 
“??” (sweat) is an example word listed under 
the verb sense of the character “?” (perspire), 
thus the character “?” (perspire) in the word “?
?” (sweat) functions as a verb.  However, “?
?” (sweat) is not an example for the character 
“?” (sweat).  Figure 2 show that there are two 
possible parts of speech, noun and verb, for the 
character “?” (sweat).  We then show how to 
identify its function in the word “??”.   
 
1
Goes out from the button to the top or 
from inside to outside.  For example, 
fume, smoking, and sweat. ?????
???????????????
?????????? 
2
Burst into or regardless of.  For example, 
take risk, to offend, and offense.  ?
??????????????
????????… 
verb 
3
Fake or on the pretext of.  For example, 
personate and to pretend to be. ???
??????????????? 
ad-
verb 1
Crude or rash.  For example, offensively 
and advance rashly.  ??????
???????????? 
noun 1 Family name. ?? 
Figure 1: Specification of “?” in MOEDCW 
1
Sweat.  For example, cold sweat, night 
sweat, sweatiness, and to drip with 
sweat. ?????????????
????????????????
??????????????… 
noun
2 Family name?? 
verb 1 To sweat ??????? 
Figure 2: Specification of  “?” in MOEDCW 
)( )( POS,CnsesNumberOfSePOS,CT =  (11)
 
The number of possible meanings one charac-
ter can bear when it functions as a certain part of 
1263
speech is employed to estimate how often this 
part of speech is used.  The function T(C, POS) 
shown in Formula (11) defines the score of a 
character C functioning as a particular part of 
speech POS.  Here, POS may be noun (N), adjec-
tive (ADJ), verb (V), adverb (ADV), auxiliary 
(AUX), conjunction (CONJ), pronoun (PRON), 
preposition (PREP), and interjection (INT).  In 
Figure 2, T(?<sweat>, N) = 2 and  T(?<sweat>, 
V) = 1. 
4.2 Features for Classifiers 
Features for training SVM and CRF classifiers 
include the pronunciation and the tone of the 
word, parts of speech of the first and the second 
characters of training words, and the position 
information of the composite characters.  The 
tone of the word is acquired from MOEDCW.  
The parts of speech are estimated by Formula 
(11).   f(C, POS, k, start/end) counts the number 
of k-grams (k=2, 3, 4).  In Figures 1 and 2, f(?, 
V, 2, start)=6, f(?, V, 2, end)= 2, f(?, ADV, 2, 
start) = 2, and f(?, ADV, 2, end)=0.  This ex-
ample shows that when the character “?” func-
tions as a verb or an adverb, it serves as the start-
ing character more often than the ending charac-
ter. 
4.3 CRF and SVM Classifier  
CRF and SVM are both common used algorithms 
for building classifiers (Lafferty et al., 2001).  
We adopted CRF++1 and libSVM (Chang and 
Lin, 2001) to develop our classifiers.  The fea-
tures for training our CRF and SVM classifiers 
include the input word W, the tone of W, the first 
and the second characters C1 and C2, T(C1, POS), 
T(C2, POS),  f(C1, POS, k, start), f(C1, POS, k, 
end), f(C2, POS, k, start), and f(C2, POS, k, end).  
POS denotes one of nine parts of speech in 
MOEDCW, and k equals to 2, 3 or 4. 
Using SVM is straightforward.  To classify a 
word into one of the morphological structure 
types, we construct the word's feature vector and 
input the vector into SVM.  When using CRF, a 
different approach is taken.  When predicting the 
classes of two successive instances, CRF takes 
the predicted class of the first instance into ac-
count when predicting the second instance's class.  
Here is how we exploit this capability.  In a nut-
shell, we perform classification at the character 
level instead of the word level.  Let W be a word 
composed of the two characters C1 and C2.  Let v 
                                                 
1 http://crfpp.sourceforge.net/ 
be the feature vector of W.  Let t be the morpho-
logical structure type of W.  We define C1's fea-
ture vector to be composed of the features in v 
which are related to C1, e.g., T(C1, verb).  Simi-
larly, C2's feature vector is composed of the fea-
tures in v which are related to C2.  C1's class and 
C2's class are defined as t_1 and t_2, respectively.  
Since t has five possible values, there are 10 
character classes. 
To determine a word W's morphological struc-
ture type, we first apply CRF on W's constituent 
characters C1 and C2's feature vectors.  For C1, 
CRF will return a set of probabilities P(C1,t_q), 
where q ? {1, 2}, indicating the likelihood of C1 
being an instance of class t_q.  Similarly, a set of 
probabilities P(C2,t_q) is returned for C2.  W's 
morphological structure type is defined as the 
value of t which maximizes the product of 
P(C1,t_1) and P(C2,t_2). 
Though CRF is mostly used for sequential la-
beling, the idea of using CRF is to tail this classi-
fication questions into a labeling question in or-
der to utilizing the position information of char-
acters.  As mentioned, if a word W of two char-
acters C1C2 is of type 1, CRF will label C1 1_1 
(type1_1st char) and C2 1_2 (type1_2nd char).  
The labeling of each character considers both the 
previous character's features and the next charac-
ter's features.  That is, if the current character is 
the first character, its previous character is an 
empty character (which is used for segmenting 
sequences in CRF); if the current character is the 
second character, its next character is an empty 
character. Hence the position information will be 
considered by CRF. 
5 Experiments and Discussion  
Experiments verify whether the morphological 
types benefit opinion polarity detection on words.  
The relation between the performance of mor-
phological classifiers and opinion polarity detec-
tion is discussed. 
5.1 Experimental Setup  
To compare the bag-of-characters approach (Ku 
et al., 2007) with our morphological structure 
approach, we adopt the same evaluation data set 
containing 836 words.  To evaluate the perform-
ance of our two morphological classifiers, we 
prepare two sets of words, including the testing 
set of 836 words for word-level opinion predic-
tion (abbreviated as OP), and a set of 8,186 
words selected from words in MOEDCW corpus 
and news documents except those can be classi-
1264
fied by patterns (abbreviated as TRAIN set), all 
with their morphological types annotated.  Table 
1 lists the distributions of morphological types in 
OP and TRAIN sets. 
The polarity of words is predicted by their 
opinion scores ranging between -1 to 1.  We set a 
positive threshold.  Those words with scores 
above it are considered as positive while those 
below this threshold multiplied by (-1) are re-
garded as negative.  The words with non-zero 
scores falling between the positive and negative 
thresholds are neutral.  Fifty grids from 0 to 0.5 
are searched for the best threshold.  Since the 
opinion extraction at word level concerns only 
word structure, no retraining for the best thresh-
old is need when domain shifts, which is a supe-
riority of our method. 
5.2 Morphological Type Classification and 
Polarity Detection  
The performances of CRF and SVM classifiers 
on each morphological type are listed in Table 2.  
We perform four-fold cross validation on the 
TRAIN set.  Results show that CRF classifier 
achieves better performance than SVM classifier 
in this task.  The accuracy of CRF classifier 
(0.70) is 8% higher than that of SVM classifier 
(0.62).  Note those type 8 words which could be 
extracted by rules are excluded from classifica-
tion experiment. The remaining type 8 words are 
usually proper names.  It is difficult for both 
classifiers to identify such words. 
Table 3 further shows the performance of po-
larity prediction using morphological types de-
termined by CRF classifier and SVM classifier.  
The performance of polarity detection is evalu-
ated by the f-score defined in Formula (12). 
The f-scores of polarity detection using CRF 
classified types and SVM classified types are 
0.5806 and 0.5938, respectively.  Both of them 
outperform baseline’s f-score 0.5455, i.e., the 
bag-of-characters approach (Ku et al., 2007).  
Experiments show that adopting morphological 
types annotated by two classifiers for polarity 
prediction has little difference.  In other words, 
CRF and SVM classifiers have an 8% f-score 
difference in their best performance of classifica-
tion, while the performance gap in word polarity 
prediction using morphological types provided 
by these two classifiers is around 1.3% only 
(0.5806 vs. 0.5938).  The reason may be that we 
define scoring functions of each morphological 
type in a straightforward way.  If they are not the 
best scoring functions, the benefit of considering 
the morphological type information could be re-
stricted.  Nevertheless, experimental results show 
that morphological type information is useful for 
word polarity detection (with p-value less than 
0.05). 
 
)(
)()(
opinionproposed
polaritycorrectopinioncorrect
P
?
= , 
)(
)()(
opiniongold
polaritycorrectopinioncorrect
R
?
= , 
RP
RP
scoref
+
??
=?
2 . 
(12)
 
set/type 1 2 3 4 5 6 7 8 
TRAIN 26.15 44.97 1.64 15.14 9.22 0 0 2.88 
OP 45.8 24.4 1.3 7.9 8.0 2.3 0.5 9.8 
Table 1: The Percentage of distribution for morphological types in TRAIN and OP sets 
MorphoType 1 2 3 4 5 8 Accuracy 
CRF 0.63 0.78 0.41 0.66 0.78 0.17 0.70 
SVM 0.49 0.73 0.22 0.52 0.55 0 0.62 
Table 2: The f-score of CRF and SVM classifiers 
We further examine how well our polarity de-
tection method works in combination with a 
word sentiment dictionary.  We use the NTUSD2 
word sentiment dictionary.  If a word appears in 
NTUSD, then the word's polarity is the one 
specified in NTUSD.  If a word does not appear 
in NTUSD, then the word's polarity is deter-
mined using our morphological type method. 
                                                 
2 http://nlg18.csie.ntu.edu.tw:8080/opinion/ 
After introducing a sentiment dictionary 
NTUSD3, CRF and SVM classifiers both achieve 
the f-score 0.77 for opinion word extraction, and 
achieve f-scores 0.61 and 0.62 for polarity detec-
tion, respectively.  Note that if only NTUSD is 
used to extract opinion words by string matching, 
the f-score is only 0.44. 
 
                                                 
3 http://nlg18.csie.ntu.edu.tw:8080/opinion/ 
1265
Polarity f-score Without NTUSD With NTUSD 
Ku 0.5455 0.5789 
CRF type 0.5806 0.6100 
SVM type 0.5938 0.6246 
 
Table 3: Prediction with Morphological Types 
We further analyze the improvement of polar-
ity prediction for each morphological type.  We 
find that the f-scores of polarity prediction of all 
morphological types are improved in different 
degrees, and among them the performance of 
type 2 words are improved the most.  We have 
shown that our method can assign an opinion 
score to an arbitrary word without any word 
thesauri by considering its morphological infor-
mation.  Moreover, since the Substantive-
Modifier (type 2) is the most common way to 
form a new word in the Chinese language 
(Cheng and Tian, 1992), the result presents the 
strength of our method in solving the coverage 
problem. 
6 Syntactic Structure for Chinese Opin-
ion Analysis 
As mentioned, the relations introduced in Section 
2 exist not only within words, but also between 
sentence segments.  Relations between sentence 
segments are represented by structural trios here-
after and will be introduced in next section.  We 
have already shown that morphological types are 
useful when extracting opinion words and would 
like to further testify whether structural trios also 
benefit the opinion analysis on sentences.  We 
annotate these relations manually, propose a 
method to identify these relations, and compare 
results of experimental settings using structural 
trios with those not using structural trios. 
6.1 Structural Trio 
Each node in a parsing tree dominates a word 
string in a sentence.  Linguistics have shown that 
there are also five relations between sentence 
segments: Parallel, Substantive-Modifier, Sub-
jective-Predicate, Verb-Object, and Verb-
Complement, same as morphological types (1) to 
(5).  Because parsing trees have hierarchical 
structures, we define a structural trio to represent 
a relation between two nodes as follows: 
(1) A structure trio contains two children 
nodes which bear a relation. 
(2) A structure trio contains one head node 
which is the nearest common parent of two 
children nodes in (1). 
 
 
Figure 3: Example of structural trios 
Figure 3 shows an example of a structure trio.  
It is a part of a parsing tree containing words “?
?” (obtain), “??” (happy), “??” (results).  
Two structural trios are shown in this example.  
The lower one contains two children nodes “?
?” (happy) and “??” (results), and is labeled 
as Substantive-Modifier (S-M (2)) in their near-
est common parent node, while the upper one 
contains two children nodes “??” (obtain) and 
“????” (happy results), and is labeled as 
Verb-Object (V-O (4)). 
6.2 Experimental Corpus 
To experiment with structural trios, we need the 
parsing trees of all experimental sentences.  For 
this purpose, we adopted Chinese Treebank 5.14 
as the experimental materials.  Chinese Treebank 
contains raw Chinese news documents together 
with their segmented, part of speech tagged, and 
parsed versions.  The parsed documents are 
adopted in experiments utilizing structural trios, 
and the part of speech tagged documents are used 
in experiments not utilizing structural trios. 
In Chinese Treebank, a unique ID is labeled 
on each sentence.  For each sentence, we had 
three annotators label their opinions and then we 
generate the gold standard following NTCIR 5 
MOAT protocol (Seki et al., 2008).  We also 
annotated structure trios in Chinese Treebank.  A 
total of 17,159 sentences are obtained after drop-
ping some faulty sentences such as empty sen-
tences and sentences composed of more than one 
parsing tree.  The statistics of opinion sentences 
and structural trios in the constructed experimen-
tal materials are shown in Table 4 and Table 5. 
 
 
                                                 
4 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp? 
catalogId=LDC2005T01 
5 http://research.nii.ac.jp/ntcir/index-en.html 
1266
Opinion Non-Opinion 
Positive Neutral Negative 
6,380 1,537 1,714 # 
9,631 
7,528 
66.24 15.96 17.80 % 
56.13 
43.87 
Table 4: Statistics of opinion sentences 
Trio Type Number Percentage % 
2 18,483 36.85 
3 13,687 27.29 
4 15,970 31.84 
5 965 1.92 
Others 1,054 2.10 
Total 50,159 100.00 
Table 5: Statistics of structural trios 
6.3 Experiment Setup 
The aim of our experiments is to know how 
opinion analysis approach performs when mor-
phological and syntactic structures are incorpo-
rated.  They are compared with the bag-of-
character and bag-of-word approaches. We im-
plemented the bag-of-word approach proposed 
by Ku et al. (2007) to show its performance on 
Chinese Treebank.  In their approach, the opin-
ion scores of words are summed to generate the 
opinion scores of sentences, and the negation 
words will negate the closest opinion words.  
Based on this approach, we further consider 
structural trios to experiment whether syntactic 
structures of sentences are beneficial for opinion 
analysis.  Because the scoring functions may not 
be straight forward as those we have adopted for 
opinion word extraction, we did not design scor-
ing functions for utilizing all types of structural 
trios.  Instead, we emphasize their original opin-
ion scores by multiplying a variable alpha to see 
whether these structures are important.  In this 
paper, alpha equals five. 
We have shown that word morphological 
structures benefit the word opinion extraction.  
When we experiment on sentences, we also in-
corporate the word morphological structures to 
see whether they are also useful for opinion 
analysis on sentences.  Five experimental set-
tings are listed as below:  
(1) bag[w]-bag[s]: structural information is 
not considered for both words and sen-
tences.  The bag-of-character approach 
is used to calculate the opinion scores of 
words, and the bag-of-word approach 
sentences. 
(2) struc[w]-bag[s]: morphological struc-
tures are utilized to calculate word opin-
ion scores, but structural trios are not 
considered. The bag-of-word approach 
is used to calculate the opinion scores of 
sentences. 
(3) bag[w]-struc[s]: structural trios are con-
sidered for calculating sentence opinion 
scores, while the bag-of-character ap-
proach is used to calculate the opinion 
scores of words. 
(4) struc[w]-(m)struc[s]: both word mor-
phological structures and manually la-
beled structural trios are adopted. 
(5) struc[w]-struc[s]: both morphological 
structure of words and system labeled 
structural trios are adopted. 
As we have shown that NTUSD is beneficial 
to the opinion analysis at word level, it is used as 
described in section 5.2 by default. 
Our system adopted CRF algorithm to label 
structural trios for setting (5).  The content string 
and the part of speech of the current node, its 
parent node, its offspring nodes in the next three 
generations, together with the depth of the cur-
rent node in the Chinese Treebank, are used as 
the features for each node in CRF.  The co-
occurrence of the current node and all its siblings 
are defined in CRF’s template file.  CRF will 
label whether the current node is the first child or 
the second child of a certain relation in a struc-
tural trio, or it is not part of any structural trios.  
A four-fold experiment is performed for the 
learning and testing of this labeling  process by 
CRF. 
6.4 Results and Discussion 
Table 6 shows the statistics of manually labeled 
structural trios in Chinese Treebank and identifi-
cation performance of CRF.  Table 7 shows the 
performance of five experiment settings de-
scribed in Section 6.3.  The experiment results 
show that the morphological structures of words 
do not have a large contribution for opinion sen-
tence analysis (setting 1 vs. setting 2; setting 3 vs. 
setting 4).  However, considering the structural 
trios improve the performance.   
 
 
 
 
 
 
 
 
1267
Trio Type Number Percentage f-Score
2 18,483 36.85% 0.4883
3 13,687 27.29% 0.4944
4 15,970 31.84% 0.6360
5 965 1.92% 0.2034
Others 1,054 2.10% 
Total 50159 100%  
Table 6: Statistics and Results of Identifying 
Structural Trios 
Setting Word [w] 
Sentence 
 [s] 
f-Score 
(opinion) 
f-Score 
(polarity)
1 bag bag 0.7073 0.4988 
2 struc bag 0.7162 0.5117 
3 bag struc 0.8000 0.5361 
4 struc (m)struc 0.7922 0.5297 
5 struc struc 0.7993 0.5187 
Table 7: Results of Opinion Extraction  
on Chinese Treebank 
By summarizing the experimental results in 
Section 5 and this section, we can conclude that 
considering the word morphological structures 
benefits the opinion polarity detection, but in the 
current approach its assistance to words does not 
propagate to sentences.  Considering the syntac-
tic structures, however, do help in opinion analy-
sis both for the opinion sentence extraction and 
the polarity detection.  The performance of opin-
ion extraction boosts to an f-score 0.80 and the 
performance of polarity detection an f-score 0.54.   
However, the utilization of structure trios 
needs the parsing tree of sentences as the prior 
knowledge.  Hence these two kinds of structural 
information may be suitable for different applica-
tions: structural trios for well written sentences 
such as those in the news articles, while the mor-
phological structures for casually written sen-
tences such as those appear in SMS messages or 
articles with limit length on the Web. 
Because there are no opinion experiments per-
formed on Chinese Treebank, we mention the 
performance of Ku’s approach (setting (1)) for 
opinion sentence extraction, f-score 0.6846, in 
NTCIR-7 MOAT task, on news articles, as a re-
sult for comparison.  Their approach was ranked 
the second in this task, and the best team 
achieved an f-score 0.7453. 
7 Conclusion and Future Work  
This paper considers morphological and syntac-
tic structures in analyzing Chinese opinion words 
and sentences.  For morphological structures, 
eight Chinese morphological types are defined. 
CRF classifier and SVM classifier for morpho-
logical type classification are proposed.  Experi-
ments show that CRF classifier achieves the best 
accuracy 0.70 in type classification, which is 8% 
better than SVM classifier.  We further show that 
word morphological structures benefit the opin-
ion word extraction significantly.  With the help 
of the sentiment dictionary NTUSD, the f-score 
of opinion word extraction achieves 0.77 and the 
f-score of the word polarity detection achieves 
0.62 when the word morphological types are 
provided by the SVM classifier.  They are com-
parably better than bag-of-character approach 
and the dictionary based approach. 
We defined structural trios to represent the re-
lations between sentence segments and also ex-
tract these relations using CRF algorithm.  Re-
sults show that considering structural trios bene-
fits the opinion analysis on sentences.  An f-
score 0.80 for opinion extraction and an f-score 
0.54 for polarity detection are achieved, which is 
a great improvement.  
The opinion scoring functions for morphologi-
cal types and structural trios are critical for polar-
ity detection, and scoring functions for words 
determine the scoring functions for sentences.  
Now we define these functions intuitively based 
on linguistic rules, but learning methods like re-
gression will be investigated in the future.  Ex-
amining the interaction of cues from word and 
sentence levels on the opinion sentence extrac-
tion and the opinion polarity detection is our next 
goal. 
Acknowledgement 
Research of this paper was partially supported by Na-
tional Science Council, Taiwan, under the contract 
NSC95-2221-E-002-265-MY3.  
References  
Banea, C., Mihalcea, R., Wiebe, J. and Hassan, S. 
2008. Multilingual Subjectivity Analysis Using 
Machine Translation. In Proceedings of Empirical 
Methods in Natural Language Processing (EMNLP 
2008). 
Bautin, M., Vijayarenu, L. and Skiena, S. 2008. Inter-
national sentiment analysis for news and blogs. In 
Proceedings of the International Conference on 
Weblogs and Social Media (ICWSM). 
Carenini, G., Ng, R. T. and Pauls, A. 2006. Interactive 
Multimedia Summaries of Evaluative Text. In Pro-
ceedings of the 11th International Conference on 
Intelligent User Interfaces (pp. 124-131), Sydney, 
Australia. 
1268
Cesarano, C., Picariello, A., Reforgiato, D. and 
Subrahmanian, V.S. 2007. The OASYS 2.0 Opin-
ion Analysis System.  Demo in Proceedings of In-
ternational Conference on Weblogs and Social 
Media (pp. 313-314), Boulder, CO USA. 
Chang, Chih-Chung and Lin, Chih-Jen. 2001. 
LIBSVM: a library for support vector machines, 
http://www.csie.ntu.edu.tw/~cjlin/libsvm  
Chen, A., Xu, L., Gey, F.C. and Meggs, J. 1997. Chi-
nese Text Retrieval without Using a Dictionary. 
ACM SIGIR Forum, Volume 31, Issue SI (pp. 42-
49). 
Cheng, X.-H. and Tian, X.-L. 1992. Modern Chinese.  
Bookman Books Ltd. 
Dave, K., Lawrence, S., and Pennock, D.M. 2003. 
Mining the Peanut Gallery: Opinion Extraction 
and Semantic Classification of Product Reviews. 
In Proc. of the 12th International WWW Confer-
ence (pp. 519-528). 
Kawai, Y., Kumamoto, T. and Tanaka, K. 2007. Fair 
News Reader: Recommending news articles with 
different sentiments based on user preference. In 
Proceedings of Knowledge-Based Intelligent In-
formation and Engineering Systems (KES), No. 
4692 in Lecture Notes in Computer Science (pp. 
612–622). 
Kim, S.-M. and Hovy, E. 2004. Determining the Sen-
timent of Opinions. In Proc. of the 20th ICCL (pp. 
1367-1373). 
Ku, L.-W. and Chen, H.-H. 2007. Mining Opinions 
from the Web: Beyond Relevance Retrieval. Jour-
nal of American Society for Information Science 
and Technology, Special Issue on Mining Web Re-
sources for Enhancing Information Retrieval, 
58(12), 1838-1850. 
Lafferty, J., McCallum, A. and Pereira, F. 2001. Con-
ditional Random Fields: Probabilistic Models for 
Segmenting and Labeling Sequence Data, In Proc. 
of ICML (pp.282-289). 
Pang, B., Lee, L. and Vaithyanathan, S. 2002. Thumbs 
up? Sentiment Classification Using Machine 
Learning Techniques. In Proc. of the 2002 Confer-
ence on EMNLP (pp. 79-86). 
Riloff, E. and Wiebe, J. 2003. Learning Extraction 
Patterns for Subjective Expressions. In Proc. of the 
2003 Conference on EMNLP (pp. 105-112).  
Seki, Y., Evans, D. K., Ku, L.-W., Sun, L., Chen, H.-H. 
and Kando, N. 2008.  Overview of Multilingual 
Opinion Analysis Task at NTCIR-7. In Proceed-
ings of the 7th NTCIR Workshop Meeting on 
Evaluation of Information Access Technologies: 
Information Retrieval, Question Answering, and 
Cross-Lingual Information Access. 
Somasundaran, S., Ruppenhofer, J. and Wiebe, J. 
2007. Detecting arguing and sentiment in meetings. 
Proceedings of the SIGdial Workshop on Dis-
course and Dialogue, 2007.8.6 
Takamura, H., Inui, T. and Okumura, M. 2005. Ex-
tracting Semantic Orientations of Words Using 
Spin Model. In Proc. of the 43rd Annual Meeting 
of the ACL (pp. 133-140). 
Tzeng, H. and Chen, K.-J. 2002. Design of Chinese 
Morphological Analyzer.  In Proc. of the 1st 
SIGHAN Workshop on Chinese Language Process-
ing, vol.18, 1-7. 
Wiebe, J. 2000. Learning Subjective Adjectives from 
Corpora. In Proc. of the 17th National Conference 
on AAAI and Twelfth Conference on IAAI (pp. 735-
740). 
 
1269
