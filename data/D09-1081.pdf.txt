Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 775–783,
Singapore, 6-7 August 2009.
c
©2009 ACL and AFNLP
Estimating Semantic Distance Using Soft Semantic Constraints
in Knowledge-Source–Corpus Hybrid Models
Yuval Marton
?†
, Saif Mohammad
†
, and Philip Resnik
?†
?
Department of Linguistics and
†
Laboratory for Computational Linguistics and Information Processing,
Institute for Advanced Computer Studies.
University of Maryland, College Park, MD 20742-7505, USA.
{ymarton,saif,resnik}@umiacs.umd.edu
Abstract
Strictly corpus-based measures of seman-
tic distance conflate co-occurrence infor-
mation pertaining to the many possible
senses of target words. We propose a
corpus–thesaurus hybrid method that uses
soft constraints to generate word-sense-
aware distributional profiles (DPs) from
coarser “concept DPs” (derived from a
Roget-like thesaurus) and sense-unaware
traditional word DPs (derived from raw
text). Although it uses a knowledge
source, the method is not vocabulary-
limited: if the target word is not in the
thesaurus, the method falls back grace-
fully on the word’s co-occurrence infor-
mation. This allows the method to access
valuable information encoded in a lexical
resource, such as a thesaurus, while still
being able to effectively handle domain-
specific terms and named entities. Exper-
iments on word-pair ranking by semantic
distance show the new hybrid method to
be superior to others.
1 Introduction
Semantic distance is a measure of the closeness
in meaning of two concepts. People are consis-
tent judges of semantic distance. For example, we
can easily tell that the concepts of “exercise” and
“jog” are closer in meaning than “exercise” and
“theater”. Studies asking native speakers of a lan-
guage to rank word pairs in order of semantic dis-
tance confirm this—average inter-annotator corre-
lation on ranking word pairs in order of semantic
distance has been repeatedly shown to be around
0.9 (Rubenstein and Goodenough, 1965; Resnik,
1999).
A number of natural language tasks such as ma-
chine translation (Lopez, 2008) and word sense
disambiguation (Banerjee and Pedersen, 2003;
McCarthy, 2006), can be framed as semantic
distance problems. Thus, developing automatic
measures that are in-line with human notions of
semantic distance has received much attention.
These automatic approaches to semantic distance
rely on manually created lexical resources such as
WordNet, large amounts of text corpora, or both.
WordNet-based information content measures
have been successful (Hirst and Budanitsky,
2005), but there are significant limitations on their
applicability. They can be applied only if a Word-
Net exists for the language of interest (which is
not the case for the “low-density” languages); and
even if there is a WordNet, a number of domain-
specific terms may not be encoded in it. On the
other hand, corpus-based distributional measures
of semantic distance, such as cosine and ?-skew
divergence (Dagan et al., 1999), rely on raw text
alone (Weeds et al., 2004; Mohammad, 2008).
However, when used to rank word pairs in order
of semantic distance or correct real-word spelling
errors, they have been shown to perform poorly
(Weeds et al., 2004; Mohammad and Hirst, 2006).
Mohammad and Hirst (2006) and Patwardhan
and Pedersen (2006) argued that word sense ambi-
guity is a key reason for the poor performance of
traditional distributional measures, and they pro-
posed hybrid approaches that are distributional in
nature, but also make use of information in lexical
resources such as published thesauri and WordNet.
However, both these approaches can be applied to
estimate the semantic distance between two terms
only if both terms exist in the lexical resource they
rely on. We know lexical resources tend to have
limited vocabulary and a large number of domain-
775
specific terms are usually not included.
It should also be noted that similarity values
from different distance measures are not compa-
rable (even after normalization to the same scale),
that is, a similarity score of .75 as per one distance
measure does not correspond to the same seman-
tic distance as a similarity score of .75 from an-
other distance measure.
1
Thus if one uses two
independent distance measures, in this case: one
resource-reliant and one only corpus-dependent,
then these two measures are not comparable (and
hence cannot be used in tandem), even if both
rely—partially or entirely—on distributional cor-
pus statistics.
We propose a hybrid semantic distance method
that inherently combines the elements of a
resource-reliant measure and a strictly corpus-
dependent measure by imposing resource-reliant
soft constraints on the corpus-dependent model.
We choose the Mohammad and Hirst (2006)
method as the resource-reliant method and not
one of the WordNet-based measures because, un-
like the WordNet-based measures, the Moham-
mad and Hirst method is distributional in nature
and so lends itself immediately for combination
with traditional distributional similarity measures.
Our new hybrid method combines concept–word
co-occurrence information (the Mohammad and
Hirst distributional profiles of thesaurus concepts
(DPC)) with word–word co-occurrence informa-
tion, to generate word-sense-biased distributional
profiles. The “pure” corpus-based distributional
profile (a.k.a. co-occurrence vector, or word asso-
ciation vector), for some target word u, is biased
with soft constraints towards each of the concepts
c that list u in the thesaurus, to create a distribu-
tional profile that is specific to u in the sense that
is most related to the other words listed under c.
Thus, this method can make more fine-
grained distinctions than the Mohammad and Hirst
method, and yet uses word sense information.
2
Our proposed method falls back gracefully to rely
only on word-word co-occurrence information if
any of the target terms is not listed in the lexical re-
source. Experiments on the word-pair ranking task
1
All we can infer is that if w
1
and w
2
have a similarity
score of .75 and w
3
and w
4
have a score of .5 by the same
distance measure, then w
1
–w
2
are closer in meaning than
w
3
–w
4
.
2
Even though Mohammad and Hirst (2006) use thesaurus
categories as coarse concepts, their algorithm can be applied
using more finer-grained thesaurus word groupings (para-
graphs and semicolon units), as well.
on three different datasets show that the our pro-
posed hybrid measure outperforms all other com-
parable distance measures.
Mohammad and Hirst (2007) show that their
method can be used to compute semantic dis-
tance in a resource poor language L
1
by com-
bining its text with a thesaurus in a resource-rich
language L
2
using an L
1
–L
2
bilingual lexicon to
create cross-lingual distributional profiles of con-
cepts, that is, L
2
word co-occurrence profiles of
L
1
thesaurus concepts. Since our method makes
use of the Mohammad and Hirst DPCs, it can just
as well make use of their cross-lingual DPCs, to
compute semantic distance in a resource-poor lan-
guage, just as they did. We leave that for future
work.
2 Background and Related Work
Strictly speaking, semantic distance/closeness is
a property of lexical units—a combination of the
surface form and word sense.
3
Two terms are con-
sidered to be semantically close if there is a lex-
ical semantic relation between them. Such a re-
lation may be a classical relation such as hyper-
nymy, troponymy, meronymy, and antonymy, or
it may be what have been called an ad-hoc non-
classical relation, such as cause-and-effect (Mor-
ris and Hirst, 2004). If the closeness in meaning
is due to certain specific classical relations such as
hypernymy and troponymy, then the terms are said
to be semantically similar. Semantic relatedness
is the term used to describe the more general form
of semantic closeness caused by any semantic re-
lation (Hirst and Budanitsky, 2005). So the nouns
liquid and water are both semantically similar and
semantically related, whereas the nouns boat and
rudder are semantically related, but not similar.
The next three sub-sections describe three kinds
of automatic distance measures: (1) lexical-
resource-based measures that rely on a manually
created resource such as WordNet; (2) corpus-
based measures that rely only on co-occurrence
statistics from large corpora; and (3) hybrid mea-
sures that are distributional in nature, and that also
exploit the information in a lexical resource.
2.1 Lexical-resource-based measures
WordNet is a manually-created hierarchical net-
work of nodes (taxonomy), where each node in
3
The notion of semantic distance can be generalized, of
course, to larger units such as phrases, sentences, passages,
and so on (Landauer et al., 1998).
776
the network represents a fine-grained concept or
word sense. An edge between two nodes rep-
resents a lexical semantic relation such as hy-
pernymy and troponymy. WordNet-based mea-
sures consider two terms to be close if they occur
close to each other in the network (connected by
only a few arcs), if their definitions share many
terms (Banerjee and Pedersen, 2003; Patwardhan
and Pedersen, 2006), or if they share a lot of infor-
mation (Lin, 1998; Resnik, 1999). The length of
each arc/link (distance between nodes) can be as-
sumed a unit length, or can be computed from cor-
pus statistics. Within WordNet, the is-a hierarchy
is much more well-developed than that of other
lexical semantic relations. So, not surprisingly,
the best WordNet-based measures are those that
rely only on the is-a hierarchy. Therefore, they
are good at measuring semantic similarity (e.g.,
doctor–physician), but not semantic relatedness
(e.g., doctor–scalpel). Further, the measures can
only be used in languages that have a (sufficiently
developed) WordNet. WordNet sense information
has been criticized to be too fine grained (Agirre
and Lopez de Lacalle Lekuona, 2003; Navigli,
2006). See Hirst and Budanitsky (2005) for a com-
prehensive survey of WordNet-based measures.
2.2 Corpus-based measures
Strictly corpus-based measures of distributional
similarity rely on the hypothesis that words that
occur in similar context tend to be semantically
close (Firth, 1957; Harris, 1940). The set of
contexts of each target word u is represented by
its distributional profile (DP)—the set of words
that tend to co-occur with u within a certain dis-
tance, along with numeric scores signifying this
co-occurrence tendency with u. Then measures
such as cosine or ?-skew divergence are used to
determine how close the DPs of the two target
words are. See Section 3 for more details and re-
lated work. These measures are very appealing
because they rely simply on raw text, but, as de-
scribed earlier, when used to rank word pairs in
order of semantic distance, or to correct real-word
spelling errors, they perform poorly, compared
to the WordNet-based measures. See Weeds et
al. (2004), Mohammad (2008), and Curran (2004)
for detailed surveys of distributional measures.
As Mohammad and Hirst (2006) point out, the
DP of a word u conflates information about the
potentially many senses of u. For example, con-
sider the following. The noun bank has two senses
“river bank” and “financial institution”. Assume
that bank, when used in the “financial institu-
tion” sense, co-occurred with the noun money 100
times in a corpus. Similarly, assume that bank,
when used in the “river bank” sense, co-occurred
with the noun boat 80 times. So the DP of bank
will have co-occurrence information with money
as well as boat:
DPW(bank):
money,100; boat,80; bond,70; fish,77; . . .
Assume that the DP of the word ATM is:
DPW(ATM):
money,120; boat,0; bond,90; fish,0; . . .
Thus the distributional distance of bank with ATM
will be some sort of an average of the seman-
tic distance between the “financial institution” and
“ATM” senses and the semantic distance between
the “river bank” and “ATM” senses. However, in
various natural language tasks, we need the se-
mantic distance between the intended senses of
bank and ATM, which often also tends to be the
semantic distance between their closest senses.
2.3 Hybrid measures
Both Mohammad and Hirst (2006) and Patward-
han and Pedersen (2006) proposed measures that
are not only distributional in nature but also rely
on a lexical resource to exploit the manually en-
coded information therein as well as to overcome
the sense-conflation problem (described in sec-
tion 2.2). Since we essentially combine the Mo-
hammad and Hirst method with a “pure” word-
based distributional measure to create our hybrid
approach, we briefly describe their method here.
Mohammad and Hirst (2006) generate separate
distributional profiles for the different senses of
a word, without using any sense-annotated data.
They use the categories in a Roget-style thesaurus
(Macquaries (Bernard, 1986)) as coarse senses or
concepts. There are about 1000 categories in a
thesaurus, and each category has on average 120
closely related words. A word may be found in
more than one category if it has multiple meaning.
They use a simple unsupervised algorithm to de-
termine the vector of words that tend to co-occur
with each concept and the corresponding strength
of association (a measure of how strong the ten-
dency to co-occur is). The target word u will be
assigned one DPC for each of the concepts that
777
list u. Below are example DPCs of the two con-
cepts pertaining to bank:
4
DPC(“fin. inst.”):
money,1000; boat,32; bond,705; fish,0; . . .
DPC(“river bank”):
money,5; boat,863; bond,0; fish,948; . . .
The distance between two words u, v is deter-
mined by calculating the closeness of each of the
DPCs of u to each of DPCs of v, and the closest
DPC-pair distance is chosen.
Mohammad and Hirst (2006) show that their ap-
proach performs better than other strictly corpus-
based approaches that they experimented with.
However, all those experiments were on word-
pairs that were listed in the thesaurus. Their ap-
proach is not applicable otherwise. In Sections 3
and 4 we show how cosine–log-likelihood-ratio
(or any comparable distributional measure) can be
combined with the Mohammad and Hirst DPCs to
form a hybrid approach that is not limited to the
vocabulary of a lexical resource.
Erk and Pad´o (2008) proposed a way of rep-
resenting a word sense in context by biasing the
target word’s DP according to the context sur-
rounding a target (specific) occurrence of the tar-
get word. They use dependency relations and se-
lectional preferences of the target word and com-
bine multiple DPs of words appearing in the con-
text of the target occurrence, in a manner so as
to give more weight to words co-occurring with
both the target word and the target occurrence’s
context words. The advantage of this approach
is that it does not rely on a thesaurus or Word-
Net. Its disadvantage is that it relies on depen-
dency relations and selectional preferences infor-
mation, and that the context information it uses in
order to determine the word sense is quite limited
(only the words surrounding a single occurrence
of the and hence the representation of that sense
might not be sufficiently accurate. Their approach
effectively assumes that each occurrence of a word
has a unique sense.
3 Distributional Measures with Soft
Semantic Constraints
Traditional distributional profiles of words (DPW)
give word–word co-occurrence frequencies. For
example, DPW(u) gives the number of times
4
The relatively large co-occurrence frequency values for
DPCs as compared to DPWs is because a concept can be ref-
ered to by many words (on average 100).
the target word u co-occurs with with all other
words:
5
DPW(u):
w
1
,f(u,w
1
); w
2
,f(u,w
2
); w
3
,f(u,w
3
); . . .
where f stands for co-occurrence frequency (and
can be generalized to stand for any strength
of association (SoA) measure such as the log-
likelihood ratio). Mohammad and Hirst create
concept–word co-occurrence vectors, “distribu-
tional profiles of concepts” (DPCs), from non-
annotated corpus. For example, DPC(c) gives the
number of times the concept (thesaurus category)
c co-occurs with all the words in a corpus.
DPC(c):
w
1
,f(c,w
1
); w
2
,f(c,w
2
); w
3
,f(c,w
3
); . . .
A target word u that appears under thesaurus con-
cepts c
1
, ..., c
n
would be assigned to DPC(c
1
), ...,
DPC(c
n
). Therefore, if a target word v also ap-
pears under some same concept c, the DPCs of u
and v would be indistinguishable.
We propose the creation of distributional pro-
files of word senses (DPWS(u
c
)) that approximate
the SoA of the target word u, when used in sense
c, with each of the words in the corpus:
DPWS(u
c
):
w
1
,f(u
c
,w
1
); w
2
,f(u
c
,w
2
); w
3
,f(u
c
,w
3
); . . .
In order to get exact counts, one needs sense-
annotated data. However, such data is expensive
to create, and is scarce. Therefore, we propose
estimating these counts from the DPW and DPC
counts:
f(u
c
, w
i
) = p(c|w
i
)× f(u,w
i
) (1)
where the conditional probability p(c|w
i
) is calcu-
lated from the co-occurrence frequencies in DPCs;
and the co-occurrence count f(u,w
i
) is calcu-
lated from DPWs. If the target word is not in
the thesaurus’s vocabulary, then we assume uni-
form distribution over all concepts, and in prac-
tice use a single sense, and take the conditional
probability to be 1. Since the method takes sense-
proportional co-occurrence counts, we will refer
to this method as the hybrid-sense-proportional-
counts method (or, hybrid-prop for short).
5
The dimensions of the DP co-occurrence vector can be
defined arbitrarily, and do not have to correspond to the words
in the vocabulary. The most notable alternative representation
is the Latent Semantic Analysis and its variants (Landauer et
al., 1998; Finkelstein et al., 2002; Budiu et al., 2006).
778
For example, below is the DPWS of bank in
the “financial institution” sense, calculated from
its DPW and DPCs:
DPW(bank):
money,100; boat,80; bond,70; fish,77; . . .
DPC(“fin. inst.”):
money,1000; boat,32; bond,705; fish,0; . . .
DPC(“river bank”):
money,5; boat,863; bond,0; fish,948; . . .
DPWS(bank
“fin.inst.”
):
money,(
1000
1000+5
× 100); boat,(
32
32+863
× 80);
bond,(
705
705+0
× 70); fish,(
0
0+948
× 77); . . .
Once the DPWS are calculated, any counts-
based SoA and distance measures can be ap-
plied. For example, in this work we use log-
likelihood ratio (Dunning, 1993) to determine
the SoA between a word sense and co-occurring
words, and cosine to determine the distance be-
tween two DPWS’s log likelihood vectors (Mc-
Donald, 2000). We also contrast this measure with
cosine of conditional probabilities vectors. Given
two target words, we determine the distance be-
tween each of their DPWS pairings and the closest
DPWS-pair distance is chosen.
3.1 The hybrid-sense-filtered-counts method
Since the DPCs are created in an unsupervised
manner, they are expected to be somewhat noisy.
Therefore, we also experimented with a variant of
the method proposed above, that simply makes use
of whether the conditional probability p(c|w
i
) is
greater than 0 or not:
f(u
c
, w
i
) =
{
f(u,w
i
) If p(c|w
i
) > 0
0 Otherwise
(2)
Since this method essentially filters out collocates
that are likely not relevant to the target sense c of
the target word u, we will refer to this method
as the hybrid-sense-filtered-counts method (or,
just hybrid-filt for short). Below is an example
hybrid-filtered DPWS of bank in the “financial in-
stitution” sense:
DPWS(bank
“fin.inst.”
:
money,100); boat,80; bond,70; . . .
Note that the collocate fish is now filtered out,
whereas bank’s co-occurrence counts with money,
boat, and bond are left as is (and not sense-
proportionally attenuated).
4 Evaluation
We evaluated various methods on the task of
ranking word pairs in order of semantic dis-
tance. These methods included our sense-biased
methods as well as several baselines: the Mo-
hammad and Hirst (2006) DPC-based methods,
the traditional word-based distributional similar-
ity methods, and several Latent Semantic Analysis
(LSA)-based methods. We used three testsets and
their corresponding human judgment gold stan-
dards: (1) the Rubenstein and Goodenough (1965)
set of 65 noun pairs—denoted RG-65; (2) the
WordSimilarity-353 (Finkelstein et al., 2002) set
of 353 noun pairs (which include the RG-65
pairs) of which we discarded of one repeating
pair—denoted WS-353; and (3) the Resnik and
Diab (2000) set of 27 verb pairs—denoted RD-00.
4.1 Corpora and Pre-processing
We generated distributional profiles (DPWs
and DPCs) from the British National Corpus
(BNC) (Burnard, 2000), which is a balanced cor-
pus. We lowercased the characters, and stripped
numbers, punctuation marks, and any SGML-like
syntactic tags, but kept sentence boundary mark-
ers. The BNC contained 102,100,114 tokens of
546,299 types (vocabulary size) after tokenization.
For the verb set, we also lemmatized this corpus.
We considered two words as co-occurring if
they occurred in a window of±5 words from each
other. We stoplisted words that co-occurred with
more than 2000 word types.
4.2 Results
The Spearman rank correlations of the automatic
rankings of the RG-65, WS353, and RD-00 test-
sets with the corresponding gold-standard human
rankings is listed in Table 1.
6
The higher the
Spearman rank correlation, the more accurate is
the distance measure.
4.2.1 Results on the RG-65 testset
Baselines. We replicated the traditional word-
based distributional distance measure using co-
sine of vectors (DPs) containing conditional prob-
abilities (word-cos-cp). Its rank correlation of
.53 is close to the correlation of .54 reported in
Mohammad and Hirst (2006), hereafter MH06.
We replicated the MH06 concept-based approach
6
Certain experiments were not pursued as they were re-
dundant in supporting our claims.
779
Method RG-65 WS-353 RD-00
Baselines (replicated):
Traditional distributional measures
word-cos-cp .53 .31 .46
word-cos-ll .70 .54 .51
word-cos-pmi .62 .43 .57
Mohammad and Hirst methods and variants
concept-cos-cp .62 .38 .41
concept*-cos-cp .65 .33 .43
concept-cos-ll .60 .37 .43
concept*-cos-ll .64 .25 .27
concept*-cos-pmi .40 .19 .28
Other (LSA and variants)
LSA .56 .47 .55
GLSA-cos-pmi .18 n.p. n.p.
GLSA-cos-ll .47 n.p. .29
New methods:
hybrid-prop-cos-ll .72 .49 .53
hybrid-prop*-cos-ll .69 .46 .45
hybrid-filt-cos-ll .73 .54 .38
hybrid-filt*-cos-ll .77 .54 .39
hybrid-prop*-cos-pmi .58 .43 .71
hybrid-filt*-cos-pmi .61 .42 .64
Table 1: Spearman rank correlation on RG-65,
WS-353, and RD-00 testsets, trained on BNC.
‘*’ indicates the use of a smaller bootstrapped
concept–word co-occurrence matrix. ‘n.p.’ indi-
cates that the experiment was not pursued.
(concept-cos-cp), and its bootstrapped variant that
uses a smaller concept–word co-occurrence matrix
(concept*-cos-cp). The latter yielded a correla-
tion score .65, close to the .69 reported in MH06.
We also experimented with cosine of PMI vec-
tors (word-cos-pmi) which obtained a correlation
of .62. Log likelihood ratios (word-cos-ll) gave
best results among the baseline methods (.70), and
so we it more often in the implementations of our
hybrid method.
We conducted experiments with LSA and its
GLSA variants (Budiu et al., 2006) as additional
baselines. A limited vocabulary of the 33,000
most frequent words in the BNC and all test words
was used in these experiments. (A larger vocab-
ulary was computationally expensive and 33,000
is also the vocabulary size used by Budiu et
al. (2006) in their LSA experiments.)
New Methods: The hybrid method variants
proposed in this paper (hybrid-prop-cos-ll and
hybrid-filt-cos-ll) were the best performers on the
RG-65 test set. Particularly, they performed better
than both the traditional word-distance measures
(word-cos-ll), and our concept-based methods—
variants of the MH06 method that are used with
likelihood ratios (concept-cos-ll, concept*-cos-
ll). The -pmi methods were all poorer performers
than their -ll counterparts. The -pmi hybrid vari-
ants obtained higher scores than the concept-based
ones, but almost the same scores as the word-
based ones.
4.2.2 Results on WS-353 and RD-00 testsets
On WS-353, all our hybrid methods out-
performed their concept counterparts, and were
on par with their word-based counterparts. On
RD-00, word-cos-pmi out-performed all other
word-based methods, and the hybrid -pmi meth-
ods were best performers with scores of .64 and
.71. Our word-cos-ll, hybrid-prop-cos-ll, and
the two hybrid pmi results on RD-00 are better
than any non-WordNet results reported by Resnik
and Diab (2000), including their syntax-informed
methods—the variants of Lin (“distrib”, .43) and
Dorr (“LCS”, .39). In fact, our hybrid*-prop-cos-
pmi and hybrid*-filt-cos-pmi results reach corre-
lation levels of the WordNet-based methods re-
ported there (.66–.68). Also, on WS-353, our
hybrid sense-filtered variants and word-cos-ll ob-
tained a correlation score higher than published re-
sults using WordNet-based measures (Jarmasz and
Szpakowicz, 2003) (.33 to .35) and Wikipedia-
based methods (Ponzetto and Strube, 2006) (.19
to .48); and very close to the results obtained by
thesaurus-based (Jarmasz and Szpakowicz, 2003)
(.55) and LSA-based methods (Finkelstein et al.,
2002) (.56).
The lower correlation scores of all measures on
the WS-353 test set are possibly due to it hav-
ing politically biased word pairs (examples in-
clude: Arafat–peace, Arafat–terror, Jerusalem–
Palestinian) for which BNC texts are likely to in-
duce low correlation with the human raters of WS-
353. This testset also has disproportionately many
terms from the news domain.
The concept methods performed poorly on WS-
353 partly because many of the target words do
not exist in the thesaurus. For instance, there
were 17 such word types that occurred in 20 WS-
353 testset word pairs. When excluding these
pairs, concept-cos-cp goes up from .38 to .45, and
concept*-cos-pmi from .19 to .24. Interestingly,
results of the hybrid methods show that they were
largely unaffected by the out-of-vocabulary prob-
lem on the WS-353 dataset.
On the verbs dataset RD-00, while hybrid-prop-
cos-ll fared slightly better than word-cos-ll, using
the smaller matrix seemed to hurt performance of
780
hybrid*-prop-cos-ll compared to word-cos-ll. But
results suggest that the -pmi methods might serve
as a better measure than -ll for verbs, although this
claim should be tested more rigorously.
Human judgments of semantic distance are less
consistent on verb-pairs than on noun-pairs, as re-
flected in inter-rater agreement measures in Resnik
and Diab (2000) and others). Thus, not surpris-
ingly, the scores of almost all measures are lower
for the verb data than the RG-65 noun data.
5 Discussion
The hybrid methods proposed in this paper ob-
tained higher accuracies than all other methods on
the RG-65 testset (all of whose words were in the
published thesaurus), and on the RD-00 testset,
and their performance was at least respectable on
the WS-353 testset (many of whose words were
not in the published thesaurus). This is in con-
trast to the concept-distance methods which suf-
fer greatly when the target words are not in the
lexical resource (here, the thesaurus) they rely on,
even though these methods can make use of co-
occurrence information of words not in the the-
saurus with concepts from the thesaurus.
Amongst the two hybrid methods proposed, the
sense-filtered-counts method performed better
using the smaller bootstrapped concept–word co-
occurrence matrix whereas the sense-proportional
method performed better using the larger concept–
word co-occurrence matrix. We believe this is be-
cause the bootstrapping method proposed in Mo-
hammad and Hirst (2006) has the effect of reset-
ting to 0 the small co-occurrence counts. The
noise from these small co-occurrence counts af-
fects the sense-filtered-counts method more ad-
versely (since any non-zero value will cause the
inclusion of the corresponding collocate’s full co-
occurrence count) and so the bootstrapped matrix
is more suitable for this method.
The results also show that the cosine of log-
likelihood ratios method mostly performs better
than cosine of conditional probabilities and the
pmi methods on the noun sets. This further
supports the claim by Dunning (1993) that log-
likelihood ratio is much less sensitive than pmi
to low counts. Interestingly, on the verb set, the
pmi methods, and especially hybrid*-prop-cos-
pmi, did extremely well. Further investigation is
needed in order to determine if pmi is indeed more
suitable for verb semantic similarity, and why.
6 Conclusion
Traditional distributional similarity conflates co-
occurrence information pertaining to the many
senses of the target words. Mohammad and
Hirst (2006) show how distributional measures
can be used to compute distance between very
coarse word senses or concepts (thesaurus cat-
egories), and even obtain better results than
traditional distributional similarity. However,
their method requires that the target words be
listed in the thesaurus, which is often not the
case for domain-specific terms and named enti-
ties. In this paper, we proposed hybrid meth-
ods (hybrid-sense-filtered-counts and hybrid-
sense-proportional-counts) that combine word–
word co-occurrence information (traditional dis-
tributional similarity) with word–concept co-
occurrence information (Mohammad and Hirst,
2006), with soft constraints in such a manner
that the method makes use of information en-
coded in the thesaurus when available, and de-
grades gracefully if the target word is not listed
in the thesaurus. Our method generates word-
sense-biased distributional profiles (DPs) from
non-annotated corpus-based word-based DPs and
coarser-grained aggregated thesaurus-based “con-
cept DPs” (DPCs). We showed that the hybrid
method correlates with human judgments of se-
mantic distance in most cases better than any of
the other methods we replicated.
We are now interested in improving seman-
tic distance measures for verb–verb, adjective–
adjective, and cross-part-of-speech pairs, by ex-
ploiting specific information pertaining to these
parts of speech in lexical resources in addition to
purely co-occurrence information.
Acknowledgments
We thank Mona Diab for her help with her verb
test set, Raluca Budiu for her help and clarifica-
tions regarding the GLSA method and its imple-
mentation details, and the anonymous reviewers
for their valuable feedback. This work was sup-
ported, in part, by the National Science Founda-
tion under Grant No. IIS-0705832, and in part, by
the Human Language Technology Center of Ex-
cellence. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of the sponsor.
781
References
Eneko Agirre and Oier Lopez de Lacalle Lekuona.
2003. Clustering WordNet word senses. In Pro-
ceedings of the 1st International Conference on
Recent Advances in Natural Language Processing
(RANLP-2003), Borovets, Bulgaria.
Satanjeev Banerjee and Ted Pedersen. 2003. Ex-
tended gloss overlaps as a measure of semantic re-
latedness. In Proceedings of the Eighteenth Inter-
national Joint Conference on Artificial Intelligence
(IJCAI-03), pages 805–810, Acapulco, Mexico.
John R. L. Bernard, editor. 1986. The Macquarie The-
saurus. Macquarie Library, Sydney, Australia.
Raluca Budiu, Christiaan Royer, and Peter Pirolli.
2006. Modeling information scent: A compari-
son of LSA, PMI and GLSA similarity measures
on common tests and corpora. In Proceedings of
RIAO’07, Pittsburgh, PA.
Lou Burnard. 2000. Reference Guide for the British
National Corpus. Oxford University Computing
Services, Oxford, England, world edition edition.
James R. Curran. 2004. From Distributional to Seman-
tic Similarity. Ph.D. thesis, School of Informatics,
University of Edinburgh, Edinburgh, UK.
Ido Dagan, Lillian Lee, and Fernando Pereira. 1999.
Similarity-based models of cooccurrence probabili-
ties. Machine Learning, 34(1–3):43–69.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61–74.
Katrin Erk and Sebastian Pad´o. 2008. A struc-
tured vector space model for word meaning in con-
text. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP-
2086), pages 897–906, Honolulu, HI.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-
tan Ruppin. 2002. Placing search in context: The
concept revisited. ACM Transactions on Informa-
tion Systems, 20(1):116–131.
John R. Firth. 1957. A synopsis of linguistic theory
193055. Studies in Linguistic Analysis, (special vol-
ume of the Philological Society):132. Distributional
Hypothesis.
Zellig S. Harris. 1940. Review of Louis H. Gray, foun-
dations of language (New York: Macmillan, 1939).
Language, 16(3):216–231.
Graeme Hirst and Alexander Budanitsky. 2005. Cor-
recting real-word spelling errors by restoring lexical
cohesion. NLE, 11(1):87–111.
Mario Jarmasz and Stan Szpakowicz. 2003. Ro-
get’s Thesaurus and semantic similarity. In Pro-
ceedings of the International Conference on Recent
Advances in Natural Language Processing (RANLP-
2003), pages 212–219, Borovets, Bulgaria.
Thomas Landauer, Peter Foltz, and Darrell Laham.
1998. Introduction to latent semantic analysis. Dis-
course Processes, 25:259 – 284.
Dekang Lin. 1998. An information-theoretic defini-
tion of similarity. In Proceedings of the 15th In-
ternational Conference on Machine Learning, page
296304, San Francisco, CA.
Adam Lopez. 2008. Statistical machine translation.
ACM Computing Surveys, 40(3):149.
Diana McCarthy. 2006. Relating WordNet senses for
word sense disambiguation. In Proceedings of the
European Chapter of the Association for Computa-
tional Linguistics Workshop Making Sense of Sense -
Bringing Computational Linguistics and Psycholin-
guistics Together, pages 17–24, Trento, Italy.
S. McDonald. 2000. Environmental determinants of
lexical processing effort. Ph.D. thesis, University of
Edinburgh, Edinburgh, UK.
Saif Mohammad and Graeme Hirst. 2006. Distribu-
tional measures of concept-distance: A task-oriented
evaluation. In Proceedings of EMNLP.
Saif Mohammad, Iryna Gurevych, Graeme Hirst, and
Torsten Zesch. 2007. Cross-lingual distribu-
tional profiles of concepts for measuring seman-
tic distance. In Proceedings of the Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP/CoNLL-2007), pages 571–580,
Prague, Czech Republic.
Saif Mohammad. 2008. Measuring Semantic Distance
using Distributional Profiles of Concepts. Ph.D. the-
sis, Department of Computer Science, University of
Toronto, Toronto, Canada.
Jane Morris and Graeme Hirst. 2004. Non-classical
lexical semantic relations. In Proceedings of the
Workshop on Computational Lexical Semantics, Hu-
man Language Technology Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 46–51, Boston, Mas-
sachusetts.
Roberto Navigli. 2006. Meaningful clustering of
senses helps boost word sense disambiguation per-
formance. In Proceedings of the 21st International
Conference on Computational Linguistics and the
44th annual meeting of the Association, pages 105–
112, Sydney, Australia.
Siddharth Patwardhan and Ted Pedersen. 2006. Us-
ing WordNet based context vectors to estimate the
semantic relatedness of concepts. In Proceedings of
Making Sense of Sense EACL Workshop, pages 1–8.
Simone Paolo Ponzetto and Michael Strube. 2006.
Exploiting semantic role labeling, WordNet and
Wikipedia for coreference resolution. In Proceed-
ings of the Human Language Technology Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics (NAACL-2006),
pages 192–199, New York, NY.
Philip Resnik and Mona Diab. 2000. Measuring verb
similarity. In 22nd Annual Meeting of the Cognitive
Science Society (COGSCI2000), Philadelphia, PA.
Philip Resnik. 1999. Semantic similarity in a taxon-
omy: An information-based measure and its appli-
cation to problems of ambiguity in natural language.
JAIR, 11:95–130.
782
Herbert Rubenstein and John B. Goodenough. 1965.
Contextual correlates of synonymy. Communica-
tions of the ACM, 8(10):627–633.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional
similarity. In Proceedings of the 20th Interna-
tional Conference on Computational Linguistics
(COLING-04), pages 1015–1021, Geneva, Switzer-
land.
783
