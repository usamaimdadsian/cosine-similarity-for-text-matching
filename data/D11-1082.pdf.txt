Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 889–898,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics
A Correction Model for Word Alignments
J. Scott McCarley, Abraham Ittycheriah, Salim Roukos, Bing Xiang, Jian-ming Xu
IBM T.J. Watson Research Center
1101 Kitchawan Road, Rt. 134
Yorktown Heights, NY 10598
{jsmc,abei,roukos,bxiang,jianxu}@us.ibm.com
Abstract
Models of word alignment built as sequences
of links have limited expressive power, but are
easy to decode. Word aligners that model the
alignment matrix can express arbitrary align-
ments, but are difficult to decode. We pro-
pose an alignment matrix model as a cor-
rection algorithm to an underlying sequence-
based aligner. Then a greedy decoding al-
gorithm enables the full expressive power of
the alignment matrix formulation. Improved
alignment performance is shown for all nine
language pairs tested. The improved align-
ments also improved translation quality from
Chinese to English and English to Italian.
1 Introduction
Word-level alignments of parallel text are crucial for
enabling machine learning algorithms to fully uti-
lize parallel corpora as training data. Word align-
ments appear as hidden variables in IBM Models 1-
5 (Brown et al., 1993) in order to bridge a gap be-
tween the sentence-level granularity that is explicit
in the training data, and the implicit word-level cor-
respondence that is needed to statistically model lex-
ical ambiguity and word order rearrangements that
are inherent in the translation process. Other no-
table applications of word alignments include cross-
language projection of linguistic analyzers (such as
POS taggers and named entity detectors,) a subject
which continues to be of interest. (Yarowsky et al.,
2001), (Benajiba and Zitouni, 2010)
The structure of the alignment model is tightly
linked to the task of finding the optimal alignment.
Many alignment models are factorized in order to
use dynamic programming and beam search for ef-
ficient marginalization and search. Such a factoriza-
tion encourages - but does not require - a sequential
(often left-to-right) decoding order. If left-to-right
decoding is adopted (and exact dynamic program-
ming is intractable) important right context may ex-
ist beyond the search window. For example, the link-
age of an English determiner may be considered be-
fore the linkage of a distant head noun.
An alignment model that jointly models all of the
links in the entire sentence does not motivate a par-
ticular decoding order. It simply assigns comparable
scores to the alignment of the entire sentence, and
may be used to rescore the top-N hypotheses of an-
other aligner, or to decide whether heuristic pertur-
bations to the output of an existing aligner constitute
an improvement. Both the training and decoding of
full-sentence models have presented difficulties in
the past, and approximations are necessary.
In this paper, we will show that by using an ex-
isting alignment as a starting point, we can make a
significant improvement to the alignment by propos-
ing a series of heuristic perturbations. In effect, we
train a model to fix the errors of the existing aligner.
From any initial alignment configuration, these per-
turbations define a multitude of paths to the refer-
ence (gold) alignment. Our model learns alignment
moves that modify an initial alignment into the ref-
erence alignment. Furthermore, the resulting model
assigns a score to the alignment and thus could be
used in numerous rescoring algorithms, such as top-
N rescorers.
In particular, we use the maximum entropy frame-
889
work to choose alignment moves. The model is sym-
metric: source and target languages are interchange-
able. The alignment moves are sufficiently rich to
reach arbitrary phrase to phrase alignments. Since
most of the features in the model are not language-
specific, we are able to test the correction model
easily on nine language pairs; our corrections im-
proved the alignment quality compared to the input
alignments in all nine. We also tested the impact on
translation and found a 0.48 BLEU improvement on
Chinese to English and a 1.26 BLEU improvement
on English to Italian translation.
2 Alignment sequence models
Sequence models are the traditional workhorse for
word alignment, appearing, for instance, in IBM
Models 1-5. This type of alignment model is not
symmetric; interchanging source and target lan-
guages results in a different aligner. This parameter-
ization does not allow a target word to be linked to
more than one source word, so some phrasal align-
ments are simply not considered. Often the choice of
directionality is motivated by this restriction, and the
choice of tokenization style may be designed (Lee,
2004) to reduce this problem. Nevertheless, aligners
that use this parameterization internally often incor-
porate various heuristics in order to augment their
output with the disallowed alignments - for example,
swapping source and target languages to obtain a
second alignment (Koehn et al., 2007) with different
limitations. Training both directions jointly (Liang
et al., 2006) and using posterior probabilities dur-
ing alignment prediction even allows the model to
see limited right context. Another alignment combi-
nation strategy (Deng and Zhou, 2009) directly op-
timizes the size of the phrase table of a target MT
system.
Generative models (such as Models 1-5, and the
HMM model (Vogel et al., 1996)) motivate a narra-
tive where alignments are selected left-to-right and
target words are then generated conditioned upon
the alignment and the source words. Generative
models are typically trained unsupervised, from par-
allel corpora without manually annotated word-level
alignments.
Discriminative models of alignment incorporate
source and target words, as well as more linguisti-
cally motivated features into the prediction of align-
ment. These models are trained from annotated
word alignments. Examples include the maximum
entropy model of (Ittycheriah and Roukos, 2005) or
the conditional random field jointly normalized over
the entire sequence of alignments of (Blunsom and
Cohn, 2006).
3 Joint Models
An alternate parameterization of alignment is the
alignment matrix (Niehues and Vogel, 2008). For a
source sentence F consisting of words f1...fm, and
a target sentence E = e1...el, the alignment matrix
A = {?ij} is an l × m matrix of binary variables.
If ?ij = 1, then ei is said to be linked to fj . If ei
is unlinked then ?ij = 0 for all j. There is no con-
straint limiting the number of source tokens to which
a target word is linked either; thus the binary ma-
trix allows some alignments that cannot be modeled
by the sequence parameterization. All 2lm binary
matrices are potentially allowed in alignment matrix
models. For typical l and m, 2lm  (m + 1)l, the
number of alignments described by a comparable se-
quence model. This parameterization is symmetric -
if source and target are interchanged, then the align-
ment matrix is transposed.
A straightforward approach to the alignment ma-
trix is to build a log linear model (Liu et al., 2005)
for the probability of the alignment A. (We continue
to refer to “source” and “target” words only for con-
sistency of notation - alignment models such as this
are indifferent to the actual direction of translation.)
The log linear model for the alignment (Liu et al.,
2005) is
p(A|E,F ) = exp (
?
i ?i?i(A,E, F ))
Z(E,F ) (1)
where the partition function (normalization) is given
by
Z(E,F ) =
?
A
exp
(?
i
?i?i(A,E, F )
)
. (2)
Here the ?i(A,E, F ) are feature functions. The
model is parameterized by a set of weights ?i, one
for each feature function. Feature functions are often
binary, but are not required to be. Feature functions
890
may depend upon any number of components ?ij of
the alignment matrix A.
The sum over all alignments of a sentence pair
(2lm terms) in the partition function is computa-
tionally impractical except for very short sentences,
and is rarely amenable to dynamic programming.
Thus the partition function is replaced by an ap-
proximation. For example, the sum over all align-
ments may be restricted to a sum over the n-best
list from other aligners (Liu et al., 2005). This ap-
proximation was found to be inconsistent for small
n unless the merged results of several aligners were
used. Alternately, loopy belief propagation tech-
niques were used in (Niehues and Vogel, 2008).
Loopy belief propagation is not guaranteed to con-
verge, and feature design is influenced by consider-
ation of the loops created by the features. Outside
of the maximum entropy framework, similar models
have been trained using maximum weighted bipar-
tite graph matching (Taskar et al., 2005), averaged
perceptron (Moore, 2005), (Moore et al., 2006), and
transformation-based learning (Ayan et al., 2005).
4 Alignment Correction Model
In this section we describe a novel approach to word
alignment, in which we train a log linear (maximum
entropy) model of alignment by viewing it as correc-
tion model that fixes the errors of an existing aligner.
We assume a priori that the aligner will start from
an existing alignment of reasonable quality, and will
attempt to apply a series of small changes to that
alignment in order to correct it. The aligner naturally
consists of a move generator and a move selector.
The move generator perturbs an existing align-
ment A in order to create a set of candidate align-
mentsMt(A), all of which are nearby to A in the
space of alignments. We index the set of moves by
the decoding step t to indicate that we generate en-
tirely different (even non-overlapping) sets of moves
at different steps t of the alignment prediction. Typ-
ically the moves affect linkages local to a particular
word, e.g. the t’th source word.
The move selector then chooses one of the align-
ments At+1 ? Mt(At), and proceeds iteratively:
At+2 ? Mt+1(At+1), etc. until suitable termina-
tion criteria are reached. Pseudocode is depicted in
Fig. (1.) In practice, one move for each source and
Input: sentence pair E1 .. El, F1 .. Fm
Input: alignment A
Output: improved alignment Afinal
for t = 1? l do
generate moves:Mt(At)
select move:
At+1 ? argmaxA?Mt(At)p(A|At, E, F )
Afinal ? Al+1
{repeat for source words}
Figure 1: pseudocode for alignment correction
target word is sufficient.
4.1 Move generation
Many different types of alignment perturbations are
possible. Here we restrict ourselves to a very sim-
ple move generator that changes the linkage of ex-
actly one source word at a time, or exactly one target
word at a time. Many of our corrections are simi-
lar to those of (Setiawan et al., 2010), although our
motivation is perhaps closer to (Brown et al., 1993),
who used similar perturbations to approximate in-
tractable sums that arise when estimating the param-
eters of the generative models Models 3-5, and ap-
proach refined in (Och and Ney, 2003). We note that
our corrections are designed to improve even a high-
quality starting alignment; in contrast the model of
(Fossum et al., 2008) considers deletion of links
from an initial alignment (union of aligners) that is
likely to overproduce links.
From the point of view of the alignment ma-
trix, we consider changes to one row or one col-
umn (generically, one slice) of the alignment matrix.
At each step t, the move setMt(At) is formed by
choosing a slice of the current alignment matrix At,
and generating all possible alignments from a few
families of moves. Then the move generator picks
another slice and repeats. The m + l slices are cy-
cled in a fixed order: the first m slices correspond to
source words (ordered according to a heuristic top-
down traversal of the dependency parse tree if avail-
able), and the remaining l slices correspond to target
words, similarly parse-ordered. For each slice we
consider the following families of moves, illustrated
by rows.
• add link to row i - for one j such that ?ij = 0,
891
make ?ij = 1 (shown here for row i = 1.)
? ? ?
a ? ? ?
b ? • ?
c ? ? ?
=?
? ? ?
a • ? ?
b ? • ?
c ? ? ?
• remove one or more links from row i - for some
j such that ?ij = 1, make ?ij = 0 (shown here
for i = 3.)
? ? ?
a • ? ?
b ? • ?
c ? ? •
=?
? ? ?
a • ? ?
b ? • ?
c ? ? ?
• move a link in row i - for one j and one j? such
that ?ij = 1 and ?ij? = 0, make ?ij = 0 and
?ij? = 1 (shown here for i = 1.)
? ? ?
a ? • ?
b ? • ?
c ? ? ?
=?
? ? ?
a • ? ?
b ? • ?
c ? ? ?
• leave row i unchanged
Similar families of moves apply to column slices
(source words.) In practice, perturbations are re-
stricted by a window (typically ±5 from existing
links.) If the given source word is unlinked, we
consider adding a link to each target word in a win-
dow (±5 from nearby links.) The window size re-
strictions mean that some reference alignments are
not reachable from the starting point. However, this
is unlikely to limit performance - an oracle aligner
achieves 97.6%F -measure on the Arabic-English
training set.
4.2 Move selection
A log linear model for the selection of the candidate
alignment at t+1 from the set of alignmentsMt(At)
generated by the move generator at step t takes the
form:
p(At+1|E,F,Mt(At)) =
e
P
i ?i?i(At+1,E,F )
Z(E,F,Mt(At))
(3)
where the partition function is now given by
Z(E,F,M) =
?
A?M
e
P
i ?i?i(A,E,F ) (4)
and At+1 ? Mt(At) is required for correct normal-
ization. This equation is notationally very similar
to equation (1), except that the predictions of the
model are restricted to a small set of nearby align-
ments. For the move generator considered in this pa-
per, the summation in Eq.(4) is similarly restricted,
and hence training the model is tractable. The set
of candidate alignmentsMt(At) typically does not
contain the reference (gold) alignment; we model
the best alignment among a finite set of alternatives,
rather than the correct alignment from among all
possible alignments. This is a key difference be-
tween our model and (Liu et al., 2005).
Note that if we extended our definition of pertur-
bation to the limiting case that the alignment set in-
cluded all possible alignments then we would clearly
recover the standard log linear model of alignment.
4.3 Training
Since the model is designed to predict perturbation
to an alignment, it is trained from a collection of
errorful alignments and corresponding reference se-
quences of aligner moves that reach the reference
(gold) alignment. We construct a training set from
a collection of sentence pairs and reference align-
ments for training (A?n, En, Fn)Nn=1, as well as col-
lections of corresponding “first pass” alignments An1
produced by another aligner. For each n, we form a
number of candidate alignment sets Mt(Ant ), one
for each source and target word. For training pur-
poses, the true alignment from the set is taken to be
the one identical withA?n in the slice targeted by the
move generator at the current step. (A small number
of move sets do not have an exact match and are dis-
carded.) Then we form an objective function from
the log likelihood of reference alignment, smoothed
with a gaussian prior
L =
?
n
Ln +
?
i
(?i/?)2 (5)
892
where the likelihood of each training sample is
Ln =
?
?
log p1(A0n|E,Fn;M(f?, A0n, E, Fn))
+
?
?
log p1(A0n|E,Fn;M(e?, A0n, E, Fn)) (6)
The likelihood has a term for each sentence pair
and for each decoder step. The model is trained
by gradient ascent using the l-BFGS method (Liu
and Nocedal, 1989), which has been successfully
used for training log linear models (Blunsom and
Cohn, 2006) in many natural language tasks, includ-
ing alignment.
5 Features
A wide variety of features were used in the model.
We group the features in three broad categories:
link-based, geometrical, and parse-based.
Link-based features are those which decompose
into a (linear) sum of alignment matrix elements ?ij .
An example link-based feature is one that fires if a
source language noun is linked to a target language
determiner. Note that this feature may fire more than
once in a given sentence pair: as with most fea-
tures in our model, it is an integer-valued feature
that counts the number of times a structure appears
in a sentence pair. These features do not capture any
correlation between different ?ij . Among the link-
based features are those based on Model 1 transla-
tion matrix parameters ?(ei|fj) and ?(fj |ei). We
bin the model 1 parameters, and form integer-valued
features for each bin that count the number of links
with ?0 < ?(ei|fj) < ?1.
Geometrical features are those which capture cor-
relation between different ?ij based on adjacency or
nearness. They capture the idea that nearby words
in one language link to nearby words in the other
language - the motivation of HMM-based models
of alignment. An example is a feature that counts
the number of times that the next word in the source
language is linked to the next word in the target lan-
guage:
?(A,E, F ) =
?
ij
?ij?i+1,j+1 (7)
Parse-based features are those which capture cor-
relation between different ?ij , but use parsing to de-
termine links which are correlated - for example, if a
determiner links to the same word as its head noun.
As an example, if ei is the headword of ei? , and fj is
the headword of fj? , then
?(A,E, F ) =
?
ij
?ij?i?j? (8)
counts the number of times that a dependency rela-
tion in one language is preserved by alignment in the
other language. This feature can also be decorated,
either lexically, or with part-of-speech tags (as many
features in all three categories are.)
5.1 Unsupervised Adaptation
We constructed a heuristic phrase dictionary for un-
supervised adapatation. After aligning a large unan-
notated parallel corpus with our aligner, we enumer-
ate fully lexicalized geometrical features that can be
extracted from the resulting alignments - these are
entries in a phrase dictionary. These features are
tied, and treated as a single real-valued feature that
fires during training and decoding phases if a set of
hypothesized links matches the geometrical feature
extracted from the unannotated data. The value of
this real-valued feature is the log of the number of
occurrences of the identical (lexicalized) geometri-
cal feature in the aligned unannotated corpus.
6 Results
We design our experiments to validate that a cor-
rection model using simple features, mostly non-
language-specific, can improve the alignment accu-
racy of a variety of existing aligners for a variety of
language pairs; we do not attempt to exactly match
features between comparison aligners - this is un-
likely to lead to a robust correction model.
6.1 Arabic-English alignment results
We trained the Arabic-English alignment system
on 5125 sentences from Arabic-English treebanks
(LDC2008E61, LDC2008E22) that had been an-
notated for word alignment. Reference parses
were used during the training. Results are mea-
sured on a 500 sentence test set, sampled from
a wide variety of parallel corpora, including vari-
ous genres. During alignment, only automatically-
generated parses (based on the parser of (Rat-
naparkhi, 1999)) were available. Alignments on
893
initial align correction model R (%) P (%) F (%) ?F
GIZA++ 76 76 76
corr(GIZA++) 86 94 90 14?
corr(ME-seq) 88 92 90 14?
HMM 73 73 73
corr(HMM) 87 92 89 16?
corr(ME-seq) 87 93 90 17?
ME-seq 82 84 83
corr(HMM) 88 92 90 7?
corr(GIZA++) 87 94 91 8?
corr(ME-seq) 89 94 91 8?
Table 1: Alignment accuracy for Arabic-English systems in percentage recall (R), precision(P), and F -measure. ?
denotes statistical significance (see text.)
lang method R (%) P(%) F (%) ?F
ZH?EN GIZA++ 55 67 61
ME-seq 66 72 69
corr(ME-seq) 74 76 75 6?
Table 2: Alignment accuracy for Chinese(ZH)-English(EN) systems. ? denotes statistical significance
lang aligner R(%) P(%) F (%) ?F
IT? EN ME-seq 74 87 80
corr(ME-seq) 84 92 88 8?
EN?IT ME-seq 75 86 80
corr(ME-seq) 84 92 88 8?
PT?EN ME-seq 77 83 80
corr(ME-seq) 87 91 89 9†
EN?PT ME-seq 79 87 83
corr(ME-seq) 88 90 89 6†
JA?EN ME-seq 72 78 75
corr(ME-seq) 77 83 80 5?
RU?EN ME-seq 81 85 83
corr(ME-seq) 82 92 87 4?
DE?EN ME-seq 77 82 79
corr(ME-seq) 78 87 82 3?
ES?EN ME-seq 93 86 90
corr(ME-seq) 92 88 90 0.6
FR?EN ME-seq 89 91 90
corr(ME-seq) 88 92 90 0.1
Table 3: Alignment accuracy for additional languages. ? denotes statistical significance; † statistical significance not
available. IT=Italian, PT=Portuguese, JA=Japanese, RU=Russian, DE=German, ES=Spanish, FR=French
894
the training and test sets were decoded with three
other aligners, so that the robustness of the cor-
rection model to different input alignments could
be validated. The three aligners were GIZA++
(Och and Ney, 2003) (with the MOSES (Koehn
et al., 2007) postprocessing option -alignment
grow-diag-final-and) the posterior HMM
aligner of (Ge, 2004), a maximum entropy sequen-
tial model (ME-seq) (Ittycheriah and Roukos, 2005).
ME-seq is our primary point of comparison: it is
discriminatively trained (on the same training data,)
uses a rich set of features, and provides the best
alignments of the three. Three correction models
were trained: corr(GIZA++) is trained to correct
the alignments produced by GIZA++, corr(HMM)
is trained to correct the alignments produced by the
HMM aligner, and corr(ME-seq) is trained to correct
the alignments produced by the ME-seq model.
In Table (1) we show results for our system cor-
recting each of the aligners as measured in the usual
recall, precision, and F -measure.1 The resulting
improvements in F -measure of the alignments pro-
duced by our models over their corresponding base-
lines is statistically significant (p < 10?4, indicated
by a ?.) Statistical significance is tested by a Monte
Carlo bootstrap (Efron and Tibshirani, 1986) - sam-
pling with replacement the difference in F -measure
of the two system’s alignments of the same sentence
pair. Both recall and precision are improved, but the
improvement in precision is somewhat larger. We
also show cross-condition results in which a correc-
tion model trained to correct HMM alignments is ap-
plied to correct ME-seq alignments. These results
show that our correction model is robust to different
starting aligners.
6.2 Chinese-English alignment results
Table (2) presents results for Chinese-English word
alignments. The training set for the corr(ME-
seq) model consisted of approximately 8000 hand-
aligned sentences sampled from LDC2006E93 and
LDC2008E57. The model was trained to correct
the output of the ME-seq aligner, and tested on
the same condition. For this language pair, refer-
ence parses were not available in our training set, so
1We do not distinguish sure and possible links in our anno-
tations - under this circumstance, alignment error rate(Och and
Ney, 2003) is 1? F .
automatically-generated parses were used for both
training and test sets. Results are measured on a 512
sentence test set, sampled from a wide variety of par-
allel corpora of various genres. We compare perfor-
mance with GIZA++, and with the ME-seq aligner.
Again the resulting improvement over the ME-seq
aligner is statistically significant. However, here the
improvement in recall is somewhat larger than the
improvement in precision.
6.3 Additional language pairs
Table (3) presents alignment results for seven other
language pairs. Separate alignment corrector mod-
els were trained for both directions of Italian ?
English and Portuguese ? English. The training
and test data vary by language, and are sampled
uniformly from a diverse set of corpora of various
genres, including newswire, and technical manuals.
Manual alignments for training and test data were
annotated. We compare performance with the ME-
seq aligner trained on the same training data. As
with the Chinese results above, customization and
feature development for the language pairs was min-
imal. In general, machine parses were always avail-
able for the English half of the pair. Machine parses
were also available for French and Spanish. Ma-
chine part of speech tags were available for all lan-
guage (although character-based heuristic was sub-
stituted for Japanese.) Large amounts (up to 10 mil-
lion sentence pairs) of unaligned parallel text was
available for model 1 type features. Our model ob-
tained improved alignment F -measure in all lan-
guage pairs, although the improvements were small
for ES?EN and FR?EN, the language pairs for
which the baseline accuracy was the highest.
6.4 Analysis
Some of the improvement can be attributed to “look-
ahead” during the decoding. For example, the
English word “the”, which (during Arabic-English
alignment) should often be aligned to the same Ara-
bic words to which its headword is linked. The num-
ber of errors associated with “the” dropped from 383
(186 false alarms, 197 misses) in the ME-seq model
to 137 (60 false alarms and 77 misses) in the current
model.
In table 5, we show contributions to performance
resulting from various classes of features. The
895
Zh-En Ar-En
method correct miss fa correct miss fa
hmm 147 256 300
GIZA++ 139 677 396 132 271 370
ME-seq 71 745 133 127 276 191
corr(ME-seq) 358 458 231 264 139 114
Table 4: Analysis of 2?1 alignments errors (misses and false alarms) for Zh-En and Ar-En aligners
largest contribution is noted by removing features
based on the Model 1 translation matrices. These
features contain a wealth of lexical information
learned from approximately 7 × 106 parallel sen-
tences - information that cannot be learned from
a relatively small amount of word-aligned train-
ing data. Geometrical features contribute more
than parse-based features, but the contribution from
parse-based features is important, and these are
more difficult to incorporate into sequential mod-
els. We note that all of the comparison aligners had
equivalent lexical information.
We show a small improvement from the unsuper-
vised adaptation - learning phrases from the parallel
corpus that are not captured by the lexical features
based on model 1. The final row in the table shows
the result of running the correction model on its own
output. The improvement is not statistically signif-
icant, but it is important to note the performance is
stable - a further indication that the model is robust
to a wide variety of input alignments, and that our
decoding scheme is a reasonable approach to find-
ing the best alignment.
In table 4, we characterize the errors based on the
fertility of the source and target words. We focus
on the case that exactly one target word is linked to
exactly two source words. These are the links that
feature R(%) P(%) F (%) Nexact
base 89 94 91 136
base-M1 82 88 85 89
base-geometric 83 90 86 92
base-parse 87 93 90 116
base+un.adapt 89 94 92 141
+iter2 90 94 92 141
Table 5: Importance of feature classes - ablation experi-
ments
corpus-level p90
alignment TER BLEU TER BLEU
ME-seq 56.06 32.65 64.20 21.31
corr(Me-seq) 56.25 33.10 63.47 22.02
both 56.07 33.13 63.41 22.14
Table 6: Translation results, Zh to En. BLEU=BLEUr4n4
alignment TER BLEUr1n4
ME-seq 35.02 69.94
corr(Me-seq ) 33.10 71.20
Table 7: Translation results, En to It
are poorly suited for the HMM and ME-seq mod-
els used in this comparison because of the chosen
directionality: the source (Arabic, Chinese) words
are the states and the target (English) words are the
observation. The HMM is able to produce these
links only by the use of posterior probabilities, rather
than viterbi decoding. The ME-seq model only pro-
duces these links because of language-specific post-
processing. GIZA++ has an underlying sequential
model, but uses both directionalities. The correc-
tion model improved performance across all three of
these links structures. The single exception is that
the number of 2?1 false alarms increased (Zh-En
alignments) but in this case, the first pass ME-seq
alignment produced few false alarms because it sim-
ply proposed few links of this form. It is also notable
that 1?2 links are more numerous than 2?1 links,
in both language pairs. This is consequence of the
choice of directionality and tokenization style.
6.5 Translation Impact
We tested the impact of improved alignments on
the performance of a phrase-based translation sys-
tem (Ittycheriah and Roukos, 2007) for three lan-
896
guage pairs. Our alignment did not improve the
performance of a mature Arabic to English trans-
lation system, but two notable successes were ob-
tained: Chinese to English, and English to Italian.
It is well known that improved alignment perfor-
mance does not always improve translation perfor-
mance (Fraser and Marcu, 2007). A mature machine
translation system may incorporate alignments ob-
tained from multiple aligners, or from both direc-
tions of an asymmetric aligner. Furthermore, with
large amounts of training data (the Gale Phase 4
Arabic English corpus consisting of 8 × 106 sen-
tences,) a machine translation system is subject to
a saturation effect: correcting an alignment may
not yield a significant improvement because the the
phrases learned from the correct alignment have al-
ready been acquired in other contexts.
For the Chinese to English translation system (ta-
ble 6) the training corpus consisted of 11× 106 sen-
tence pairs, subsampled to 106. The test set was
NIST MT08 Newswire, consisting of 691 sentences
and 4 reference translations. Corpus-level perfor-
mance (columns 2 and 3) improved when measured
by BLEU, but not by TER. Performance on the
most difficult sentences (near the 90th percentile,
columns 4 and 5) improved on both BLEU and TER
(Snover et al., 2006), and the improvement in BLEU
was larger for the more difficult sentences than it
was overall. Translation performance further im-
proved, by a smaller amount, using bothME-seq and
corr(ME-seq) alignments during the training.
The improved alignments impacted the transla-
tion performance of the English to Italian transla-
tion system (table 7) even more strongly. Here the
training corpus consisted of 9.4×106 sentence pairs,
subsampled to 387000 pairs. The test set consisted
of 7899 sentences. Overall performance improved
as measured by both TER and BLEU (1.26 points.)
7 Conclusions
A log linear model for the alignment matrix is used
to guide systematic improvements to an existing
aligner. Our system models arbitrary alignment ma-
trices and allows features that incorporate such in-
formation as correlations based on parse trees in
both languages. We train models to correct the er-
rors of several existing aligners; we find the resulting
models are robust to using different aligners as start-
ing points. Improvements in alignment F -measure,
often significant improvements, show that our model
successfully corrects input alignments from existing
models in all nine language pairs tested. The result-
ing Chinese-English and English-Italian word align-
ments also improved translation performance, espe-
cially on the English-Italian test, and notably on the
particularly difficult subset of the Chinese sentences.
Future work will assess its impact on translation for
the other language pairs, as well as its impact on
other tasks, such as named entity projection.
8 Acknowledgements
We would like to acknowledge the support of
DARPA under Grant HR0011-08-C-0110 for fund-
ing part of this work. The views, opinions, and/or
findings contained in this article/presentation are
those of the author/presenter and should not be in-
terpreted as representing the official views or poli-
cies, either expressed or implied, of the Defense Ad-
vanced Research Projects Agency or the Department
of Defense.
References
Necip Fazil Ayan, Bonnie J. Dorr, and Christof Monz.
2005. Alignment link projection using transformation-
based learning. In Proceedings of the conference on
Human Language Technology and Empirical Methods
in Natural Language Processing, HLT ’05, pages 185–
192, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Yassine Benajiba and Imed Zitouni. 2010. Enhanc-
ing mention detection using projection via aligned
corpora. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing,
EMNLP ’10, pages 993–1001. Association for Com-
putational Linguistics.
Phil Blunsom and Trevor Cohn. 2006. Discriminative
word alignment with conditional random fields. In In
Proc. of ACL-2006, pages 65–72.
Peter F. Brown, Stephen Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematic
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263–311.
Yonggang Deng and Bowen Zhou. 2009. Optimizing
word alignment combination for phrase table training.
In Proceedings of the ACL-IJCNLP 2009 Conference
897
Short Papers, ACLShort ’09, pages 229–232, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
B. Efron and R. Tibshirani. 1986. Bootstrap meth-
ods for standard errors, confidence intervals, and other
measures of statistical accuracy. Statistical Science,
1(1):pp. 54–75.
Victoria Fossum, Kevin Knight, and Steven Abney. 2008.
Using syntax to improve word alignment precision for
syntax-based machine translation. In Proceedings of
the Third Workshop on Statistical Machine Transla-
tion, StatMT ’08, pages 44–52. Association for Com-
putational Linguistics.
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine transla-
tion. Comput. Linguist., 33(3):293–303.
Niyu Ge. 2004. Improvement in word alignments. In
DARPA/TIDES MT workshop.
Abraham Ittycheriah and Salim Roukos. 2005. A maxi-
mum entropy word aligner for arabic-english machine
translation. In HLT-EMNLP, pages 89–96.
Abraham Ittycheriah and Salim Roukos. 2007. Direct
translation model 2. In Human Language Technolo-
gies 2007: The Conference of the NA-ACL, pages 57–
64, Rochester, New York, April. Association for Com-
putational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In ACL.
Young-Suk Lee. 2004. Morphological analysis for sta-
tistical machine translation. In Proceedings of HLT-
NAACL 2004: Short Papers on XX, HLT-NAACL ’04,
pages 57–60. Association for Computational Linguis-
tics.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the main con-
ference on Human Language Technology Conference
of the North American Chapter of the Association of
Computational Linguistics, pages 104–111. Associa-
tion for Computational Linguistics.
Dong C. Liu and Jorge Nocedal. 1989. On the lim-
ited memory bfgs method for large scale optimization.
Mathematical Programming, 45:503–528.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear
models for word alignment. In ACL ’05: Proceedings
of the 43rd Annual Meeting on Association for Com-
putational Linguistics, pages 459–466. Association for
Computational Linguistics.
Robert C. Moore, Wen-tau Yih, and Andreas Bode. 2006.
Improved discriminative bilingual word alignment. In
ACL-44: Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, pages 513–520. Association for Computa-
tional Linguistics.
Robert C. Moore. 2005. A discriminative framework for
bilingual word alignment. In In Proceedings of HLT-
EMNLP, pages 81–88.
Jan Niehues and Stephan Vogel. 2008. Discrimina-
tive word alignment via alignment matrix modeling.
In Proceedings of the Third Workshop on Statistical
Machine Translation, pages 18–25, Columbus, Ohio,
June. Association for Computational Linguistics.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Adwait Ratnaparkhi. 1999. Learning to parse natu-
ral language with maximum entropy models. Mach.
Learn., 34:151–175, February.
Hendra Setiawan, Chris Dyer, and Philip Resnik. 2010.
Discriminative word alignment with a function word
reordering model. In Proceedings of the 2010 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, EMNLP ’10, pages 534–544. Association for
Computational Linguistics.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linea
Micciulla, and John Makhoul. 2006. A study of trans-
lation edit rate with targeted human annotation. In
Proceedings of Association for Machine Translation in
the Americas.
Ben Taskar, Simon Lacoste-julien, and Dan Klein. 2005.
A discriminative matching approach to word align-
ment. In In Proceedings of HLT-EMNLP, pages 73–
80.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the 16th conference on Com-
putational linguistics, pages 836–841.
David Yarowsky, Grace Ngai, and Richard Wicentowski.
2001. Inducing multilingual text analysis tools via ro-
bust projection across aligned corpora. In Proceedings
of the first international conference on Human lan-
guage technology research, HLT ’01, pages 1–8. As-
sociation for Computational Linguistics.
898
