Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2492–2502,
Lisbon, Portugal, 17-21 September 2015.
c©2015 Association for Computational Linguistics.
A Tableau Prover for Natural Logic and Language
Lasha Abzianidze
TiLPS, Tilburg University, the Netherlands
L.Abzianidze@uvt.nl
Abstract
Modeling the entailment relation over sen-
tences is one of the generic problems of
natural language understanding. In or-
der to account for this problem, we de-
sign a theorem prover for Natural Logic,
a logic whose terms resemble natural lan-
guage expressions. The prover is based on
an analytic tableau method and employs
syntactically and semantically motivated
schematic rules. Pairing the prover with a
preprocessor, which generates formulas of
Natural Logic from linguistic expressions,
results in a proof system for natural lan-
guage. It is shown that the system obtains
a comparable accuracy (?81%) on the un-
seen SICK data while achieving the state-
of-the-art precision (?98%).
1 Introduction
A problem of recognizing textual entailments
(RTE)—given two text fragments T (for a text)
and H (for a hypothesis), determine whether T
entails, contradicts or is neutral to H—is consid-
ered as a complex and, at the same time, funda-
mental problem for several NLP tasks (Dagan et
al., 2005). For more than a decade, RTE chal-
lenges have been held, where systems are compet-
ing to each other with respect to human annotated
RTE test data; but there are few systems that try
to solve RTE problems by computing meanings
of linguistic expressions and employing inference
engines similar to proof procedures of formal log-
ics. Moreover, those few systems are usually used
in combination with shallow classifiers since the
systems’ performances alone are poor.
The current paper advocates that purely deduc-
tive inference engines over linguistic representa-
tions backed up with a simple lexical knowledge
base could be solely and successfully used for the
RTE task. Our work builds on the theory of an
analytic tableau system for Natural Logic (Natural
Tableau) introduced by Muskens (2010). The the-
ory offers to employ a tableau method—a proof
procedure used for many formal logics—for the
version of Natural Logic that employs Lambda
Logical Forms (LLFs)—certain terms of simply
typed ?-calculus—as Logical Forms (LFs) of lin-
guistic expressions. The merits of the current ap-
proach are several and they can be grouped in two
categories: virtues attributed to the tableau prover
are (i) the high precision for the RTE task charac-
teristic to proof procedures, (ii) the transparency
of the reasoning process, and (iii) ability for solv-
ing problems with several premises; and those
concerning LLFs are (iv) an evidence for LFs that
are reminiscent of Surface Forms but still retaining
complex semantics, and (v) an automatized way of
obtaining LLFs from wide-coverage texts.
The rest of the paper is organized as follows.
First, Natural Tableau is introduced, and then a
method of obtaining LLFs from raw text is de-
scribed. We outline the architecture of an imple-
mented theorem prover that is based on the the-
ory of Natural Tableau. The power of the prover is
evaluated against the SICK data; the results are an-
alyzed and compared to related RTE systems. The
paper concludes with future work.
2 Natural Tableau for Natural Logic
Natural Logic is a vague notion and refers to log-
ics that account for valid inferences of natural
languages, where reasoning and the grammar are
strongly related to each other and LFs resemble
surface forms (Lakoff, 1972). On the other hand,
a tableau method (Beth, 1955) is a popular proof
procedure and nowadays many formal logics have
their own version of it (D’Agostino et al., 1999).
A combination of these two devices is offered by
Muskens (2010), where the language of Natural
Logic is considered to be a part of simply typed
2492
X A B : [ ] : F
A : [c] : T
B : [c] : F
?
F
s.t. X ? {all, every}
and c is a fresh term
A B : [
#
C ] : X
A : [B,
#
C ] : X
PUSH
A : [B,
#
C ] : X
A B : [
#
C ] : X
PULL
A : [
#
C ] : T
B : [
#
C ] : F
×
?
×
s.t. A ? B
X A B : [ ] : F
A : [d] : F B : [d] : F
?
F
s.t. X ? {some, a} and d is an old term
not A : [
#
C ] : X
A : [
#
C ] : X
NOT
Figure 1: Tableau rules for quantifiers (?
F
and ?
F
), Boolean operators (NOT), formatting (PUSH and
PULL) and inconsistency (?
×
). The relation ? stands for entailment,
#
C and X are meta-variables over
sequences of terms and truth signs (T and F), respectively; the bar operator X negates a sign.
?-terms that are built up from variables and lexi-
cal constant terms with the help of application and
lambda abstraction. The terms of the language
are called LLFs and resemble linguistic surface
forms:
1
a
(et)(et)t
bird
et
fly
et
some
(et)(et)t
bird
et
(not
(et)et
fly
et
)
not
((et)(et)t)(et)(et)t
all
(et)(et)t
bird
et
fly
et
Note that common nouns and intransitive verbs
are typed as properties (i.e. functions from enti-
ties to truth values) and quantifiers as binary rela-
tions over properties; the latter typing treats quan-
tified noun phrases (QNPs) as generalized quanti-
fiers (GQs)—a term of type properties over prop-
erties (et)t.
A Natural Tableau entry is a tuple containing
a term, a sequence of terms representing an argu-
ment list, and a truth sign. The entries are such that
when a term is applied to all arguments from an ar-
gument list in the order of the list, the resulted term
is of type truth value. For example, A
eet
c
e
: [d
e
] :T
is a valid tableau entry (i.e. a node) since it con-
sists of a term A
eet
c
e
, an argument list [d
e
] and
a truth sign T standing for true, and additionally,
A
eet
c
e
d
e
is a term of type t.
A tableau method is a refutation method and it
proves an argument by searching a counterexam-
ple. The search process is guided by applications
of certain set of rules. A tableau rule is a schema
with a set of antecedent nodes above a line and a
set of precedent branches below a line, where each
1
Since modeling intensionality is beyond the scope of
the paper, we present LLFs typed with extensional seman-
tic types, i.e. types are built up from basic e (for entities) and
t (for truth values) types. We use the comma as a type con-
structor, e.g., (e, t) stands for a functional type from entities
to truth values. The comma is omitted when types are de-
noted by single letters, e.g., et stands for (e, t). Taking into
account right-associativity of the type constructor we often
drop parentheses for better readability. Terms are optionally
annotated with their types in a subscript.
1 : not all bird fly : [ ] : T
2 : some bird (not fly) : [ ] : F
3
PUSH[1]
: not all bird : [fly] : T
4
PUSH[3]
: not all : [bird, fly] : T
5
NOT[4]
: all : [bird, fly] : F
6
PULL[5]
: all bird : [fly] : F
7
PULL[6]
: all bird fly : [ ] : F
8
?
F
[7]
: bird : [c] : T
9
?
F
[7]
: fly : [c] : F
11
?
F
[2]
: not fly : [c] : F
13
NOT[11]
: fly : [c] : T
14
?
×
[9,13]
:×
10
?
F
[2]
: bird : [c] : F
12
?
×
[8,10]
:×
Figure 2: The closed tableau serves as a proof for:
not all birds fly? some bird does not fly
branch consists of (precedent) nodes. A rule is ap-
plicable if all its antecedent nodes match to some
nodes in a tableau, and after the rule is applied,
precedent nodes of the rule are introduced in the
tableau. A tableau consists of branches where each
branch models a situation and is either closed (i.e.,
inconsistent) or open (i.e., consistent) depending
whether it contains a closure × sign (i.e., an ob-
vious contradiction). A tableau is closed if all its
branches are closed, otherwise it is open.
In Figure 2, a tableau proof, which employs the
rules of (Muskens, 2010) from Figure 1, is pre-
sented. In order to show a way the tableau is de-
veloped, the nodes are enumerated and annotated
with a source rule and IDs of nodes from which
a current node is obtained. For example, 3 is ob-
tained from 1 by the PUSH rule. In order to prove
an argument, the tableau starts with a counterex-
ample of the argument, i.e. a premise being true
and a conclusion false. After several rule applica-
tions, all the branches of the tableau close meaning
2493
that none of the situations for the counterexample
were consistent.
An advantage of Natural Tableau is that it treats
both single and multi-premised arguments in the
same fashion and represents a deductive procedure
in an intuitive and transparent way.
3 Obtaining LLFs for Natural Tableau
3.1 CCG and the C&C Parser
Combinatory Categorial Grammar (CCG) is a lex-
icalized grammar formalism that assigns a syntac-
tic category and a semantic interpretation to lexi-
cal items, where the items are combined via com-
binatory rules (Steedman, 2000; Steedman and
Baldridge, 2011). The CCG category A/B (or
A\B) is a category of an item that becomes of cat-
egory A when it is combined with an item of cat-
egory B on its right (or left, respectively) side. In
the example below, the sentence every man walks
is analyzed in the CCG formalism, where lexical
items are combined via the forward application
rule and unspecified semantic interpretations are
written in a boldface:
every
(S/(S\NP ))/N : every
man
N : man
S/(S\NP ) : every man
walks
S\NP : walk
S : (every man) walk
The CCG derivation trees are suitable structures
for obtaining LLFs for at least two reasons. First,
the CCG framework is characterized by a trans-
parent interface between syntactic categories and
semantic types; second, there exist efficient and
robust CCG parsers for wide-coverage texts.
During obtaining LLFs, we employ the C&C
CCG parser of Clark and Curran (2007) and Easy-
CCG of Lewis and Steedman (2014). While the
C&C parser is a pipeline of several NLP sys-
tems: POS-tagger, chunker, named entity recog-
nizer (NER), lemmatizer (Minnen et al., 2001)
supertagger and sub-parser, EasyCCG is an ex-
tremely simple but still comparably accurate CCG
parser based on A* parsing.
2
These two parsers
use different settings for supertagging and parsing;
therefore, it is interesting to test both parsers for
our application.
In Figure 3, there is a CCG derivation by the
2
The employed C&C parser is trained on rebanked CCG-
bank (Honnibal et al., 2010)—an updated version of CCG-
bank (Hockenmaier and Steedman, 2007) with improved
analyses for predicate-argument structures and nominal mod-
ifiers. For EasyCCG, input sentences are already processed
by the POS-tagger and the NER of the C&C parser.
ba[S
dcl
]
fa[S
dcl
\NP
thr
]
fa[NP ]
ba[N ]
lx[N\N,S
ng
\NP ]
fa[S
ng
\NP ]
fa[NP ]
tomato
N
tomato
NN
a
NP/N
a
DT
cutting
(S
ng
\NP )/NP
cut
VBG
one
N
one
NN
no
NP/N
no
DT
is
(S
dcl
\NP
thr
)/NP
be
VBZ
There
NP
thr
there
EX
Figure 3: The CCG tree by the C&C parser for
there is no one cutting a tomato (SICK-2404),
where thr, dcl, ng category features stand for an
expletive there, declarative and present participle,
respectively.
C&C parser displayed in a tree style: terminal
nodes are annotated with tokens, syntactic cate-
gories, lemmas and POS-tags while non-terminal
nodes are marked with combinatory rules and re-
sulted categories; some basic categories are sub-
categorized by features.
3.2 From CCG Trees to LLFs
Initially, it may seem easy to obtain fine-grained
LLFs from CCG trees of the parsers, but careful
observation on the trees reveals several compli-
cations. The transparency between the categories
and types is violated by the parsers as they employ
lexical (i.e. type-changing) rules—combinatory
rules, non-native ones for CCG, which changes
categories. Lexical rules were initially introduced
in CCGbank (Hockenmaier and Steedman, 2007)
to decrease the total number of categories and
rules. In the tree of Figure 3, a lexical rule changes
a category S
ng
\NP of a phrase cutting a tomato
with N\N . In addition to this problem, the trees
contain mistakes from supertaggers (and from the
other tools, in case of the C&C parser).
The first step in processing CCG trees is to re-
move directionality from the categories. This step
is the same as obtaining unspecified semantic in-
terpretation of a phrase in the CCG framework.
While converting categories A\B and A/B into
a non-directional type (b, a), the arrangement of
nodes must be changed in a corresponding way.
For instance, in case of the top backward appli-
cation rule (ba[S
dcl
] in Figure 3), the order of
2494
sdcl
There
np
thr
there
EX
np
thr
, s
dcl
np
n
one
n
one
NN
n, n
np, s
ng
np
tomato
n
tomato
NN
a
n, np
a
DT
cutting
np, np, s
ng
cut
VBG
no
n, np
no
DT
is
np, np
thr
, s
dcl
be
VBZ
Figure 4: A CCG term obtained from the CCG tree
of Figure 3. Categories are converted into types.
nodes is reversed to guarantee that the function
category (s
dcl
, np
thr
) precedes its argument cate-
gory np
thr
. There are about 20 combinatory rules
used by the parsers and for each of them we de-
sign a way of reordering subtrees. In the end, the
order of nodes coincides with the order according
to which semantic interpretations are combined.
The reordering recipes for each combinatory rule
is quite intuitive and can be found in (Steedman,
2000) and (Bos, 2009), where the latter work also
uses the C&C parser to obtain semantic interpre-
tations. Trees obtained after removing the direc-
tionality from the categories are called CCG terms
since they resemble syntactic trees of typed ?-
terms (see Figure 4).
on
np,pp
(ice
n
)
np
?? on
np,pp
(a
n,np
ice
n
) (1)
run
np,s
(dogs
n
)
np
?? run
np,s
(s
n,np
dog
n
) (2)
(Dow
PER
n,n
Jones
PER
n
)
np
?? Dow Jones
np
(3)
(two
n,n
dogs
n
)
np
?? two
n,np
dogs
n
(4)
her
(pp,n),np
car
pp,n
?? her
n,np
car
n
(5)
who
w
V (Q
n,np
N) ?? Q
n,np
(who
w
?
V N) (6)
nobody ?? no
n,np
person
n
(7)
Lexical rules are the third most commonly used
combinatory rules (7% of all rules) by the parsers
on the SICK data (Marelli et al., 2014b), and there-
fore, they deserve special attention. In order to
compositionally explain several category changes
made by lexical rules (represented with (.)
?
oper-
ator in terms), either types of constant terms are
set to proper types or lexical entries are inserted in
CCG terms. For explaining a lexical rule n; np,
mainly used for bare nouns, an indefinite deter-
miner is inserted for singular nouns (1) and a plu-
s
dcl
There
np
thr
there
EX
np
thr
, s
dcl
np
n
person
n
person
NN
n, n
vp
dcl
vp
ng
np
tomato
n
tomato
NN
a
n, np
a
DT
cutting
np, vp
ng
cut
VBG
is
vp
ng
, vp
dcl
be
VBZ
which
vp
dcl
, n, n
which
WDT
no
n, np
no
DT
is
np, vp
thr,dcl
be
VBZ
Figure 5: A fixed CCG term that is obtained
from the CCG term of Figure 4. A node with a
dashed (solid) frame is inserted (substituted, re-
spectively). A type vp
a,b
abbreviates (np
a
, s
b
).
ral morpheme s is used as a quantifier for plurals
(2). Also identifying proper names with the fea-
ture assigned by the C&C NER tool helps to elim-
inate n; np change (3). Correcting the type of a
quantifier that is treated as a noun modifier is an-
other way of eliminating this lexical rule (4). In
case of (s, np); (n, n) change, which is phrase
is inserted and salvages the category-type trans-
parency of CCG (see Figure 5). As a whole, the
designed procedures explain around 99% of lex-
ical rules used in CCG terms of the SICK sen-
tences. Note that explaining lexical rules guaran-
tees a well-formed CCG term in the end.
Apart from the elimination of lexical rules, we
also manually design several procedures that fix a
CCG term: make it more semantically adequate or
simplify it. For example, the C&C parser assigns
a category N/PP of relational nouns to nouns that
are preceded by possessives. In these cases, a type
n is assigned to a noun and a type of possessive is
changed accordingly (5). To make a term seman-
tically more adequate, a relative clause is attached
to a noun instead of a noun phrase (6), where a
type w ? (vp, np, s) of a wh-word is changed with
w
?
? (vp, n, s). CCG terms are simplified by sub-
stituting terms for no one, nobody, everyone, etc.
with their synonymous terms (see (7) and Figure
5). These substitutions decrease a vocabulary size,
and hence, decrease the number of tableau rules.
The final operation is to convert a fixed CCG
term into an LLF, meaning to convert QNPs into
GQs of (Montague, 1974; Barwise and Cooper,
1981). In this procedure, a type (n, np) of a quan-
2495
tifier is replaced with (n, (np, s), s), and the re-
sulted new NP is applied to the smallest clause it
occurs in; but if there are other QNPs too, then
it also applies to the clauses where other QNPs
are situated. This operation is not deterministic
and can return several terms due to multi-options
in quantifier scope ordering. As an example, two
?-terms, (9) and (10), are obtained from the CCG
term (8) of Figure 5.
3
b(no(w(b(c(a t)))p))th (8)
no
(
w(b(?x.a t(?y. cyx)))p
)(
?z.b z th
)
(9)
a t(?x.no
(
w(b(cx))p
) (
?z.b z th
)
) (10)
Eventually the final ?-terms, analogous to (9)
and (10), obtained from CCG trees will be con-
sidered as LLFs that will be used in the wide-
coverage theorem prover. It has to be stressed that
generated LLFs are theory-independent abstract
semantic representation. Any work obtaining se-
mantic representations from CCG derivations can
combine its lexicon with (already corrected) LLFs
and produce more adequate semantics in this way.
3.3 Extending the Type System
An obvious and simple way to integrate the LLFs,
obtained in Subsection 3.2, in Natural Tableau is
to translate their types into semantic types built up
from e and t.
4
We will not do so, because this
means the information loss since the information
about syntactic types are erased; for example, usu-
ally syntactic types pp, n and (np, s) are trans-
lated as et type. Retaining syntactic types also
contributes to fine-grained matching of nodes dur-
ing rule application in the prover. For instance,
without syntactic types it is more complex to de-
termine the context in which a term game occurs
and find an appropriate tableau rule when consid-
ering the following LLFs, game
n,n
theory and
game
pp,n
(of X), as both (n, n) and (pp, n) are
usually translated into (et)et type, like it is done
by (Bos, 2009).
In order to accommodate the LLFs with syntac-
tic types in LLFs of (Muskens, 2010), we extend
the semantic type system with np, n, s, pp basic
syntactic types corresponding to basic CCG cate-
3
We use initial letters of lemmas to abbreviate a term cor-
responding to a lexical entry. Note that (9) represents a read-
ing with no one having a wide scope while, in (10), a tomato
has a wide scope.
4
The similar translation is carried out in (Bos, 2009) for
Boxer (Bos, 2008), where basic CCG categories are mapped
to semantic types and the mapping is isomorphically ex-
tended to complex categories.
gories. Thus complex types are now built up from
the set {e, t, np, n, s, pp} of types. The extension
automatically licenses LLFs with syntactic types
as terms of the extended language.
We go further and establish interaction between
semantic and syntactic types in terms of a subtyp-
ing v relation. The relation is defined as a partial
order over types and satisfies the following condi-
tions for any ?
1
, ?
2
, ?
1
, and ?
2
types:
(a) e v np, s v t, n v et, pp v et;
(b) (?
1
, ?
2
)v(?
1
, ?
2
) iff ?
1
v?
1
and ?
2
v?
2
;
Moreover, we add an additional typing rule to the
calculus: a term is of type ? if it is already of type
? and ? v ?. According to this typing rule, now a
term can be of multiple types. For example, both
walk
np,s
and man
n
terms are also of type et, and
all terms of type s are of type t too. From this
point on we will use a boldface style for lexical
constants of syntactic types.
Initially it may seem that the lexicon of con-
stant terms is doubled in size, but this is not
the case as several syntactic constants can mir-
ror their semantic counterparts. This is achieved
by multiple typing which enables to put seman-
tic and syntactic terms in the same term. For in-
stance, love
np,np,s
c
e
john
np
and at
np,pp
c
e
d
e
are
well-formed LLFs of type t that combine terms
of syntactic and semantic types, and there is no
need of introducing semantic terms (e.g., at
eet
or
love
eet
) in order to have a well-formed term. In
the end, the extension of the language is conserva-
tive in the sense that LLFs and the tableau proof
of Section 2 are preserved. The latter is the case
since the tableau rules are naturally extensible to
match new LLFs.
4 Implementation of the Prover
In order to further develop and evaluate Natural
Tableau, we implement the prover, LangPro, based
on the extended theory. Its general architecture
is based on the first-order logic (FOL) prover of
Fitting (1990). The prover also contains a mod-
ule for ?-calculus that roughly follows (Blackburn
and Bos, 2005).
Setup of the inventory of rules is a crucial for ef-
ficiency of the prover. There is a priority order for
the categories of rules according to their computa-
tional efficiency. The prover most prefers to em-
ploy non-branching rules that introduce no fresh
terms and antecedents of which can be ignored af-
2496
ter the application (e.g., NOT). Less preferred and
inefficient rules are the ones that branch, produce
new terms or antecedents of which are kept after
the application (e.g., ?
F
and ?
F
). In order to en-
courage finding short proofs, admissible rules rep-
resenting shortcuts of several rule applications are
also introduced (e.g., FUN? and ARG in Figure 9).
The inventory consists of about 50 rules, where
most of them are manually designed based on RTE
problems (see Section 5.1) and the rest represents
the essential part of the rules found in (Muskens,
2010).
The LLF generator (LLFgen) is a procedure that
generates LLFs from a CCG derivation in the way
described in Subsection 3.2. We also implement
an LLF-aligner that serves as an optional prepro-
cessor between LLFgen and the prover itself; it
aligns identical chunks of LLFs and treats them as
a constant (i.e. having no internal structure). This
treatment often leads to smaller tableau proofs.
The example of aligned LLFs is given in Figure 8.
LangPro uses only the antonymy relation and
a transitive closure of the hyponymy/hypernymy
relations from WordNet 3.0 (Fellbaum, 1998) as
its knowledge base (KB). The entailment ? (con-
tradiction ?) relation between lexical constants of
the same type A ? B (A?B) holds if there ex-
ists a WordNet sense of A that is a transitive hy-
ponym (an antonym) of some WordNet sense of
B. Note that there is no word sense disambigua-
tion (WSD) used by the prover; therefore, adopt-
ing these interpretations of entailment and contra-
diction amounts to considering all senses of the
words. For example, a man is crying entails a man
is screaming as there are senses of cry and scream
that are in the entailment relation.
All in all, chaining a CCG parser, LLFgen, the
LLF-aligner, the prover and KB results in an au-
tomatized tableau prover LangPro which operates
directly over natural language text.
5 Learning and Evaluation
5.1 Learning
For learning and evaluation purposes, we use the
SICK data (Marelli et al., 2014b). The data con-
sists of problems that are rich in the lexical, syn-
tactic and semantic phenomena that compositional
distributional semantic models (Mitchell and La-
pata, 2010) are expected to account for.
5
The
5
SICK is partitioned in three parts (trail, train and test)
and used as a benchmark for RTE14 (Marelli et al., 2014a).
SICK data contains around 10K text-hypothesis
pairs that are classified in three categories: entail-
ment, contradiction, and neutral.
During learning we used only the trial portion
of the data, SICK-trial, including 500 problems.
The learning process consists of improving the
components of the prover while solving the RTE
problems: designing fixing procedures of LLFgen,
adding new sound rules to the inventory, and intro-
ducing valid relations in KB that were not found
in WordNet (e.g., woman?lady, note?paper and
food?meal). During learning, each RTE problem
is processed as follows:
input: (T,H, answer);
1: t = the first LLF of llf(T );
2: h = the first LLF of llf(H);
3: case answer, tab{t :T, h :F}, tab{t :T, h :T}
ENTAILMENT, CLOSED, OPEN: HALT;
CONTRADICTION, OPEN, CLOSED: HALT;
NEUTRAL, OPEN, OPEN: HALT;
4: otherwise
5: if t or h is incorrect then try to amend llf; go to 1
6: else if a rule is missing then add it; go to 3
7: else if a relation is missing then add it; go to 3
8: else HALT;
A function llf denotes the combination of
LLFgen and a CCG parser; for learning
we use only the C&C parser. A function
tab : S ? {CLOSED, OPEN} returns CLOSED if
one of the tableaux initiated with aligned or non-
aligned set S of nodes closes; otherwise it re-
turns OPEN. For instance, while checking a prob-
lem (T,H) on entailment (contradiction), tableau
starts with a counterexample: T being true and H
false (true, respectively). Note that 5-7 procedures
are carried out manually while the phase is signifi-
cantly facilitated by graphical proofs produced by
LangPro.
6
As a result, there were collected around 30 new
rules where about a third of them are admissible
ones; the new rules cover phenomena like noun
and adverbial modifiers, prepositional phrases,
passive constructions, expletive sentences, verb-
particle constructions, auxiliaries, light verb con-
structions, etc. Most of the new rules are discussed
in more details in (Abzianidze, 2015).
The data and the system results of RTE14 are available at
http://alt.qcri.org/semeval2014/task1/
6
Automating a tableau rule extraction is quite hard for the
following reasons: it is unclear how to determine automat-
ically whether a CCG derivation is wrong, a tableau rule is
missing, or lexical knowledge is lacking; and the general for-
mat of a rule makes search procedure extremely inefficient.
2497
ID Gold/LP Problem (premise ? conclusion)
3670 E/N It is raining on a walking man ? A man is walking in the rain
219 E/N There is no girl in white dancing ? A girl in white is dancing
5248 N/E Someone is playing with a toad ? Someone is playing with a frog
8490 N/C A man with a shirt is holding a football ? A man with no shirt is holding a football
7402 N/C There is no man and child kayaking through gentle waters ? A man and a young boy are riding in a yellow kayak
1431 C/C A man is playing a guitar ? A man is not playing a guitar
8913 N/C A couple is not looking at a map ? A couple is looking at a map
Table 1: Problems from SICK-trial and SICK-train with gold and LangPro judgments.
#
10 20 50 100 200 400 800 1600
.45
.5
.55
.75
.8
.98
1
mins. 2 5 9 14 23 38 60 115
#Rule applications & runtime for 2.4GHz CPU
Acc
Rec
Prec
Figure 6: Performance of LangPro on SICK-train
(4500) using CCG derivations of the C&C parser.
LangPro was unable to prove several problems
requiring complex background knowledge (e.g.,
SICK-3670 in Table 1) or having wrong CCG
derivations from the C&C parser (e.g., in SICK-
219, white dancing is a noun constituent).
5.2 Development
The part of the SICK data, SICK-train, issued for
training at RTE14 was used for development. Af-
ter running LangPro on SICK-train, we only an-
alyzed false positives, i.e. neutral problems that
were identified either as entailment or contradic-
tion by the prover. The analysis reveals that the
parsers and WordNet are responsible for almost
all these errors. For example, in Table 1, SICK-
5248 is classified as entailment since toad and
frog might have synonymous senses; this problem
shows the advantage of not using WSD, where a
proof search also searches for word senses that
might give rise to a logical relation. SICK-7402
was falsely identified as contradiction because of
the wrong analyses of the premise by both CCG
parsers: no man and child... are in coordination,
which implies there is no man, and hence, contra-
dicts the conclusion. SICK-8490 is proved as con-
tradiction since the prover considers LLFs where
shirt takes a wide scope. With the help of Lang-
Pro, we also identified inconsistency in the annota-
tions of problems, e.g., SICK-1431, 8913 are sim-
ilar problems but classified differently; it is also
X
X
X
X
X
X
X
X
X
X
X
LangPro
SICK test (4927 problems)
Prec% Rec% Acc%
Baseline (majority) - - 56.36
+C&C+50 98.03 53.75 79.52
+EasyCCG+50 98.03 51.41 78.53
LangPro Hybrid-50 97.99 57.03 80.90
+C&C+800 97.99 54.73 79.93
+EasyCCG+800 98.00 52.67 79.05
LangPro Hybrid-800 97.95 58.11 81.35
Table 2: Evaluation of the versions of LangPro
surprising that SICK-5248 is classified as neutral.
During this phase, also the effective (800) and
efficient (50) upper bounds for the rule application
number were determined (see Figure 6). More-
over, 97.4% of proofs found in 1600 rule appli-
cations are actually attainable in at most 50 rule
applications; this shows that the rule application
strategy of LangPro is quite efficient.
5.3 Evaluation
We evaluate LangPro on the unseen portion of the
SICK data, SICK-test, which was used as a bench-
mark at RTE14; the data was also held out from
the process of designing LLFgen. The prover clas-
sifies each SICK problem as follows:
input: (T,H);
try t = the first LLF of llf(T );
h = the first LLF of llf(H)
if no error then
case tab{t :T, h :F}, tab{t :T, h :T}
CLOSED, OPEN: classify as ENTAILMENT;
OPEN, CLOSED: classify as CONTRADICTION;
OPEN, OPEN: classify as NEUTRAL;
CLOSED, CLOSED: classify as ENTAILMENT; report it;
else classify as NEUTRAL; report it;
The results, in Table 2, show evaluation of
LangPro on SICK-test using both parsers sepa-
rately with the efficient and effective rule applica-
tion upper bounds. Slightly better results with the
C&C parser is explained by employing the parser
in the learning phase. The difference of .5% in
2498
XX
X
X
X
X
X
X
X
X
X
System
Measure+
Prec% Rec% Acc% (+LP)
Illinois-LH 81.56 81.87 84.57 (+0.55)
ECNU 84.37 74.37 83.64 (+1.69)
UNAL-NLP 81.99 76.80 83.05 (+1.44)
SemantiKLUE 85.40 69.63 82.32 (+2.78)
The Meaning Factory 93.63 60.64 81.59 (+2.72)
LangPro Hybrid-800 97.95 58.11 81.35
UTexas 97.87 38.71 73.23 (+8.97)
Prob-FOL - - 76.52
Nutcracker - - 78.40
Baseline (majority) - - 56.69
Table 3: Comparing LangPro to the top or related
RTE systems and combining their answers
7
accuracy between the C&C-based and EasyCCG-
based provers show that LLFgen was not fitted to
the C&C parser’s output during the learning phase.
In order to eliminate at some extent errors com-
ing from the parsers, hybrid provers are designed
that simply combine answers of two systems—if
one of the systems proves a relation then it is an
answer. Both hybrid versions of LangPro show
more than 80% of accuracy while only 5 systems
were able to do so at RTE14, where 77.1% was a
median accuracy. The prover turns out to be ex-
tremely reliable with its state-of-the-art precision
being almost 98%. A high precision is conditioned
by the formal deductive proof nature of LangPro
and by the sound rules it employs.
In Table 3, we compare the best version of hy-
brid LangPro to the top 5 systems of RTE14 on
SICK-test and show the improvement it gives to
each system when blindly adopting its positive an-
swers (i.e. entailment and contradiction).
The decision procedure of the prover is com-
pletely rule-based and easy to comprehend since
it follows the intuitive deductive rules. Tableaux
proofs by LangPro for SICK-247 (in Figure 7) and
SICK-2895 (in Figure 8) show step by step how T
contradicts and entails, respectively, H .
8
Several
new rules employed in these tableaux are given in
Figure 9. Note that the both problems, SICK-247,
2895, were wrongly classified by all the top 7 sys-
tems of the RTE14. Taking into account that solv-
ing SICK-247 requires a sort of De Morgan’s law
7
The top 5 systems of RTE14 are Illinois-LH (Lai and
Hockenmaier, 2014), ECNU (Zhao et al., 2014), UNAL-NLP
(Jimenez et al., 2014), SemantiKLUE (Proisl et al., 2014) and
The Meaning Factory (Bjerva et al., 2014).
8
In the tableaux, due to lack of space, several constants
are denoted with initial characters of their lemmas and some
intermediate nodes are omitted. Some of the nodes are anno-
tated with a sequence of source rule applications.
for negation and disjunction, this demonstrates
where LangPro, a purely logic-based system, out-
performs non-logic-based systems.
9
The another
problem, SICK-2895, is an evidence how unreli-
able the state-of-the-art and non-logic-based RTE
systems might be since solving the problem only
requires a lexical knowledge barbell ? weight ,
which is available in WordNet.
6 Related Work
Using formal logic tools for a wide-coverage RTE
task goes back to the Nutcracker system (Bos and
Markert, 2005), where a wide-coverage semantic
processing tool Boxer (Bos, 2008), in combination
with the C&C tools, first produces discourse rep-
resentation structures of (Kamp and Reyle, 1993)
and then FOL semantic representations (Curran et
al., 2007). Reasoning over FOL formulas is car-
ried by off-the-shelf theorem provers and model
builders for FOL.
10
Our approach differs from
the latter in several main aspects: (i) the under-
ling logic of LLFs (i.e. higher-order logic) is
more expressive than FOL (e.g., it can properly
model GQs and subsective adjectives), (ii) LLFs
are cheap to get as they are easily obtained from
CCG derivations, and (iii) we develop a com-
pletely new proof procedure and a prover for a ver-
sion of Natural Logic.
The other related works are (MacCartney and
Manning, 2008) and (Angeli and Manning, 2014).
Both works contribute to Natural Logic and are
based on the same methodology.
11
The approach
has two main shortcomings compared to Natural
Tableau; namely, it is unable to process multi-
premised problems, and its underling logic is
weaker (e.g., according to (MacCartney, 2009), it
cannot capture the entailment in Figure 2).
9
Even a shallow heuristic—if H has a named entity that
does not appear in T , then there is no entailment—is not suf-
ficient for showing that SICK-247 is contradiction. We thank
our reviewer for mentioning this heuristic w.r.t. SICK-247.
10
Nutcracker obtains 3% lower accuracy on SICK than our
prover (Pavlick et al., 2015). The Meaning Factory (Bjerva
et al., 2014) that is a brother system of Nutcracker, instead
of solely relying on decisions of theorem provers and model
builders, uses machine learning methods over the features ex-
tracted from these tools; this method results in a more ro-
bust system. RTE systems UTexas (Beltagy et al., 2014) and
Prob-FOL (Beltagy and Erk, 2015) also use Boxer FOL rep-
resentations but employ probabilistic FOL. For comparison
purposes, the results of these systems on the SICK data are
given in Table 3.
11
They relate two sentences by a sequence of string edits;
the final logical relation between the sentences is computed
by composing logical relations associated with these edits.
2499
1 : the w (not (be (?x.or (a hd) (s gl) (?y.wear y x)))) : [ ] : T
2 : a w (be (?x.a (Eg hd) (?y.wear y x))) : [ ] : T
3
?
T
[2]
: w : [c] : T
4
?
T
[2]
: be (?x.a (Eg hd) (?y.wear y x)) : [c] : T
5
AUX[4]
: ?x.a (Eg hd) (?y.wear y x) : [c] : T
6
?PULL[5]
: a (Eg hd) (?y.wear y c) : [ ] : T
7
THE C[1,3]
: not (be (?x.or (a hd) (s gl) (?y.wear y x))) : [c] : T
9
AUX, NOT[7]
: ?x.or (a hd) (s gl) (?y.wear y x) : [c] : F
10
?PULL[9]
: or (a hd) (s gl) (?y.wear y c) : [ ] : F
11
ARG D[10]
: or (a hd (?y.wear y c)) (s gl (?y.wear y c)) : [ ] : F
12
OR
F
[11]
: a hd (?y.wear y c) : [ ] : F
16
?
T
[6]
: Eg hd : [d] : T
18
?PULL, ?
T
[6]
: wear d c : [ ] :T
19
SUB ADJ[16]
: hd : [d] : T
21
?PULL, ?C
T
[12,19]
: wear d c : [ ] : F
22
?
×
[18,21]
:×
Figure 7: A closed tableau for SICK-247:
The woman is not wearing glasses or a headdress
? A woman is wearing an Egyptian headdress
7 Conclusion and Future Work
We made Natural Tableau of Muskens (2010) suit-
able for the wide-coverage RTE task by extending
it both in terms of rules and language. Based on
the extended Natural Tableau, the prover LangPro
was implemented, which has a modular architec-
ture consisting of the inventory of rules, KB and
the LLF generator. As a whole, the prover repre-
sents a deductive model of natural reasoning with
the transparent and naturally interpretable decision
procedure. While learning only from the SICK-
trial data, LangPro showed the comparable accu-
racy and the state-of-the-art precision on the un-
seen SICK data.
For future work, we plan to explore the FraCaS
(Consortium et al., 1996) and newswire RTE (Da-
gan et al., 2005) data sets to further improve the
LLF generator and enrich the inventory of tableau
rules. These tasks are also interesting for two rea-
sons: to find out how much effort is required for
1 : not (be (?x.s weight (?y.lift y x))) M : [ ] : T
2 : be (?x.s barbell (?y.lift y x)) M : [ ] : T
4
AUX, PUSH[2]
: (?x.s barbell (?y.lift y x)) : [M] : T
5
?PULL[4]
: s barbell (?y.lift y M) : [ ] : T
7
NOT, PUSH[1]
: be (?x.s weight (?y.lift y x)) : [M] : F
9
?PULL, AUX[7]
: s weight (?y.lift y M): [ ] : F
10
FUN?[5,9]
: s barbell : [?y.lift yM] : T
11
FUN?[5,9]
: s weight : [?y.lift yM] : F
12
?
×
[10,11]
:×
Figure 8: A closed tableau for SICK-2895: The
man isn’t lifting weights ? The man is lifting
barbells, where M abbreviates a shared term
the man aligned by the LLF-aligner.
G A : [
#
C ] : T
H A : [
#
C ] : F
G : [A,
#
C ] : T
H : [A,
#
C ] : F
ARG
the N V : [ ] : X
N : [c] : T
V : [c] : X
THE C
X V : [
#
C ] : X
V : [
#
C ] : X
AUX
s.t. X ? {be,do}
F A : [
#
C ] : T
F B : [
#
C ] : F
A : [
#
D] : T
B : [
#
D] : F
FUN?
s.t.
#
D is fresh and
F is upward monotone
A N : [c] : T
N : [c] : T
SUB ADJ
s.t. A is subsective
?x.A : [d
#
C ] : X
A[x := d] : [
#
C ] : X
?PULL
Figure 9: Several rules learned from SICK-trial
adapting the LLF generator to different data, and
which rules are to be added to the inventory for
tackling the new RTE problems. Incorporating
more WordNet relations (e.g., similarity, deriva-
tion and verb-group) and the paraphrase database
(Ganitkevitch et al., 2013) in KB is also a part of
our future plans.
Acknowledgments
I thank Reinhard Muskens for helpful discussions
on this work, Jan Sprenger for his feedback on an
early version of this paper, the authors of (Honni-
bal et al., 2010) for sharing a recent parser model,
and anonymous reviewers for useful comments.
This work is a part of the project “Towards Logics
that Model Natural Reasoning” and supported by
the NWO grant (project number 360-80-050).
2500
References
Lasha Abzianidze. 2015. Towards a wide-coverage
tableau method for natural logic. In Tsuyoshi
Murata, Koji Mineshima, and Daisuke Bekki, edi-
tors, New Frontiers in Artificial Intelligence, volume
9067 of Lecture Notes in Artificial Intelligence, page
Forthcoming. Springer-Verlag Berlin Heidelberg.
Gabor Angeli and Christopher D. Manning. 2014.
Naturalli: Natural logic inference for common sense
reasoning. In Proceedings of the 2014 Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 534–545, Doha, Qatar, Oc-
tober. Association for Computational Linguistics.
Jon Barwise and Robin Cooper. 1981. Generalized
quantifiers and natural language. Linguistics and
Philosophy, 4(2):159–219.
Islam Beltagy and Katrin Erk. 2015. On the proper
treatment of quantifiers in probabilistic logic seman-
tics. In Proceedings of the 11th International Con-
ference on Computational Semantics (IWCS-2015),
London, UK, April.
Islam Beltagy, Stephen Roller, Gemma Boleda, Katrin
Erk, and Raymond Mooney. 2014. Utexas: Natu-
ral language semantics using distributional seman-
tics and probabilistic logic. In Proceedings of the
8th International Workshop on Semantic Evaluation
(SemEval 2014), pages 796–801, Dublin, Ireland,
August. Association for Computational Linguistics
and Dublin City University.
Evert W. Beth. 1955. Semantic Entailment and Formal
Derivability. Koninklijke Nederlandse Akademie
van Wentenschappen, Proceedings of the Section of
Sciences, 18:309–342.
Johannes Bjerva, Johan Bos, Rob Van der Goot, and
Malvina Nissim. 2014. The meaning factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval 2014), pages 642–646, Dublin, Ire-
land.
Patrick Blackburn and Johan Bos. 2005. Represen-
tation and Inference for Natural Language: A First
Course in Computational Semantics. CSLI Press.
Johan Bos and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. In Proceed-
ings of the 2005 Conference on Empirical Methods
in Natural Language Processing (EMNLP 2005),
pages 628–635.
Johan Bos. 2008. Wide-coverage semantic analy-
sis with boxer. In Johan Bos and Rodolfo Del-
monte, editors, Semantics in Text Processing. STEP
2008 Conference Proceedings, Research in Compu-
tational Semantics, pages 277–286. College Publi-
cations.
Johan Bos. 2009. Towards a large-scale formal se-
mantic lexicon for text processing. In C. Chiarcos,
R. Eckart de Castilho, and Manfred Stede, editors,
From Form to Meaning: Processing Texts Automati-
cally. Proceedings of the Biennal GSCL Conference
2009, pages 3–14.
Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with ccg and
log-linear models. Computational Linguistics, 33.
The Fracas Consortium, Robin Cooper, Dick Crouch,
Jan Van Eijck, Chris Fox, Josef Van Genabith,
Jan Jaspars, Hans Kamp, David Milward, Man-
fred Pinkal, Massimo Poesio, Steve Pulman, Ted
Briscoe, Holger Maier, and Karsten Konrad. 1996.
Using the framework.
James Curran, Stephen Clark, and Johan Bos. 2007.
Linguistically motivated large-scale nlp with c&c
and boxer. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics Companion Volume Proceedings of the Demo
and Poster Sessions, pages 33–36, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognising textual entailment
challenge. In Proceedings of the PASCAL Chal-
lenges Workshop on Recognising Textual Entail-
ment.
Marcello D’Agostino, Dov M. Gabbay, Reiner Hhnle,
and Joachim Posegga, editors. 1999. Handbook of
Tableau Methods. Springer.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Melvin Fitting. 1990. First-order Logic and Au-
tomated Theorem Proving. Springer-Verlag New
York, Inc., New York, NY, USA.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of NAACL-HLT, pages
758–764, Atlanta, Georgia, June. Association for
Computational Linguistics.
Julia Hockenmaier and Mark Steedman. 2007. Ccg-
bank: A corpus of ccg derivations and dependency
structures extracted from the penn treebank. Com-
put. Linguist., 33(3):355–396, September.
Matthew Honnibal, James R. Curran, and Johan Bos.
2010. Rebanking ccgbank for improved np inter-
pretation. In Proceedings of the 48th Meeting of
the Association for Computational Linguistics (ACL
2010), pages 207–215, Uppsala, Sweden.
Sergio Jimenez, George Due˜nas, Julia Baquero, and
Alexander Gelbukh. 2014. Unal-nlp: Combining
soft cardinality features for semantic textual similar-
ity, relatedness and entailment. In Proceedings of
2501
the 8th International Workshop on Semantic Evalu-
ation (SemEval 2014), pages 732–742, Dublin, Ire-
land, August. Association for Computational Lin-
guistics and Dublin City University.
Hans Kamp and Uwe Reyle. 1993. From discourse to
logic; an introduction to modeltheoretic semantics
of natural language, formal logic and DRT. Dor-
drecht: Kluwer.
Alice Lai and Julia Hockenmaier. 2014. Illinois-lh: A
denotational and distributional approach to seman-
tics. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014), pages
329–334, Dublin, Ireland, August. Association for
Computational Linguistics and Dublin City Univer-
sity.
George Lakoff. 1972. Linguistics and natural logic. In
Donald Davidson and Gilbert Harman, editors, Se-
mantics of Natural Language, volume 40 of Syn-
these Library, pages 545–665. Springer Nether-
lands.
Mike Lewis and Mark Steedman. 2014. A* ccg pars-
ing with a supertag-factored model. In Proceed-
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
990–1000, Doha, Qatar, October. Association for
Computational Linguistics.
Bill MacCartney and Christopher D. Manning. 2008.
Modeling semantic containment and exclusion in
natural language inference. In Donia Scott and Hans
Uszkoreit, editors, COLING, pages 521–528.
Bill MacCartney. 2009. Natural language inference.
Phd thesis, Stanford University.
Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014a. Semeval-2014 task 1: Evaluation of
compositional distributional semantic models on full
sentences through semantic relatedness and textual
entailment. In Proceedings of SemEval 2014 (Inter-
national Workshop on Semantic Evaluation), pages
1–8, East Stroudsburg PA. ACL.
Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014b. A sick cure for the evaluation of
compositional distributional semantic models. In
Nicoletta Calzolari, Khalid Choukri, Thierry De-
clerck, Hrafn Loftsson, Bente Maegaard, Joseph
Mariani, Asuncion Moreno, Jan Odijk, and Stelios
Piperidis, editors, Proceedings of the Ninth Inter-
national Conference on Language Resources and
Evaluation (LREC’14), Reykjavik, Iceland. Euro-
pean Language Resources Association (ELRA).
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of english. Nat-
ural Language Engineering, 7(3):207–223, Septem-
ber.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1439.
Richard Montague. 1974. English as a Formal Lan-
guage. In Richmond H. Thomason, editor, Formal
philosophy: Selected Papers of Richard Montague,
chapter 6, pages 188–221. Yale University Press.
Reinhard Muskens. 2010. An analytic tableau sys-
tem for natural logic. In Maria Aloni, Harald Bas-
tiaanse, Tikitu de Jager, and Katrin Schulz, editors,
Logic, Language and Meaning, volume 6042 of Lec-
ture Notes in Computer Science, pages 104–113.
Springer Berlin Heidelberg.
Ellie Pavlick, Johan Bos, Malvina Nissim, Charley
Beller, Benjamin Van Durme, and Chris Callison-
Burch. 2015. Adding semantics to data-driven para-
phrasing. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2015), pages 1512–1522.
Thomas Proisl, Stefan Evert, Paul Greiner, and Besim
Kabashi. 2014. Semantiklue: Robust semantic
similarity at multiple levels using maximum weight
matching. In Proceedings of the 8th International
Workshop on Semantic Evaluation (SemEval 2014),
pages 532–540, Dublin, Ireland, August. Associa-
tion for Computational Linguistics and Dublin City
University.
Mark Steedman and Jason Baldridge. 2011. Combina-
tory categorial grammar. In D. Borsley, Robert and
Kersti Brjars, editors, Non-Transformational Syn-
tax: Formal and Explicit Models of Grammar, pages
181–224. Wiley-Blackwell.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, MA, USA.
Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. Ecnu:
One stone two birds: Ensemble of heterogenous
measures for semantic relatedness and textual entail-
ment. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014), pages
271–277, Dublin, Ireland, August. Association for
Computational Linguistics and Dublin City Univer-
sity.
2502
