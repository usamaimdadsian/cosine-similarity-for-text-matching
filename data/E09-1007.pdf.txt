Proceedings of the 12th Conference of the European Chapter of the ACL, pages 51–59,
Athens, Greece, 30 March – 3 April 2009. c©2009 Association for Computational Linguistics
Clique-Based Clustering for improving Named Entity Recognition systems
Julien Ah-Pine
Xerox Research Centre Europe
6, chemin de Maupertuis
38240 Meylan, France
julien.ah-pine@xrce.xerox.com
Guillaume Jacquet
Xerox Research Centre Europe
6, chemin de Maupertuis
38240 Meylan, France
guillaume.jacquet@xrce.xerox.com
Abstract
We propose a system which builds, in a
semi-supervised manner, a resource that
aims at helping a NER system to anno-
tate corpus-specific named entities. This
system is based on a distributional ap-
proach which uses syntactic dependen-
cies for measuring similarities between
named entities. The specificity of the
presented method however, is to combine
a clique-based approach and a clustering
technique that amounts to a soft clustering
method. Our experiments show that the
resource constructed by using this clique-
based clustering system allows to improve
different NER systems.
1 Introduction
In Information Extraction domain, named entities
(NEs) are one of the most important textual units
as they express an important part of the meaning
of a document. Named entity recognition (NER)
is not a new domain (see MUC1 and ACE2 confer-
ences) but some new needs appeared concerning
NEs processing. For instance the NE Oxford illus-
trates the different ambiguity types that are inter-
esting to address:
• intra-annotation ambiguity: Wikipedia lists
more than 25 cities named Oxford in the world
• systematic inter-annotation ambiguity: the
name of cities could be used to refer to the uni-
versity of this city or the football club of this
city. This is the case for Oxford or Newcastle
• non-systematic inter-annotation ambiguity:
Oxford is also a company unlike Newcastle.
The main goal of our system is to act in a com-
plementary way with an existing NER system, in
order to enhance its results. We address two kinds
1http://www-nlpir.nist.gov/related projects/muc/
2http://www.nist.gov/speech/tests/ace
of issues: first, we want to detect and correctly
annotate corpus-specific NEs3 that the NER sys-
tem could have missed; second, we want to correct
some wrong annotations provided by the existing
NER system due to ambiguity. In section 3, we
give some examples of such corrections.
The paper is organized as follows. We present,
in section 2, the global architecture of our system
and from §2.1 to §2.6, we give details about each
of its steps. In section 3, we present the evalu-
ation of our approach when it is combined with
other classic NER systems. We show that the re-
sulting hybrid systems perform better with respect
to F-measure. In the best case, the latter increased
by 4.84 points. Furthermore, we give examples of
successful correction of NEs annotation thanks to
our approach. Then, in section 4, we discuss about
related works. Finally we sum up the main points
of this paper in section 5.
2 Description of the system
Given a corpus, the main objectives of our system
are: to detect potential NEs; to compute the possi-
ble annotations for each NE and then; to annotate
each occurrence of these NEs with the right anno-
tation by analyzing its local context.
We assume that this corpus dependent approach
allows an easier NE annotation. Indeed, even if
a NE such as Oxford can have many annotation
types, it will certainly have less annotation possi-
bilities in a specific corpus.
Figure 1 presents the global architecture of our
system. The most important part concerns steps
3 (§2.3) and 4 (§2.4). The aim of these sub-
processes is to group NEs which have the same
annotation with respect to a given context. On
the one hand, clique-based methods (see §2.3 for
3In our definition a corpus-specific NE is the one which
does not appear in a classic NEs lexicon. Recent news articles
for instance, are often constituted of NEs that are not in a
classic NEs lexicon.
51
Figure 1: General description of our system
details on cliques) are interesting as they allow
the same NE to be in different cliques. In other
words, cliques allow to represent the different pos-
sible annotations of a NE. The clique-based ap-
proach drawback however, is the over production
of cliques which corresponds to an artificial over
production of possible annotations for a NE. On
the other hand, clustering methods aim at struc-
turing a data set and such techniques can be seen
as data compression processes. However, a sim-
ple NEs hard clustering doesn’t allow a NE to be
in several clusters and thus to express its differ-
ent annotations. Then, our proposal is to combine
both methods in a clique-based clustering frame-
work. This combination leads to a soft-clustering
approach that we denote CBC system. The fol-
lowing paragraphs, from 2.1 to 2.6, describe the
respective steps mentioned in Figure 1.
2.1 Detection of potential Named Entities
Different methods exist for detecting potential
NEs. In our system, we used some lexico-
syntactic constraints to extract expressions from a
corpus because it allows to detect some corpus-
specific NEs. In our approach, a potential NE is a
noun starting with an upper-case letter or a noun
phrase which is (see (Ehrmann and Jacquet, 2007)
for similar use):
• a governor argument of an attribute syntactic
relation with a noun as governee argument (e.g.
president
attribute
????? George Bush)
• a governee argument of a modifier syntactic re-
lation with a noun as a governor argument (e.g.
company
modifier
????? Coca-Cola).
The list of potential NEs extracted from the cor-
pus will be denoted NE and the number of NEs
|NE|.
2.2 Distributional space of NEs
The distributional approach aims at evaluating a
distance between words based on their syntac-
tic distribution. This method assumes that words
which appear in the same contexts are semanti-
cally similar (Harris, 1951).
To construct the distributional space associated
to a corpus, we use a robust parser (in our ex-
periments, we used XIP parser (A?¨t et al., 2002))
to extract chunks (i.e. nouns, noun phrases, . . . )
and syntactic dependencies between these chunks.
Given this parser’s output, we identify triple in-
stances. Each triple has the form w1.R.w2 where
w1 and w2 are chunks and R is a syntactic relation
(Lin, 1998), (Kilgarriff et al., 2004).
One triple gives two contexts (1.w1.R and
2.w2.R) and two chunks (w1 and w2). Then, we
only select chunks w which belong to NE. Each
point in the distributional space is a NE and each
dimension is a syntactic context. CT denotes the
set of all syntactic contexts and |CT| represents its
cardinal.
We illustrate this construction on the sentence
“provide Albania with food aid”. We obtain the
three following triples (note that aid and food aid
are considered as two different chunks):
provide VERB•I-OBJ•Albania NOUN
provide VERB•PREP WITH•aid NOUN
provide VERB•PREP WITH•food aid NP
From these triples, we have the following
chunks and contexts4:
Chunks: Contexts:
provide VERB 1.provide VERB.I-OBJ
Albania NOUN 1.provide VERB.PREP WITH
aid NOUN 2.Albania NOUN.I-OBJ
food aid NP 2.aid NOUN.PREP WITH
2.food aid NP.PREP WITH
According to the NEs detection method de-
scribed previously, we only keep the chunks and
contexts which are in bold in the above table.
4In the context 1.VERB:provide.I-OBJ, the figure 1
means that the verb provide is the governor argument of the
Indirect OBJect relation.
52
We also use an heuristic in order to reduce the
over production of chunks and contexts: in our ex-
periments for example, each NE and each context
should appear more than 10 times in the corpus for
being considered.
D is the resulting (|NE| × |CT|) NE-Context
matrix where ei : i = 1, . . . , |NE| is a NE and
cj : j = 1, . . . , |CT| is a syntactic context. Then
we have:
D(ei, cj) = Nb. of occ. of cj associated to ei (1)
2.3 Cliques of NEs computation
A clique in a graph is a set of pairwise adja-
cent nodes which is equivalent to a complete sub-
graph. A maximal clique is a clique that is not a
subset of any other clique. Maximal cliques com-
putation was already employed for semantic space
representation (Ploux and Victorri, 1998). In this
work, cliques of lexical units are used to represent
a precise meaning. Similarly, we compute cliques
of NEs in order to represent a precise annotation.
For example, Oxford is an ambiguous NE
but a clique such as <Cambridge, Oxford, Ed-
inburgh University, Edinburgh, Oxford Univer-
sity> allows to focus on the specific annota-
tion <organization> (see (Ehrmann and Jacquet,
2007) for similar use).
Given the distributional space described in the
previous paragraph, we use a probabilistic frame-
work for computing similarities between NEs.
The approach that we propose is inspired from
the language modeling framework introduced in
the information retrieval field (see for example
(Lavrenko and Croft, 2003)). Then, we construct
cliques of NEs based on these similarities.
2.3.1 Similarity measures between NEs
We first compute the maximum likelihood esti-
mation for a NE ei to be associated with a con-
text cj : Pml(cj |ei) =
D(ei,cj)
|ei|
, where |ei| =
?|CT|
j=1 D(ei, cj) is the total occurrences of the NE
ei in the corpus.
This leads to sparse data which is not suitable
for measuring similarities. In order to counter
this problem, we use the Jelinek-Mercer smooth-
ing method: D?(ei, cj) = ?Pml(cj |ei) + (1 ?
?)Pml(cj |CORP) where CORP is the corpus and
Pml(cj |CORP) =
P
i D(ei,cj)P
i,j D(ei,cj)
. In our experi-
ments we took ? = 0.5.
Given D?, we then use the cross-entropy as a
similarity measure between NEs. Let us denote by
s this similarity matrix, we have:
s(ei, e
?
i) = ?
?
cj?CT
D?(ei, cj) log(D
?(ei? , cj)) (2)
2.3.2 From similarity matrix to adjacency
matrix
Next, we convert s into an adjacency matrix de-
noted sˆ. In a first step, we binarize s as fol-
lows. Let us denote {ei1, . . . , e
i
|NE|}, the list of NEs
ranked according to the descending order of their
similarity with ei. Then, L(ei) is the list of NEs
which are considered as the nearest neighbors of
ei according to the following definition:
L(ei) = (3)
{ei1, ..., e
i
p :
?p
i?=1 s(ei, e
i
i?)
?|NE|
i?=1 s(ei, ei?)
? a; p ? b}
where a ? [0, 1] and b ? {1, . . . , |NE|}. L(ei)
gathers the most significant nearest neighbors of ei
by choosing the ones which bring the a most rele-
vant similarities providing that the neighborhood’s
size doesn’t exceed b. This approach can be seen
as a flexible k-nearest neighbor method. In our
experiments we chose a = 20% and b = 10.
Finally, we symmetrize the similarity matrix as
follows and we obtain sˆ:
sˆ(ei, ei?) =
{
1 if ei? ? L(ei) or ei ? L(ei?)
0 otherwise
(4)
2.3.3 Cliques computation
Given sˆ, the adjacency matrix between NEs, we
compute the set of maximal cliques of NEs de-
noted CLI. Then, we construct the matrix T of
general term:
T (clik, ei) =
{
1 if ei ? clik
0 otherwise
(5)
where clik is an element of CLI. T will be the
input matrix for the clustering method.
In the following, we also use clik
for denoting the vector represented by
(T (clik, e1), . . . , T (clik, e|NE|)).
Figure 2 shows some cliques which contain Ox-
ford that we can obtain with this method. This fig-
ure also illustrates the over production of cliques
since at least cli8, cli10 and cli12 can be annotated
as <organization>.
53
Figure 2: Examples of cliques containing Oxford
2.4 Cliques clustering
We use a clustering technique in order to group
cliques of NEs which are mutually highly simi-
lar. The clusters of cliques which contain a NE
allow to find the different possible annotations of
this NE.
This clustering technique must be able to con-
struct “pure” clusters in order to have precise an-
notations. In that case, it is desirable to avoid
fixing the number of clusters. That’s the reason
why we propose to use the Relational Analysis ap-
proach described below.
2.4.1 The Relational Analysis approach
We propose to apply the Relational Analysis ap-
proach (RA) which is a clustering model that
doesn’t require to fix the number of clusters
(Michaud and Marcotorchino, 1980), (Be´de´carrax
and Warnesson, 1989). This approach takes as in-
put a similarity matrix. In our context, since we
want to cluster cliques of NEs, the correspond-
ing similarity matrix S between cliques is given
by the dot products matrix taken from T : S =
T · T ?. The general term of this similarity matrix
is: S(clik, clik?) = Skk? = ?clik, clik??. Then, we
want to maximize the following clustering func-
tion:
?(S,X) = (6)
|CLI|?
k,k?=1
(
Skk? ?
?
(k??,k???)?S+ Sk??k???
|S+|
)
? ?? ?
contkk?
Xkk?
where S+ = {(clik, clik?) : Skk? > 0}.
In other words, clik and clik? have more chances
to be in the same cluster providing that their sim-
ilarity measure, Skk? , is greater or equal to the
mean average of positive similarities.
X is the solution we are looking for. It is a bi-
nary relational matrix with general term: Xkk? =
1, if clik is in the same cluster as clik? ; andXkk? =
0, otherwise. X represents an equivalence rela-
tion. Thus, it must respect the following proper-
ties:
• binarity: Xkk? ? {0, 1};?k, k?,
• reflexivity: Xkk = 1;?k,
• symmetry: Xkk? ?Xk?k = 0;?k, k?,
• transitivity: Xkk? + Xk?k?? ? Xkk?? ?
1;?k, k?, k??.
As the objective function is linear with respect
toX and as the constraints thatX must respect are
linear equations, we can solve the clustering prob-
lem using an integer linear programming solver.
However, this problem is NP-hard. As a result, in
practice, we use heuristics for dealing with large
data sets.
2.4.2 The Relational Analysis heuristic
The presented heuristic is quite similar to another
algorithm described in (Hartigan, 1975) known as
the “leader” algorithm. But unlike this last ap-
proach which is based upon euclidean distances
and inertial criteria, the RA heuristic aims at max-
imizing the criterion given in (6). A sketch of this
heuristic is given in Algorithm 1, (see (Marco-
torchino and Michaud, 1981) for further details).
Algorithm 1 RA heuristic
Require: nbitr = number of iterations; ?max = maximal
number of clusters; S the similarity matrix
m?
P
(k,k?)?S+ Skk?
|S+|
Take the first clique clik as the first element of the first
cluster
? = 1 where ? is the current number of cluster
for q = 1 to nbitr do
for k = 1 to |CLI| do
for l = 1 to ? do
Compute the contribution of clique clik with clus-
ter clul: contl =
P
clik??clul
(Skk? ?m)
end for
clul? is the cluster id which has the highest contribu-
tion with clique clik and contl? is the corresponding
contribution value
if (contl? < (Skk ?m)) ? (? < ?max) then
Create a new cluster where clique clik is the first
element and ?? ?+ 1
else
Assign clique clik to cluster clul?
if the cluster where was taken clik before its new
assignment, is empty then
?? ?? 1
end if
end if
end for
end for
We have to provide a number of iterations
54
or/and a delta threshold in order to have an approx-
imate solution in a reasonable processing time.
Besides, it is also required a maximum number of
clusters but since we don’t want to fix this param-
eter, we put by default ?max = |CLI|.
Basically, this heuristic has a O(nbitr×?max×
|CLI|) computation cost. In general terms, we can
assume that nbitr << |CLI|, but not ?max <<
|CLI|. Thus, in the worst case, the algorithm has
a O(?max × |CLI|) computation cost.
Figure 3 gives some examples of clusters of
cliques5 obtained using the RA approach.
Figure 3: Examples of clusters of cliques (only the
NEs are represented) and their associated contexts
2.5 NE resource construction using the CBC
system’s outputs
Now, we want to exploit the clusters of cliques in
order to annotate NE occurrences. Then, we need
to construct a NE resource where for each pair (NE
x syntactic context) we have an annotation. To this
end, we need first, to assign a cluster to each pair
(NE x syntactic context) (§2.5.1) and second, to
assign each cluster an annotation (§2.5.2).
2.5.1 Cluster assignment to each pair (NE x
syntactic context)
For each cluster clul we provide a score
Fc(cj , clul) for each context cj and a score
5We only represent the NEs and their frequency in the
cluster which corresponds to the number of cliques which
contain the NEs. Furthermore, we represent the most relevant
contexts for this cluster according to equation (7) introduced
in the following.
Fe(ei, clul) for each NE ei. These scores6 are
given by:
Fc(cj , clul) = (7)
?
ei?clul
D(ei, cj)
?|NE|
i=1 D(ei, cj)
?
ei?clul
1{D(ei,cj) 6=0}
where 1{P} equals 1 if P is true and 0 otherwise.
Fe(ei, clul) = #(clul, ei) (8)
Given a NE ei and a syntactic context
cj , we now introduce the contextual clus-
ter assignment matrix Actxt(ei, cj) as fol-
lows: Actxt(ei, cj) = clu? where: clu? =
Argmax{clul:clul3ei;Fe(ei,clul)>1}Fc(cj , clul).
In other words, clu? is the cluster for which we
find more than one occurrence of ei and the high-
est score related to the context cj .
Furthermore, we compute a default cluster as-
signment matrix Adef , which does not depend on
the local context: Adef (ei) = clu• where: clu• =
Argmax{clul:clul3{clik:clik3ei}}|clik|.
In other words, clu• is the cluster containing the
biggest clique clik containing ei.
2.5.2 Clusters annotation
So far, the different steps that we have introduced
were unsupervised. In this paragraph, our aim is to
give a correct annotation to each cluster (hence, to
all NEs in this cluster). To this end, we need some
annotation seeds and we propose two different
semi-supervised approaches (regarding the classi-
fication given in (Nadeau and Sekine, 2007)). The
first one is the manual annotation of some clusters.
The second one proposes an automatic cluster an-
notation and assumes that we have some NEs that
are already annotated.
Manual annotation of clusters This method is
fastidious but it is the best way to match the cor-
pus data with a specific guidelines for annotating
NEs. It also allows to identify new types of an-
notation. We used the ACE2007 guidelines for
manually annotating each cluster. However, our
CBC system leads to a high number of clusters of
cliques and we can’t annotate each of them. For-
tunately, it also leads to a distribution of the clus-
ters’ size (number of cliques by cluster) which is
6For data fusion tasks in information retrieval field, the
scoring method in equation (7) is denoted CombMNZ (Fox
and Shaw, 1994). Other scoring approaches can be used see
for example (Cucchiarelli and Velardi, 2001).
55
similar to a Zipf distribution. Consequently, in our
experiments, if we annotate the 100 biggest clus-
ters, we annotate around eighty percent of the de-
tected NEs (see §3).
Automatic annotation of clusters We suppose
in this context that many NEs in NE are already
annotated. Thus, under this assumption, we have
in each cluster provided by the CBC system, both
annotated and non-annotated NEs. Our goal is to
exploit the available annotations for refining the
annotation of a cluster by implicitly taking into
account the syntactic contexts and for propagating
the available annotations to NEs which have no
annotation.
Given a cluster clul of cliques, #(clul, ei) is the
weight of the NE ei in this cluster: it is the number
of cliques in clul that contain ei. For all annota-
tions ap in the set of all possible annotations AN,
we compute its associated score in cluster clul: it
is the sum of the weights of NEs in clul that is
annotated ap.
Then, if the maximal annotation score is greater
than a simple majority (half) of the total votes7, we
assign the corresponding annotation to the clus-
ter. We precise that the annotation <none>8 is
processed in the same way as any other annota-
tions. Thus, a cluster can be globally annotated
<none>. The limit of this automatic approach is
that it doesn’t allow to annotate new NE types than
the ones already available.
In the following, we will denote by Aclu(clul)
the annotation of the cluster clul.
The cluster annotation matrix Aclu associated
to the contextual cluster assignment matrix Actxt
and the default cluster assignment matrix Adef in-
troduced previously will be called the CBC sys-
tem’s NE resource (or shortly the NE resource).
2.6 NEs annotation processes using the NE
resource
In this paragraph, we describe how, given the CBC
system’s NE resource, we annotate occurrences of
NEs in the studied corpus with respect to its local
context. We precise that for an occurrence of a NE
ei its associated local context is the set of syntac-
tical dependencies cj in which ei is involved.
7The total votes number is given byP
ei?clul
#(clul, ei).
8The NEs which don’t have any annotation.
2.6.1 NEs annotation process for the CBC
system
Given a NE occurrence and its local context we
can use Actxt(ei, cj) and Adef (ei) in order to get
the default annotation Aclu(Adef (ei)) and the list
of contextual annotations {Aclu(Actxt(ei, cj))}j .
Then for annotating this NE occurrence using
our NE resource, we apply the following rules:
• if the list of contextual annotations
{Aclu(Actxt(ei, cj))}j is conflictual, we
annotate the NE occurrence as <none>,
• if the list of contextual annotations is non-
conflictual, then we use the corresponding an-
notation to annotate the NE occurrence
• if the list of contextual annotations is empty,
we use the default annotation Aclu(Adef (ei)).
The NE resource plus the annotation process de-
scribed in this paragraph lead to a NER system
based on the CBC system. This NER system will
be called CBC-NER system and it will be tested in
our experiments both alone and as a complemen-
tary resource.
2.6.2 NEs annotation process for an hybrid
system
We place ourselves into an hybrid situation where
we have two NER systems (NER 1 + NER 2)
which provide two different lists of annotated
NEs. We want to combine these two systems when
annotating NEs occurrences.
Therefore, we resolve any conflicts by applying
the following rules:
• If the same NE occurrence has two different an-
notations from the two systems then there are
two cases. If one of the two system is CBC-
NER system then we take its annotation; oth-
erwise we take the annotation provided by the
NER system which gave the best precision.
• If a NE occurrence is included in another one
we only keep the biggest one and its annota-
tion. For example, if Jacques Chirac is anno-
tated <person> by one system and Chirac by
<person> by the other system, then we only
keep the first annotation.
• If two NE occurrences are contiguous and have
the same annotation, we merge the two NEs in
one NE occurrence.
3 Experiments
The system described in this paper rather target
corpus-specific NE annotation. Therefore, our ex-
56
periments will deal with a corpus of recent news
articles (see (Shinyama and Sekine, 2004) for
motivations regarding our corpus choice) rather
than well-known annotated corpora. Our corpus
is constituted of news in English published on
the web during two weeks in June 2008. This
corpus is constituted of around 300,000 words
(10Mb) which doesn’t represent a very large cor-
pus. These texts were taken from various press
sources and they involve different themes (sports,
technology, . . . ). We extracted randomly a sub-
set of articles and manually annotated 916 NEs (in
our experiments, we deal with three types of an-
notation namely <person>, <organization> and
<location>). This subset constitutes our test set.
In our experiments, first, we applied the XIP
parser (A?¨t et al., 2002) to the whole corpus in or-
der to construct the frequency matrix D given by
(1). Next, we computed the similarity matrix be-
tween NEs according to (2) in order to obtain sˆ de-
fined by (4). Using the latter, we computed cliques
of NEs that allow us to obtain the assignment ma-
trix T given by (5). Then we applied the clustering
heuristic described in Algorithm 1. At this stage,
we want to build the NE resource using the clus-
ters of cliques. Therefore, as described in §2.5,
we applied two kinds of clusters annotations: the
manual and the automatic processes. For the first
one, we manually annotated the 100 biggest clus-
ters of cliques. For the second one, we exploited
the annotations provided by XIP NER (Brun and
Hage`ge, 2004) and we propagated these annota-
tions to the different clusters (see §2.5.2).
The different materials that we obtained consti-
tute the CBC system’s NE resource. Our aim now
is to exploit this resource and to show that it allows
to improve the performances of different classic
NER systems.
The different NER systems that we tested are
the following ones:
• CBC-NER system M (in short CBC M) based
on the CBC system’s NE resource using the
manual cluster annotation (line 1 in Table 1),
• CBC-NER system A (in short CBC A) based
on the CBC system’s NE resource using the au-
tomatic cluster annotation (line 1 in Table 1),
• XIP NER or in short XIP (Brun and Hage`ge,
2004) (line 2 in Table 1),
• Stanford NER (or in short Stanford) associ-
ated to the following model provided by the
tool and which was trained on different news
Systems Prec. Rec. F-me.
1
CBC-NER system M 71.67 23.47 35.36
CBC-NER system A 70.66 32.86 44.86
2
XIP NER 77.77 56.55 65.48
XIP + CBC M 78.41 60.26 68.15
XIP + CBC A 76.31 60.48 67.48
3
Stanford NER 67.94 68.01 67.97
Stanford + CBC M 69.40 71.07 70.23
Stanford + CBC A 70.09 72.93 71.48
4
GATE NER 63.30 56.88 59.92
GATE + CBC M 66.43 61.79 64.03
GATE + CBC A 66.51 63.10 64.76
5
Stanford + XIP 72.85 75.87 74.33
Stanford + XIP + CBC M 72.94 77.70 75.24
Stanford + XIP + CBC A 73.55 78.93 76.15
6
GATE + XIP 69.38 66.04 67.67
GATE + XIP + CBC M 69.62 67.79 68.69
GATE + XIP + CBC A 69.87 69.10 69.48
7
GATE + Stanford 63.12 69.32 66.07
GATE + Stanford + CBC M 65.09 72.05 68.39
GATE + Stanford + CBC A 65.66 73.25 69.25
Table 1: Results given by different hybrid NER
systems and coupled with the CBC-NER system
corpora (CoNLL, MUC6, MUC7 and ACE):
ner-eng-ie.crf-3-all2008-distsim.ser.gz (Finkel
et al., 2005) (line 3 in Table 1),
• GATE NER or in short GATE (Cunningham et
al., 2002) (line 4 in Table 1),
• and several hybrid systems which are given by
the combination of pairs taken among the set
of the three last-mentioned NER systems (lines
5 to 7 in Table 1). Notice that these baseline
hybrid systems use the annotation combination
process described in §2.6.1.
In Table 1 we first reported in each line, the re-
sults given by each system when they are applied
alone (figures in italics). These performances rep-
resent our baselines. Second, we tested for each
baseline system, an extended hybrid system that
integrates the CBC-NER systems (with respect to
the combination process detailed in §2.6.2).
The first two lines of Table 1 show that the
two CBC-NER systems alone lead to rather poor
results. However, our aim is to show that the
CBC-NER system is, despite its low performances
alone, complementary to other basic NER sys-
tems. In other words, we want to show that the
exploitation of the CBC system’s NE resource is
beneficial and non-redundant compared to other
baseline NER systems.
This is actually what we obtained in Table 1 as
for each line from 2 to 7, the extended hybrid sys-
tems that integrate the CBC-NER systems (M or
57
A) always perform better than the baseline either
in terms of precision9 or recall. For each line, we
put in bold the best performance according to the
F-measure.
These results allow us to show that the NE re-
source built using the CBC system is complemen-
tary to any baseline NER systems and that it al-
lows to improve the results of the latter.
In order to illustrate why the CBC-NER systems
are beneficial, we give below some examples taken
from the test corpus for which the CBC system A
had allowed to improve the performances by re-
spectively disambiguating or correcting a wrong
annotation or detecting corpus-specific NEs.
First, in the sentence “From the start, his par-
ents, Lourdes and Hemery, were with him.”, the
baseline hybrid system Stanford + XIP anno-
tated the ambiguous NE “Lourdes” as <location>
whereas Stanford + XIP + CBC A gave the correct
annotation <person>.
Second, in the sentence “Got 3 percent chance
of survival, what ya gonna do?” The back read,
”A) Fight Through, b) Stay Strong, c) Overcome
Because I Am a Warrior.”, the baseline hybrid
system Stanford + XIP annotated “Warrior” as
<organization> whereas Stanford + XIP + CBC
A corrected this annotation with <none>.
Finally, in the sentence “Matthew, also a fa-
vorite to win in his fifth and final appearance,
was stunningly eliminated during the semifinal
round Friday when he misspelled “secernent”.”,
the baseline hybrid system Stanford + XIP didn’t
give any annotation to “Matthew” whereas Stan-
ford + XIP + CBC A allowed to give the annota-
tion <person>.
4 Related works
Many previous works exist in NEs recognition and
classification. However, most of them do not build
a NEs resource but exploit external gazetteers
(Bunescu and Pasca, 2006), (Cucerzan, 2007).
A recent overview of the field is given in
(Nadeau and Sekine, 2007). According to this pa-
per, we can classify our method in the category
of semi-supervised approaches. Our proposal is
close to (Cucchiarelli and Velardi, 2001) as it uses
syntactic relations (§2.2) and as it relies on exist-
ing NER systems (§2.6.2). However, the partic-
ularity of our method concerns the clustering of
9Except for XIP+CBC A in line 2 where the precision is
slightly lower than XIP’s one.
cliques of NEs that allows both to represent the
different annotations of the NEs and to group the
latter with respect to one precise annotation ac-
cording to a local context.
Regarding this aspect, (Lin and Pantel, 2001)
and (Ngomo, 2008) also use a clique computa-
tion step and a clique merging method. However,
they do not deal with ambiguity of lexical units
nor with NEs. This means that, in their system, a
lexical unit can be in only one merged clique.
From a methodological point of view, our pro-
posal is also close to (Ehrmann and Jacquet, 2007)
as the latter proposes a system for NEs fine-
grained annotation, which is also corpus depen-
dent. However, in the present paper we use all
syntactic relations for measuring the similarity be-
tween NEs whereas in the previous mentioned
work, only specific syntactic relations were ex-
ploited. Moreover, we use clustering techniques
for dealing with the issue related to over produc-
tion of cliques.
In this paper, we construct a NE resource from
the corpus that we want to analyze. In that con-
text, (Pasca, 2004) presents a lightly supervised
method for acquiring NEs in arbitrary categories
from unstructured text of Web documents. How-
ever, Pasca wants to improve web search whereas
we aim at annotating specific NEs of an ana-
lyzed corpus. Besides, as we want to focus on
corpus-specific NEs, our work is also related to
(Shinyama and Sekine, 2004). In this work, the
authors found a significant correlation between the
similarity of the time series distribution of a word
and the likelihood of being a NE. This result mo-
tivated our choice to test our approach on recent
news articles rather than on well-known annotated
corpora.
5 Conclusion
We propose a system that allows to improve NE
recognition. The core of this system is a clique-
based clustering method based upon a distribu-
tional approach. It allows to extract, analyze and
discover highly relevant information for corpus-
specific NEs annotation. As we have shown in our
experiments, this system combined with another
one can lead to strong improvements. Other appli-
cations are currently addressed in our team using
this approach. For example, we intend to use the
concept of clique-based clustering as a soft clus-
tering method for other issues.
58
References
S. A?¨t, J.P. Chanod, and C. Roux. 2002. Robustness
beyond shallowness: incremental dependency pars-
ing. NLE Journal.
C. Be´de´carrax and I. Warnesson. 1989. Relational
analysis and dictionnaries. In Proceedings of AS-
MDA 1988, pages 131–151. Wiley, London, New-
York.
C. Brun and C. Hage`ge. 2004. Intertwining deep
syntactic processing and named entity detection. In
Proceedings of ESTAL 2004, Alicante, Spain.
R. Bunescu and M. Pasca. 2006. Using encyclope-
dic knowledge for named entity disambiguation. In
Proceedings of EACL 2006.
A. Cucchiarelli and P. Velardi. 2001. Unsupervised
Named Entity Recognition using syntactic and se-
mantic contextual evidence. Computational Lin-
guistics, 27(1).
S. Cucerzan. 2007. Large-scale named entity disam-
biguation based on wikipedia data. In Proceedings
of EMNLP/CoNLL 2007, Prague, Czech Republic.
H. Cunningham, D. Maynard, K. Bontcheva, and
V. Tablan. 2002. GATE: A framework and graphical
development environment for robust NLP tools and
applications. In Proceedings of ACL 2002, Philadel-
phia.
M. Ehrmann and G. Jacquet. 2007. Vers une dou-
ble annotation des entite´s nomme´es. Traitement Au-
tomatique des Langues, 47(3).
J.R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating non-local information into information
extraction systems by gibbs sampling. In Proceed-
ings of ACL 2005.
E.A. Fox and J.A. Shaw. 1994. Combination of multi-
ple searches. In Proceedings of the 3rd NIST TREC
Conference, pages 105–109.
Z. Harris. 1951. Structural Linguistics. University of
Chicago Press.
J.A. Hartigan. 1975. Clustering Algorithms. John Wi-
ley and Sons.
A. Kilgarriff, P. Rychly, P. Smr, and D. Tugwell. 2004.
The sketch engine. In In Proceedings of EURALEX
2004.
V. Lavrenko and W.B. Croft. 2003. Relevance models
in information retrieval. In W.B. Croft and J. Laf-
ferty (Eds), editors, Language modeling in informa-
tion retrieval. Springer.
D. Lin and P. Pantel. 2001. Induction of semantic
classes from natural language text. In Proceedings
of ACM SIGKDD.
D. Lin. 1998. Using collocation statistics in informa-
tion extraction. In Proceedings of MUC-7.
J.F. Marcotorchino and P. Michaud. 1981. Heuris-
tic approach of the similarity aggregation problem.
Methods of operation research, 43:395–404.
P. Michaud and J.F. Marcotorchino. 1980. Optimisa-
tion en analyse de donne´es relationnelles. In Data
Analysis and informatics. North Holland Amster-
dam.
D. Nadeau and S. Sekine. 2007. A survey of Named
Entity Recognition and Classification. Lingvisticae
Investigationes, 30(1).
A. C. Ngonga Ngomo. 2008. Signum a graph algo-
rithm for terminology extraction. In Proceedings of
CICLING 2008, Haifa, Israel.
M. Pasca. 2004. Acquisition of categorized named
entities for web search. In Proceedings of CIKM
2004, New York, NY, USA.
S. Ploux and B. Victorri. 1998. Construction d’espaces
se´mantiques a` l’aide de dictionnaires de synonymes.
TAL, 39(1).
Y. Shinyama and S. Sekine. 2004. Named Entity Dis-
covery using comparable news articles. In Proceed-
ings of COLING 2004, Geneva.
59
