The donkey  s t r ikes  back  
Extending the dynamic interpretation "constructively" 
Tim Fernando 
fernando@cwi, nl 
Centre for Mathematics and Computer Science 
P.O. Box 4079, 1009 AB Amsterdam, The Netherlands 
Abstract 
The dynamic interpretation of a formula 
as a binary relation (inducing transitions) 
on states is extended by alternative treat- 
ments of implication, universal quantifi- 
cation, negation and disjunction that are 
more "dynamic" (in a precise sense) than 
the usual reductions to tests from quanti- 
fied dynamic logic (which, nonetheless, can 
be recovered from the new connectives). An 
analysis of the "donkey" sentence followed 
by the assertion "It will kick back" is pro- 
vided. 
1 In t roduct ion  
The line 
If a farmer owns a donkey he beats it (1) 
from Geach \[6\] is often cited as one of the success to- 
ries of the so-called "dynamic" approach to natural 
language semantics (by which is meant Kamp \[12\], 
Heim \[9\], Sarwise \[1\], and Groenendijk and Stokhof 
\[7\], among others). But add the note 
It will kick back (2) 
and the picture turns sour: processing (1) may leave 
no beaten donkey active. Accordingly, providing a 
referent for the pronoun it in (2) would appear to 
call for some non-compositional surgery (that may 
upset many a squeamish linguist). The present pa- 
per offers, as a preventive, a "dynamic" form of im- 
plication =~ applied to (1). Based on a "construc- 
tive" conception of discourse analysis, an overhaul 
of Groenendijk and Stokhof \[7\]'s Dynamic Predicate 
Logic (DPI.) is suggested, although :=~ can also be 
introduced less destructively so as to extend DPL 
conservatively. Thus, the reader who prefers the 
old "static" interpretation f (1) can still make that 
choice, and declare the continuation (2) to be "se- 
mantically ill-formed." On the other hand, Groe- 
nendijk and Stokhof \[7\] themselves concede that "at 
least in certain contexts, we need alternative xter- 
nally dynamic interpretations of universal quantifi- 
cation, implication and negation; a both internally 
and externally dynamic treatment ofdisjunction." A
proposal for such connectives is made below, extend- 
ing the dynamic interpretation i a manner analo- 
gous to the extension of classical logic by constructive 
logic (with its richer collection of primitive connec- 
tives), through a certain conjunctive notion of par- 
allelism. 
To put the problem in a somewhat general per- 
spective, let us step back a bit and note that in as- 
signing a natural language utterance a meaning, it is 
convenient to isolate an intermediate notion of (say) 
a formula. By taking for granted a translation of the 
utterance to a formula, certain complexities in natu- 
ral language can be abstracted away, and semantics 
can be understood rigorously as a map from formu- 
las to meanings. Characteristic of the dynamic ap- 
proach mentioned above is the identification of the 
meaning of a formula A with a binary relation on 
states (or contexts) describing transitions A induces, 
rather than with a set of states validating A. In the 
present paper, formulas are given by first-order for- 
mulas, and the target binary relations given by pro- 
grams. To provide an account of anaphora in natu- 
ral language, DPL translates first-order formulas A 
r m DPL ro tiff 1 to p ogra s A f m (quan " ed) dynam'c logic 
(see, for example, Harel \[8\]) as follows 
A DPL - A? for atomic A 
130 
(A&B) DPL = ADPL; BDPL 
(~A)DPL --- .., (A DPL) 
(:Ix A) DPL = :r "-'~ • A DPL 
The negation --,p of a program p is the dynamic logic 
test 
(\[p\] ±) ? 
with universal and static features (indicated respec- 
tively by \[p\] and ?),1 neither of which is intrinsic to 
the concept of negation. Whereas ome notion of uni- 
versality is essential to universal quantification and 
implication (which are formulated through negation 
VzA = -~3z-~A 
A D B = -,(A&-~B) 
and accordingly inherit some properties of negation), 
our treatment of (2) will be based on a dynamic 
(rather than static) form =~ of implication. Dynamic 
forms of negation ~, universal quantification and dis- 
junction will also be proposed, but first we focus on 
implication. 
2 The idea in brief 
The semantics \[A\] assigned to a first-order formula 
A is that given to the program A DP\[ - -  i.e., a binary 
relation on states. In dynamic logic, states are vab 
uations; more precisely, the set of states is defined, 
relative to a fixed first-order model M and a set X of 
variables (from which the free variables of formulas 
A are drawn), as the set \[M\[x of functions f ,g , . . .  
from X to the universe IMI of M. Atomic programs 
come in two flavors: tests A? where A is a formula 
in the signature of M with free variables from X, 
and random assignments x :=? where z E X. These 
are analyzed semantically by a function p taking a 
X X program p to a binary relation p(p) C IMI x IMI 
according to 
fp(A?)g iff f=gandM~A\ [ f \ ]  
fp(x :=?)g iff f = g except possibly at x . 
The programs are then closed under sequential com- 
position (interpreted as relational composition) 
fp(p;p')g iff fp(p)h and hp(p')g for some h ,  
non-deterministic choice (interpreted as union) 
f p(p + p')g iff f p(p)g or hp(p')g ,
and Kleene star (interpreted as the reflexive transive 
closure). Rather than extending ~ simultaneously 
to formulas built from modalites \[p\] and (p) labelled 
by programs p, it is sufficient o close the programs 
1The semantics of dynamic logic is reviewed in the 
next section, where what exactly is meant, for example, 
by %tactic" is explained. 
under a negation operation interpreted semantically 
as follows 
fP('~P)g iff f = g and fp(p)h for no h .  
As previously noted, -~p is equivalent to (\[p\]_l.)?. 
Returning to DP1, an implication A D B between 
formulas is interpreted in DP1 by equating it with 
-~ (A ~ -~B), which is in turn translated into the 
dynamic logic program 
-~ (ADPL ; -,(BDPL)). 
Applying the semantic function p to this then yields 
s\[ADB\]t  iff t=s  and 
(Vs' such that s\[A\]s') 
, ' \ [B i t ' .  (3) 
Now, given that a state is a single function from X 
to JMJ, it is hardly odd that implication is static 
(in the sense that the input and output states s and 
t must be the same), as any number of instantia- 
tions of s t (and t e) may be relevant o the right hand 
side of (3). That is, in terms of (1), the difficulty 
is that there may be several farmer/donkey couples, 
whereas a state can accomodate only one such pair, 
rendering an interpretation of (2) problematic. To 
overcome this predicament, he collection of states 
can be extended in at least two ways. 
(P1) Borrowing and modifying an idea from Kleene 
\[14\] (and Brouwer, Kolmogorov,...), incorporate 
into the final state t a functional witness f to 
the V3-clause in the right hand side of (3) to 
obtain 
s\[Azc, B\]t iff t=(s , f )  and 
f is a function with 
domain {s' \[s\[A\]s'}, 
and (Vs' E dom(f)) 
s'\[B\]f(s') . 
Or, to simplify the state t slightly, break the con- 
dition (in the righthand side) up into two mutu- 
ally exclusive clauses depending on whether or 
not the domain of f is empty 
s\[A=~ Bit iff (t is a function with 
non-empty domain 
{s' J s\[A\]s'} and 
(Vs' e dom(/)) 
s'\[n\]t(s')) 
or  
(t = s and 
-,3s' s\[A\]s') , 
so that closing the notion of a state under a par- 
tial function space construct becomes ufficient. 
131 
i P2) Keep only the image of a functional witness so 
that the new (expanded) set of states consists 
simply of the old states (i.e, valuations) together 
with sets of valuations. More precisely, define 
sEA~ Bit iff (3 a function f with 
non-empty domain 
{s' l s\[A\]s' } where 
t is the collapsed 
image of jr and 
(Vs' • dom(jr)) 
s'\[B\]jr(s')) 
or  
(t = s and 
",3s' s\[A\]s').  (4) 
The "collapsed image of fl', 
{t' e IMI x I 3s' jr(s t) - - t ' )  U 
U{e c_ IMI x I _~s' jr(s') = e}) ,  
is simply the image of jr except hat the sets of 
valuations in the image are "collapsed", so that 
the resulting set has only valuations as elements. 
(The collapsing is "justified" by the associativity 
of conjunction.) 
Observe that, in either case, DPL's negation can be 
derived 
--A = A=~_L 
(whence D is also definable from => and &). The 
first proposal, (P1), yields a dizzying tower of higher- 
order functions, in comparison to which, the second 
proposal is considerably simpler. Behind the step 
from (3) to either proposal is the idea that implica- 
tion can spawn processes running in parallel. (Buried 
in (3) is the possibility of the input state s branching 
off to a multiplicity of states t'.) The parallelism here 
is "conjunctive" in that a family of parallel processes 
proceeds along happily so long as every member of 
the family is well; all is lost as soon as one fails. 2 
More precisely, observe that, under (P2), a natural 
clause for s\[A\]t, where s is a set of valuations and A 
is an atomic formula, is 3 
s\[A\]t iff B a function jr : s -*onto t such that 
(Vs' e s) s'\[Alf(s') . 
2The notion of parallelism is thus not unlike that of 
concurrent dynamic logic (Peleg \[19\]). By contrast, the 
non-empty) sets of valuations used (e.g., in Fernando 
\]) to bring out the eliminative character of information 
growth induced by tests A? live disjunctively (and die 
conjunctively). 
3A (non-equivalent) alternative is
s\[Alt iff (Vs' e s) (3t' e t) s'IAlt' and 
(Vt' e t) (3s' e s) s'\[AIt', 
yielding a more promiscuous ontology. This is studied in 
Fernando \[5\], concerning which, the reader is referred to 
the next footnote. 
(That is, in the case of (2), every donkey that a 
farmer beats according to (1) must kick back.) A 
similar clause must be added to (P1), although to 
make the details for (P1) obvious, it should be suffi- 
cient to focus (as we will) on the case of (P2), where 
the states are structurally simpler. But then, a few 
words justifying the structural simplification i  (P2) 
relative to (P1) might be in order. 4
3 A digression: forgetfulness and 
information growth 
If semantic analysis amounts abstractly to a mapping 
from syntactic objects (or formulas) to other math- 
ematical objects (that we choose to call meanings), 
then what (speaking in the same abstract erms) is 
gained by the translation? Beyond some vague hope 
that the meanings have more illuminating structure 
than have the formulas, a reason for carrying out 
the semantic analysis is to abstract away inessen- 
tim syntactic detail (with a view towards isolating 
the essential "core"). Thus, one might expect the 
semantic function not to be 1-1. The more general 
point is that an essential feature of semantic analysis 
is the process of forgetting what can be forgotten. 
More concretely, turning to dynamic logic and its 
semantic function p, observe that after executing 
a random assignment x :=?, the previous ( - input 
state) value of x is overwritten (i.e., forgotten) in the 
output state, s Perhaps an even more helpful example 
is the semantic definition of a sequential composition 
p; p'. The intermediate state arising after p but be- 
fore p' is forgotten by p(p;p') (tracking, as it does, 
only input/output states). Should such information 
be stored? No doubt, recording state histories would 
not decrease the scope of the account hat can then 
be developed. It would almost surely increase it, but 
at what cost? The simpler the semantic framework, 
the better - -  all other things being equal, that is 
(chief among which is explanatory power). Other- 
wise, a delicate balance must be struck between the 
complexity of the framework and its scope. Now, 
part of the computational intuition underlying dy- 
namic logic is that at any point in time, a state (i.e., 
valuation) embodies all that is relevant about the 
past to what can happen in the future. (In other 
words, the meaning of a program is specified simply 
by pairs of input/output states.) This same intu- 
ition underlies (P2), discarding (as it does) the wit- 
4The discussion here will be confined to a somewhat 
intuitive and informal evel. A somewhat more techni- 
cal mathematical ccount is developed at length in Fer- 
nando \[5\], where (P2) is presented as a reduction of (P1) 
to a disjunctive normal form (in the sense of the "con- 
junctive" and "disjunctive" notions of parallelism already 
mentioned). 
5It should, in fairness, be pointed out that Vermeulen 
\[22\] presents a variant of dynamic logic directed towards 
revising this very feature. 
132 
ness function tracing processes back to their "roots." 
(Forgetting that spawning record would seem to be 
akin to forgetting the intermediate state in a sequen- 
tial composition p; p~.) Furthermore, for applications 
to natural language discourse, forgetfulness would 
appear quite innocuous if the information content 
of a state increases in the course of interpreting dis- 
course (so that all past states have no more infor- 
mation content han has the current state). And it 
is quite natural in discourse analysis to assume that 
information does grow. 
Consider the following claim in an early paper 
(Karttunen \[13\]) pre-occupied with a problem (viz., 
that of presuppositions) that may appear peripheral 
to (1) or (2), but is nonetheless fundamental to the 
"constructive" outlook on which =¢, is based 
There are definitions of pragmatic presup- 
position ... which suggest that there is 
something amiss in a discourse that does 
not proceed in \[an\] ideal orderly fashion . . . .  
All  things considered, this is an unreason- 
able view . . . .  People do make leaps and 
shortcuts by using sentences whose presup- 
positions are not satisfied in the conversa- 
tional context. This is the rule rather than 
the exception, and we should not base our 
notion of presupposition on the false pre- 
miss that it does not or should not happen. 
But granting that ordinary discourse is not 
always fully explicit in the above sense, I
think we can maintain that a sentence is 
always taken to be an increment o a con- 
te~:t that satisfies its presuppositions. \[p. 
191, italics added\] 
To bring out an important dimension of "increment 
to a context", and at the same time get around the 
destruction of information in DPL by a random as- 
signment, we will modify the translation .DPI. (map- 
ping first-order formulas into programs) slightly into 
a translation .~, over which (P2) will be worked out 
(though the reader should afterwards have no dif- 
ficulty carrying out the similar extension to DPI.). 
The modification is based (following Fernando \[4\], 
and, further back, Barwise \[1\]) on (i) a switch from 
valuations defined on all variables to valuations de- 
fined on only finitely many variables, and on (ii) the 
use of guarded assignments x := * (in place of ran- 
dom assignments), given by 
=z? + -~(z=z?);  ~:=?,  
which has the effect of assigning a value to x pre- 
cisely when initially z is unbound (in which ease 
the test z = z? fails). Note that (i) spoils biva- 
lence, which is to say that certain presuppositions 
may fail. 6 Accordingly, our translation R(~) ~ of an 
STo what extent an account of presuppositions can 
be based on the break down in bivalence resulting from 
atomic formula R(~) to a program must first attend 
to presuppositions by plugging truth gaps through 
guarded assignments, before testing R(~) 
= • :=  • ; (5 )  
(where • :-- • abbreviates xl := * ; . . . ; z~ := • for 
= z l , . . . , xk ) .  To avoid clashes with variables 
bound by quantifiers, the latter variables might be 
marked 
(3x A)  e = YA,z : - ' *  ; A\[yA,~/x\] e , (6) 
the idea being to sharpen (5) by translating atomic 
formulas R(~, y, ~) with unmarked variables 3, and 
marked variables y, ~ (for 3 and V respectively) as 
follows 
= := • ; (7 )  
Note that to assert a formula A is not simply to test 
A, but also to establish A (if this is at all possible). 
Establishing not A is (intuitively) different from test- 
ing (as in DPL) that A cannot be established. 7 A 
negation ,-, reflecting the former is described next, 
avoiding an appeal to a modal notion (hidden in -~ 
by writing --,p instead of (\[p\]_l_)?). 
4 Working out the idea formally 
Starting over and proceeding a bit more rigorously 
now, given a first-order signature L, throw in, for 
every n-ary predicate symbol R E L, a fresh n-ary 
predicate symbol/~ and extend the map : to these 
symbols by setting R = R. Then, interpret/~ in an 
L-structure M as the complement of R 
/~M _ IM I ' -R  M. 
So, without loss of generality, assume that we are 
working with a signature L equipped with such a 
map :, and let M be an L-model obeying the com- 
plementarity condition above (readily expressible in 
the first-order language). Fix a countable set X0 of 
variables, and define two fresh (disjoint) sets Y and 
Z of "marked" variables inductively simultaneously 
with a set ~ of L-formulas (built from &, V, V, 3 and 
=~) as follows 
(i) T, _1_ and every atomic L-formula with free vari- 
ables from Xo U Y U Z is in 
(ii) if A and B are in ~, then so are A&B,  A V B 
and A ~ B 
(iii) for every ("unmarked") z E X0, if A E ¢, then 
Vz A and 3z A belong to 
uninitialized variables will not be taken up here. The in- 
terested reader is referred to Fernando \[4\] for an internal 
notion of proposition as an initial step towards this end. 
7As detailed in Fernando \[4\], this distinction c~n 
be exploited to provide an account of Veltman \[21\]'s 
might operator as -1--. relative to an internal notion of 
proposition. 
133 
(iv) for every x E X0, if A E 4, then the fresh 
("marked") variables YA,, and za,, belong to 
Y and Z respectively. 
Next, define a "negation" map ,-~ • on ~ by 
, - ,T  = 1. 
~ .L  = T 
~ R(~,~,-~) = R(~,~,-~) 
.~(A&B) = ,,,A V , . ,B  
,~(AVB)  = ,-~A &,,~B 
(VxA) = 3x ,-~A 
-~(3xA) = Vx ,,-A 
~(A::# B) = A & NB . 
This approach, going back at least to Nelson \[17\] (a 
particularly appropriate reference, given its connec- 
tion with Kleene \[14\]), treats positive and negative 
information in a nearly symmetric fashion; on for- 
mulas in ~ without an occurrence of ::~, the function 
,~N. is the identity. Furthermore, were it not for 
:V, our translation -~ would map formulas in (~ to 
programs interpreted as binary relations on 
So = {s \[ s is a function from 
a finite subset of X to IMI} , 
where X is the full set of marked an unmarked vari- 
ables 
X = XoUYUZ.  
All the same, the clauses for s\[A\]t can be formulated 
uniformly whether or not s E So, so long as it is 
understood that for a set s of valuations, u E X, and 
atomic A, 
sp(u := , ) t  iff 3 a function f : s --*~,o t such 
that (Vs' e s) s' p(u := *)f(s ' )  
sp(A?)t iff ~ = s and (Ys' 6. s) s'p(A?)s' . 
(These clauses are consistent with the intuition de- 
scribed in section 2 of a "conjunctive" family of pro- 
cesses running in parallel.) The translation .e is then 
given by (7), 
(A&B) e = A ' ;B  e 
(AVB)  e = Ae+B e ,  
(6) and (4), with IMI x replaced by So. All that 
is missing is the clause for universal quantification 
Vx A, which (following Kleene \[14\]) can be inter- 
preted essentially as zA,~ = ZA,~: ~ A\[ZA,x/X\], ex- 
cept that in the antecedent, ZA,,: is treated as un- 
marked 
s~/x Air iff t is the collapsed image of 
a function f with domain 
{s' I sp( A,  := ,)s'} such 
that (Vs' e dom(f))  
s'\[A\[zA,x/z\]\]f(s') . 
The reader seeking the definition of \[A\] spelled out 
in full is referred to the appendix. 
Observe that non-deterministic choice + (for 
which DPL has no use) is essential for defining N. 
Strong negation ,,, is different from -% and lacks the 
universal force necessary to interpret implication (ei- 
ther as ,,~ (.& ~ .)) or as -V ,~ .). On the other hand, 
--A can be recovered as A =~ .L, whence static impli- 
cation D is also derivable. Note also that an element 
s of So can be identified with {s}, yielding states of 
a homogeneous form. 
5 A few examples 
The present work does not rest on the claim that the 
disorderly character of discourse mentioned above by 
Karttunen \[13\] admits a compositional translation to 
a first-order formula. The problem of translating a
natural language utterance to a first-order formula 
(e.g., assigning a variable to a discourse marker) is 
essentially taken for granted, falling (as it does) out- 
side the scope of formal semantics (conceived as a 
function from formulas to meanings). This affords 
us considerable freedom to accomodate various in- 
terpretations. The donkey sentence (1) can be for- 
mulated as 
  _ srCx) o sCx, y) ao eyCy) 
beats(x, y) 
or given an alternative "weak" reading 
f~,-~er(z) a o~s(z ,  z) & do~key(z) 
::> 
y) doPey(y) beat (x, y) 
so that not every donkey owned by a farmer need be 
beaten (Chierchia \[2\]). In either case, the pay back 
(2) can be formulated as 
kicks-back(y, x) . 
A further alternative that avoids presupposing the 
existence of a donkey is to formulate (1) and (2) as 
o s(x, y) do sy(y) 
beat-(x, y) kick -baek(y, x), 
observing that 
\[(A=> B)&C\] ~ \[A => (B&C) \ ] .  
N ext, 
nendijk and Stokhof \[7\] 
If a client turns up, you treat him politely. 
You offer him a cup of coffee and ask 
him to wait. 
Every player chooses a pawn. He puts it 
we consider a few examples from Groe- 
(8) 
134 
on square one. 
It is not true that John doesn't own a car. 
It is red, and it is parked in front of his 
house. 
Either there is no bathroom here, or it 
is a funny place. In any case, it is not 
on the first floor. 
Example (8) can be formulated as 
client(z) turns-up(z) 
treat-polit ely(y, x) 
(9) 
(10) 
(11) 
followed by 
o  er-co  ee(y,z) as -to-.ait(y,z), 
and (9) as 
p layer(z)  ::~ ehoose(z,y) & pawn(y) 
followed by 
put-on-sqaare-on~x, y) . 
The double negation in (10) can be analyzed ynam- 
ically using - ,~. ,  and (11) can be treated as 
bathroom(z) :~ -here(x) V funny-place 
followed by 
~on-first-floo~z) , 
where, in this case, the difference between -,, and -~ 
is immaterial. 
Groenendijk and Stokhof \[7\] suggest equating (not 
A) implies B, in its dynamic form, with A V B. To 
allow not A to be dynamic, not should not be inter- 
preted as ~. But even (-~ A) =:~ B is different from 
A V B, as the non-determinism in A V B is lost in 
(,,~ A) :¢. B, and :=~ may lead to structurally more 
complex states (¢ So). What is true is that 
,,~,,~ ((NA) :=~ B) = ,,, ((~A) & ~B)  
= (-,,~A) V ,~,~B 
which reduces to A V B if ~ occurs neither in A 
nor B. Whereas the translation -~-~. yields a static 
approximation, the translation ~,-,-, applied recur- 
sively, projects to an approximation that is a binary 
relation on So. 
Notice that quantifers do not appear in the trans- 
lations above of natural language utterances into 
first-order formulas. The necessary quantification is 
built into the semantic analysis of quantifier-free for- 
mulas, following the spirit (if not the letter) of Pagin 
and Westerst£hl \[18\]. (A crucial difference, of course, 
is that the universal quantification above arises from 
a dynamic =~.) The reader interested in composi- 
tionality should be pleased by this feature, insofar as 
quantifer-free formulas avoid the non-compositional 
relabelling of variables bound by quantifiers (in the 
semantic analysis above of quantified formulas). 
6 Concern ing  cer ta in  po in ts  
The present paper is admittedly short on linguistic 
examples - -  a defect that the author hopes some 
sympathetic reader (better qualified than he) will 
correct. Towards this end, it may be helpful to take 
up specific points (beyond the need for linguistic ex- 
amples) raised in the review of the work (in the form 
it was originally submitted to EACL). 
Referee 1. What are the advantages over expla- 
nations of the anaphoric phenomenon i question in 
terms of discourse structure which do not require a 
change of the formal semantics apparatus? 
The "anaphoric phenomenon i question" amounts, 
under the analysis of first-order formulas as pro- 
grams, to the treatment of variables across entential 
boundaries. A variable can have existential force, as 
does the farmer in 
A farmer owns a donkey, 
or universal force, as does the farmer in 
Every farmer owns a donkey. 
Taking the "the formal semantics apparatus" to 
be dynamic logic, DPL treats existential variables 
through random assignments. The advantage of the 
proposal(s) above is the treatment of universal vari- 
ables across sentential variables, based on an exten- 
sion of dynamic logic with an implication connective 
(defined by (4), if A and B are understood as pro- 
grams). (Note that negation and disjunction can be 
analyzed ynamically already within dynamic logic.) 
Referee 2. Suggestions for choosing between the 
static/dynamic versions would enhance the useful- 
ness of the framework. 
Choose the dynamic version. Matching discourse 
items with variables is, afterall, done by magic, 
falling (as it does) outside the scope of DPL or Dis- 
course Representation Theory (DRT, Kamp \[12\]). 
But the reader may have good reason to object. 
P rogramme Commit tee .  A comparison to a 
DRT-style semantics should be added. 
Yes, the author would like to describe the discourse 
representation structures (DRS's) for the extension 
to higher-order states above. Unfortunately, he does 
not (at present) know how to. s Short of that, it 
may be helpful to present he passage to states that 
are conjunctive sets of valuations in a different light. 
Given a state that is a set s of valuations l, s~,...,  
let X, be the set of variables in the domain of some 
si Gs 
X, = U dom(si). 
siEs 
SSome steps (related to footnote 4) towards that di- 
rection are taken in Fernando \[5\]. Another approacb, 
somewhat more syntactic in spirit, would be to build on 
K. Fine's arbitrary objects (Meyer Viol \[15\]). 
135 
Now, s can be viewed as a set F, of functions f~ 
labelled by variables z E X, as follows. Let f~ be 
the map with domain {si e s \[ z e dom(si)} that 
sends such an si to si(z). In pictures, we pass from 
to 
I st :dl~ct 1 s = s2:d2--+c2 
{ f~ l :{s i~s lz t~d i}__+Cl  } 
F, -- f~2 : {si E s I z2 E di} -.-* c2 , 
so that the step from states sl ,s2,. . ,  in So to the 
more complicated states s in Power(S0) amounts to 
a semantic analysis of variables as functions, rather 
than as fixed values from the underlying first-order 
model. (But now what is the domain of such a func- 
tion?) The shift in point of view here is essentially 
the "ingenious little trick" that Muskens \[16\] (p. 418) 
traces back to Janssen \[11\] of swapping rows with 
columns. We should be careful to note, however, 
that the preceding analysis of variables was carried 
out relative to a fixed state s - -  a state s that is 
to be supplied as an argument to the partial binary 
functions globally representing the variables. 
Finally, A. Visser and J. van Eijck have suggested 
that a comparison with type-theoretic and game- 
theoretical semantics (e.g., Ranta \[20\] and Hintikka 
and Kulas \[10\]) is in order. 
This again is no simple matter to discuss, and (alas) 
fails somewhat beyond the scope of the present pa- 
per. For now, suffice it to say that (i) the trans- 
lation • e above starts from first-order formulas, on 
which (according to Ranta \[20\], p. 378) the game- 
theoretic "truth definition is equivalent to the tra- 
ditional Tarskian one", and that (ii) the use of con- 
structive logic in Ranta \[20\] renders the reduction 
from the proposal (P1) to (P2) (described in section 
2) implausible inasmuch as that represents a (con- 
structively unsound) transformation to a disjunctive 
normal form (referred to in footnote 4). But what 
about constructiveness? 
7 Between const ruct ion  and  t ru th  
Having passed somewhat hastily from (P1) to (P2), 
the reader is entitled to ask why the present au- 
thor has bothered mentioning realizability (allud- 
ing somewhat fashionably or unfashionably to "con- 
structiveness") and has said nothing about (classical) 
modal ogic-style formalizations (e.g., Van Eijck and 
De Vries \[3\]), building say on concurrent dynamic 
logic (Peleg \[19\]). A short answer is that the con- 
nection with so-called and/or computations came to 
the author only after trying to understand the inter- 
pretation of implication in Kleene \[14\] (interpreting 
implication as a program construct being nowhere 
suggested in Peleg \[19\], which instead introduces a
"conjunction" fl on programs). A more serious an- 
swer would bring up his attitude towards the more 
interesting question 
does all talk about so-called dynamic 
semantics come to modal logic? 
The crazy appeal dynamic semantics exerts on the 
author is the claim that a formula (normally con- 
ceived statically) is a program (i.e., something dy- 
namic); showing how a program can be understood 
statically is less exciting. Some may, of course, find 
the possibility of "going static" as well as "going dy- 
namic" comforting (if not pleasing). But if reduc- 
ing dynamic semantics to static truth conditions is 
to complete that circle, then formulas must first be 
translated to programs. And that step ought not to 
be taken completely for granted (or else why bother 
talking about "dynamic semantics"). Understanding 
a computer program in a precise (say "mathemati- 
cal") sense is, in principle, to be expected insofar 
as the states through which the computer program 
evolves can be examined. If a program can be im- 
plemented in a machine, then it has a well-defined 
operational semantics that, moreover, is subject (in 
some sense or another) to Church's thesis. In that 
sense, understanding a computer program relative 
to a mathematical world of eternal truths and static 
formulas is not too problematic. Not too problem- 
atic, that is, when compared to natural language, 
for which nothing like Church's thesis has gained ac- 
ceptance. To say that 
natural anguage is a programming language 
is outrageous (- -  perhaps deliberately so --),  and 
those of us laboring under this slogan must admit 
that we do not know how to translate an English 
sentence into a FORTRAN program (whatever that 
may mean). Nor, allowing for certain abstractions, 
formulas into programs. Furthermore, a favorite toy 
translation, DPL, goes beyond ordinary computabil- 
ity (and FORTRAN) when interpreted over the nat- 
ural numbers. (The culprit is --.) Not that the 
idea of a program must necessarily be understood 
in the strict sense of ordinary recursion theory. But 
some sensitivity to matters relating to computation 
("broadly construed") is surely in order when speak- 
ing of programs. 
It was the uncomputable character of DPL's nega- 
tion and implication that, in fact, drove the present 
work. Strong negation ,~ is, from this standpoint, 
a mild improvement, but it would appear that the 
situation for implication has only been made more 
complicated. This complication can be seen, how- 
ever, as only a first step towards getting a handle on 
the computational character of the programs used 
in interpreting formulas dynamically. Whether more 
effective forms of realizability (incorporating, as was 
136 
originally conceived, some notion of construction or 
proof into the witnessing by functions) can shed any 
helpful light on the idea of dynamic semantics is 
an open question. That realizability should, crazily 
enough, have anything to say whatsoever about a lin- 
guistic problem might hearten those of us inclined to 
investigate the matter. (Of course, one might take 
the easy way out, and simply restrict =~ to finite 
models.) 
Making certain features explicit that are typically 
buried in classical ogic (such as the witness to the 
V3-clause in ::~) is a characteristic practice of con- 
structive mathematics that just might prove fruit- 
ful in natural language semantics. A feature that 
would seem particularly relevant to the intuition that 
discourse interpretation amounts to the construction 
of a context is information growth. 9 The extension 
of the domain of a finite valuation is an important 
aspect of that growth (as shown in Fernando \[4\], 
appealing to Henkin witnesses, back-and-forth con- 
structions, ...). The custom in dynamic logic of re- 
ducing a finite valuation to the set of its total ex- 
tensions (relative to which a static notion of truth is 
then defined) would appear to run roughshod over 
this feature - -  a feature carefully employed above to 
draw a distinction between establishing and testing 
a formula (mentioned back at the end of section 3). 
But returning to the dynamic implication ::~ intro- 
duced above, observe that beyond the loss of struc- 
ture (and information) in the step from (P1) to (P2), 
it is possible within (P2) (or, for that matter, within 
(P1)) to approximate =~ by more modest extensions. 
There is, for instance, the translation -,~,,~ • (not to 
be confused with -----) which (in general) abstracts 
away structure with each application. The interpre- 
tation of implication can be simplified further by not- 
ing that --Tr can be recovered as ~r =V .1_, and thus the 
static implication D of DPI. can be derived from ::~. 
Reflecting on these simplifications, it is natural to 
ask what structure can dynamic semantics afford to 
forget? 
Is there more structure lurking behind 
construction than concerns truth? 
With the benefit of the discussion above about 
the dual (establishing/testing) nature of asserting a
proposition - -  or perhaps even without being sub- 
jected to all that babble - - ,  surely we can agree that 
Story-telling requires more imagination 
than verifying facts. 
9The idea that information grows during the run of 
a typical computer program is, by comparison, not so 
clear. One difference is that whereas guarded assign- 
ments would seem sufficient for natural anguage appli- 
cations, a typical computer program will repeatedly as- 
sign different values to the same variable. To pursue the 
matter further, the reader may wish to (again) consult 
Vermeulen \[22\]. 
Acknowledgments  
My thanks to J. van Eijck and J. Ginzburg for 
criticisms of a draft, to K. Vermeulen, W. Meyer- 
Viol, A. Visser, P. Blackburn D. Beaver, and M. 
Kanazawa for helpful discussions, and to the con- 
ference's anonymous referees for various suggestions. 
Appendix: (P2) fleshed out without 
prose 
Fix a first-order model M and a set X of vari- 
ables partitioned between the unmarked (x , . . . )  and 
marked (y , . . .  and z , . . .  for existential and universal 
quantification, respectively). (It may be advisable to 
ignore the marking of variables, and quantified for- 
mulas; see section 5 for some examples.) Let So be 
the set of functions defined on a finite subset of X, 
ranging over the universe of M. Given a sequence 
of variables ux , . . . ,  u,, in X, define the binary rela- 
tion p(~ := *) on s and t E So U Power(So) by 
sp(~:=*)t iff ( sESo ,  teSo ,  t _Dsand 
dom(t) = dom(s) U {ul , . . . ,  u,}) 
or  
(s ~ So and 
3 a function f : s --'o,~to t such 
that (Vs r E s) s'p(~ := *)f(s~)) . 
L-formulas A from the set @ defined in section 3 are 
interpreted semantically by binary relations 
~'A\] C (So U Power(so))x 
(So u Power(S0)) 
according to the following clauses, understood induc- 
tively 
sl\[n(~,y,~)\]t iff (s E So , sp('~ : -  . ) t  
and M ~ nit\]) 
or  
(3 a function f from 
s onto t such that 
(Vs' e s) 
s'\[R(~,y,-~\]f(s')) 
s\[A&S\]t iff s\[A\]\]u and u\[B\]t for 
some u 
s\[A V B\]t iff s\[A\]\]t or s\[B\]t 
s~/x A\]\]t iff t is the collapsed image 
of a function f with 
domain 
{s' I sp(zA,. := ,)s'} 
such that 
(Vs' e dom(/))  
s'\[A\[za,o:/x\]\]f(s') 
s\[3x A\]t iff sp(YA,~ :=*)u  and 
137 
u~A\[yA,~/x\]\]t for 
some u 
s\[A ~ B\]t iff (3 afunction f with 
non-empty domain 
{s' i s\[A\]s'} where 
t is the collapsed 
image of f and 
(Vs' e dora(f)) 
s'\[Blf(s')) 
or  
(t = s and 
-,Bs' s\[A\]s') , 
and, not to forget negation, 
s\[T\]t iff s=t  
s\[±\]t iff you're a donkey 
(in which case you are free to derive anything). 
References  
\[1\] Jon Barwise. Noun phrases, generalized quan- 
tifiers and anaphora. In E. Engdahl and 
P. G~denfors, editors, Generalized Quantiflers, 
Studies in Language and Philosophy. Dordrecht: 
Rediel, 1987. 
\[2\] G. Chierchia. Anaphora and dynamic logic. 
ITLI Prepublication, University of Amsterdam, 
1990. 
\[3\] J. van Eijck and F.J. de Vries. Dynamic inter- 
pretation and Hoare deduction. J. Logic, Lan- 
guage and Information, 1, 1992. 
\[4\] Tim Fernando. Transition systems and dynamic 
semantics. In D. Pearce and G. Wagner, edi- 
tors, Logics in AI, LNCS 633 (subseries LNAI). 
Springer-Verlag, Berlin, 1992. A slightly cor- 
rected version has appeared as CWI Report CS- 
R9217, June 1992. 
\[5\] Tim Fernando. A higher-order xtension of con- 
straint programming in discourse analysis. Po- 
sition paper for the First Workshop on Princi- 
ples and Practice of Constraint Programming 
(Rhode Island, April 1993). 
\[6\] P.T. Geach. Reference and Generality: an Ex- 
amination of Some Medieval and Modern The- 
ories. Cornell University Press, Ithaca, 1962. 
\[7\] J. Groenendijk and M. Stokhof. Dynamic predi- 
cate logic. Linguistics and Philosophy, 14, 1991. 
\[8\] David Hard. Dynamic logic. In D. Gabbay and 
F. Guenthner, editors, Handbook of Philosophi- 
cal Logic, Volume 2. D. Reidel, 1984. 
\[9\] Irene Heim. The semantics of definite and in- 
definite noun phrases. Dissertation, University 
of Massachusetts, Amherst, 1982. 
\[10\] J. Hintikka and J. Kulas. The Game of Lan- 
guage. D. Reidel, Dordrecht, 1983. 
\[11\] Theo Janssen. Foundations and Applications of 
Montague Grammar. Dissertation, University of 
Amsterdam (published in 1986 by CWI, Ams- 
terdam), 1983. 
\[12\] \].A.W. Kamp. A theory of truth and semantic 
representation. In J. Groenendijk et. al., edi- 
tors, Formal Methods in the Study of Language. 
Mathematical Centre Tracts 135, Amsterdam, 
1981. 
\[13\] Lauri Karttunen. Presupposition and linguistic 
context. Theoretical Linguistics, pages 181-194, 
1973. 
\[14\] S.C. Kleene. On the interpretation of intuition- 
istic number theory. J. Symbolic Logic, 10, 1945. 
\[15\] W.P.M. Meyer Viol. Partial objects and DRT. 
In P. Dekker and M. Stokhof, editors, Proceed- 
ings of the Eighth Amsterdam Colloquium. In- 
stitute for Logic, Language and Computation, 
Amsterdam, 1992. 
\[16\] Reinhard Muskens. Anaphora and the logic of 
change. In J. van Eijck, editor, Logics in AI: 
Proc. European Workshop JELIA '90. Springer- 
Verlag, 1991. 
\[17\] David Nelson. Constructible falsity. Y. Symbolic 
Logic, 14, 1949. 
\[18\] P. Pagin and D. Westerst£hl. Predicate logic 
with flexibly binding operators and natural an- 
guage semantics. Preprint. 
\[19\] David Peleg. Concurrent dynamic logic. J. As- 
soc. Computing Machinery, 34(2), 1987. 
\[20\] Aarne Ranta. Propositions as games as types. 
Synthese, 76, 1988. 
\[21\] Frank Veltman. Defaults in update semantics. 
In J.A.W. Kamp, editor, Conditionals, Defaults 
and Belief Revision. Edinburgh, Dyana deliver- 
able R2.5.A, 1990. 
\[22\] C.F.M. Vermeulen. Sequence semantics for dy- 
namic logic. Technical report, Philosophy De- 
partment, Utrecht, 1991. To appear in J. Logic, 
Language and Information. 
138 
