Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 443–454,
October 25-29, 2014, Doha, Qatar.
c©2014 Association for Computational Linguistics
An I-vector Based Approach to Compact Multi-Granularity Topic Spaces
Representation of Textual Documents
Mohamed Morchid
†
, Mohamed Bouallegue
†
, Richard Dufour
†
,
Georges Linar
`
es
†
, Driss Matrouf
†
and Renato de Mori
†‡
†
LIA, University of Avignon, France
‡
McGill University, School of Computer Science, Montreal, Quebec, Canada
{firstname.lastname}@univ-avignon.fr
rdemori@cs.mcgill.ca
Abstract
Various studies highlighted that topic-
based approaches give a powerful spo-
ken content representation of documents.
Nonetheless, these documents may con-
tain more than one main theme, and their
automatic transcription inevitably contains
errors. In this study, we propose an orig-
inal and promising framework based on a
compact representation of a textual docu-
ment, to solve issues related to topic space
granularity. Firstly, various topic spaces
are estimated with different numbers of
classes from a Latent Dirichlet Allocation.
Then, this multiple topic space representa-
tion is compacted into an elementary seg-
ment, called c-vector, originally developed
in the context of speaker recognition. Ex-
periments are conducted on the DECODA
corpus of conversations. Results show the
effectiveness of the proposed multi-view
compact representation paradigm. Our
identification system reaches an accuracy
of 85%, with a significant gain of 9 points
compared to the baseline (best single topic
space configuration).
1 Introduction
Automatic Speech Recognition (ASR) systems
frequently fail on noisy conditions and high Word
Error Rates (WER) make the analysis of the au-
tomatic transcriptions difficult. Speech analyt-
ics suffer from these transcription issues that may
be overcome by improving the ASR robustness
and/or the tolerance of speech analytic systems to
ASR errors. This paper proposes a new method
to improve the robustness of speech analytics by
combining a semantic multi-model approach and
a noise reduction technique based on the i-vector
paradigm.
This method is evaluated in the application
framework of the RATP call centre (Paris Public
Transportation Authority), focusing on the theme
identification task (Bechet et al., 2012).
Telephone conversations are a particular case
of human-human interaction whose automatic
processing raises problems, especially due to the
speech recognition step required to obtain the
transcription of the speech contents. First, the
speaker’s behavior may be unexpected and the
training/test mismatch may be very large. Second,
the speech signal may be strongly impacted by
various sources of variability: environment and
channel noises, acquisition devices, etc.
Telephone conversation issues
Topics are related to the reason why the customer
called. Various classes corresponding to the
main customer’s requests are considered (lost and
founds, traffic state, timelines, etc). In addition
to classical issues in such adverse conditions,
the topic-identification system should deal with
problems related to class proximity. For example,
a lost & found request is related to itinerary
(where was the object lost?) or timeline (when?),
that could appear in most of the classes. In fact,
these conversations involve a relatively small
set of basic concepts related to transportation
issues. Figure 1 shows an example of a dialogue
which is manually labeled by the agent as an
issue related to an infraction. However, words
in bold suggest that this conversation could be
related to a transportation card. Thus, we assume
that a dialogue representation should be seen as
a multi-view problem to substantiate the claims
regarding the multi-theme representation of a
given dialogue.
On the other hand, multi-view approaches in-
troduce additional variability due to the diversity
of the views. This variability is also due to the
vocabulary used by both agent and customer
443
Agent: Hello
Customer: Hello
Agent: Speaking ...
Customer: I call you because 
I was fined today, but I still 
have an imagine card 
suitable for zone 1 [...] I forgot 
to use my navigo card for 
zone 2
Agent: You did not use 
your navigo card, that is 
why they give you a fine not 
for a zone issue [...]
Customer: Thanks, bye
Agent: bye
Agent
Customer
Transportation
cards
Figure 1: Example of a dialogue from the DE-
CODA corpus labeled by the agent as an infraction
issue which contains more than one theme (infrac-
tion + transportation cards).
during a telephone conversation. Indeed, an
agent have to follow an predefined scenario of
conversation. Thus, the agent can find the main
reason for the call which corresponds to the theme.
Proposed solutions
An efficient way to tackle both ASR robustness
and class ambiguity could be to map dialogues
into a topic space abstracting the ASR outputs.
Then, dialogue categorization is achieved in this
topic space. Numerous unsupervised methods for
topic-space estimation were proposed in the past.
Latent Dirichlet Allocation (LDA) (Blei et al.,
2003) has been largely used for speech analytics;
one of its main drawbacks is the tuning of the
model, that involves various meta-parameters
such as the number of classes (that determines
the model granularity), word distribution meth-
ods, temporal spans. . . If the decision process is
highly dependent on these features, the system’s
performance could be quite unstable.
Classically, this abstract representation involves
selecting the right number of classes composing
the topic space. This decision is crucial since
topic model perplexity, which expresses its qual-
ity, is highly dependent on this feature. Further-
more, the multi-theme context of the study (see
Figure 1) involves a more complex dialogue rep-
resentation. In this paper, we propose to deal with
these two drawbacks by using a compact represen-
tation from multiple topic spaces. This model is
based on a robust multi-view representation of the
textual documents.
A multi-view representation of a dialogue intro-
duces both a relevant variability needed to repre-
sent different contexts of the dialogue, and a noisy
variability related to topic space processing. Thus,
a topic-based representation of a dialogue is built
from the dialogue content itself. For this reason,
the mapping process of a dialogue into several
topic spaces generates a noisy variability related to
the difference between the dialogue and the con-
tent of each class. In the same way, the relevant
variability comes from the common content be-
tween the dialogue and the classes composing the
topic space.
We propose to reduce the noisy variability by
using a factor analysis technique, which was ini-
tially developed in the domain of speaker identifi-
cation. In this field, the factor analysis paradigm
is used as a decomposition model that enables to
separate the representation space into two sub-
spaces containing respectively useful and useless
information. The general Joint Factor Analysis
(JFA) paradigm (Kenny et al., 2008) considers
multiple variabilities that may be cross-dependent.
Therefore, JFA representation allows us to com-
pensate the variability within sessions of a same
speaker. This representation is an extension of the
GMM-UBM (Gaussian Mixture Model-Universal
Background Model) models (Reynolds and Rose,
1995). (Dehak et al., 2011) extract a compact
super-vector (called an i-vector) from the GMM
super-vector. The aim of the compression pro-
cess (i-vector extraction) is to represent the super-
vector variability in a low dimensional space. Al-
though this compact representation is widely used
in speaker recognition systems, this method has
not been used yet in the field of text classification.
In this paper, we propose to apply factor anal-
ysis to compensate noisy variabilities due to the
multiplication of LDA models. Furthermore, a
normalization approach to condition dialogue rep-
resentations (multi-model and i-vector) is pre-
sented. The two methods showed improvements
for speaker verification: within Class Covariance
Normalization (WCCN) (Dehak et al., 2011) and
Eigen Factor Radial (EFR) (Bousquet et al., 2011).
The latter includes length normalization (Garcia-
Romero and Espy-Wilson, 2011). Both methods
dilate the total variability space as a means of re-
ducing the within-class variability. In our multi-
model representation, the within class variability
is redefined according to both dialogue content
444
(vocabulary) and topic space characteristics (word
distributions among the topics). Thus, the speaker
is represented by a theme, and the speaker session
is a set of topic-based representations (frames) of
a dialogue (session).
The paper is organized as follows. Section 2
presents previous related works. The dialogue rep-
resentation is described in Section 3. Section 4 in-
troduces the i-vector compact representation and
presents its application to text documents. Sec-
tions 5 and 6 report experiments and results. The
last section concludes and proposes some perspec-
tives.
2 Related work
In the past, several approaches considered a
text document as a mixture of latent topics.
These methods, such as Latent Semantic Analysis
(LSA) (Deerwester et al., 1990; Bellegarda, 1997),
Probabilistic LSA (PLSA) (Hofmann, 1999) or
Latent Dirichlet Allocation (LDA) (Blei et al.,
2003), build a higher-level representation of the
document in a topic space. ¿ Document is
then considered as a bag-of-words (Salton, 1989)
where the word order is not taken into account.
These methods have demonstrated their perfor-
mance on various tasks, such as sentence (Belle-
garda, 2000) or keyword (Suzuki et al., 1998) ex-
traction.
In opposition to a multinomial mixture model,
LDA considers that a theme is associated to each
occurrence of a word composing the document,
rather than associate a topic to the complete doc-
ument. Therefore, a document can change topics
from a word to another one. However, word oc-
currences are connected by a latent variable which
controls the global match of the distribution of
the topics in the document. These latent topics
are characterized by a distribution of associated
word probabilities. PLSA and LDA models have
been shown to generally outperform LSA on IR
tasks (Hofmann, 2001). Moreover, LDA provides
a direct estimate of the relevance of a topic given
a word set. In this paper, probabilities of hidden
topic features, estimated with LDA, are considered
for possibly capturing word dependencies express-
ing the semantic contents of a given conversation.
Topic-based approaches involve defining a
number of topics composing the topic space. The
choice of the “right” number of topics is a crucial
step, especially when the documents may contain
multiple themes. Many studies have tried to find
a relevant method to deal with this issue. (Arun et
al., 2010) proposed to use a Singular Value De-
composition (SVD) to represent the separability
between the words contained in the vocabulary.
Then, if the singular values of the topic-word ma-
trix M equal the norm of the rows of M, this means
that the vocabulary is well separated among the
topics. This method has to be evaluated with the
Kullback-Liebler divergence metric for each topic
space. However, this process would be time con-
suming for thousands of representations of a dia-
logue.
(Teh et al., 2004) proposed the Hierarchical
Dirichlet Process (HDP) method to find the “right”
number of topics by assuming that the data has
a hierarchical structure. The HDP models were
then compared to the LDA ones on the same
dataset. (Zavitsanos et al., 2008) presented a
method to learn the right depth of an ontology de-
pending of the number of topics of LDA models.
The study presented by (Cao et al., 2009) is quite
similar to (Teh et al., 2004). The authors consider
the average correlation between pairs of topics at
each stage as the right number of topics.
All these methods assume that a document can
have only one representation since they consider
that finding the optimal topic model is the best so-
lution. Another solution would be to consider a set
of topic models to represent a document. Nonethe-
less, a multi-topic-based representation of a dia-
logue can involve a noisy variability due to the
mapping of a dialogue in each topic space. Indeed,
a dialogue does not share its content (i.e. words)
with each class composing the topic space. Thus,
a variability is added during the mapping pro-
cess. Another weakness of the multi-view repre-
sentation is the relation between classes in a topic
space. (Blei and Lafferty, 2006) show that classes
into a LDA topic space are correlated. More-
over, (Li and McCallum, 2006) consider a class
as a node of an acyclic graph and as a distribu-
tion over other classes contained in the same topic
space.
3 Multi-view representation of automatic
dialogue transcriptions in a
homogeneous space
The purpose of the considered application is the
identification of the major theme of a human-
human telephone conversation in the customer
445
care service (CCS) of the RATP Paris transporta-
tion system. The approach considered in this pa-
per focuses on modeling the variability between
different dialogues expressing the same theme t.
For this purpose, it is important to select relevant
features that represent semantic contents for the
theme of a dialogue. An attractive set of features
for capturing possible semantically relevant word
dependencies is obtained with Latent Dirichlet Al-
location (LDA) (Blei et al., 2003), as described in
section 2.
Given a training set of conversations D, a hid-
den topic space is derived and a conversation d
is represented by its probability in each topic of
the hidden space. Estimation of these probabili-
ties is affected by a variability inherent to the es-
timation of the model parameters. If many hidden
spaces are considered and features are computed
for each hidden space, it is possible to model the
estimation variability together with the variability
of the linguistic expression of a theme by different
speakers in different real-life situations. Even if
the purpose of the application is theme identifica-
tion and a training corpus annotated with themes is
available, supervised LDA (Griffiths and Steyvers,
2004) is not suitable for the proposed approach.
LDA is used only for producing different feature
sets used involved in statistical variability models.
In order to estimate the parameters of differ-
ent hidden spaces, a set of discriminative words
V is constructed as described in (Morchid et al.,
2014a). Each theme t contains a set of specific
words. Note that the same word may appear in
several discriminative word sets. All the selected
words are then merged without repetition to form
V .
Several techniques, such as Variational Meth-
ods (Blei et al., 2003), Expectation-propagation
(Minka and Lafferty, 2002) or Gibbs Sam-
pling (Griffiths and Steyvers, 2004), have been
proposed for estimating the parameters describ-
ing a LDA hidden space. Gibbs Sampling is
a special case of Markov-chain Monte Carlo
(MCMC) (Geman and Geman, 1984) and gives
a simple algorithm for approximate inference in
high-dimensional models such as LDA (Heinrich,
2005). This overcomes the difficulty to directly
and exactly estimate parameters that maximize the
likelihood of the whole data collection defined as:
p(W |
??
? ,
??
? ) =
?
w?W
p(
??
w |
??
? ,
??
? ) for the whole
data collection W knowing the Dirichlet parame-
ters
??
? and
??
? .
Gibbs Sampling allows us both to estimate the
LDA parameters in order to represent a new dia-
logue d with the r
th
topic space of size n, and to
obtain a feature vector V
z
r
d
of the topic representa-
tion of d. The j
th
feature V
z
r
j
d
= P (z
r
j
|d) (where
1 ? j ? n) is the probability of topic z
r
j
to be
generated by the unseen dialogue d in the r
th
topic
space of size n (see Figure 2) and V
w
z
r
j
= P (w|z
r
j
)
is the vector representation of a word into r.
Agent: Hello
Customer: Hello
Agent: Speaking ...
Customer: I call you because I 
was fined today, but I still have an 
imagine card suitable for zone 1 
[...] I forgot to use my navigo card 
for zone 2
Agent: You did not use your 
navigo card, that is why they give 
you a fine not for a zone issue [...]
Customer: Thanks, bye
Agent: bye
Agent
Customer
Conversations agent/customer 
customer care service of the 
Paris transportation system
TOPIC 1
P(w|z)           w
0.03682338236708009   card
0.026680126910873955 month
0.026007114700509565 navigo
0.01615229304874531   old
0.015527353139121238 agency
0.014229401019132776 euros
0.013123738102105566 imagine
TOPIC n
P(w|z)           w
0.06946564885496183   card
0.04045801526717557  fine
0.016793893129770993 transport
0.01603053435114504   woman
0.01450381679389313  fined
0.013740458015267175 aïe
0.012977099236641221 infraction
...
P(z |d) P(z |d)
...
1
n
Agent: Hello
Customer: Hello
Agent: Speaking ...
Customer: I call you because I 
was fined today, but I still have an 
imagine card suitable for zone 1 
[...] I forgot to use my navigo card 
for zone 2
Agent: You did not use your 
navigo card, that is why they give 
you a fine not for a zone issue [...]
Customer: Thanks, bye
Agent: bye
Agent
Customer
Conversations agent/customer 
customer care service of the 
Paris transportation system
TOPIC 1
P(w|z)           w
0.03682338236708009   card
0.026680126910873955 month
0.0260 7114700509565 navigo
0.01615229304874531   old
0.015527353139121238 agency
0.014229401019132776 euros
0.013123738102105566 imagine
TOPIC n
P(w|z)           w
0.06946564885496183   card
0.0404580152 717557  fine
0.016793893129770993 transport
0.01603053435114504   woman
0.01450381679389313  fined
0.013740458015267175 aïe
0.012977099236641221 infraction
...
P(z |d) P(z |d)
...
1
n
Figure 2: Example of a dialogue d mapped into a
topic space of size n.
In the LDA technique, topic z
j
, j is drawn
from a multinomial over ? which is drawn from
a Dirichlet distribution over
??
? . Thus, a set of
p topic spaces are learned using LDA by varying
the number of topics n to obtain p topic spaces of
size n. The number of topics n varies from 10 to
3, 010. Thus, a set of 3, 000 topic spaces is esti-
mated. This is high enough to generate, for each
dialogue, many feature sets for estimating the pa-
rameters of a variability model.
The next process allows us to obtain a homo-
geneous representation of transcription d for the
r
th
topic space r. The feature vector V
z
m
d
of
d is mapped to the common vocabulary space
V composed with a set of |V | discriminative
words (Morchid et al., 2014a) of size 166, to ob-
tain a new feature vector V
w
d,r
= {P (w|d)
r
}
w?V
446
of size |V | for the r
th
topic space r of size nwhere
the i
th
(0 ? i ? |V |) feature is:
V
w
i
d,r
= P (w
i
|d)
=
n
?
j=1
P (w
i
|z
r
j
)P (z
r
j
|d)
=
n
?
j=1
V
w
i
z
r
j
× V
z
r
j
d
=
?
???
V
w
i
z
r
,
???
V
z
r
d
?
where ?·, ·? is the inner product, ? being the fre-
quency of the term w
i
in d, V
w
i
z
r
j
= P (w
i
|z
j
) and
V
z
r
j
d
= P (z
j
|d) evaluated using Gibbs Sampling
in the topic space r.
4 Compact multi-view representation
In this section, an i-vector-based method to
represent automatic transcriptions is presented.
Initially introduced for speaker recognition, i-
vectors (Kenny et al., 2008) have become very
popular in the field of speech processing and re-
cent publications show that they are also reli-
able for language recognition (Mart?nez et al.,
2011) and speaker diarization (Franco-Pedroso et
al., 2010). I-vectors are an elegant way of re-
ducing the imput space dimensionality while re-
taining most of the relevant information. The
technique was originally inspired by the Joint
Factor Analysis framework (Kenny et al., 2007).
Hence, i-vectors convey the speaker characteris-
tics among other information such as transmission
channel, acoustic environment or phonetic content
of speech segments. The next sections describe
the i-vector extraction process, the application of
this compact representation to textual documents
(called c-vector), and the vector transformation
with the EFR method and the Mahalanobis met-
ric.
4.1 Total variability space definition
I-vector extraction could be seen as a probabilistic
compression process that reduces the dimension-
ality of speech super-vectors according to a linear-
Gaussian model. The speech (of a given speech
recording) super-vector m
s
of concatenated GMM
means is projected in a low dimensionality space,
named Total Variability space, with:
m
(h,s)
= m+ Tx
(h,s)
, (1)
where m is the mean super-vector of the UBM
1
.
T is a low rank matrix (MD × R), where M is
the number of Gaussians in the UBM and D is the
cepstral feature size, which represents a basis of
the reduced total variability space. T is named To-
tal Variability matrix; the components of x
(h,s)
are
the total factors which represent the coordinates of
the speech recording in the reduced total variabil-
ity space called i-vector (i for identification).
4.2 From i-vector speaker identification to
c-vector textual document classification
The proposed approach uses i-vectors to model
transcription representation through each topic
space in a homogeneous vocabulary space. These
short segments are considered as basic semantic-
based representation units. Indeed, vector V
w
d
rep-
resents a segment or a session of a transcription d.
In the following, (d, r) will indicate the dialogue
representation d in the topic space r. In our model,
the segment super-vector m
(d,r)
of a transcription
d knowing a topic space r is modeled:
m
(d,r)
= m+ Tx
(d,r)
(2)
where x
(d,r)
contains the coordinates of the topic-
based representation of the dialogue in the re-
duced total variability space called c-vector (c for
classification).
Let N
(d,r)
and X
(d,r)
be two vectors containing
the zero order and first order dialogue statistics re-
spectively. The statistics are estimated against the
UBM:
N
r
[g] =
?
t?r
?
g
(t); {X
(d,r)
}
[g]
=
?
t?(d,r)
?
g
(t) · t
(3)
where ?
g
(t) is the a posteriori probability of Gaus-
sian g for the observation t. In the equation,
?
t?(d,r)
represents the sum over all the frames be-
longing to the dialogue d.
Let X
(d,r)
be the state dependent statistics de-
fined as follows:
{X
(d,r)
}
[g]
={X
(d,r)
}
[g]
?m
[g]
·
?
(d,r)
N
(d,r)
[g]
(4)
Let L
(d,r)
be a R × R matrix, and B
(d,r)
a vector
1
The UBM is a GMM that represents all the possible ob-
servations.
447
Algorithm 1: Estimation algorithm of T and
latent variable x.
For each dialogue d mapped into the topic
space r: x
(d,r)
? 0, T? random ;
Estimate statistics: N
(d,r)
, X
(d,r)
(eq.3);
for i = 1 to nb iterations do
for all d and r do
Center statistics: X
(d,r)
(eq.4);
Estimate L
(d,r)
and B
(d,r)
(eq.5);
Estimate x
(d,r)
(eq.6);
end
Estimate matrix T (eq. 7 and 8) ;
end
of dimension R, both defined as:
L
(d,r)
= I +
?
g?UBM
N
(d,r)
[g] · {T}
t
[g]
·?
?1
[g]
· {T}
[g]
B
(d,r)
=
?
g?UBM
{T}
t
[g]
·?
?1
g
· {X
(d,r)
}
[g]
,
(5)
By using L
(d,r)
and B
(d,r)
, x
(d,r)
can be obtained
using the following equation:
x
(d,r)
= L
?1
(d,r)
· B
(d,r)
(6)
The matrix T can be estimated line by line, with
{T}
i
[g]
being the i
th
line of {T}
[g]
then:
T
i
[g]
= LU
?1
g
· RU
i
g
, (7)
where RU
i
g
and LU
g
are given by:
LU
g
=
?
(d,r)
L
?1
(d,r)
+ x
(d,r)
x
t
(d,r)
· N
(d,r)
[g]
RU
i
g
=
?
(d,r)
{X
(d,r)
}
[i]
[g]
· x
(d,r)
(8)
Algorithm 1 presents the method adopted to es-
timate the multi-view variability dialogue matrix
with the above developments where the standard
likelihood function can be used to assess the con-
vergence. One can refer to (Matrouf et al., 2007)
to find out more about the implementation of the
factor analysis.
C-vector representation suffers from 3 raised c-
vector issues: (i) the c-vectors x of equation 2
have to be theoretically distributed among the nor-
mal distribution N (0, I), (ii) the “radial” effect
should be removed, and (iii) the full rank total
factor space should be used to apply discriminant
transformations. The next section presents a solu-
tion to these 3 problems.
4.3 C-vector standardization
A solution to standardize c-vectors has been de-
veloped in (Bousquet et al., 2011). The authors
proposed to apply transformations for training and
test transcription representations. The first step is
to evaluate the empirical mean x and covariance
matrix V of the training c-vector. Covariance ma-
trix V is decomposed by diagonalization into:
PDP
T
(9)
where P is the eigenvector matrix of V and D is the
diagonal version of V. A training i-vector x
(d,r)
is
transformed in x
?
(d,r)
as follows:
x
?
(d,r)
=
D
?
1
2
P
T
(x
(d,r)
? x)
?
(x
(d,r)
? x)
T
V
?1
(x
(d,r)
? x)
(10)
The numerator is equivalent by rotation to
V
?
1
2
(x
(d,r)
? x) and the Euclidean norm of x
?
(d,r)
is equal to 1. The same transformation is applied
to the test c-vectors, using the training set parame-
ters x and mean covariance Vas estimations of the
test set of parameters.
Figure 3 shows the transformation steps: Fig-
ure 3-(a) is the original training set; Figure 3-
(b) shows the rotation applied to the initial train-
ing set around the principal axes of the total vari-
ability when P
T
is applied; Figure 3-(c) shows
the standardization of c-vectors when D
?
1
2
is
applied; and finally, Figure 3-(d) shows the c-
vector x
?
(d,r)
on the surface area of the unit hyper-
sphere after a length normalization by a division
of
?
(x
(d,r)
? x)
T
V
?1
(x
(d,r)
? x).
5 Experimental Protocol
The proposed c-vector representation of automatic
transcriptions is evaluated in the context of the
theme identification of a human-human telephone
conversation in the customer care service (CCS)
of the RATP Paris transportation system. The met-
ric used to identify of the best theme is the Maha-
lanobis metric.
5.1 Theme identification task
The DECODA project corpus (Bechet et al., 2012)
was designed to perform experiments on the iden-
tification of conversation themes. It is composed
of 1,514 telephone conversations, corresponding
to about 74 hours of signal, split into a training
448
l ll
l
l ll
l
lll
l
l
l
l
l
l ll
l
l
l
l l l
l
l
l
l
l
ll
l
ll
ll ll
ll l
l
l
l
l l
?3 ?2 ?1 0 1 2 3
?
2
?
1
0
1
2
a.Inital: M
l ll
ll
ll l
ll
l
l
ll ll l lll
l
l
l
ll
l
l ll ll
l
ll
ll l ll
ll lll l
?3 ?2 ?1 0 1 2 3
?
2
?
1
0
1
2
b.Rotation: Pt
l
l
l
l
l ll l
ll
l
l
ll ll l lll
l
l
l
ll
l
l l
l ll
l
ll
ll
l
l
l
l
ll lll l
?3 ?2 ?1 0 1 2 3
?
2
?
1
0
1
2
c.Standardization: D?1 2
l l l
ll
ll l
l l
l ll
l
l
l l
l
ll llll l
l
?3 ?2 ?1 0 1 2 3
?
2
?
1
0
1
2
d.Norm: (x ? x)tV?1(x ? x)
Figure 3: Effect of the standardization with the EFR algorithm.
set (740 dialogues), a development set (175 dia-
logues) and a test set (327 dialogues), and manu-
ally annotated with 8 conversation themes: prob-
lems of itinerary, lost and found, time schedules,
transportation cards, state of the traffic, fares, in-
fractions and special offers.
An LDA model allowed us to elaborate 3,000
topics spaces by varying the number of topics from
10 to 3,010. A topic space having less than 10
topics is not suitable for a corpus of more than 700
dialogues (training set). For each theme {C
i
}
8
i=1
,
a set of 50 specific words is identified. All the
selected words are then merged without repetition
to compose V , which is made of 166 words. The
topic spaces are made with the LDA Mallet Java
implementation
2
.
The LIA-Speeral ASR system (Linar`es et al.,
2007) is used for the experiments. Acoustic model
parameters were estimated from 150 hours of
speech in telephone conditions. The vocabulary
contains 5,782 words. A 3-gram language model
(LM) was obtained by adapting a basic LM with
the training set transcriptions. A “stop list” of 126
words
3
was used to remove unnecessary words
(mainly function words), which results in a Word
Error Rate (WER) of 33.8% on the training, 45.2%
on the development, and 49.5% on the test. These
2
http://mallet.cs.umass.edu/
3
http://code.google.com/p/stop-words/
high WER are mainly due to speech disfluencies
and to adverse acoustic environments (for exam-
ple, calls from noisy streets with mobile phones).
5.2 Mahalanobis metric
Given a new observation x, the goal of the task is
to identify the theme belonging to x. Probabilistic
approaches ignore the process by which c-vectors
were extracted and they pretend instead they were
generated by a prescribed generative model. Once
a c-vector is obtained from a dialogue, its repre-
sentation mechanism is ignored and it is regarded
as an observation from a probabilistic generative
model. The Mahalanobis scoring metric assigns a
dialogue d with the most likely theme C. Given
a training dataset of dialogues, let W denote the
within dialogue covariance matrix defined by:
W =
K
?
k=1
n
t
n
W
k
=
1
n
K
?
k=1
n
t
?
i=0
(
x
k
i
? x
k
)(
x
k
i
? x
k
)
t
(11)
where W
k
is the covariance matrix of the k
th
theme C
k
, n
t
is the number of utterances for the
theme C
k
, n is the total number of dialogues, and
x
k
is the centroid (mean) of all dialogues x
k
i
ofC
k
.
449
Each dialogue does not contribute to the co-
variance in an equivalent way. For this reason,
the term
n
t
n
is introduced in equation 11. If ho-
moscedasticity (equality of the class covariances)
and Gaussian conditional density models are as-
sumed, a new observation x from the test dataset
can be assigned to the most likely themeC
k
Bayes
us-
ing the classifier based on the Bayes decision rule:
C
k
Bayes
= argmax
k
{N (x | x
k
,W)}
= argmax
k
{
?
1
2
(x? x
k
)
t
W
?1
(x? x
k
) + a
k
}
where W is the within theme covariance ma-
trix defined in eq. 11; N denotes the normal dis-
tribution and a
k
= log (P (C
k
)). It is noted that,
with these assumptions, the Bayesian approach is
similar to Fisher’s geometric approach: x is as-
signed to the class of the nearest centroid, accord-
ing to the Mahalanobis metric (Xing et al., 2002)
of W
?1
:
C
k
Bayes
= argmax
k
{
?
1
2
||x? x
k
||
2
W
?1
+ a
k
}
6 Experiments and results
The proposed c-vector approach is applied to
the same classification task and corpus proposed
in (Morchid et al., 2014a; Morchid et al., 2014b;
Morchid et al., 2013) (state-of-the-art in text clas-
sification in (Morchid et al., 2014a)). Experiments
are conducted using the multiple topic spaces esti-
mated with an LDA approach. From these mul-
tiple topic spaces, a classical way is to find the
one that reaches the best performance. Figure 4
presents the theme classification performance ob-
tained on the development and test sets using vari-
ous topic-based representation configurations with
the EFR normalization algorithm (baseline).
For sake of comparison, experiments are con-
ducted using the automatic transcriptions only
(ASR) only. The conditions indicated by the ab-
breviations between parentheses are considered
for the development (Dev) and the test (Test) sets.
Only homogenous conditions (ASR for both
training and validations sets) are considered in this
study. Authors in (Morchid et al., 2014a) notice
that results collapse dramatically when heteroge-
nous conditions are employed (TRS or TRS+ASR
for training set and ASR for validation set).
First of all, we can see that this baseline ap-
proach reached a classification accuracy of 83%
and 76%, respectively on the development and the
test sets. However, we note that the classifica-
tion performance is rather unstable, and may com-
pletely change from a topic space configuration to
another. The gap between the lower and the higher
classification results is also important, with a dif-
ference of 25 points on the development set (the
same trend is observed on the test set). As a result,
finding the best topic space size seems crucial for
this classification task, particularly in the context
of highly imperfect automatic dialogue transcrip-
tions containing more than one theme.
The topic space that yields the best accuracy
with the baseline method (n = 15 topics) is pre-
sented in Figure 5. This figure presents each of the
15 topics and their 10 most representative words
(highest P (w|z)). Several topics contain more or
less the same representative words, such as topics
3, 6 and 9. This figure points out some interesting
topics that allow us to distinguish a theme from the
others. For example:
• topics 2, 10 and 15 represent some words re-
lated to itinerary problems,
• the transportation cards theme is mostly rep-
resented in topic 4 and 15 (Imagine and Nav-
igo are names of transportation cards),
• the words which represent the time schedules
theme are contained in topic 5,6,7 and less in
topic 9,
• state of the traffic could be discussed with
words such as: departure, line, service, day.
These words and others are contained in topic
13,
• topics 4 and 12 are related to the infractions
theme with to words fine, pass, zone or ticket,
• but topic 12 could be related to theme fares
or special offers as well .
Table 1 presents results obtained with the pro-
posed c-vector approach coupled with the EFR al-
gorithm. We can firstly note that this compact rep-
resentation allows it to outperform the best topic
space configuration (baseline), with a gain of 9.4
points on the development data and of 9 points on
the test data. Moreover, if we consider the differ-
ent c-vector configurations with the development
450
15 500 1500 2000 2497 3010
50
60
70
80
90
Max = 83.3
Min = 58.6
(a) Accuracy with the development set
Items by varying the granularity 10 ? n ? 3010
A
c
c
u
r
a
c
y
(
%
)
15 500 825 1500 2000 3010
50
60
70
80
90
Max = 76.0
Min = 56.8
(b) Accuracy with the test set
Items by varying the granularity 10 ? n ? 3010
A
c
c
u
r
a
c
y
(
%
)
Figure 4: Theme classification accuracies using various topic-based representations with EFR normal-
ization (baseline) on the development and test sets (X-coordinates start at 10 indeed, but to show the best
configuration point (15), the origine (10) has been removed).
Table 1: Theme classification accuracy (%) with different c-vectors and GMM-UBM sizes.
DEV TEST
c-vector Number of Gaussians in GMM-UBM
size 32 64 128 256 32 64 128 256
60 88.8 86.5 91.2 90.6 85.0 82.6 83.5 84.7
100 91.2 92.4 92.4 87.7 86.0 85.0 83.5 84.7
120 89.5 92.2 89.5 87.7 85.0 83.5 85.4 84.1
Table 2: Maximum (Max), minimum (Min) and Difference (Max ?Min) theme classification accu-
racies (%) using the baseline and the proposed c-vector approaches.
Max Min Difference
Method DEV TEST DEV TEST DEV TEST
baseline 83.3 76.0 58.6 56.8 14.7 20.8
c-vector 92.4 85.0 86.5 82.6 5.9 2.4
and test sets, the gap between accuracies is much
smaller: classification accuracy does not go be-
low 82.6%, while it reached 56% for the worst
topic-based configuration. Indeed, as shown in Ta-
ble 2, the difference between the maximum and
the minimum theme classification accuracies is of
20% using the baseline approach while it is only
of 2.4% using the c-vector method.
We can conclude that this original c-vector ap-
proach allows one to better handle the variabilities
451
w P(w|z)
TOPIC 1
line
bag
metro
lost
hours
name
found
thing
object
instant
0.028
0.027
0.018
0.017
0.015
0.013
0.012
0.012
0.011
0.009
w P(w|z)
TOPIC 2
bus
direction
road
stop
sixty
five
three
go
hour
station
0.038
0.027
0.022
0.021
0.018
0.017
0.016
0.013
0.012
0.010
w P(w|z)
TOPIC 3
bus
hours
twenty
four
minutes
onto
old
know
sunday
line
0.024
0.023
0.019
0.014
0.014
0.013
0.010
0.010
0.010
0.008
w P(w|z)
TOPIC 4
card
pass
navigo
month
euro
go
agency
mail
fine
address
0.040
0.032
0.024
0.022
0.021
0.018
0.016
0.012
0.010
0.009
w P(w|z)
TOPIC 5
line
know
station
traffic
hour
say
level
time
today
instant
0.029
0.027
0.024
0.021
0.017
0.015
0.014
0.014
0.012
0.011
w P(w|z)
TOPIC 6
bus
hour
hundred
line
ten
old
mister
morning
lost
bag
0.030
0.021
0.020
0.019
0.018
0.016
0.015
0.015
0.014
0.012
w P(w|z)
TOPIC 7
ticket
say
old
bus
issue
never
always
time
validate
normal
0.026
0.017
0.016
0.015
0.015
0.014
0.014
0.013
0.012
0.011
w P(w|z)
TOPIC 8
saint
plus
say
road
level
station
train
city
four
far
0.018
0.017
0.013
0.013
0.012
0.011
0.011
0.010
0.010
0.009
w P(w|z)
TOPIC 9
hour
four
ten
bus
hundred
miss
zero
line
five
six
0.041
0.039
0.037
0.036
0.024
0.024
0.022
0.020
0.018
0.017
w P(w|z)
TOPIC 10
station
saint
direction
orly
take
madame
metro
line
north
bus
0.041
0.036
0.024
0.020
0.015
0.015
0.013
0.012
0.012
0.011
w P(w|z)
TOPIC 11
madame
service
address
mail
metro
paris
old
stop
lac
dock
0.028
0.027
0.022
0.021
0.020
0.019
0.018
0.018
0.016
0.015
w P(w|z)
TOPIC 12
paris
euro
zone
ticket
fare
card
buy
station
noisy
week
0.025
0.025
0.017
0.015
0.014
0.014
0.013
0.013
0.010
0.010
w P(w|z)
TOPIC 13
service
old
line
madame
mister
ask
internet
departure
day
client
0.034
0.027
0.018
0.017
0.014
0.014
0.013
0.013
0.012
0.011
w P(w|z)
TOPIC 14
bus
direction
metro
line
stop
madame
saint
old
road
door
0.040
0.023
0.022
0.017
0.016
0.015
0.015
0.014
0.014
0.014
w P(w|z)
TOPIC 15
number
integral
card
agency
imagine
subscription
navigo
old
eleven
call
0.040
0.030
0.024
0.023
0.018
0.018
0.017
0.014
0.013
0.012
Figure 5: Topic space (15 topics) that obtains the best accuracy with the baseline system (see Fig. 4).
contained in dialogue conversations: in a classi-
fication context, better accuracy can be obtained
and the results can be more consistent when vary-
ing the c-vector size and the number of Gaussians.
7 Conclusions
This paper presents an original multi-view repre-
sentation of automatic speech dialogue transcrip-
tions, and a fusion process with the use of a factor
analysis method called i-vector. The first step of
the proposed method is to represent a dialogue in
multiple topic spaces of different sizes (i.e. num-
ber of topics). Then, a compact representation
of the dialogue from the multiple views is pro-
cessed to compensate the vocabulary and the vari-
ability of the topic-based representations. The ef-
fectiveness of the proposed approach is evaluated
in a classification task of theme dialogue identifi-
cation. Thus, the architecture of the system iden-
tifies conversation themes using the i-vector ap-
proach. This compact representation was initially
developed for speaker recognition and we showed
that it can be successfully applied to a text clas-
sification task. Indeed, this solution allowed the
system to obtain better classification accuracy than
with the use of the classical best topic space con-
figuration. In fact, we highlighted that this original
compact version of all topic-based representations
of dialogues, called c-vector in this work, coupled
with the EFR normalization algorithm, is a better
solution to deal with dialogue variabilities (high
word error rates, bad acoustic conditions, unusual
word vocabulary, etc). This promising compact
representation allows us to effectively solve both
the difficult choice of the right number of topics
and the multi-theme representation issue of partic-
ular textual documents. Finally, the classification
accuracy reached 85% with a gain of 9 points com-
pared to usual baseline (best topic space configu-
ration). In a future work, we plan to evaluate this
new representation of textual documents in other
information retrieval tasks, such as keyword ex-
traction or automatic summarization systems.
Acknowledgements
We thank the anonymous reviewers for their help-
ful comments. This work was funded by the
SUMACC and ContNomina projects supported by
the French National Research Agency (ANR) un-
der contracts ANR-10-CORD-007 and ANR-12-
BS02-0009.
452
References
R. Arun, Venkatasubramaniyan Suresh, C.E.
Veni Madhavan, and Musti Narasimha Murty.
2010. On finding the natural number of topics
with latent dirichlet allocation: Some observations.
In Advances in Knowledge Discovery and Data
Mining, pages 391–402. Springer.
Frederic Bechet, Benjamin Maza, Nicolas Bigouroux,
Thierry Bazillon, Marc El-Beze, Renato De Mori,
and Eric Arbillot. 2012. Decoda: a call-
centre human-human spoken conversation corpus.
LREC’12.
Jerome R. Bellegarda. 1997. A latent semantic analy-
sis framework for large-span language modeling. In
Fifth European Conference on Speech Communica-
tion and Technology.
Jerome R. Bellegarda. 2000. Exploiting latent se-
mantic information in statistical language modeling.
Proceedings of the IEEE, 88(8):1279–1296.
David M. Blei and John Lafferty. 2006. Correlated
topic models. Advances in neural information pro-
cessing systems, 18:147.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. The Journal of
Machine Learning Research, 3:993–1022.
Pierre-Michel Bousquet, Driss Matrouf, and Jean-
Franc¸ois Bonastre. 2011. Intersession compensa-
tion and scoring methods in the i-vectors space for
speaker recognition. In Interspeech, pages 485–488.
Juan Cao, Tian Xia, Jintao Li, Yongdong Zhang, and
Sheng Tang. 2009. A density-based method for
adaptive lda model selection. Neurocomputing,
72(7):1775–1781.
Scott Deerwester, Susan T. Dumais, George W. Fur-
nas, Thomas K. Landauer, and Richard Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American society for information science,
41(6):391–407.
Najim Dehak, Patrick J. Kenny, R´eda Dehak, Pierre
Dumouchel, and Pierre Ouellet. 2011. Front-end
factor analysis for speaker verification. IEEE Trans-
actions on Audio, Speech, and Language Process-
ing, 19(4):788–798.
Javier Franco-Pedroso, Ignacio Lopez-Moreno, Doro-
teo T Toledano, and Joaquin Gonzalez-Rodriguez.
2010. Atvs-uam system description for the audio
segmentation and speaker diarization albayzin 2010
evaluation. In FALA VI Jornadas en Tecnologa del
Habla and II Iberian SLTech Workshop, pages 415–
418.
Daniel Garcia-Romero and Carol Y Espy-Wilson.
2011. Analysis of i-vector length normalization in
speaker recognition systems. In Interspeech, pages
249–252.
Stuart Geman and Donald Geman. 1984. Stochas-
tic relaxation, gibbs distributions, and the bayesian
restoration of images. IEEE Transactions on Pattern
Analysis and Machine Intelligence, (6):721–741.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
academy of Sciences of the United States of Amer-
ica, 101(Suppl 1):5228–5235.
Gregor Heinrich. 2005. Parameter estimation
for text analysis. Web: http://www. arbylon.
net/publications/text-est. pdf.
Thomas Hofmann. 1999. Probabilistic latent semantic
analysis. In Proc. of Uncertainty in Artificial Intelli-
gence, UAI ’ 99, page 21. Citeseer.
Thomas Hofmann. 2001. Unsupervised learning
by probabilistic latent semantic analysis. Machine
Learning, 42(1):177–196.
Patrick Kenny, Gilles Boulianne, Pierre Ouellet, and
Pierre Dumouchel. 2007. Joint factor analysis ver-
sus eigenchannels in speaker recognition. IEEE
Transactions on Audio, Speech, and Language Pro-
cessing, 15(4):1435–1447.
Patrick Kenny, Pierre Ouellet, Najim Dehak, Vishwa
Gupta, and Pierre Dumouchel. 2008. A study of in-
terspeaker variability in speaker verification. IEEE
Transactions on Audio, Speech, and Language Pro-
cessing, 16(5):980–988.
Wei Li and Andrew McCallum. 2006. Pachinko allo-
cation: Dag-structured mixture models of topic cor-
relations.
Georges Linar`es, Pascal Noc´era, Dominique Massonie,
and Driss Matrouf. 2007. The lia speech recogni-
tion system: from 10xrt to 1xrt. In Text, Speech and
Dialogue, pages 302–308. Springer.
David Mart?nez, Oldrich Plchot, Luk´as Burget, On-
drej Glembek, and Pavel Matejka. 2011. Language
recognition in ivectors space. Interspeech, pages
861–864.
Driss Matrouf, Nicolas Scheffer, Benoit G.B. Fauve,
and Jean-Francois Bonastre. 2007. A straightfor-
ward and efficient implementation of the factor anal-
ysis model for speaker verification. In Interspeech,
pages 1242–1245.
Thomas Minka and John Lafferty. 2002. Expectation-
propagation for the generative aspect model. In
Proceedings of the Eighteenth conference on Uncer-
tainty in artificial intelligence, pages 352–359. Mor-
gan Kaufmann Publishers Inc.
Mohamed Morchid, Georges Linar`es, Marc El-Beze,
and Renato De Mori. 2013. Theme identification in
telephone service conversations using quaternions of
speech features. In Interspeech. ISCA.
453
Mohamed Morchid, Richard Dufour, Pierre-Michel
Bousquet, Mohamed Bouallegue, Georges Linar`es,
and Renato De Mori. 2014a. Improving dialogue
classification using a topic space representation and
a gaussian classifier based on the decision rule. In
ICASSP. IEEE.
Mohamed Morchid, Richard Dufour, and Georges
Linar`es. 2014b. A LDA-Based Topic Classification
Approach from Highly Imperfect Automatic Tran-
scriptions. In LREC.
Douglas A. Reynolds and Richard C. Rose. 1995.
Robust text-independent speaker identification using
gaussian mixture speaker models. IEEE Transac-
tions on Speech and Audio Processing, 3(1):72–83.
Gerard Salton. 1989. Automatic text processing: the
transformation. Analysis and Retrieval of Informa-
tion by Computer.
Yoshimi Suzuki, Fumiyo Fukumoto, and Yoshihiro
Sekiguchi. 1998. Keyword extraction using term-
domain interdependence for dictation of radio news.
In 17th international conference on Computational
linguistics, volume 2, pages 1272–1276. ACL.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal,
and David M. Blei. 2004. Sharing clusters among
related groups: Hierarchical dirichlet processes. In
NIPS.
Eric P. Xing, Michael I. Jordan, Stuart Russell, and
Andrew Ng. 2002. Distance metric learning with
application to clustering with side-information. In
Advances in neural information processing systems,
pages 505–512.
Elias Zavitsanos, Sergios Petridis, Georgios Paliouras,
and George A. Vouros. 2008. Determining auto-
matically the size of learned ontologies. In ECAI,
volume 178, pages 775–776.
454
