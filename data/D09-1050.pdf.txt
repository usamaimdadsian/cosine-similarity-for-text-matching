Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 478–486,
Singapore, 6-7 August 2009. c©2009 ACL and AFNLP
Acquiring Translation Equivalences of Multiword Expressions by 
Normalized Correlation Frequencies 
Ming-Hong Bai1,2 Jia-Ming You1 Keh-Jiann Chen1 Jason S. Chang2 
1 Institute of Information Science, Academia Sinica, Taiwan 
2 Department of Computer Science, National Tsing-Hua University, Taiwan 
mhbai@sinica.edu.tw, swimming@hp.iis.sinica.edu.tw, 
kchen@iis.sinica.edu.tw, jschang@cs.nthu.edu.tw 
 
Abstract 
In this paper, we present an algorithm for ex-
tracting translations of any given multiword 
expression from parallel corpora. Given a 
multiword expression to be translated, the 
method involves extracting a short list of tar-
get candidate words from parallel corpora 
based on scores of normalized frequency, 
generating possible translations and filtering 
out common subsequences, and selecting the 
top-n possible translations using the Dice 
coefficient. Experiments show that our ap-
proach outperforms the word alignment-
based and other naive association-based me-
thods. We also demonstrate that adopting the 
extracted translations can significantly im-
prove the performance of the Moses machine 
translation system. 
1 Introduction 
Translation of multiword expressions (MWEs), 
such as compound words, phrases, collocations 
and idioms, is important for many NLP tasks, 
including the techniques are helpful for dictio-
nary compilation, cross language information 
retrieval, second language learning, and machine 
translation. (Smadja et al., 1996; Gao et al., 2002; 
Wu and Zhou, 2003). However, extracting exact 
translations of MWEs is still an open problem, 
possibly because the senses of many MWEs are 
not compositional (Yamamoto and Matsumoto, 
2000), i.e., their translations are not composi-
tions of the translations of individual words. For 
example, the Chinese idiom ???? should be 
translated as “turn a blind eye,” which has no 
direct relation with respect to the translation of 
each constituent (i.e., “to sit”, “to see” and “to 
ignore”) at the word level.  
Previous SMT systems (e.g., Brown et al., 
1993) used a word-based translation model 
which assumes that a sentence can be translated 
into other languages by translating each word 
into one or more words in the target language. 
Since many concepts are expressed by idiomatic 
multiword expressions instead of single words, 
and different languages may realize the same 
concept using different numbers of words (Ma et 
al., 2007; Wu, 1997), word alignment based me-
thods, which are highly dependent on the proba-
bility information at the lexical level, are not 
well suited for this type of translation.  
To address the above problem, some methods 
have been proposed for extending word align-
ments to phrase alignments. For example, Och et 
al. (1999) proposed the so-called grow-diag-
final heuristic method for extending word 
alignments to phrase alignments. The method is 
widely used and has achieved good results for 
phrase-based statistical machine translation. 
(Och et al., 1999; Koehn et al., 2003; Liang et al., 
2006). Instead of using heuristic rules, Ma et al. 
(2008) showed that syntactic information, e.g., 
phrase or dependency structures, is useful in ex-
tending the word-level alignment. However, the 
above methods still depend on word-based 
alignment models, so they are not well suited to 
extracting the translation equivalences of seman-
tically opaque MWEs due to the lack of word 
level relations between the translational corres-
pondences. Moreover, the aligned phrases are 
not precise enough to be used in many NLP ap-
plications like dictionary compilation, which 
require high quality translations. 
Association-based methods, e.g., the Dice 
coefficient, are widely used to extract transla-
tions of MWEs. (Kupiec, 1993; Smadja et al., 
1996; Kitamura and Matsumoto, 1996; Yama-
moto and Matsumoto, 2000; Melamed, 2001). 
The advantage of such methods is that associa-
tion relations are established at the phrase level 
instead of the lexical level, so they have the po-
tential to resolve the above-mentioned transla-
tion problem. However, when applying associa-
tion-based methods, we have to consider the fol-
lowing complications. The first complication, 
which we call the contextual effect, causes the 
extracted translation to contain noisy words. For 
478
example, translations of the Chinese idiom ??
?? (best of both worlds) extracted by a naive 
association-based method may contain noisy 
collocation words like difficult, try and cannot, 
which are not part of the translation of the idiom. 
They are actually translations of its collocation 
context, such as ??(difficult), ??(try), and 
??(cannot). This problem arises because naive 
association methods do not deal with the effect 
of strongly collocated contexts carefully. If we 
can incorporate lexical-level information to dis-
count the noisy collocation words, the contextual 
effect could be resolved. 
 
English (y) fy fx,y Dice(x,y)
quote out of context 22 19 0.56 
take out of context 17 11 0.35 
interpret out of context 2 2 0.08 
out of context 53 32 0.65 
Table 1. The Dice coefficient tends to select a com-
mon subsequence of translations. (The frequency of
???? ,fx, is 46.) 
 
The second complication, which we call the 
common subsequence problem, is that the Dice 
coefficient tends to select the common subse-
quences of a set of similar translations instead of 
the full translations. Consider the translations of 
???? (quote out of context) shown in the 
first three rows of Table 1. The Dice coefficient 
of each translation is smaller than that of the 
common subsequence “out of context” in the last 
row. If we can tell common subsequence apart 
from correct translations, the common subse-
quence problem could be resolved. 
In this paper, we propose an improved preci-
sion method for extracting MWE translations 
from parallel corpora. Our method is similar to 
that of Smadja et al. (1996), except that we in-
corporate lexical-level information into the asso-
ciation-based method. The algorithm works ef-
fectively for various types of MWEs, such as 
phrases, single words, rigid word sequences (i.e., 
no gaps) and gapped word sequences. Our expe-
riment results show that the proposed translation 
extraction method outperforms word alignment-
based methods and association-based methods. 
We also demonstrate that precise translations 
derived by our method significantly improve the 
performance of the Moses machine translation 
system. 
The remainder of this paper is organized as 
follows. Section 2 describes the methodology for   
extracting translation equivalences of MWEs. 
Section 3 describes the experiment and presents 
the results. In Section 4, we consider the appli-
cation of our results to machine translation. Sec-
tion 5 contains some concluding remarks. 
2 Extracting Translation Equivalences   
Our MWE translation extraction method is simi-
lar to the two-phase approach proposed by 
Smadja et al. (1996). The two phases can be 
briefly described as follows:  
Phase 1: Extract candidate words correlated to 
the given MWE from parallel text. 
Phase 2:  
1. Generate possible translations for the 
MWE by combining the candidate words. 
2. Select possible translations by the Dice 
coefficient. 
We propose an association function, called the 
normalized correlation frequency, to extract 
candidate words in the phase 1. This method 
incorporates lexical-level information with asso-
ciation measure to overcome the contextual ef-
fect. In phase 2, we also propose a weighted fre-
quency function to filter out false common sub-
sequences from possible translations. The filter-
ing step is applied before the translation select-
ing step of phase 2.   
Before describing our extraction method, we 
define the following important terms used 
throughout the paper. 
Focused corpus (FC): This is the corpus 
created for each targeted MWE. It is a subset of 
the original parallel corpora, and is comprised of 
the selected aligned sentence pairs that contain 
the source MWE and its translations. 
Candidate word list (CW): A list of extracted 
candidate words for the translations of the 
source MWE. 
2.1 Selecting Candidate Words 
For a source MWE, we try to extract from the 
FC a set of k candidate words CW that are high-
ly correlated to the source MWE. We then as-
sume that the target translation is a combination 
of some words in CW. As noted by Smadja et al. 
(1996), this two-step approach drastically reduc-
es the search space. 
However, translations of collocated context 
words in the source word sequence create noisy 
candidate words, which might cause incorrect 
extraction of target translations by naive statis-
tical correlation measures, such as the Dice coef-
479
ficient used by Smadja et al. (1996). The need to 
avoid this context effect motivates us to propose 
a candidate word selection method that uses the 
normalized correlation frequency as an associa-
tion measure. 
The rationale behind the proposed method is 
as follows. When counting the word frequency, 
each word in the target corpus normally contri-
butes a frequency count of one. However, we are 
only interested in the word counts correlated to a 
MWE. Therefore, intuitively, we define the 
normalized count of a target word e as the trans-
lation probability of e given the MWE.  
We explain the concept of normalizing the 
correlation count in Section 2.1.1 and the com-
putation of the normalized correlation frequency 
in Section 2.1.2. 
2.1.1 Normalizing Correlation Count 
We propose an association measure called the 
normalized correlation frequency, which ranks 
the association strength of target words with the 
source MWE. For ease of explanation, we use 
the following notations: let f=f1,f2,…,fm and 
e=e1,e2,…,en be a pair of parallel Chinese and 
English sentences; and let w=t1,t2,…,tr be the 
Chinese source MWE. Hence, w is a subse-
quence of f.  
When counting the word frequency, each 
word in the target corpus normally contributes a 
frequency count of one. However, since we are 
interested in the word counts that correlate to w, 
we adopt the concept of the translation model 
proposed by Brown et al (1993). Each word e in 
a sentence e might be generated by some words, 
denoted as r, in the source sentence f. If r is 
non-empty the relation between r and w should 
fit one of the following cases: 
 
1) All words in r belong to w, i.e., wr ? , so 
we say that e is only generated by w. 
2) No words in r belong to w, i.e., wfr ?? , 
so we say that e is only generated by context 
words.  
3) Some words in r belong to w, while others 
are context words. 
 
Intuitively, In Cases 1 and 2, the correlation 
count of an instance e should be 1 and 0 respec-
tively. In Case 3, the normalized count of e is 
the expected frequency generated by w divided 
by the expected frequency generated by f. With 
that in mind, we define the weighted correlation 
count, wcc, as follows:  
 
?
?
??
??
?+
?+=
f
w
f
w
wfe
j
i
f j
f i
fep
fep
ewcc
||)|(
||)|(
),,;( , 
 
where ? is a very small smoothing factor in case 
e is not generated by any word in f. The proba-
bility p(e | f) is the word translation probability 
trained by IBM Model 1 on the whole parallel 
corpus. 
The rationale behind the weighted correlation 
count, wcc, is that if e is part of the translation of 
w, then its association with w should be stronger 
than other words in the context. Hence its wcc 
should be closer to 1. Otherwise, the association 
is weaker and the wcc should be closer to 0. 
2.1.2 Normalized Correlation 
Once the weighted correlation counts wcc is 
computed for each word in FC, we compute the 
normalized correlation frequency for each word 
e as the total sum of the  of all w 
in bilingual sentences (e, f)  in FC. The norma-
lized correlation frequency (ncf) is defined as 
follows: 
),,;( wfeewcc
 
?
=
=
n
i
iiewccencf
1
)()( ),,;();( wfew . 
 
We choose the top-n English words ranked by 
ncf as our candidate words and filter out those 
whose ncf is less than a pre-defined threshold. 
Table 2 shows the candidate words for the Chi-
nese term ???? (quote/take/interpret out of 
context) sorted by their ncf values. To illustrate 
the effectiveness ncf, we also display candidate 
words of the term with their Dice values in 
Tables 3. As shown in the tables, noise words 
such as justify, meaning and unfair are ranked 
lower using ncf than using Dice, while correct 
candidates, such as out, take and remark are 
ranked higher.  We present more experimental 
results in Section 3. 
 
2.2 Generation and Ranking of Candi-
date Translations 
After determining the candidate words, candi-
date translations of w can be generated by mark-
ing the candidate words in each sentence of FC. 
The word sequences marked in each sentence 
are deemed possible translations. At the same 
time, the weakly associated function words,  
480
Candidate words e freq ncf(e,w) 
context 54 31.55 
out 58 24.58 
quote 26 5.84 
take 23 4.81 
remark 8 1.84 
interpret 3 1.38 
piecemeal 1 0.98 
deliberate 3 0.98 
Table 2. Candidate words for the Chinese term 
???? sorted by their global normalized correla-
tion frequencies. 
 
Candidate words e freq dice(e,w) 
context 54 0.0399 
quote 26 0.0159 
deliberate 3 0.0063 
justify 3 0.0034 
interpretation 7 0.0032 
meaning 3 0.0029 
cite 3 0.0025 
unfair 4 0.0023 
Table 3. Candidate words for the Chinese term ??
??  sorted by their Dice coefficient values. 
 
which we fail to select in the candidate word 
selection stage, should be recovered. The rule is 
quite simple: if a function word is adjacent to 
any candidate word, it should be recovered. For 
example, in the following sentence, the function 
word of would be recovered and added to the 
marked sequence: 
 
“The financial secretary has 
been quoted out of context. 
??? ?? ? ?? ? ????.”  
 
 The marked words are shown in boldface.  
2.2.1 Generating Possible Translations 
Although we have selected a reliable candidate 
word list, it may still contain some noisy words 
due to the MWE’s collocation context. Consider 
the following example: 
 
...as quoted in the audit 
report, if taken out of con-
text...  
 
In this instance, quoted is a false positive; there-
fore, the marked word sequence m “quoted tak-
en out of context” is not the correct translation. 
To avoid such false positives, we include m and 
all its subsequences as possible translations.  
quoted taken out of context 
quoted taken out of 
quoted taken out context 
quoted taken of context 
quoted out of context 
taken out of context 
… 
quoted out 
taken out 
quoted 
taken 
out 
context
Table 4. Example subsequences generated of w and 
add them to the candidate translation list.  
 
Table 4 shows the subsequences of m in the 
above example. The generation process is used 
to increase the coverage of correct translations in 
the candidate list; otherwise, many correct trans-
lations will be lost. However, the process may 
also trigger the side effect of the common sub-
sequence problem described in Section 1.  Since 
all candidates compete for the best translations 
by comparing their association strength with w, 
the common subsequences will have an advan-
tage. 
 
2.2.2 Filtering Common Subsequences 
To resolve the common subsequence effect prob-
lem, we evaluate each candidate translation, in-
cluding its subsequences, by a concept similar to 
the normalized correlation frequency. As men-
tioned in Section 1, the Dice coefficient tends to 
select the common subsequences of some candi-
dates because they have higher frequencies. To 
avoid this problem, we use the normalized corre-
lation frequency to filter out false common sub-
sequences from the candidate translation list. 
Here, we also use the weighted correlation count 
wcc to weight the frequency count of a candidate 
translation. Suppose we have a marked sequence 
in a sentence, m, whose subsequences are gener-
ated in the way described in the previous section. 
If the weighted count of m is assigned the score 
1, the weighted count (wc) of a subsequence t is 
then defined as follows: 
 
?
???
?=
tm
wfewmfet
e
ewccwc )),,;(1(),,,;( . 
 
The underlying concept of wc is that the original 
marked sequence m is supposed to be the most 
481
likely translation of w and the weighted count is 
set to 1. Then, if a subsequence t is generated by 
removing a word e from m, the weighted count 
of the subsequence is reduced by multiplying the 
complement probability of e generated by w. 
Note that the weighted correlation count wcc is 
the probability of the word e generated by w. 
After all  in each sentence of 
the FC have been computed, the weighted fre-
quency for a sequence t can be determined by 
summing the weighted frequencies over FC as 
follows:  
),,,;( wmfetwc
 
?
??
=
FC
wcwf
),(
),,,;();(
fe
wmfetwt . 
 
We compute the wf for each candidate transla-
tion and then sort the candidate translations by 
their wf values. 
Next, we filter out common subsequences 
based on the following rule: for a sequence t, if 
there is a super-sequence t' on the sorted candi-
date translation list and the wf value of t is less 
than that of t', then t is assumed be a common 
subsequence of real translations and removed 
from the list. 
 
candidate translation list freq wf 
quote out of context 19 17.55 
of context 35 15.45 
out of context 32 14.82 
quote of context 19 13.32 
out 35 11.92 
quote 23 11.63 
quote out 19 9.42 
Table 5. Part of the candidate translation list for the 
Chinese idiom, ????, sorted by the wf values. 
 
Table 5 shows an example of the rule’s appli-
cation. The candidate translation list is sorted by 
the translations’ wf values. Then, candidates 2-7 
are removed because they are subsequences of 
the first candidate and their wf values are smaller 
than that of the first candidate. 
2.3 Selection of Candidate Translations 
Having removed the common subsequences of 
real translations from the candidate translation 
list of w, we can select the best translations by 
comparing their association strength with w for 
the remaining candidates.  The Dice coefficient 
is a good measure for assessing the association 
strength and selecting translations from the can-
didate list. For a candidate translation t, the Dice 
coefficient is defined as follows: 
 
)()(
),(2
),(
wt
wt
wt
pp
p
Dice += . 
 
Where p(t,w), p(t), p(w) are probabilities of  
(t,w), t, w derived from the training corpus.  
After obtaining the Dice coefficients of the 
candidate translations, we select the top-n candi-
date translations as possible translations of w. 
 
3 Experiments 
In our experiments, we use the Hong Kong Han-
sard and the Hong Kong News parallel corpora 
as training data. The training data was prepro-
cessed by Chinese word segmentation to identify 
words and parsed by Chinese parser to extract 
MWEs. To evaluate the proposed approach, we 
randomly extract 309 Chinese MWEs from 
training data, including dependent word pairs 
and rigid idioms. We then randomly select 103 
of those MWEs as the development set and use 
the other 206 as the test set. The reference trans-
lations of each Chinese MWE are manually ex-
tracted from the parallel corpora. 
 
3.1 Evaluation of Word Candidates 
To evaluate the method for selecting candidate 
words, we use the coverage rate, which is de-
fined as follows: 
 
?
?
?=
w w
ww
||
||1
A
CA
n
coverage , 
 
where n is the number of MWEs in the test set, 
Aw denotes the word set of the reference transla-
tions of w, and Cw denotes a candidate word list 
extracted by the system.  
Table 6 shows the coverage of our method, 
NCF, compared with the coverage of the IBM 
model 1 and the association-based methods MI, 
Chi-square, and Dice. As we can see, the top-10 
candidate words of NCF cover almost 90% of 
the words in the reference translations. Whereas, 
the coverage of the association-based methods 
and IBM model 1 is much lower than 90%. The 
result implies that the candidate extraction me-
thod can extract a more precise candidate set 
than other methods. 
 
482
Method Top10 Top20 Top30 
MI 0.514 0.684 0.760 
Chi-square 0.638 0.765 0.828 
Dice 0.572 0.735 0.803 
IBM 1 0.822 0.900 0.948
NCF 0.899 0.962 0.973 
Table 6. The coverage rates of the candidate words 
extracted by the compared methods 
 
Figure 1 shows the curve diagram of the cov-
erage rate of each method. As the figure shows, 
when the size of the candidate list is increased, 
the coverage rate of using NCF rises rapidly as n 
increases but levels off after n=20. Whereas, the 
coverage rates of other measures grow much 
slowly.  
 
 
Figure 1. The curve diagram of the coverage of 
the candidate word list compiled by each method. 
 
From the evaluation of candidate word selec-
tion, we find that the ncf method, which incorpo-
rates lexical-level information into association-
based measure, can effectively filter out noisy 
words and generates a highly reliable list of can-
didate words for a given MWE. 
 
3.2 Evaluating Extracted Translations 
To evaluate the quality of MWE translations 
extracted automatically, we use the following 
three criteria: 
 
1) Translation accuracy: 
This criterion is used to evaluate the top-n 
translations of the system. It treats each 
translation produced as a string and com-
pares the whole string with the given ref-
erence translations. If any one of the top-n 
hypothesis translations is included in the 
reference translations, it is deemed correct.   
2) WER (word error rate): 
This criterion compares the top-1 hypo-
thesis translation with the reference trans-
lations by computing the edit distance (i.e., 
the minimum number of substitutions, in-
sertions, and deletions) between the hypo-
thesis translation and the given reference 
translations. 
3) PER (position-independent word error 
rate): 
This criterion ignores the word order and 
computes the edit distance between the 
top-1 hypothesis translation and the given 
reference translations. 
 
We also use the MT task to evaluated our me-
thod with other systems. For that, we use the 
GIZA++ toolkit (Och et al., 2000 ) to align the 
Hong Kong Hansard and Hong Kong News pa-
rallel corpora. Then, we extract the translations 
of the given source sequences from the aligned 
corpus as the baseline. We use the following two 
methods to extract translations from the aligned 
results. 
 
1) Uni-directional alignment  
We mark all English words that were 
linked to any constituent of w in the pa-
rallel Chinese-English aligned corpora. 
Then, we extract the marked sequences 
from the corpora and compute the fre-
quency of each sequence. The top-n high 
frequency sequences are returned as the 
possible translations of w. 
2) Bi-directional alignments 
We use the grow-diag-final heuristic (Och 
et al., 1999) to combine the Chinese-
English and English-Chinese alignments, 
and then extract the top-n high frequency 
sequences as described in method 1. 
 
To determine the effect of the common subse-
quence filtering method, FCS, we divide the 
evaluation of our system into two phases: 
 
1) NCF+Dice: 
This system uses the normalized correla-
tion frequency, NCF, to select candidate 
words as described in Section 2.1. It then 
extracts candidate translations (described 
in Section 2.2), but FCS is not used. 
2) NCF+FCS+Dice: 
This is similar to system 1, but it uses 
FCS to filter out common subsequences 
(described in subsection 2.2.2). 
483
Method WER(%) PER(%) 
Uni-directional 4.84 4.02 
Bi-directional 5.84 5.12 
NCF+Dice 3.55 3.24 
NCF+FCS+Dice 2.45 2.23 
Table 7. Translation error rates of the systems. 
 
 
Method Top1 Top2 Top3 
Uni-directional 67.5 79.6 83.0 
Bi-directional 65.5 77.7 81.1 
NCF+Dice 72.8 85.9 88.3 
NCF+FCS+Dice 78.2 89.3 91.7 
Table 8. Translation accuracy rates of the systems. 
(%) 
 
Table 7 shows the word error rates for the 
above systems. As shown in the first and second 
rows, the translations extracted from uni-
directional alignments are better than those ex-
tracted from bi-directional alignments. This 
means that the grow-diag-final heuristic reduces 
the accuracy rate when extracting MWE transla-
tions.  
The results in the third row show that the 
NCF+Dice system outperforms the methods 
based on GIZA++. In other words, the NCF me-
thod can effectively resolve the difficulties of 
extracting MWE translations discussed in Sec-
tion 1. 
In addition, the fourth row shows that the 
NCF+FCS+Dice system also outperforms the 
NCF+Dice system.  Thus, the FCS method can 
resolve the common subsequence problem effec-
tively. 
Table 8 shows the translation accuracy rates 
of each system. The NCF+FCS+Dice system 
achieves the best translation accuracy. Moreover, 
it significantly improves the performance of 
finding MWE translation equivalences. 
 
4 Applying  MWE Translations to MT 
To demonstrate the usefulness of extracted 
MWE translations to existing statistical machine 
translation systems, we use the XML markup 
scheme provided by the Moses decoder, which 
allows the specification of translations for parts 
of a sentence. The procedure for this experiment 
consists of three steps: (1) the extracted MWE 
translations are added to the test set with the 
XML markup scheme, (2) after which the data is 
input to the Moses decoder to complete the 
translation task, (3) the results are evaluated 
 Moses  MWE +Moses
NIST06-sub 23.12 23.49 
NIST06 21.57 21.79 
 Table 9. BLEU scores of the translation results. 
 
using the BLEU metric (Papineni et al., 2002). 
4.1 Experimental Settings 
To train a translation model for Moses, we use 
the Hong Kong Hansard and the Hong Kong 
News parallel corpora as training data 
(2,222,570 sentence pairs). We also use the 
same parallel corpora to extract translations of 
MWEs. The NIST 2008 evaluation data (1,357 
sentences, 4 references) is used as development 
set and NIST 2006 evaluation data (1,664 sen-
tences, 4 references) is used as test set. 
4.2 Selection of MWEs 
Due to the limitation of the XML markup 
scheme, we only consider two types of MWEs: 
continuous bigrams and idioms. Since the goal 
of this experiment is not focus on extraction of 
MWEs, simple methods are applied to extract 
MWEs from the training data: (1) we collect all 
continuous bigrams from Chinese sentences in 
the training data and then simply filter out the 
bigrams by mutual information (MI) with a thre-
shold1, (2) we also extract all idioms from Chi-
nese sentences of the training data by collecting 
all 4-syllables words from the training data and 
filtering out obvious non-idioms, such as deter-
minative-measure words and temporal words by 
their part-of-speeches, because most Chinese 
idioms are 4-syllables words.  
In total, 33,767 Chinese bigram types and 
20,997 Chinese idiom types were extracted from 
training data; and the top-5 translations of each 
MWE were extracted by the method described in 
Section 2. Meanwhile 1,171 Chinese MWEs 
were added to the translations in the test set. The 
Chinese words covered by the MWEs in test 
data set were 2,081 (5.3%). 
 
4.3 Extra Information 
When adding the translations to the test data, 
two extra types of information are required by 
the Moses decoder. The first type comprises the 
function words between the translation and its 
context. For example, if ??  ??/economic 
cooperation is added to the test data, possible  
                                                 
1 We set the threshold at 5. 
484
source sentence ... ??  <MWE>????</MWE>  ??? ... 
Moses ... entered blinded by the colourful community ... 
MWE+Moses ... entered the colourful community ... 
reference ... entered the colorful society ... 
source sentence ... ?????  <MWE>???  ??</MWE>  ?? ... 
Moses ... do not want to see an escalation of crisis ... 
MWE+Moses ... do not want to see a further escalation of crisis ... 
reference ... don 't want to see the further escalation of the crisis ... 
source sentence ... ?? ?? ? <MWE>?? ??</MWE> ... 
Moses ... the people 's interests ... 
MWE+Moses ... the people of the fundamental interests ... 
reference ... the fundamental interests of the masses ... 
Table 10. Examples of improved translation quality with the MWE translation equivalences. 
 
function words, such as ‘in’ or ‘with’, should be 
provided for the translation. Because the Moses 
decoder does not generate function words that 
are context dependent, it treats a function word 
as a part of the translation. Therefore, we collect 
possible function words for each translation 
from the corpora when the conditional probabili-
ty is larger than a threshold2. 
The second type of information is the phrase 
translation probability and lexical weighting. 
Computing the phrase translation probability is 
trivial in the training corpora, but lexical weight-
ing (Koehn et al., 2003) needs lexical-level 
alignment. For convenience, we assume that 
each word in an MWE links to each word in the 
translations. Under this assumption, the lexical 
weighting is simplified as follows:   
 
??
??= ?= aji ji
n
i
w efpajij
ap
),(1
)|(
|}),(|{|
1
),|( ef
        ? ?
= ??
?
n
i e
ji
j
efp
1
)|(
||
1
ee
. 
 
Then, it is trivial to compute the simplified lexi-
cal weighting of each MWE correspondence 
when the word translation probability table is 
provided. Here, we use the IBM model 1 to learn 
the table from the training data. 
4.4 Evaluation Results 
We trained a model using Moses toolkit (Koehn 
et al., 2007) on the training data as our baseline 
system.  
Table 9 shows the influence of adding the 
MWE translations to the test data. In the first 
row (NIST06-sub), we only consider sentences 
containing MWE translations for BLEU score 
evaluation (726 sentences). In the second row, 
we took the whole NIST 2006 evaluation set 
into consideration (1,664 sentences). The Chi-
nese words covered by the MWEs in NIST06-
sub and NIST06 were 9.9% and 5.3% respec-
tively. 
Adding MWE translations to the test data sta-
tistically significantly lead to better results than 
those of the baseline. Significance was tested 
using a paired bootstrap (Koehn, 2004) with 
1000 samples (p<0.02). Although the improve-
ment in BLEU score seems small, it is actually 
reasonably good given that the MWEs account 
for only 5% of the NIST06 test set. Examples of 
improved translations are shown in Table 10. 
There is still room for improvement of the pro-
posed MWE extraction method in order to pro-
vide more MWE translation pairs or design a 
feasible way to incorporate discontinuous bilin-
gual MWEs to the decoder. 
5 Conclusions and Future Work 
We have proposed a high precision algorithm for 
extracting translations of multiword expressions 
from parallel corpora. The algorithm can be used 
to translate any language pair and any type of 
word sequence, including rigid sequences and 
discontinuous sequences. Our evaluation results 
show that the algorithm can cope with the diffi-
culties caused by indirect association and the 
common subsequence effects, leading to signifi-
cant improvement over the word alignment-
based extraction methods used by the state of the 
art systems and other association-based extrac-
tion methods. We also demonstrate that ex-
tracted translations significantly improve the                                                  
2 We set the threshold at 0.1. 
485
performance of the Moses machine translation 
system. 
In future work, it would be interesting to de-
velop a machine translation model that can be 
integrated with the translation acquisition algo-
rithm in a more effective way. Using the norma-
lized-frequency score to help phrase alignment 
tasks, as the grow-diag-final heuristic, would 
also be interesting direction to explore. 
 
Acknowledgement 
This research was supported in part by the Na-
tional Science Council of Taiwan under the NSC 
Grants: NSC 96-2221-E-001-023-MY3. 
References  
Brown, Peter F., Stephen A. Della Pietra, Vincent J. 
Della Pietra, Robert L. Mercer. 1993. The Mathe-
matics of Statistical Machine Translation: Parame-
ter Estimation. Computational Linguistics, 
19(2):263-311.  
Gao, Jianfeng, Jian-Yun Nie, Hongzhao He, Weijun 
Chen, Ming Zhou. 2002. Resolving Query Trans-
lation Ambiguity using a Decaying Co-occurrence 
Model and Syntactic Dependence Relations. In 
Proc. of SIGIR’02. pp. 183 -190. 
Kitamura, Mihoko and Yuji Matsumoto. 1996. Au-
tomatic Extraction of Word Sequence Correspon-
dences in Parallel Corpora. In Proc. of the 4th An-
nual Workshop on Very Large Corpora. pp. 79-87. 
Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 
2003. Statistical Phrase-Based Translation. In Proc. 
of HLT/NAACL’03. pp. 127-133. 
Koehn, Philipp. 2004. Statistical significance tests for 
machine translation evaluation. In Proc. 
EMNLP’04. pp. 388-395. 
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses: 
Open source toolkit for statistical machine transla-
tion. In ACL’07, demonstration session. 
Kupiec, Julian. 1993. An Algorithm for Finding 
Noun Phrase Correspondences in Bilingual Corpo-
ra. In Proc. of ACL’93 . pp. 17-22. 
Liang, Percy, Ben Taskar, Dan Klein. 2006. Align-
ment by Agreement. In Proc. of HLT/NAACL’06. 
pp. 104-111. 
Ma, Yanjun, Nicolas Stroppa, Andy Way. 2007. 
Bootstrapping Word Alignment via Word Packing. 
In Proc. of ACL’07. pp. 304-311. 
Ma, Yanjun, Sylwia Ozdowska, Yanli Sun, and Andy 
Way. 2008. Improving Word Alignment Using 
Syntactic Dependencies. In Proc. of ACL/HLT’08 
Second Workshop on Syntax and Structure in Sta-
tistical Translation. pp. 69-77. 
Melamed, Ilya Dan. 2001. Empirical Methods for 
Exploiting parallel Texts. MIT press. 
Och, Franz Josef and Hermann Ney. 2000. Improved 
Statistical Alignment Models. In Proc. of ACL‘00. 
pp. 440-447. 
Och, Franz Josef, Christoph Tillmann, and Hermann 
Ney. 1999. Improved Alignment Models for Sta-
tistical Machine Translation. In Proc. of 
EMNLP/VLC’99. pp. 20-28. 
Papineni, Kishore, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu. 2002. BLEU: a Method for Auto-
matic Evaluation of Machine Translation. In Proc. 
of ACL’02. pp. 311-318. 
Smadja, Frank, Kathleen R. McKeown, and Vasileios 
Hatzivassiloglou. 1996. Translating Collocations 
for Bilingual Lexicons: A Statistical Approach. 
Computational Linguistics, 22(1):1-38. 
Wu, Dekai. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Cor-
pora. Computational Linguistics, 23(3):377-403.  
Wu, Hua, Ming Zhou. 2003. Synonymous Colloca-
tion Extraction Using Translation Information. In 
Proc. of ACL’03. pp. 120-127. 
Yamamoto, Kaoru, Yuji Matsumoto. 2000. Acquisi-
tion of Phrase-level Bilingual Correspondence us-
ing Dependency Structure. In Proc. of COL-
ING’00. pp. 933-939. 
 
486
