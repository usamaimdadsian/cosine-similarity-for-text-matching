Acquiring and Exploiting the User's Knowledge in Guidance 
Interactions 
Eya l  Sh i f ron i  and  Uzz i  Ornan  
Depar tment  of  Computer  Sc ience 
Techn ion  - Israel  Ins t i tu te  of  Techno logy  
Techn ion  City,  Ha i fa  32000, Israel  
emai l :  sh i f ron i@cs . techn ion.ac . i l ,  o rnan@cs . techn ion .ac . i l  
J anuary  5, 1992 
1 Introduction 
This paper presents a model for Flexible Interactive 
Guidance System (FIGS) that provides people with 
instructions about natural tasks. The model is de- 
veloped on the basis of a phenomenological analy- 
sis of human guidance and illustrated by a system 
that gives directions in geographical domains. The 
instructions are provided through a dialog adapted 
both in form and content o user's needs. The main 
problem addressed is how to provide a user-adapted 
guidance during the normal course of the guidance 
dialog, without introducing a special time consuming 
sub-dialog to gain information about the user's state 
of knowledge. 
A user-adapted guidance system must collect in- 
formation about the user's knowledge of the guid- 
ance domain and build a User Model (UM). It is 
known that a UM can improve the behavior of dia- 
log systems and contribute to the ease of their usage 
and the naturalness of their response ( (Rich, 1979)). 
However, a UM may also have negative ffects on the 
system's behavior, since the process of its acquisition 
may increase both the time and the effort the user 
must invest in the interaction. The model suggested 
here addresses this problem by weighing the effort 
required to acquire the UM against the benefits of 
its usage. 
2 Background 
User modeling systems that were built during the 
80s were developed for advisory systems. Early sys- 
tems used an explicit method to acquire the UM (e.g., 
(Rich, 1979)). In such a method facts about the user 
are provided to the UM by the user himself. This 
method however, has a major drawback, since the 
user who is interested in obtaining information from 
the system, is forced to provide answers to a sequence 
of questions posed by the system. Recently, several 
methods to infer facts about the user implicitly were 
suggested (see (Kass, 1990) for an overview). These 
methods exploit the user's questions and the user's 
answers to questions posed by the system, to indi- 
rectly infer new facts about him, and are thus able to 
construct a detailed UM based on a relatively short 
dialog. 
The explicit acquisition method was described 
in the recent literature as inferior to the implicit 
method because of its consumption of the user's time. 
However, implicit acquisition includes a risk of miss- 
ing essential facts about the user, and hence may 
cause the system to provide unnecessary information 
that is already known to the user. 
3 Integrating Explicit  and Im- 
plicit Methods 
The model suggested here integrates the explicit ac- 
quisition method with a variety of implicit methods 
in a context of a Guidance dialog. In contrast o 
advisory dialogs that usually contain an interview 
phase aiming to elicit from the user information re- 
quired for the advice generation, in guidance interac- 
tions most of the dialog consists of instructions pro- 
vided by the system, and user's responses to these 
instructions. Although questions to the guidance re- 
cipient - the guidee - do occur, they do not con- 
stitute a separate phase but are rather scattered in 
the instruction sequence. In the current study and 
249
in other studies of human guidance dialogs it was 
found that in such dialogs any instruction made by 
the guide is followed by a guidee's response such as 
question, interruption, or confirmation-signal. In hu- 
man interaction confirmation-signals re provided by 
either verbal (e.g., "ahm") or non-verbal (e.g., head 
nodding) means, this can be simulated in human- 
computer interaction by a special "continue" button 
that is used to signal the system to move to the next 
instruction. 
We claim that any instruction-response pair in the 
guidance sequence can serve as a basis for inferences 
about the guidee. In general, each such pair type 
triggers different inferences and consumes a differ- 
ent amount of the user's resources (time, effort, pa- 
tience). For example, inferences can be drawn from 
an instruction/confirmation-signal pair; the confir- 
mation signal shows that the user understands the 
instruction and thus affirms the assumptions which 
led to its production. Such default inferences are less 
certain than those based on answers to explicit ques- 
tions, but they do not consume the resources of the 
guidee: No special action from him is required; in 
fact the guidee may not even be aware to the fact 
that inferences about him are being made. A strat- 
egy of explicit questioning is justified only when the 
needed fact is informative, and there was no way in 
which the system could infer it from the previous 
dialog. In any other case a more implicit strategy 
should be preferred. 
This view extends the explicit-implicit distinction 
mentioned above since each utterance pair type facil- 
itates a different acquisition method, and each such 
method has a different level of explicitness. Our 
model provides therefore, a new definition of the no-  
t ion  of explicitness which extends the previous no-  
t ion  in two ways. First, we distinguish between Ac- 
quisition Explicitness and Transmission Explicitness, 
this way the notion can be applied both for informa- 
tion flowing from guide to guidee (guidance infor- 
mation), and for information flowing from guidee to 
guide (user modeling information). Second, we al- 
low various levels of explicitness, rather than the two 
extremes only. The system's explicitness level is de- 
fined in terms of the interactive ffort that is invested 
in the dialog. This can either be the effort required 
to provide a fact to the guidee, or the effort required 
to acquire a fact about him. 
We define FIGS as a system that provides inter- 
active, user-adapted guidance, and satisfies the fol- 
lowing two conditions: (1) It is equipped with a set 
of instruction-acquisition strategies, each of which is 
characterized by a different level of acquisition ex- 
plicitness and transmission explicitness; and (2) It 
has a mechanism to dynamically select a strategy. 
This mechanism attempts to reach optimMity with 
respect o the interactive ffort required for providing 
the information eeded by the guidee. 
The suggested model implements the forego- 
ing considerations, it includes four instruction- 
acquisition strategies: (1) Question - the user pro- 
vides a needed fact, (2) Explanation - no facts about 
the user are used, (3) Explicit Assumption - the in- 
struction is based on an assumption about the user, 
and the assumption is mentioned, and (4) Implicit 
Assumption - an assumption is used without men- 
tioning it. 
A major feature of our model is that UM acqui- 
sition considerations are integrated into the FIGS's 
utterance planning process. Hence, the user mod- 
eling and the instruction generation are done incre- 
mentally by inter-related processes. We use heuris- 
tic rules to select among the four strategies; these 
rules weigh four discourse parameters: information 
content, user knowledge (as described by the current 
UM), likelihood to acquire new facts about the user, 
and consumption of user's resources. 
The computational model we suggested was imple- 
mented by a computer program (called FIGS1) that 
offers directional instructions in a complex university 
building. FIGS1 uses heuristic rules to control both 
the strategy selection and the UM construction. A 
more detailed exposition of our model and its im- 
plementation can be found in (Shifroni & Shanon, 
1991), and (Shifroni & Ornan, 1991). 
References 
Kass, R. (1990). Building a user model explicitly 
from a cooperative advisory dialog. In Second 
International Workshop on User Modeling. 
Rich, E. (1979). User modeling via stereotypes. Cog- 
nitive Science, 3(4), 329-354. 
Shifroni, E. & Ornan, U. (1991). FIGSI: A flexible 
guidance dialog system. In Proceedings of the 
8th Israeli Symposium on Artificial Intelligence, 
(pp. 51-68). Color print press Jerusalem. 
Shifroni, E. &: Shanon, B. (1991). Interactive user 
modeling: An integrating explicit-implicit ap- 
proach. Submitted to the journal of User Mod- 
eling and User Adapted Interaction. 
250
