Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1037–1045,
Singapore, 6-7 August 2009. c©2009 ACL and AFNLP
Fast Translation Rule Matching for Syntax-based Statistical 
Machine Translation 
 
 
 
Hui Zhang1, 2   Min Zhang1   Haizhou Li1   Chew Lim Tan2    
1Institute for Infocomm Research                    2National University of Singapore                    
zhangh1982@gmail.com   {mzhang, hli}@i2r.a-star.edu.sg   tancl@comp.nus.edu.sg 
 
 
 
 
 
 
 
Abstract 
In a linguistically-motivated syntax-based trans-
lation system, the entire translation process is 
normally carried out in two steps, translation 
rule matching and target sentence decoding us-
ing the matched rules. Both steps are very time-
consuming due to the tremendous number of 
translation rules, the exhaustive search in trans-
lation rule matching and the complex nature of 
the translation task itself. In this paper, we pro-
pose a hyper-tree-based fast algorithm for trans-
lation rule matching. Experimental results on 
the NIST MT-2003 Chinese-English translation 
task show that our algorithm is at least 19 times 
faster in rule matching and is able to help to 
save 57% of overall translation time over previ-
ous methods when using large fragment transla-
tion rules. 
1 Introduction 
Recently linguistically-motivated syntax-based 
translation method has achieved great success in 
statistical machine translation (SMT) (Galley et al., 
2004; Liu et al., 2006, 2007; Zhang et al., 2007, 
2008a; Mi et al., 2008; Mi and Huang 2008; 
Zhang et al., 2009). It translates a source sentence 
to its target one in two steps by using structured 
translation rules. In the first step, which is called 
translation rule matching step, all the applicable1 
translation rules are extracted from the entire rule 
set by matching the source parse tree/forest. The 
second step is to decode the source sentence into 
its target one using the extracted translation rules. 
Both of the two steps are very time-consuming 
due to the exponential number of translation rules 
and the complex nature of machine translation as 
                                                           
1 Given a source structure (either a parse tree or a parse 
forest), a translation rule is applicable if and only if the 
left hand side of the translation rule exactly matches a 
tree fragment of the given source structure. 
an NP-hard search problem (Knight, 1999). In the 
SMT research community, the second step has 
been well studied and many methods have been 
proposed to speed up the decoding process, such 
as node-based or span-based beam search with 
different pruning strategies (Liu et al., 2006; 
Zhang et al., 2008a, 2008b) and cube pruning 
(Huang and Chiang, 2007; Mi et al., 2008). How-
ever, the first step attracts less attention. The pre-
vious solution to this problem is to do exhaustive 
searching with heuristics on each tree/forest node 
or on each source span. This solution becomes 
computationally infeasible when it is applied to 
packed forests with loose pruning threshold or rule 
sets with large tree fragments of large rule height 
and width. This not only overloads the translation 
process but also compromises the translation per-
formance since as shown in our experiments the 
large tree fragment rules are also very useful.  
To solve the above issue, in this paper, we pro-
pose a hyper-tree-based fast algorithm for transla-
tion rule matching. Our solution includes two 
steps. In the first step, all the translation rules are 
re-organized using our proposed hyper-tree struc-
ture, which is a compact representation of the en-
tire translation rule set, in order to make the com-
mon parts of translation rules shared as much as 
possible. This enables the common parts of differ-
ent translation rules to be visited only once in rule 
matching. Please note that the first step can be 
easily done off-line very fast. As a result, it does 
not consume real translation time. In the second 
step, we design a recursive algorithm to traverse 
the hyper-tree structure and the input source forest 
in a top-down manner to do the rule matching be-
tween them. As we will show later, the hyper-tree 
structure and the recursive algorithm significantly 
improve the speed of the rule matching and the 
entire translation process compared with previous 
methods. 
With the proposed algorithm, we are able to 
carry out experiments with very loose pruning 
1037
thresholds and larger tree fragment rules effi-
ciently. Experimental results on the NIST MT-
2003 Chinese-English translation task shows that 
our algorithm is 19 times faster in rule matching 
and is able to save 57% of overall translation time 
over previous methods when using large fragment 
translation rules with height up to 5. It also shows 
that the larger rules with height of up to 5 signifi-
cantly outperforms the rules with height of up to 3 
by around 1 BLEU score. 
The rest of this paper is organized as follows. 
Section 2 introduces the syntax-based translation 
system that we are working on. Section 3 reviews 
the previous work. Section 4 explains our solution 
while section 5 reports the experimental results. 
Section 6 concludes the paper. 
2 Syntax-based Translation 
This section briefly introduces the forest/tree-
based tree-to-string translation model which 
serves as the translation platform in this paper. 
2.1 Tree-to-string model 
   
                                                    
 
                                                      
XNA declaration is related to some regulation 
 
Figure 1. A tree-to-string translation process. 
 
The tree-to-string model (Galley et al. 2004; Liu et 
al. 2006) views the translation as a structure map-
ping process, which first breaks the source syntax 
tree into many tree fragments and then maps each 
tree fragment into its corresponding target transla-
tion using translation rules, finally combines these 
target translations into a complete sentence. Fig. 1 
illustrates this process. In real translation, the 
number of possible tree fragment segmentations 
for a given input tree is exponential in the number 
of tree nodes.  
2.2 Forest-based translation 
To overcome parse error for SMT, Mi and Huang 
(2008) propose forest-based translation by using a 
packed forest instead of a single syntax tree as the 
translation input. A packed forest (Tomita 1987; 
Klein and Manning, 2001; Huang and Chiang, 
2005) is a compact representation of many possi-
ble parse trees of a sentence, which can be for-
mally described as a triple , where V is 
the set of non-terminal nodes, E is the set of hy-
per-edges and S is a sentence represented as an 
ordered word sequence. A hyper-edge in a packed 
forest is a group of edges in a tree which connects 
a father node to all its children nodes, representing 
a CFG-based parse rule. Fig. 2 is a packed forest 
incorporating two parse trees T1 and T2 of a sen-
tence as shown in Fig. 3 and Fig. 4. Given a hy-
per-edge e, let h be its father node, then we say 
that e is attached to h. 
A non-terminal node in a packed forest can be 
represented as “label [start, stop]”, where “label” 
is its syntax category and “[start, stop]” is the 
range of words it covers. For example, the node in 
Fig. 5 pointed by the dark arrow is labelled as 
“NP[3,4]”, where NP is its label and [3,4] means 
that it covers the span from the 3rd word to the 4th  
word. In forest-based translation, rule matching is 
much more complicated than the tree-based one.  
 
 
 
Figure 2. A packed forest 
 
Zhang et al. (2009) reduce the tree sequence 
problem into tree problem by introducing virtual 
node and related forest conversion algorithms, so 
1038
the algorithm proposed in this paper is also appli-
cable to the tree sequence-based models. 
 
     
 
Figure 3. Tree 1 (T1)      Figure 4. Tree 2 (T2) 
3 Matching Methods in Previous Work  
In this section, we discuss the two typical rule 
matching algorithms used in previous work. 
3.1 Exhaustive search by tree fragments 
This method generates all possible tree fragments 
rooted by each node in the source parse tree or 
forest, and then matches all the generated tree 
fragments against the source parts (left hand side) 
of translation rules to extract the useful rules 
(Zhang et al., 2008a).  
 
 
 
Figure 5. Node NP[3,4] in packed forest 
 
 
 
Figure 6. Candidate fragments on NP[3,4] 
For example, if we want to extract useful rules 
for node NP[3,4] in Fig 5, we have to generate all 
the tree fragments rooted at node NP[3,4] as 
shown in Fig 6, and then query each fragment in 
the rule set. Let  be a node in the packed forest, 
 represents the number of possible tree frag-
ments rooted at node , then we have: 
 
 
?
?? ?? ??? 
??? ????????
 ???? ?? ?
? ?? ? ?????????? 
???????? ?? ?
 
 
 
The above equation shows that the number of 
tree fragments is exponential to the span size, the 
height and the number of hyper-edges it covers. In 
a real system, one can use heuristics, e.g. the max-
imum number of nodes and the maximum height 
of fragment, to limit the number of possible frag-
ments. However, these heuristics are very subjec-
tive and hard to optimize. In addition, they may 
filter out some “good” fragments.  
3.2 Exhaustive search by rules 
This method does not generate any source tree 
fragments. Instead, it does top-down recursive 
matching from each node one-by-one with each 
translation rule in the rule set (Mi and Huang 
2008). 
For example, given a translation rule with its 
left hand side as shown in Fig. 7, the rule match-
ing between the given rule and the node IP[1,4] in 
Fig. 2 can be done as follows.  
1. Decompose the left hand side of the transla-
tion rule as shown in Fig. 7 into a sequence of hy-
per-edges in top-down, left-to-right order as fol-
lows: 
IP => NP VP;  NP => NP NP;  NP => NN; 
NN => ?? 
 
 
 
Figure 7. The left hand side of a rule 
 
2. Pattern match these hyper-edges(rule) one-
by-one in top-down left-to-right order from node 
IP[1,4]. If there is a continuous path in the forest 
matching all of these hyper-edges in order, then 
we can say that the rule is useful and matchable 
1039
with the tree fragment covered by the continuous 
path. The following illustrates the matching steps: 
1. Match hyper-edge “IP => NP VP” with node 
IP[1,4]. There are two hyper-edges in the forest 
matching it: “IP[1,4] => NP[1,1] VP[2,4]” and 
“IP[1,4] => NP[1,2] VP [3,4]”, which generates 
two candidate paths. 
2. Since hyper-edge “NP => NP NP” fails to 
match NP[1,1], the path initiated with “IP[1,4] => 
NP[1,1] VP[2,4]” is pruned out. 
3.  Since there is a hyper-edge “NP[1,2] => 
NP[1,1] NP[2,2]” matching “NP => NP NP” on 
NP[1,2], then continue for further matching. 
4. Since “NP=>NN” on NP[2,2] matches 
“NP[2,2] => NN[2,2]”, then continue for further 
matching. 
5. “NN=>??” on NN[2,2] matches “NN[2,2] 
=>??” and it is the last hyper-edge in the input 
rules. Finally, there is one continuous path suc-
cessfully matching the left hand side of the input 
rule.  
This method is able to avoid the exponential 
problem of the first method as described in the 
previous subsection. However, it has to do one-by-
one pattern matching for each rule on each node. 
When the rule set is very large (indeed it is very 
large in the forest-based model even with a small 
training set), it becomes very slow, and even much 
slower than the first method. 
4 The Proposed Hyper-tree-based Rule 
Matching Algorithm 
In this section, we first explain the motivation why 
we re-organize the translation rule sets, and then 
elaborate how to re-organize the translation rules 
using our proposed hyper-tree structure. Finally 
we discuss the top-down rule matching algorithm 
between forest and hyper-tree.  
4.1 Motivation 
 
 
              Figure 8.  Two rules’ left hand side 
 
 
Figure 9. Common part of the two rules’ left hand  
sides in Figure 8 
 
Fig. 9 shows the common part of the left hand 
sides of two translation rules as shown in Fig. 8. 
In previous rule matching algorithm, the common 
parts are matched as many times as they appear in 
the rule set, which reduces the rule matching 
speed significantly. This motivates us to propose 
the hyper-tree structure and the rule matching al-
gorithm to make the common parts shared by mul-
tiple translation rules to be visited only once in the 
entire rule matching process. 
4.2 Hyper-node, hyper-path and hyper-tree 
A hyper-tree is a compact representation of a 
group of tree translation rules with common parts 
shared. It consists of a set of hyper-nodes with 
edges connecting different hyper-nodes into a big 
tree. A hyper-tree is constructed from the transla-
tion rule sets in two steps: 
1) Convert each tree translation rule into a hy-
per-path; 
2) Construct the hyper-tree by incrementally 
adding each individual hyper-path into the 
hyper-tree. 
A tree rule can be converted into a hyper-path 
without losing information. Fig. 10 demonstrates 
the conversion process:  
1) We first fill the rule tree with virtual nodes  
to make all its leaves have the same depth 
to the root; 
2) We then group all the nodes in the same 
tree level to form a single hyper-node, 
where we use a comma as a delimiter to 
separate the tree nodes with different father 
nodes; 
3) A hyper-path is a set of hyper-nodes linked 
in a top-down manner. 
The commas and virtual nodes  are introduced 
to help to recover the original tree from the hyper-
path. Given a tree node in a hyper-node, if there 
are n commas before it, then its father node is the 
(n+1)th tree node in the father hyper-node. If we 
could find father node for each node in hyper-
nodes, then it is straightforward to recover the 
original tree from the hyper-path by just adding 
the edges between original father and children 
nodes except the virtual node .  
1040
After converting each tree rule into a hyper-
path, we can organize the entire rule set into a big 
hyper-tree as shown in Figure 11. The concept of 
hyper-path and hyper-tree could be viewed as an 
extension of the "prefix merging" ideas for CFG 
rules (Klein and Manning 2001). 
 
         
 
 
 
 
Figure 10. Convert tree to hyper-path 
 
 
 
Figure 11. A hyper-tree example 
 
Algorithm 1 shows how to organize the rule set 
into a big hyper-tree. The general process is that 
for each rule we convert it into a hyper-path and 
then add the hyper-path into a hyper-tree incre-
mentally. However, there are many different hy-
per-trees generated given a big rule set. We then 
introduce a TOP label as the root node to link all 
the individual hyper-trees to a single big hyper-
tree. Algorithm 2 shows the process of adding a 
hyper-path into a hyper-tree. Given a hyper-path, 
we do a top-down matching between the hyper-
tree and the input hyper-path from root hyper-
node until a leaf hyper-node is reached or there is 
no matching hyper-node at some level found. 
Then we add the remaining unmatchable part of 
the input hyper-path as the descendants of the last 
matchable hyper-node. 
Please note that in Fig. 10 and Fig. 11, we ig-
nore the target side (right hand side) of translation 
rules for easy discussion. Indeed, we can easily 
represent all the complete translation rules (not 
only left hand side) in Fig. 11 by simply adding 
the corresponding rule target sides into each hy-
per-node as done by line 5 of Algorithm 1.  
Any hyper-path from the root to any hyper-
node (not necessarily be a leaf of the hyper-tree) 
in a hyper-tree can represent a tree fragment. As a 
result, the hyper-tree in Fig. 11 can represent up to 
6 candidate tree fragments. It is easy to understand 
that the maximum number of tree fragments that a 
hyper-tree can represent is equal to the number of 
hyper-nodes in it except the root. It is worth not-
ing that a hyper-node in a hyper-tree without any 
target side rule attached means there is no transla-
tion rule corresponding to the tree fragment repre-
sented by the hyper-path from the root to the cur-
rent hyper-node. The compact representation of 
the rule set by hyper-tree enables a fast algorithm 
to do translation rule matching. 
 
Algorithm 1. Compile rule set into hyper-tree 
Input: rule set 
Output: hyper-tree 
 
1.  Initialize hyper-tree as a TOP node  
2.  for  each rule in rule set  do 
3.          Convert the left hand side tree to a hyper-path p 
4.          Add hyper-path p into hyper-tree 
5. Add rule’s right hand side to the leaf hyper-node of  
a hyper-path in the hyper-tree  
6. end for 
 
Algorithm  2. Add hyper-path into hyper-tree 
Input: hyper-path p and hyper-tree t 
Notation:  
   h: the height of hyper-path p 
   p(i) : the hyper-node of ith level (top-down) of p 
   TN: the hyper-node in hyper-tree  
Output: updated hyper-tree t  
 
1. Initialize TN as TOP 
2. for  i := 1 to h  do 
3.       if there is a child c of TN has the same label as p(i)    
              then 
4.             TN := c 
5.       else  
6.             Add a child c to TN, label c as p(i) 
7.             TN := c 
4.3 Translation rule matching between forest 
and hyper-tree 
Given the source parse forest and the translation 
rules represented in the hyper-tree structure, here 
we present a fast matching algorithm to extract so-
called useful translation rules from the entire rule 
set in a top-down manner for each node of the for-
est.  
As shown in Algorithm 3, the general process 
of the matching algorithm is as follows: 
 
1041
Algorithm 3. Rule matching on one node  
Input: hyper-tree T, forest F, and node n 
Notation:   
      FP: a pair <FNS, TN>, FNS is the frontier nodes of      
             matched tree fragment,  
             TN is the hyper-tree node matching it 
      SFP: the queue of FP 
Output: Available rules on node n 
 
1. if there is no child c of TOP having the same label as n      
   then 
2.        Return failure. 
3. else  
4.      Initialize FP as <{n},c> and put it into SFP 
5.      for each FP in SFP do 
6.                 SFP Å PropagateNextLevel(FP.FNS, FP.TN)  
7.      for each FP in SFP do 
8.          if the rule set attached to FP.TN is not empty   
         then 
9.               Add FP to result 
 
Algorithm 4. PropagateNextLevel  
Input: Frontier node sequence FNS, hyper-tree node TN 
Notation: 
           CT: a child node of TN 
                  the number of node sequence (separated by  
                  comma, see Fig 11) in CT is equal to the number  
                  of node in TN.   
           CT(i) : the ith node sequence in hyper-node CT 
           FNS(i): the ith node in FNS 
           TFNS: the temporary set of frontier node sequence 
           RFNS: the result set of frontier node sequence  
           FP:  a pair of frontier node sequence  
                   and hyper-tree node 
           RFP: the result set of FP 
Output: RFP  
 
1. for each child hyper-node CT of TN do 
2.        for i:= 1 to the number of node sequence in CT do 
3.              empty TFNS 
4.              if CT(i) ==  then 
5.                      Add FNS(i) to TFNS. 
6.              else 
7.                   for each hyper-edge e attached to FNS(i) do 
8.                         if e.children match CT(i) then 
9.                                Add e.children to TFNS 
10.              if TFNS is empty then 
11.                      empty RFNS 
12.                      break 
13.              else if i == 1 then  
14.                       RFNS := TFNS 
15.              else  
16.                       RFNS := RFNS  TFNS 
17.        for each FNS in RFNS do 
18.                add <FNS, CT > into RFP 
 
1) For each node n of the source forest if no 
child node of TOP in hyper-tree has the same label 
with it, it means that no rule matches any tree 
fragments rooted at the node n (i.e., no useful 
rules to be used for the node n) (line 1-2) 
2) Otherwise, we match the sub-forest starting 
from the node n against a sub-hyper-tree starting 
from the matchable child node of TOP layer by 
layer in a top-down manner. There may be many 
possible tree fragments rooted at node n and each 
of them may have multiple useful translation rules. 
In our implementation, we maintain a data struc-
ture of FP = <FNS, TN> to record the currently 
matched tree fragment of forest and its corres-
ponding hyper-tree node in the rule set, where 
FNS is the frontier node set of the current tree 
fragment and TN is the hyper-tree node. The data 
structure FP is used to help extract useful transla-
tion rules and is also used for further matching of 
larger tree fragments. Finally, all the FPs for the 
node n are kept in a queue. During the search, the 
queue size is dynamically increased. The matching 
algorithm terminates when all the FPs have been 
visited (line 5-6 and Algorithm 4). 
3) In the final queue, each element (FP) of the 
queue contains the frontier node sequence of the 
matched tree fragment and its corresponding hy-
per-tree node. If the target side of a rule in the hy-
per-tree node is not empty, we just output the 
frontier nodes of the matched tree fragment, its 
root node n and all the useful translation rules for 
later translation process. 
Algorithm 4 describes the detailed process of 
how to propagate the matching process down to 
the next level.  <FNS, TN> is the current level 
frontier node sequence and hyper-tree node. Given 
a child hyper-node CT of TN (line 1), we try to 
find the group of next level frontier node sequence 
to match it (line 2-18). As shown in Fig 11, a hy-
per-node consists of a sequence of node sequence 
with comma as delimiter. For the ith node se-
quence CT(i) in CT, If CT(i) is , that means 
FNS(i) is a leaf/frontier node in the matched tree 
fragment and thus no need to propagate to the next 
level (line 4-5). Otherwise, we try each hyper-
edge e of FNS(i) to see whether its children match 
CT(i), and put the children of the matched hyper-
edge into a temp set TFNS (line 7-9). If the temp 
set is empty, that means the current matching fails 
and no further expansion needs (line 10-12). Oth-
erwise, we integrate current matched children into 
the final group of frontier node sequence (line 13-
16) by Descartes Product ( ). Finally, we con-
struct all the <FNS, TN> pair for next level 
matching (line 17-18). 
It would be interesting to study the time com-
plexity of our Algorithm 3 and 4. Suppose the 
maximum number of children of each hyper-node 
in hyper-tree is N (line 1), the maximum number 
of node sequence in CT is M (line 2), the maxi-
mum number of hyper-edge in each node in 
packed forest is K (line 7), the maximum number 
of hyper-edge with same children representation 
in each node in packed forest is C (i.e. the maxi-
mum size of TFNS in line 16, and the maximum 
complexity of the Descartes Product in line 16 
1042
would be CM), then the time complexity upper-
bound of Algorithm 4 is O(NM(K+CM)). For Al-
gorithm 3, its time complexity is O(RNM(K+CM)), 
where R is the maximum number of tree fragment 
matched in each node.  
5 Experiment 
5.1 Experimental settings 
We carry out experiment on Chinese-English 
NIST evaluation tasks. We use FBIS corpus 
(250K sentence pairs) as training data with the 
source side parsed by a modified Charniak parser 
(Charniak 2000) which can output a packed forest. 
The Charniak Parser is trained on CTB5, tuned on 
301-325 portion, with F1 score of 80.85% on 271-
300 portion. We use GIZA++ (Och and Ney, 2003) 
to do m-to-n word-alignment and adopt heuristic 
“grow-diag-final-and” to do refinement. A 4-gram 
language model is trained on Gigaword 3 Xinhua 
portion by SRILM toolkit (Stolcke, 2002) with 
Kneser-Ney smoothing. We use NIST 2002 as 
development set and NIST 2003 as test set. The 
feature weights are tuned by the modified Koehn’s 
MER (Och, 2003, Koehn, 2007) trainer. We use 
case-sensitive BLEU-4 (Papineni et al., 2002) to 
measure the quality of translation result. Zhang et 
al. 2004’s implementation is used to do significant 
test. 
Following (Mi and Huang 2008), we use viterbi 
algorithm to prune the forest. Instead of using a 
static pruning threshold (Mi and Huang 2008), we 
set the threshold as the distance of the probabili-
ties of the nth best tree and the 1st best tree. It 
means the pruned forest is able to at least keep all 
the top n best trees. However, because of the shar-
ing nature of the packed forest, it may still contain 
a large number of additional trees. Our statistic 
shows that when we set the threshold as the 100th 
best tree, the average number of all possible trees 
in the forest is 1.2*105 after pruning. 
In our experiments, we compare our algorithm 
with the two traditional algorithms as discussed in 
section 3. For the “Exhaustive search by tree” al-
gorithm, we use a bottom-up dynamic program-
ming algorithm to generate all the candidate tree 
fragments rooted at each node. For the “Exhaus-
tive search by rule” algorithm, we group all rules 
with the same left hand side in order to remove the 
duplicated matching for the same left hand side 
rules. All these settings aim for fair comparison. 
5.2 Accuracy, speed vs. rule heights 
We first compare the three algorithms’ perfor-
mance by setting the maximum rule height from 1 
to 5. We set the forest pruning threshold to the 
100th best parse tree.  
Table 1 compares the speed of the three algo-
rithms. It clearly shows that the speed of both of 
the two traditional algorithms increases dramati-
cally while the speed of our hyper-tree based algo-
rithm is almost linear to the tree height. In the case 
of rule height of 5, the hyper-tree algorithm is at 
least 19 times (9.329/0.486) faster than the two 
traditional algorithms and saves 8.843(9.329 - 
0.486) seconds in rule matching for each sentence 
on average, which contributes 57% (8.843/(9.329 
+ 6.21)) speed improvement to the overall transla-
tion.  
 
H 
Rule Matching 
D Exhaus-
tive 
by tree 
Exhaus-
tive 
by rule 
Hyper- 
tree-
based 
1 0.043 0.077 0.083   2.96 
2 0.047 0.920 0.173   3.56 
3 0.237 9.572 0.358   4.02 
4 2.300 48.90 0.450   5.27 
5 9.329 90.80 0.486   6.21 
 
Table 1. Speed in seconds per sentence vs. rule 
height; “H” is rule height, “D” represents the de-
coding time after rule matching 
 
 
Height BLEU 
1 0.1646 
2 0.2498 
3 0.2824 
4 0.2874 
5 0.2925 
Moses 0.2625 
 
Table 2. BLEU vs. rule height 
 
Table 2 reports the BLEU score with different 
rule heights, where Moses, a state-of-the-art 
phrase-based SMT system, serves as the baseline 
system.  It shows the BLEU score consistently 
improves as the rule height increases. In addition, 
one can see that the rules with maximum height of 
5 are able to outperform the rules with maximum 
height of 3 by 1 BLEU score (p<0.05) and signifi-
cantly outperforms Moses by 3 BLEU score 
(p<0.01). To our knowledge, this is the first time 
to report the performance of rules up to height of 5 
for forest-based translation model.  
1043
We also study the distribution of the rules used 
in the 1-best translation output. The results are 
shown in Table 3; we could see something inter-
esting that is as the rule height increases, the total 
number of rules with that height decreases, while 
the percentage of partial-lexicalized increases 
dramatically. And one thing needs to note is the 
percentage of partial-lexicalized rules with height 
of 1 is 0, since there is no partial-lexicalized rule 
with height of 1 in the rule set (the father node of 
a word is a pos tag node).  
 
H Total 
Rule Type Percentage (%) 
F P U 
1 9814   76.58     0 23.42 
2 5289   44.99     46.40 8.60 
3 3925   18.39     77.25 4.35 
4 1810   7.90      87.68 4.41 
5 511    6.46 90.50 3.04 
 
Table 3. statistics of rules used in the 1-best trans-
lation output, “F” means full-lexicalized, “P” 
means partial-lexicalized, “U” means unlexiclaizd. 
5.3 Speed vs. forest pruning threshold 
This section studies the impact of the forest prun-
ing threshold on the rule matching speed when 
setting the maximum rule height to 5. 
 
Threshold 
Rule Matching  
Exhaus-
tive 
by tree 
Exhaus-
tive 
by rule 
Hyper- 
tree- 
based 
1 1.2 23.66 0.171 
10 3.1 36.42 0.234 
50 5.7 66.20 0.405 
100 9.3 90.80 0.486 
200 27.3 104.86 0.598 
500 133.6 148.54 0.873 
 
Table 4. Speed in seconds per sentence vs. for-
est  pruning threshold 
 
In Table 4, we can see that our hyper-tree based 
algorithm is the fastest among the three algorithms 
in all pruning threshold settings and even 150 
times faster than both of the two traditional algo-
rithms with threshold of 500th best. Table 5 shows 
the average number of parse trees embedded in a 
packed forest with different pruning thresholds per 
sentence. We can see that the number of trees in-
creases exponentially when the pruning threshold 
increases linearly. When the threshold is 500th best, 
the average number of trees per sentence is 
1.49*109. However, even in this extreme case, the 
hyper-tree based algorithm is still capable of com-
pleting rule matching within 1 second.  
 
Threshold Number of Trees  
1 1 
10 32 
50 5922 
100 128860 
200 2.75*106 
500 1.49*109 
 
Table 5. Average number of trees in packed 
forest with different pruning threshold. 
5.4 Hyper-tree compression rate 
As we describe in section 4.2, theoretically the 
number of tree fragments that a hyper-tree can 
represent is equal to the number of hyper-nodes in 
it. However, in real rule set, there is no guarantee 
that each tree fragment in the hyper-tree has cor-
responding translation rules. To gain insights into 
how effective the compact representation of the 
hyper-tree and how many hyper-nodes without 
translation rules, we define the compression rate 
as follows.  
 
 
 
 
Table 6 reports the different statistics on the 
rule sets with different maximum rule heights 
ranging from 1 to 5. The reported statistics are the 
number of rules, the number of unique left hand 
side (since there may be more than one rules hav-
ing the same left hand side), the number of hyper-
nodes and the compression rate.  
 
H n_rules n_LHS n_nodes c_rate 
1 21588 10779 10779 100% 
2 141632 51807 51903 99.8% 
3 1.73*106 491268 494919 99.2% 
4 8.65*106 2052731 2083296 98.5% 
5 1.89*107 3966742 4043824 98.1% 
 
Table 6. Statistics of rule set and hyper-tree. “H” 
is rule height, “n_rules” is the number of rules, 
“n_LHS” is the number of unique left hand side, 
“n_nodes” is the number of hyper-nodes in hyper-
tree and “c_rate” is the compression rate. 
 
Table 6 shows that in all the five cases, the 
compression rates of hyper-tree are all more than 
1044
98%. It means that almost all the tree fragments 
embedded in the hyper-tree have corresponding 
translation rules. As a result, we are able to use 
almost only one hyper-edge (i.e. only the frontier 
nodes of a tree fragment without any internal 
nodes) to represent all the rules with the same left 
hand side. This suggests that our hyper-tree is par-
ticularly effective in representing the tree transla-
tion rules compactly. It also shows that there are a 
lot of common parts among different translation 
rules. 
All the experiments reported in this section 
convincingly demonstrate the effectiveness of our 
proposed hyper-tree representation of translation 
rules and the hyper-tree-based rule matching algo-
rithm. 
6 Conclusion   
In this paper2, we propose the concept of hyper-
tree for compact rule representation and a hyper-
tree-based fast algorithm for translation rule 
matching in a forest-based translation system. We 
compare our algorithm with two previous widely-
used rule matching algorithms.  Experimental re-
sults on the NIST Chinese-English MT 2003 eval-
uation data set show the rules with maximum rule 
height of 5 outperform those with height 3 by 1.0 
BLEU and outperform MOSES by 3.0 BLEU. In 
the same test cases, our algorithm is at least 19 
times faster than the two traditional algorithms, 
and contributes 57% speed improvement to the 
overall translation. We also show that in a more 
challenging setting (forest containing 1.49*109 
trees on average) our algorithm is 150 times faster 
than the two traditional algorithms. Finally, we 
show that the hyper-tree structure has more than 
98% compression rate. It means the compact re-
presentation by the hyper-tree is very effective for 
translation rules. 
References  
Eugene Charniak. 2000. A maximum-entropy inspired 
parser. NAACL-00. 
Michel Galley, Mark Hopkins, Kevin Knight and Da-
niel Marcu. 2004. What’s in a translation rule? 
HLT-NAACL-04.  
Liang Huang and David Chiang. 2005. Better k-best 
Parsing. IWPT-05. 
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. ACL-07. 144–151 
                                                           
The corresponding authors of this paper are Hui Zhang 
(zhangh1982@gmail.com) and Min Zhang 
(mzhang@i2r.a-star.edu.sg) 
Dan Klein and Christopher D. Manning. 2001. Parsing 
and Hypergraphs. IWPT-2001. 
Dan Klein and Christopher D. Manning. 2001. Parsing 
with Treebank Grammars: Empirical Bounds, Theo-
retical Models, and the Structure of the Penn Tree-
bank. ACL - 2001. 338-345. 
Kevin Knight. 1999. Decoding Complexity in Word-
Replacement Translation Models. CL: J99-4005. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, Ri-
chard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin and Evan Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. 
ACL-07. 177-180. (poster) 
Yang Liu, Qun Liu and Shouxun Lin. 2006. Tree-to-
String Alignment Template for Statistical Machine 
Translation. COLING-ACL-06. 609-616. 
Yang Liu, Yun Huang, Qun Liu and Shouxun Lin. 
2007. Forest-to-String Statistical Translation Rules. 
ACL-07. 704-711. 
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. ACL-HLT-08. 192-199. 
Haitao Mi and Liang Huang. 2008. Forest-based 
Translation Rule Extraction. EMNLP-08. 206-214 
Franz J. Och. 2003. Minimum error rate training in 
statistical machine translation. ACL-03. 160-167. 
Franz Josef Och and Hermann Ney. 2003. A Systematic 
Comparison of Various Statistical Alignment Mod-
els. Computational Linguistics. 29(1) 19-51  
Kishore Papineni, Salim Roukos, ToddWard and Wei-
Jing Zhu. 2002. BLEU: a method for automatic 
evaluation of machine translation. ACL-02.311-318. 
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. ICSLP-02. 901-904. 
Masaru Tomita. 1987. An Efficient Augmented-
Context-Free Parsing Algorithm. Computational 
Linguistics 13(1-2): 31-46. 
Hui Zhang, Min Zhang, Haizhou Li, Aiti Aw and Chew 
Lim Tan. 2009. Forest-based Tree Sequence to 
String Translation Model. ACL-IJCNLP-09. 
Min Zhang, Hongfei Jiang, Ai Ti Aw, Jun Sun, Sheng 
Li and Chew Lim Tan. 2007. A Tree-to-Tree Align-
ment-based Model for Statistical Machine Transla-
tion. MT-Summit-07. 535-542. 
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew 
Lim Tan, Sheng Li. 2008a. A Tree Sequence Align-
ment-based Tree-to-Tree Translation Model. ACL-
HLT-08. 559-567. 
Min Zhang, Hongfei Jiang, Haizhou Li, Aiti Aw, Sheng 
Li. 2008b. Grammar Comparison Study for Transla-
tional Equivalence Modeling and Statistical Ma-
chine Translation. COLING-08. 1097-1104. 
Ying Zhang, Stephan Vogel, Alex Waibel. 2004. Inter-
preting BLEU/NIST scores: How much improvement 
do we need to have a better system? LREC-04 
1045
