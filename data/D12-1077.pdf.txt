Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 843–853, Jeju Island, Korea, 12–14 July 2012. c©2012 Association for Computational Linguistics
Inducing a Discriminative Parser to Optimize Machine
Translation Reordering
Graham Neubig1,2, Taro Watanabe2, Shinsuke Mori1
1Graduate School of Informatics, Kyoto University
Yoshida Honmachi, Sakyo-ku, Kyoto, Japan
2National Institute of Information and Communication Technology
3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan
Abstract
This paper proposes a method for learning
a discriminative parser for machine trans-
lation reordering using only aligned par-
allel text. This is done by treating the
parser’s derivation tree as a latent variable
in a model that is trained to maximize re-
ordering accuracy. We demonstrate that
efficient large-margin training is possible
by showing that two measures of reorder-
ing accuracy can be factored over the parse
tree. Using this model in the pre-ordering
framework results in significant gains in
translation accuracy over standard phrase-
based SMT and previously proposed unsu-
pervised syntax induction methods.
1 Introduction
Finding the appropriate word ordering in the
target language is one of the most difficult prob-
lems for statistical machine translation (SMT),
particularly for language pairs with widely di-
vergent syntax. As a result, there is a large
amount of previous research that handles the
problem of reordering through the use of im-
proved reordering models for phrase-based SMT
(Koehn et al., 2005), hierarchical phrase-based
translation (Chiang, 2007), syntax-based trans-
lation (Yamada and Knight, 2001), or pre-
ordering (Xia and McCord, 2004).
In particular, systems that use source-
language syntax allow for the handling of long-
distance reordering without large increases in
The first author is now affiliated with the Nara Institute
of Science and Technology.
decoding time. However, these require a good
syntactic parser, which is not available for many
languages. In recent work, DeNero and Uszko-
reit (2011) suggest that unsupervised grammar
induction can be used to create source-sentence
parse structure for use in translation as a part
of a pre-ordering based translation system.
In this work, we present a method for inducing
a parser for SMT by training a discriminative
model to maximize reordering accuracy while
treating the parse tree as a latent variable. As a
learning framework, we use online large-margin
methods to train the model to directly minimize
two measures of reordering accuracy. We pro-
pose a variety of features, and demonstrate that
learning can succeed when no linguistic informa-
tion (POS tags or parse structure) is available in
the source language, but also show that this lin-
guistic information can be simply incorporated
when it is available. Experiments find that the
proposed model improves both reordering and
translation accuracy, leading to average gains
of 1.2 BLEU points on English-Japanese and
Japanese-English translation without linguistic
analysis tools, or up to 1.5 BLEU points when
these tools are incorporated. In addition, we
show that our model is able to effectively max-
imize various measures of reordering accuracy,
and that the reordering measure that we choose
has a direct effect on translation results.
2 Preordering for SMT
Machine translation is defined as transforma-
tion of source sentence F = f1 . . . fJ to target
sentence E = e1 . . . eI . In this paper, we take
843
Figure 1: An example with a source sentence F re-
ordered into target order F ?, and its corresponding
target sentence E. D is one of the BTG derivations
that can produce this ordering.
the pre-ordering approach to machine transla-
tion (Xia and McCord, 2004), which performs
translation as a two step process of reordering
and translation (Figure 1). Reordering first de-
terministically transforms F into F ?, which con-
tains the same words as F but is in the order of
E. Translation then transforms F ? into E using
a method such as phrase-based SMT (Koehn et
al., 2003), which can produce accurate transla-
tions when only local reordering is required.
This general framework has been widely stud-
ied, with the majority of works relying on a
syntactic parser being available in the source
language. Reordering rules are defined over
this parse either through machine learning tech-
niques (Xia and McCord, 2004; Zhang et al.,
2007; Li et al., 2007; Genzel, 2010; Dyer and
Resnik, 2010; Khalilov and Sima’an, 2011) or
linguistically motivated manual rules (Collins et
al., 2005; Xu et al., 2009; Carpuat et al., 2010;
Isozaki et al., 2010b). However, as building a
parser for each source language is a resource-
intensive undertaking, there has also been some
interest in developing reordering rules without
the use of a parser (Rottmann and Vogel, 2007;
Tromble and Eisner, 2009; DeNero and Uszko-
reit, 2011; Visweswariah et al., 2011), and we
will follow this thread of research in this paper.
In particular, two methods deserve mention
for being similar to our approach. First, DeNero
and Uszkoreit (2011) learn a reordering model
through a three-step process of bilingual gram-
mar induction, training a monolingual parser
to reproduce the induced trees, and training
a reordering model that selects a reordering
based on this parse structure. In contrast, our
method trains the model in a single step, treat-
ing the parse structure as a latent variable in
a discriminative reordering model. In addition
Tromble and Eisner (2009) and Visweswariah et
al. (2011) present models that use binary clas-
sification to decide whether each pair of words
should be placed in forward or reverse order. In
contrast, our method uses traditional context-
free-grammar models, which allows for simple
parsing and flexible parameterization, including
features such as those that utilize the existence
of a span in the phrase table. Our work is also
unique in that we show that it is possible to di-
rectly optimize several measures of reordering
accuracy, which proves important for achieving
good translations.1
3 Training a Reordering Model with
Latent Derivations
In this section, we provide a basic overview of
the proposed method for learning a reordering
model with latent derivations using online dis-
criminative learning.
3.1 Space of Reorderings
The model we present here is based on the
bracketing transduction grammar (BTG, Wu
(1997)) framework. BTGs represent a binary
tree derivation D over the source sentence F
as shown in Figure 1. Each non-terminal node
can either be a straight (str) or inverted (inv)
production, and terminals (term) span a non-
empty substring f .2
The ordering of the sentence is determined by
the tree structure and the non-terminal labels
str and inv, and can be built bottom-up. Each
subtree represents a source substring f and its
reordered counterpart f ?. For each terminal
node, no reordering occurs and f is equal to f ?.
1The semi-supervised method of Katz-Brown et al.
(2011) also optimizes reordering accuracy, but requires
manually annotated parses as seed data.
2In the original BTG framework used in translation,
terminals produce a bilingual substring pair f/e, but as
we are only interested in reordering the source F , we
simplify the model by removing the target substring e.
844
For each non-terminal node spanning f with its
left child spanning f1 and its right child span-
ning f2, if the non-terminal symbol is str, the
reordered strings will be concatenated in order
as f ? = f ?1f ?2, and if the non-terminal symbol is
inv, the reordered strings will be concatenated
in inverted order as f ? = f ?2f ?1.
We define the space of all reorderings that can
be produced by the BTG as F ?, and attempt to
find the best reordering Fˆ ? within this space.3
3.2 Reorderings with Latent
Derivations
In order to find the best reordering Fˆ ? given only
the information in the source side sentence F , we
define a scoring function S(F ?|F ), and choose
the ordering of maximal score:
F? ? = arg max
F ?
S(F ?|F ).
As our model is based on reorderings licensed
by BTG derivations, we also assume that there
is an underlying derivation D that produced F ?.
As we can uniquely determine F ? given F and
D, we can define a scoring function S(D|F ) over
derivations, find the derivation of maximal score
D? = arg max
D
S(D|F )
and use D? to transform F into F ?.
Furthermore, we assume that the score
S(D|F ) is the weighted sum of a number of fea-
ture functions defined over D and F
S(D|F,w) =
?
i
wi?i(D,F )
where ?i is the ith feature function, and wi is
its corresponding weight in weight vector w.
Given this model, we must next consider how
to learn the weights w. As the final goal of our
model is to produce good reorderings F ?, it is
natural to attempt to learn weights that will al-
low us to produce these high-quality reorderings.
3BTGs cannot reproduce all possible reorderings, but
can handle most reorderings occurring in natural trans-
lated text (Haghighi et al., 2009).
Figure 2: An example of (a) the ranking function
r(fj), (b) loss according to Kendall’s ? , (c) loss ac-
cording to chunk fragmentation.
4 Evaluating Reorderings
Before we explain the learning algorithm, we
must know how to distinguish whether the F ?
produced by the model is good or bad. This
section explains how to calculate oracle reorder-
ings, and assign each F ? a loss and an accuracy
according to how well it reproduces the oracle.
4.1 Calculating Oracle Orderings
In order to calculate reordering quality, we first
define a ranking function r(fj |F,A), which indi-
cates the relative position of source word fj in
the proper target order (Figure 2 (a)). In or-
der to calculate this ranking function, we define
A = a1, . . . ,aJ , where each aj is a set of the in-
dices of the words in E to which fj is aligned.4
Given these alignments, we define an ordering
function aj1 < aj2 that indicates that the in-
dices in aj1 come before the indices in aj2 . For-
mally, we define this function as “the first index
in aj1 is at most the first index in aj2 , similarly
for the last index, and either the first or last
index in aj1 is less than that of aj2 .”
Given this ordering, we can sort every align-
ment aj , and use its relative position in the sen-
tence to assign a rank to its word r(fj). In
4Null alignments require special treatment. To do so,
we can place unaligned brackets and quotes directly be-
fore and after the spans they surround, and attach all
other unaligned words to the word directly to the right
for head-initial languages (e.g. English), or left for head-
final languages (e.g. Japanese).
845
the case of ties, where neither aj1 < aj2 nor
aj2 < aj1 , both fj1 and fj2 are assigned the
same rank. We can now define measures of re-
ordering accuracy for F ? by how well it arranges
the words in order of ascending rank. It should
be noted that as we allow ties in rank, there
are multiple possible F ? where all words are in
strictly ascending order, which we will call ora-
cle orderings.
4.2 Kendall’s ?
The first measure of reordering accuracy that
we will consider is Kendall’s ? (Kendall, 1938),
a measure of pairwise rank correlation which
has been proposed for evaluating translation re-
ordering accuracy (Isozaki et al., 2010a; Birch
et al., 2010) and pre-ordering accuracy (Talbot
et al., 2011). The fundamental idea behind the
measure lies in comparisons between each pair of
elements f ?j1 and f ?j2 of the reordered sentence,
where j1 < j2. Because j1 < j2, f ?j1 comes before
f ?j2 in the reordered sentence, the ranks should
be r(f ?j1) ? r(f ?j2) in order to produce the cor-
rect ordering.
Based on this criterion, we first define a loss
Lt(F ?) that will be higher for orderings that are
further from the oracle. Specifically, we take the
sum of all pairwise orderings that do not follow
the expected order
Lt(F ?) =
J?1
?
j1=1
J
?
j2=j1+1
?(r(f ?j1) > r(f
?
j2))
where ?(·) is an indicator function that is 1 when
its condition is true, and 0 otherwise. An exam-
ple of this is given in Figure 2 (b).
To calculate an accuracy measure for ordering
F ?, we first calculate the maximum loss for the
sentence, which is equal to the total number of
non-equal rank comparisons in the sentence5
max
F ?
Lt(F ?) =
J?1
?
j1=1
J
?
j2=j1+1
?(r(f ?j1) 6= r(f
?
j2)).
(1)
5The traditional formulation of Kendall’s ? assumes
no ties in rank, and thus the maximum loss can be cal-
culated as J(J ? 1)/2.
Finally, we use this maximum loss to normalize
the actual loss to get an accuracy
At(F ?) = 1?
Lt(F ?)
max
F˜ ?
Lt(F˜ ?)
,
which will take a value between 0 (when F ? has
maximal loss), and 1 (when F ? matches one of
the oracle orderings). In Figure 2 (b), Lt(F ?) =
2 and max
F˜ ?
Lt(F˜ ?) = 8, so At(F ?) = 0.75.
4.3 Chunk Fragmentation
Another measure that has been used in eval-
uation of translation accuracy (Banerjee and
Lavie, 2005) and pre-ordering accuracy (Talbot
et al., 2011) is chunk fragmentation. This mea-
sure is based on the number of chunks that the
sentence needs to be broken into to reproduce
the correct ordering, with a motivation that the
number of continuous chunks is equal to the
number of times the reader will have to jump to
a different position in the reordered sentence to
read it in the target order. One way to measure
the number of continuous chunks is considering
whether each word pair f ?j and f ?j+1 is discon-
tinuous (the rank of f ?j+1 is not equal to or one
greater than f ?j)
discont(f ?j , f ?j+1) =
?(r(f ?j) 6= r(f ?j+1) ? r(f ?j) + 1 6= r(f ?j+1))
and sum over all word pairs in the sentence to
create a sentence-based loss
Lc(F ?) =
J?1
?
j=1
discont(f ?j , f ?j+1) (2)
While this is the formulation taken by previ-
ous work, we found that this under-penalizes
bad reorderings of the first and last words of
the sentence, which can contribute to the loss
only once, as opposed to other words which can
contribute to the loss twice. To account for
this, when calculating the chunk fragmentation
score, we additionally add two sentence bound-
ary words f0 and fJ+1 with ranks r(f0) = 0 and
r(fJ+1) = 1 + max
f ?j?F ?
r(f ?j) and redefine the sum-
mation in Equation (2) to consider these words
(e.g. Figure 2 (c)).
846
procedure WeightUpdate(F , A, w)
D ? parse(F,w) . Create parse forest
D? ? argmax
D?D
S(D|F,w) + L(D|F,A)
. Find the model parse
Dˆ ? argmin
D?D
L(D|F,A)? ?S(D|F,w)
. Find the oracle parse
if L(Dˆ|F,A) 6= L(D?|F,A) then
w ? ?(w + ?(?(Dˆ, F )? ?(D?, F )))
. Perform weight update
end if
end procedure
Figure 3: An online update for sentence F , alignment
A, and weight vector w. ? is a very small constant,
and ? and ? are defined by the update strategy.
Similarly to Kendall’s ? , we can also define
an accuracy measure between 0 and 1 using the
maximum loss, which will be at most J + 1,
which corresponds to the total number of com-
parisons made in calculating the loss6
Ac(F ?) = 1?
Lc(F ?)
J + 1
.
In Figure 2 (c), Lc(F ?) = 3 and J + 1 = 6, so
Ac(F ?) = 0.5.
5 Learning a BTG Parser for
Reordering
Now that we have a definition of loss over re-
orderings produced by the model, we have a
clear learning objective: we would like to find
reorderings F ? with low loss. The learning algo-
rithm we use to achieve this goal is motivated
by discriminative training for machine transla-
tion systems (Liang et al., 2006), and extended
to use large-margin training in an online frame-
work (Watanabe et al., 2007).
5.1 Learning Algorithm
Learning uses the general framework of large-
margin online structured prediction (Crammer
et al., 2006), which makes several passes through
the data, finding a derivation with high model
score (the model parse) and a derivation with
6It should be noted that for sentences of length one or
sentences with tied ranks, the maximum loss may be less
than J +1, but for simplicity we use this approximation.
minimal loss (the oracle parse), and updating w
if these two parses diverge (Figure 3).
In order to create both of these parses effi-
ciently, we first create a parse forest encoding a
large number of derivations Di according to the
model scores. Next, we find the model parse D?i,
which is the parse in the forest Di that maxi-
mizes the sum of the model score and the loss
S(Dk|Fk,w)+L(Dk|Fk, Ak). It should be noted
that here we are considering not only the model
score, but also the derivation’s loss. This is
necessary for loss-driven large-margin training
(Crammer et al., 2006), and follows the basic
intuition that during training, we would like to
make it easier to select negative examples with
large loss, causing these examples to be penal-
ized more often and more heavily.
We also find an oracle parse Dˆi, which is se-
lected solely to minimize the loss L(Dk|Fk, Ak).
One important difference between the model we
describe here and traditional parsing models is
that the target derivation Dˆk is a latent variable.
Because many Dk achieve a particular reorder-
ing F ?, many reorderings F ? are able to mini-
mize the loss L(F ?k|Fk, Ak). Thus it is necessary
to choose a single oracle derivation to treat as
the target out of many equally good reorderings.
DeNero and Uszkoreit (2011) resolve this ambi-
guity with four features with empirically tuned
scores before training a monolingual parser and
reordering model. In contrast, we follow previ-
ous work on discriminative learning with latent
variables (Yu and Joachims, 2009), and break
ties within the pool of oracle derivations by se-
lecting the derivation with the largest model
score. From an implementation point of view,
this can be done by finding the derivation that
minimizes L(Dk|Fk, Ak)??S(Dk|Fk,w), where
? is a constant small enough to ensure that the
effect of the loss will always be greater than the
effect of the score.
Finally, if the model parse D?k has a loss that
is greater than that of the oracle parse Dˆk, we
update the weights to increase the score of the
oracle parse and decrease the score of the model
parse. Any criterion for weight updates may be
used, such as the averaged perceptron (Collins,
2002) and MIRA (Crammer et al., 2006), but
847
we opted to use Pegasos (Shalev-Shwartz et al.,
2007) as it allows for the introduction of regu-
larization and relatively stable learning.
To perform this full process, given a source
sentence Fk, alignment Ak, and model weights
w we need to be able to efficiently calculate
scores, calculate losses, and create parse forests
for derivations Dk, the details of which will be
explained in the following sections.
5.2 Scoring Derivation Trees
First, we must consider how to efficiently assign
scores S(D|F,w) to a derivation or forest during
parsing. The most standard and efficient way to
do so is to create local features that can be cal-
culated based only on the information included
in a single node d in the derivation tree. The
score of the whole tree can then be expressed as
the sum of the scores from each node:
S(D|F,w) =
?
d?D
S(d|F,w)
=
?
d?D
?
i
wi?i(d, F ).
Based on this restriction, we define a number of
features that can be used to score the parse tree.
To ease explanation, we represent each node in
the derivation as d = ?s, l, c, c + 1, r?, where s
is the node’s symbol (str, inv, or term), while
l and r are the leftmost and rightmost indices
of the span that d covers. c and c + 1 are the
rightmost index of the left child and leftmost
index of the right child for non-terminal nodes.
All features are intersected with the node la-
bel s, so each feature described below corre-
sponds to three different features (or two for
features applicable to only non-terminal nodes).
• ?lex: Identities of words in positions fl, fr,
fc, fc+1, fl?1, fr+1, flfr, and fcfc+1.
• ?class: Same as ?lex, but with words ab-
stracted to classes. We use the 50 classes
automatically generated by Och (1999)’s
method that are calculated during align-
ment in standard SMT systems.
• ?balance: For non-terminals, features indi-
cating whether the length of the left span
(c? l+1) is lesser than, equal to, or greater
than the length of the right span (r ? c).
• ?table: Features, bucketed by length, that
indicate whether “fl . . . fr” appears as a
contiguous phrase in the SMT training
data, as well as the log frequency of the
number of times the phrase appears total
and the number of times it appears as a
contiguous phrase (DeNero and Uszkoreit,
2011). Phrase length is limited to 8, and
phrases of frequency one are removed.
• ?pos: Same as ?lex, but with words ab-
stracted to language-dependent POS tags.
• ?cfg: Features indicating the label of the
spans fl . . . fr, fl . . . fc, and fc+1 . . . fr in a
supervised parse tree, and the intersection
of the three labels. When spans do not cor-
respond to a span in the supervised parse
tree, we indicate “no span” with the label
“X” (Zollmann and Venugopal, 2006).
Most of these features can be calculated from
only a parallel corpus, but ?pos requires a POS
tagger and ?cfg requires a full syntactic parser
in the source language. As it is preferable to
have a method that is applicable in languages
where these tools are not available, we perform
experiments both with and without the features
that require linguistic analysis tools.
5.3 Finding Losses for Derivation Trees
The above features ? and their corresponding
weights w are all that are needed to calculate
scores of derivation trees at test time. However,
during training, it is also necessary to find model
parses according to the loss-augmented scoring
function S(D|F,w)+L(D|F,A) or oracle parses
according to the loss L(D|F,A). As noted by
Taskar et al. (2003), this is possible if our losses
can be factored in the same way as the feature
space. In this section, we demonstrate that the
loss L(d|F,A) for the evaluation measures we
defined in Section 4 can (mostly) be factored
over nodes in a fashion similar to features.
848
5.3.1 Factoring Kendall’s ?
For Kendall’s ? , in the case of terminal nodes,
Lt(d = ?term, l, r?|F,A) can be calculated by
performing the summation in Equation (1). We
can further define this sum recursively and use
memoization for improved efficiency
Lt(d|F,A) =Lt(?term, l, r ? 1?|F,A)
+
r?1
?
j=l
?(r(fj) > r(fr)). (3)
For non-terminal nodes, we first focus on
straight non-terminals with parent node d =
?str, l, c, c+1, r?, and left and right child nodes
dl = ?sl, l, lc, lc+1, c? and dr = ?sr, c+1, rc, rc+
1, r?. First, we note that the loss for the subtree
rooted at d can be expressed as
Lt(d|F,A) =Lt(dl|F,A) + Lt(dr|F,A)
+
c
?
j1=l
r
?
j2=c+1
?(r(fj1) > r(fj2)).
In other words, the subtree’s total loss can be
factored into the loss of its left subtree, the
loss of its right subtree, and the additional loss
contributed by comparisons between the words
spanning both subtrees. In the case of inverted
terminals, we must simply reverse the compari-
son in the final sum to be ?(r(fj1) < r(fj2)).
5.3.2 Factoring Chunk Fragmentation
Chunk fragmentation loss can be factored in a
similar fashion. First, it is clear that the loss for
the terminal nodes can be calculated efficiently
in a fashion similar to Equation (3). In order to
calculate the loss for non-terminals d, we note
that the summation in Equation (2) can be di-
vided into the sum over the internal bi-grams
in the left and right subtrees, and the bi-gram
spanning the reordered trees
Lc(d|F,A) =Lc(dl|F,A) + Lc(dr|F,A)
+ discont(f ?c, f ?c+1).
However, unlike Kendall’s ? , this equation re-
lies not on the ranks of fc and fc+1 in the origi-
nal sentence, but on the ranks of f ?c and f ?c+1 in
the reordered sentence. In order to keep track
of these values, it is necessary to augment each
node in the tree to be d = ?s, l, c, c + 1, r, tl, tr?
with two additional values tl and tr that indi-
cate the position of the leftmost and rightmost
words after reordering. Thus, a straight non-
terminal parent d with children dl = ?sl, l, lc, lc+
1, c, tl, tlr? and dr = ?sr, c+1, rc, rc+1, r, trl, tr?
will have loss as follows
Lc(d|F,A) =Lc(dl|F,A) + Lc(dr|F,A)
+ discont(ftlr, ftrl)
with a similar calculation being possible for in-
verted non-terminals.
5.4 Parsing Derivation Trees
Finally, we must be able to create a parse forest
from which we select model and oracle parses.
As all feature functions factor over single nodes,
it is possible to find the parse tree with the high-
est score in O(J3) time using the CKY algo-
rithm. However, when keeping track of target
positions for calculation of chunk fragmentation
loss, there are a total of O(J5) nodes, an unrea-
sonable burden in terms of time and memory.
To overcome this problem, we note that this set-
ting is nearly identical to translation using syn-
chronous CFGs with an integrated bigram LM,
and thus we can employ cube-pruning to reduce
our search space (Chiang, 2007).
6 Experiments
Our experiments test the reordering and trans-
lation accuracy of translation systems using the
proposed method. As reordering metrics, we use
Kendall’s ? and chunk fragmentation (Talbot et
al., 2011) comparing the system F ? and oracle
F ? calculated with manually created alignments.
As translation metrics, we use BLEU (Papineni
et al., 2002), as well as RIBES (Isozaki et al.,
2010a), which is similar to Kendall’s ? , but eval-
uated on the target sentence E instead of the re-
ordered sentence F ?. All scores are the average
of three training runs to control for randomness
in training (Clark et al., 2011).
For translation, we use Moses (Koehn et al.,
2007) with lexicalized reordering (Koehn et al.,
2005) in all experiments. We test three types
849
en-ja ja-en
Chunk ? BLEU RIBES Chunk ? BLEU RIBES
orig 61.22 73.46 21.87 68.25 66.42 72.99 18.34 65.36
3-step 63.51 72.55 21.45 67.66 67.17 73.01 17.78 64.42
3-step+?pos 64.28 72.11 21.45 67.44 67.56 74.21 18.18 64.65
3-step+?cfg 65.76 75.32 21.67 68.47 67.23 74.06 18.18 64.93
lader 73.19 78.44 23.11 69.86 75.14 79.14 19.54 66.93
lader+?pos 73.97 79.24 23.32 69.78 75.49 78.79 19.89 67.24
lader+?cfg 75.06 80.53 23.36 70.89 75.14 77.80 19.35 66.12
Table 2: Reordering (chunk, ?) and translation (BLEU, RIBES) results for each system. Bold numbers
indicate no significant difference from the best system (bootstrap resampling with p > 0.05) (Koehn, 2004).
sent. word (ja) word (en)
RM-train 602 14.5k 14.3k
RM-test 555 11.2k 10.4k
TM/LM 329k 6.08M 5.91M
Tune 1166 26.8k 24.3k
Test 1160 28.5k 26.7k
Table 1: The number of sentences and words for
training and testing the reordering model (RM),
translation model (TM), and language model (LM).
of pre-ordering: original order with F ? ? F
(orig), pre-orderings learned using the 3-step
process of DeNero and Uszkoreit (2011) (3-
step), and the proposed model with latent
derivations (lader).7 Except when stated oth-
erwise, lader was trained to minimize chunk
fragmentation loss with a cube pruning stack
pop limit of 50, and the regularization constant
of 10?3 (chosen through cross-validation).
We test our systems on Japanese-English and
English-Japanese translation using data from
the Kyoto Free Translation Task (Neubig, 2011).
We use the training set for training translation
and language models, the development set for
weight tuning, and the test set for testing (Table
1). We use the designated development and test
sets of manually created alignments as training
data for the reordering models, removing sen-
tences of more than 60 words.
As default features for lader and the mono-
lingual parsing and reordering models in 3-step,
we use all the features described in Section 5.2
7Available open-source: http://phontron.com/lader
except ?pos and ?cfg. In addition, we test sys-
tems with ?pos and ?cfg added. For English,
we use the Stanford parser (Klein and Manning,
2003) for both POS tagging and CFG parsing.
For Japanese, we use the KyTea tagger (Neu-
big et al., 2011) for POS tagging,8 and the EDA
word-based dependency parser (Flannery et al.,
2011) with simple manual head-rules to convert
a dependency parse to a CFG parse.
6.1 Effect of Pre-ordering
Table 2 shows reordering and translation results
for orig, 3-step, and lader. It can be seen
that the proposed lader outperforms the base-
lines in both reordering and translation.9 There
are a number of reasons why lader outper-
forms 3-step. First, the pipeline of 3-step
suffers from error propogation, with errors in
monolingual parsing and reordering resulting
in low overall accuracy.10 Second, as Section
5.1 describes, lader breaks ties between ora-
cle parses based on model score, allowing easy-
to-reproduce model parses to be chosen dur-
ing training. In fact, lader generally found
trees that followed from syntactic constituency,
while 3-step more often used terminal nodes
8In addition, following the example of Sudoh et al.
(2011a)’s reordering rules, we lexicalize all particles.
9It should be noted that our results for 3-step are
significantly worse than those of DeNero and Uszkoreit
(2011). Likely reasons include a 20x difference in training
data size, the fact that we are using naturally translated
text as opposed to text translated specifically to create
word alignments, or differences in implementation.
10When using oracle parses, chunk accuracy was up to
81%, showing that parsing errors are highly detrimental.
850
en-ja ja-en
Chunk ? BLEU RIBES Chunk ? BLEU RIBES
Lc 73.19 78.44 23.11 69.86 75.14 79.14 19.54 66.93
Lt 70.37 79.57 22.57 69.47 72.51 78.93 18.52 66.26
Lc + Lt 72.55 80.58 22.89 70.34 74.44 79.82 19.21 66.48
Table 3: Results for systems trained to optimize chunk fragmentation (Lc) or Kendall’s ? (Lt).
that spanned constituent boundaries (as long as
the phrase frequency was high). Finally, as Sec-
tion 6.2 shows in detail, the ability of lader to
maximize reordering accuracy directly allows for
improved reordering and translation results.
It can also be seen that incorporating POS
tags or parse trees improves accuracy of both
lader and 3-step, particularly for English-
Japanese, where syntax has proven useful for
pre-ordering, and less so for Japanese-English,
where syntactic pre-ordering has been less suc-
cessful (Sudoh et al., 2011b).
We also tested Moses’s implementation of hi-
erarchical phrase-based SMT (Chiang, 2007),
which achieved BLEU scores of 23.21 and 19.30
for English-Japanese and Japanese-English re-
spectively, approximately matching lader in
accuracy, but with a significant decrease in de-
coding speed. Further, when pre-ordering with
lader and hierarchical phrase-based SMT were
combined, BLEU scores rose to 23.29 and 19.69,
indicating that the two techniques can be com-
bined for further accuracy improvements.
6.2 Effect of Training Loss
Table 3 shows results when one of three losses is
optimized during training: chunk fragmentation
(Lc), Kendall’s ? (Lt), or the linear interpola-
tion of the two with weights chosen so that both
losses contribute equally (Lt + Lc). In general,
training successfully maximizes the criterion it is
trained on, and Lt +Lc achieves good results on
both measures. We also find that Lc and Lc+Lt
achieve the best translation results, which is
in concert with Talbot et al. (2011), who find
chunk fragmentation is better correlated with
translation accuracy than Kendall’s ? . This is
an important result, as methods such as that
of Tromble and Eisner (2009) optimize pairwise
en-ja ja-en
BLEU/RIBES BLEU/RIBES
orig 21.87 68.25 18.34 65.36
man-602 23.11 69.86 19.54 66.93
auto-602 22.39 69.19 18.58 66.07
auto-10k 22.53 69.68 18.79 66.89
Table 4: Results based on data size, and whether
manual or automatic alignments are used in training.
word comparisons equivalent to Lt, which may
not be optimal for translation.
6.3 Effect of Automatic Alignments
Table 4 shows the difference between using man-
ual and automatic alignments in the training of
lader. lader is able to improve over the orig
baseline in all cases, but when equal numbers
of manual and automatic alignments are used,
the reorderer trained on manual alignments is
significantly better. However, as the number of
automatic alignments is increased, accuracy im-
proves, approaching that of the system trained
on a smaller number of manual alignments.
7 Conclusion
We presented a method for learning a discrim-
inative parser to maximize reordering accuracy
for machine translation. Future work includes
application to other language pairs, develop-
ment of more sophisticated features, investiga-
tion of probabilistic approaches to inference, and
incorporation of the learned trees directly in
tree-to-string translation.
Acknowledgments
We thank Isao Goto, Tetsuo Kiso, and anony-
mous reviewers for their helpful comments, and
Daniel Flannery for helping to run his parser.
851
References
Satanjeev Banerjee and Alon Lavie. 2005. ME-
TEOR: An automatic metric for MT evaluation
with improved correlation with human judgments.
In Proc. ACL Workshop.
Alexandra Birch, Miles Osborne, and Phil Blunsom.
2010. Metrics for MT evaluation: evaluating re-
ordering. Machine Translation, 24(1):15–26.
Marine Carpuat, Yuval Marton, and Nizar Habash.
2010. Improving arabic-to-english statistical ma-
chine translation by reordering post-verbal sub-
jects for alignment. In Proc. ACL.
David Chiang. 2007. Hierarchical phrase-based
translation. Computational Linguistics, 33(2).
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis test-
ing for statistical machine translation: Control-
ling for optimizer instability. In Proc. ACL, pages
176–181.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proc. ACL.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and ex-
periments with perceptron algorithms. In Proc.
EMNLP, pages 1–8.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. Journal of Machine
Learning Research, 7:551–585.
John DeNero and Jakob Uszkoreit. 2011. Induc-
ing sentence structure from parallel corpora for
reordering. In Proc. EMNLP.
Chris Dyer and Philip Resnik. 2010. Context-free
reordering, finite-state translation. In Proc. HLT-
NAACL.
Daniel Flannery, Yusuke Miyao, Graham Neubig,
and Shinsuke Mori. 2011. Training dependency
parsers from partially annotated corpora. In Proc.
IJCNLP, pages 776–784, Chiang Mai, Thailand,
November.
Dmitriy Genzel. 2010. Automatically learning
source-side reordering rules for large scale machine
translation. In Proc. COLING.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with super-
vised ITG models. In Proc. ACL.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Kat-
suhito Sudoh, and Hajime Tsukada. 2010a. Auto-
matic evaluation of translation quality for distant
language pairs. In Proc. EMNLP, pages 944–952.
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada,
and Kevin Duh. 2010b. Head finalization: A
simple reordering rule for sov languages. In Proc.
WMT and MetricsMATR.
Jason Katz-Brown, Slav Petrov, Ryan McDon-
ald, Franz Och, David Talbot, Hiroshi Ichikawa,
Masakazu Seno, and Hideto Kazawa. 2011. Train-
ing a parser for machine translation reordering. In
Proc. EMNLP, pages 183–192.
Maurice G. Kendall. 1938. A new measure of rank
correlation. Biometrika, 30(1/2):81–93.
Maxim Khalilov and Khalil Sima’an. 2011. Context-
sensitive syntactic source-reordering by statistical
transduction. In Proc. IJCNLP.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proc. ACL, pages
423–430.
Phillip Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
Proc. HLT, pages 48–54.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh system descrip-
tion for the 2005 IWSLT speech translation eval-
uation. In Proc. IWSLT.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In Proc. ACL, pages 177–180.
Philipp Koehn. 2004. Statistical significance tests
for machine translation evaluation. In Proc.
EMNLP.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,
Ming Zhou, and Yi Guan. 2007. A probabilistic
approach to syntax-based reordering for statistical
machine translation. In Proc. ACL.
Percy Liang, Alexandre Bouchard-Coˆte´, Dan Klein,
and Ben Taskar. 2006. An end-to-end discrimi-
native approach to machine translation. In Proc.
ACL, pages 761–768.
Graham Neubig, Yosuke Nakata, and Shinsuke Mori.
2011. Pointwise prediction for robust, adaptable
Japanese morphological analysis. In Proc. ACL,
pages 529–533, Portland, USA, June.
Graham Neubig. 2011. The Kyoto free translation
task. http://www.phontron.com/kftt.
Franz Josef Och. 1999. An efficient method for de-
termining bilingual word classes. In Proc. EACL.
852
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Proc.
COLING, pages 311–318.
Kay Rottmann and Stephan Vogel. 2007. Word re-
ordering in statistical machine translation with a
pos-based distortion model. In Proc. of TMI-2007.
Shai Shalev-Shwartz, Yoram Singer, and Nathan
Srebro. 2007. Pegasos: Primal estimated sub-
gradient solver for SVM. In Proc. ICML, pages
807–814.
Katsuhito Sudoh, Kevin Duh, Hajime Tsukada,
Masaaki Nagata, Xianchao Wu, Takuya Mat-
suzaki, and Jun’ichi Tsujii. 2011a. NTT-
UT statistical machine translation in NTCIR-9
PatentMT. In Proc. NTCIR.
Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Ha-
jime Tsukada, and Masaaki Nagata. 2011b. Post-
ordering in statistical machine translation. In
Proc. MT Summit.
David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Ja-
son Katz-Brown, Masakazu Seno, and Franz Och.
2011. A lightweight evaluation framework for ma-
chine translation reordering. In Proc. WMT.
Ben Taskar, Carlos Guestrin, and Daphne Koller.
2003. Max-margin Markov networks. Proc. NIPS,
16.
Roy Tromble and Jason Eisner. 2009. Learning lin-
ear ordering problems for better translation. In
Proc. EMNLP.
Karthik Visweswariah, Rajakrishnan Rajkumar,
Ankur Gandhe, Ananthakrishnan Ramanathan,
and Jiri Navratil. 2011. A word reordering
model for improved machine translation. In Proc.
EMNLP.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and
Hideki Isozaki. 2007. Online large-margin train-
ing for statistical machine translation. In Proc.
EMNLP, pages 764–773.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel cor-
pora. Computational Linguistics, 23(3).
Fei Xia and Michael McCord. 2004. Improving a
statistical MT system with automatically learned
rewrite patterns. In Proc. COLING.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
smt for subject-object-verb languages. In Proc.
NAACL.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proc. ACL.
Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural SVMs with latent variables.
In Proc. ICML, pages 1169–1176.
Yuqi Zhang, Richard Zens, and Hermann Ney. 2007.
Chunk-level reordering of source language sen-
tences with automatically learned rules for statis-
tical machine translation. In Proc. SSST.
Andreas Zollmann and Ashish Venugopal. 2006.
Syntax augmented machine translation via chart
parsing. In Proc. WMT, pages 138–141.
853
