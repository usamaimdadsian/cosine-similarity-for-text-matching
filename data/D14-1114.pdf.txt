Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1070–1080,
October 25-29, 2014, Doha, Qatar.
c©2014 Association for Computational Linguistics
Tailor knowledge graph for query understanding: linking intent topics by
propagation
Shi Zhao
z.s@pku.edu.cn
Yan Zhang
zhy@cis.pku.edu.cn
Department of Machine Intelligence, Peking University, Beijing, China
Key Laboratory on Machine Perception, Ministry of Education, Beijing, China
Abstract
Knowledge graphs are recently used for
enriching query representations in an
entity-aware way for the rich facts or-
ganized around entities in it. How-
ever, few of the methods pay attention to
non-entity words and clicked websites in
queries, which also help conveying user
intent. In this paper, we tackle the prob-
lem of intent understanding with innova-
tively representing entity words, refiners
and clicked urls as intent topics in a uni-
fied knowledge graph based framework,
in a way to exploit and expand knowl-
edge graph which we call ‘tailor’. We
collaboratively exploit global knowledge
in knowledge graphs and local contexts in
query log to initialize intent representa-
tion, then propagate the enriched features
in a graph consisting of intent topics us-
ing an unsupervised algorithm. The ex-
periments prove intent topics with knowl-
edge graph enriched features significantly
enhance intent understanding.
1 Introduction
Query understanding is the process of generating a
representation which characterizes a user’s search
intent (Croft et al., 2010), which is of vital im-
portance for information retrieval. However, users
are remarkably laconic in describing their infor-
mation needs due to anomalous state of knowledge
(Belkin et al., 1982), resulting in vague and under-
specified queries, which makes it especially dif-
ficult to understand and locate what they intended
for in mountains of web data. The problem is often
significantly compounded that people convey their
intent rather in a series of behaviors called a search
session than a single query, leaving a wealth of
clues including query reformulations, page visits,
dwell times, etc. What’s more, as entities are tak-
ing center stage (Yin and Shah, 2010), string-level
or phrase-level modeling of intent soon hits the
bottleneck, calling for an entity-aware perspective.
Knowledge repositories, better known as
knowledge graphs, such as Wikipedia, DBpedia
and Freebase, have been recently utilized for en-
hancing query understanding for the large amounts
of world knowledge they’ve harvested about en-
tities and facts. A widely accepted way to use
knowledge graph is tying queries with it by anno-
tating entities in them, also known as entity link-
ing.
However, information need is conveyed through
more than entities. Quite a few non-entity words,
aka refiners or modifiers, as well as many urls are
barely included in knowledge graph, while they
play an irreplaceable role in intent understand-
ing. For example, a user may query toyota, volvo
or just enter car soup, cars for sale and click
www.carsoup.com, which should be encoded in
a form that we could perceive their closeness in
intent. That’s why at-a-glance info cards about
merely recognized entity in the query are far from
enough and previous methods disregarding refin-
ers and urls are too limited to cover queries in ma-
jority.
We move one step further to tailor knowledge
graph for representing more than entity words. We
collect refiners and clicked urls along with en-
tity words and model intents they represent us-
ing knowledge graph based features. We use
Freebase
1
, one of the largest available knowledge
graph, in our work and our method can be easily
generalized to other knowledge repositories.
We put up an idea of intent topic which can
be query words or urls, whether mean an entity
or not, representing an atomic information need.
We identify them with intent features by exploit-
ing global knowledge in Freebase and local con-
1
http://www.freebase.com
1070
texts in query sessions. Notice the new concept
here is distinguished from query intent or query
facet in previous literature for it is in a holistic
view, not specifically meaning subtopics around a
certain query.
Our intuitive observations as follows inspire us
to represent intent features with topics and do-
mains in knowledge graph and propagate the en-
riched features in the intent topic graph.
1) Query words and urls within the same session
tend to indicate the same query intent.
2) Intent topics sharing similar query intent often
relate to similar topics in knowledge graph.
3) Knowledge graph domains sketch the query in-
tent briefly.
Observation 1 indicates domain coherency
within sessions is a good starting point to gener-
ate intent features, along with Observation 2 and 3
lay the basis of proximity that the propagation rely
on.
To the best of our knowledge, we’re the first to
represent intent behind entity words, refiners and
urls in a unified knowledge graph based frame-
work, in a way to exploit and expand knowledge
graph which we call ‘tailor’.
Our contributions include:
• An innovative and unified framework to rep-
resent intent topics, whether they can directly
link to an entity in knowledge graph or not.
• A novel algorithm to generate a specified in-
tent topic graph, which enables learning in-
tent features in an unsupervised propagation
method.
• With intent topic graph we can better under-
stand user intent conducting session-based
contextualization and potentially find highly-
related intent topic.
The rest of the paper is organized as follows. Sec-
tion 2 tells our methods to map queries to Freebase
and initialize intent features. Section 3 is about
how we model intent topics in a unified graph and
the propagation framework to learn intent features.
We provide experiments and analysis in Section 4.
Related work and conclusions are presented at the
end of the paper.
2 Labeling intent topic nodes with
Freebase-enriched features
In Freebase, facts around a certain topic and multi-
faceted intents they reflect is more like a global
domain distribution, what facet do users exactly
intend for is difficult to locate until in a specified
context, namely a query session.
We take a line in query log as a query, exhibit-
ing an interaction with the search engine, includ-
ing query words and page clicks. And a sequence
of queries with a certain time interval constitute
a session, completely conveying an information
need.
In existing knowledge graph, only a small part
of urls are contained in views of web pages be-
yond number online. Even for query words, we
can merely get access to some of them, which we
call entity words and the rest refiners. To avoid
misunderstanding, the url intent topics in the fol-
lowing will specially refer to the clicks without di-
rectly matched concepts in knowledge graph, oth-
erwise they’ll be taken as entity intent topic.
In this section, we propose a framework of
knowledge graph enriched representation of in-
tent topics, the following propagation in Section3
bases on it.
2.1 Freebase as a knowledge graph
Freebase has over 39 million concepts, aka top-
ics, about real-world entities like people, places
and things stored as nodes in a graph. They’re
linked to each other with annotated egdes named
as property. These edges actually represent facts.
There are over a billion such facts or relations that
make up the graph and they’re all available for
free. Properties are grouped into types, types are
grouped into domains, which gives a broad view
of knowledge in addtion to specific topics.
We can tap into Freebase through dump data or
API
2
. In our work, we retrieve related Freebase
topics with relevance scores for entity words via
Freebase search API, which is based on combina-
tion of topic’s inbound and outbound link counts
in Freebase and Wikipedia as well as a popularity
score computed by Google, and all the facts about
a given topic through Freebase topic API. We use
T = {t
1
, t
2
, ...t
n
}, D = {d
1
, d
2
, ...d
n
} to denote
all Freebase topics and domains used in our work.
2.2 Enriching entities and queries with
Freebase
We represent a query’s candidate intent topics by
three sets, E
q
, R
q
, C
q
, where E
q
includes entity
words and clicks which have equivalents in Free-
base, R
q
the refiner words and C
q
the rest clicks.
2
http://developers.google.com/freebase/
1071
Global knowledge in Freebase can directly enrich
each e in E
q
with Freebase topics represented in
vector t
e
, for each candidate topic there’s a Free-
base domain distribution vector d
t
. As for the rest
inR
q
and C
q
, they can learn features in later prop-
agation process.
For any topic t
i
in t
e
, the relevance of entity
words e and knowledge graph topic t
i
is estimated
as follows:
t
e
i
=
RelevanceScore(e, t
i
)
max
t
j
?T
RelevanceScore(e, t
j
)
(1)
And the domain vector d
t
i
for t
i
is:
d
t
i
j
=
pr(d
j
|t
i
)
?
d
k
?D
pr(d
k
|t
i
)
(2)
pr(d
j
|t
i
) =
# of links of t
i
in domain d
j
# of all links in domain d
j
(3)
Then we’ll get a knowledge graph enriched in-
tent description of the query by combining that of
e, r, c.
t
q
i
=
?
e?E
q
t
e
i
w
q
(e) +
?
r?R
q
t
r
i
w
q
(r) +
?
c?C
q
t
c
i
w
q
(c)
(4)
w
q
(e) = NCount
q
(e)?(e) (5)
Here t
e
t
r
t
c
correspond to the topic vector of each
entity, refiner and click respectively. The weight
indicates how dominant it is in conveying intent
in the query. It is in proportion to the normalized
count as well as each occurrence’s quality denoted
by ?(e). Such as for entity words in Equation (5),
the quality ?(e) can be estimated with the help of
entity linking methods, which describes the proba-
bility of e as a candidate reference. That for clicks
and refiners will be explained later.
The query’s domain feature can be calculated as
follows:
d
q
i
=
?
t
j
?T
d
t
j
i
t
q
j
?
d
k
?D
?
t
j
?T
d
t
j
k
t
q
j
(6)
It describes the probability of query q in domain
d
i
, in which t
q
j
can be calculated by Equation (4)
and d
t
j
i
via facts around topic t
j
by Equation (2).
2.3 Contextualized intent depiction of
sessions
The aforesaid enriched features we get about
queries rely heavily on global knowledge in Free-
base, reflecting prior distribution in the feature
space. In this part, we derive a contextualized de-
scription of session intent in a local view by aggre-
gating all the global knowledge we get about the
session’s queries. The ambiguity of a single query
can be alleviated by looking at the dominant do-
main within the session.
The intent features t
s
and d
s
of session s can
be represented by computations on its query set
Q
s
= {q
1
, q
2
, ...q
n
} with time-order decay.
t
s
i
=
?
q?Q
s
t
q
i
?
rank(q)
?
t
j
?T
?
q?Q
s
t
q
j
?
rank(q)
(7)
where we put an exponential decay controlled by
decay factor ?. We get domain feature the same
way as Equation (6).
We’ll put up an unsupervised method of learn-
ing knowledge graph based intent representation
of refiners and clicks in the following part.
3 Propagating intent features in the
intent topic graph
In this section, our idea is to characterize entities,
refiners and urls uniformly as intent topics, tailor-
ing knowledge graph to intent topic graph so as to
enrich representations by propagation.
3.1 Modeling intent topic graph
As in last section, with d
s
featuring the context,
candidate intent topics in sessions can make intent
topic nodes now. We use the concept intent topic
to stress words with local contexts tell a specified
information need, thus making a node. Taking en-
tity word fl as an example, it can be recognized
as the topic Florida in Freebase, while the intent
behind it can hardly be mapped to a single intent
topic, such as travel domain in hollywood fl, ed-
ucation domain in community college in florida,
and florida department of health actually convey
intent in government domain.
So each intent topic node is identified with its
name string and Freebase-enriched intent features
t and d. They’re directly linked by co-occurring
in the same line in the query log and implicitly
related via intent features similarities, so that con-
stitute a large graph G =< V,E,W >, where
?w ? W denotes an explicit edge weight and
?v ? V an intent topic. With intent topics and
their relations modeled in a graph, we can better
understand the query space so as to find the in-
tended query faster. We realize it by aggregating
massive sessions.
1072
The implicit intent similarity ISim of any node
pair n and v can be encoded as follows.
ISim
n,v
= ?SSim
n,v
+?DSim
n,v
+?TSim
n,v
(8)
where SSim denotes the names’ string similar-
ity, DSim the similarity of their domain feature
and TSim the topic vector similarity, with ?, ?
and ? controlling the weight. The parameters may
vary due to different scenarios. We just provide
a framework of modeling nodes’ intent features,
which actually mirror their proximity in query in-
tent.
To put it in more details, we use jaccard sim-
ilarity for name shinglings and cosine similarity
for domain and topic vector. As query log in-
duced intent topic graph is of considerable large
size, the pair-wise similarity is computationally
prohibitive, hence we use Local Sensitive Hash
(Indyk and Motwani, 1998) for each similarity
metric so as to compute ISim just in candidate
set. We use random hyperplane based hash fam-
ily proposed in (Charikar, 2002) and set the hash
code dimension and hash table numbers empiri-
cally to ensure the number of nodes falling into
each bucket is relatively stable.
3.2 Merging nodes
Although our idea of specifying intent topics by
context better models the multi-facets of queries,
it obviously also brings a sparse issue. For exam-
ple, in one session user query beep lyrics and click
www.lyricsandsongs.com, lyrics is tagged with the
song beep and the musician Pussycat Dolls, in an-
other scenario lyrics occurs with the song what
you know and url www.dapslyrics.com, intents be-
hind these two nodes are so similar that they
should come into one, otherwise connections be-
tween the two intent-coherent urls may be lost.
To avoid that, we conduct a merge process to
integrate nodes with exactly the same names and
contexts into one, combing linked nodes and intent
features together.
For a set of nearly duplicate nodes ? the cal-
culation of new node’s features can be written as:
ˆ
t =
?
u??
t
u
|?|
(9)
ˆ
d =
?
u??
d
u
|?|
(10)
In other words, we gather candidate nodes re-
trieved by LSH and then calculate ISim for them
with ? setting to 0. Only node pairs with ISim
higher than a merge threshold ? can be seen as
duplicates. The merge process is summarized in
Algorithm 1.
Algorithm 1: Merging similar nodes
Input: G =< V,E,W >, ?, ?, ?, ?
Output:
ˆ
G =<
ˆ
V ,
ˆ
E,
ˆ
W >
begin
Initialize ?? ?
for v ? V do
Find dupset ?
v
with ISim
?,?,?
if ?u ? V, ?
u
? ? and ?
v
? ?
u
6= ?
then
?
v
? ?
v
? ?
u
Remove ?
u
from ?
Add ?
v
to ?
for ? ? ? do
Merge nodes in ? into new node vˆ
Update G with replacing nodes in ?
with vˆ
3.3 Label propagation
We utilize knowledge graph induced intent fea-
tures instead of manually labels as constraints to
conduct label propagation(Zhu and Ghahramani,
2002). The idea is that node labels are propa-
gated to nearby nodes via weighted edges until
convergence, as highly weighted edges indicate
high probability of sharing labels.
Nodes in our work have soft labels, where each
dimension of intent features denotes a label, such
as a topic or domain of knowledge graph. As de-
scribed in aforesaid observations, it is intuitively
reasonable to propagate on the basis of explicit
edges and implicit intent similarities. We illustrate
the propagation with topic feature, that of domain
feature is similar.
We use matrix Y
t
? R
|V |?|T|
to denote the in-
tent topic graph’s initial topic feature labels, with
element Y
t
ik
indicating node v
i
’s relevance to t
k
,
wherer t
k
? T. Y
t
is initialized based on the
results of the feature enriching step in Section 2,
with no manually-labelled instances needed in our
model. As only part of nodes can directly map
to Freebase topics, those are initialized as labelled
nodes, then propagate t to their linked neighbors.
The number of unlabelled data is written as u,
while that of labelled data l and the total number
of nodes N .
1073
The transition matrix T indicates the impact of
nodes on each other. Note that here the w
ij
can
be replaced by other similarity measures such as
ISim in Section 3.2.
T
ij
=
w
ij
?
N
k=1
w
kj
(11)
LetD denote anN×N diagonal matrix with d
ii
=
?
j
T
ij
. Then we can get a normalized version of
transition matrix P = D
?1
T .
The normalized transition matrix can be split
into 4 sub-matrices.
P =
[
P
ll
P
lu
P
ul
P
uu
]
(12)
At each step, we propagate and clamp the labelled
data and repeat until Y converges, the propagation
step can be written as:
ˆ
Y
u
= P
uu
Y
u
+ P
ul
Y
l
(13)
As is shown in (Zhu and Ghahramani, 2002; Zhu
et al., 2003) the solution to the propagation con-
verges to:
ˆ
Y
u
= (I ? P
uu
)
?1
P
ul
Y
l
(14)
3.4 The propagation framework for intent
features
We carry the propagation in an iterative process
illustrated in Algorithm 2.
Algorithm 2: Intent feature propagation
Input: G, Y
t
l
,Y
d
l
Output:
ˆ
G,
ˆ
Y
t
u
,
ˆ
Y
d
u
Initialize Y
t
l
Y
d
with results of Section2
repeat
Merge similar nodes according to
Algorithm 1
Compute matrix P
repeat
ˆ
Y
t
u
= P
uu
Y
t
u
+ P
ul
Y
t
l
until Convergence;
Recompute
ˆ
P with
ˆ
Y
t
repeat
ˆ
Y
d
u
=
ˆ
P
uu
Y
d
u
+
ˆ
P
ul
Y
d
l
until Convergence;
until no dups;
Since intent features include both domain vec-
tor and topic vector, we propagate them in an alter-
nating way. At first we label nodes as described in
Section 2, though missing refiners’ and some urls’
intent features, they are just used for initialization.
Then we propagate Freebase topic features based
on explicit edge weights, so that more nodes in
intent topic graph have topic features now. Then
fetching the learned topic features, we reinput it
into domain feature propagation, which means we
recalculate the transition matrix combining the im-
plicit learned TSim into edge weight, then prop-
agate domain vector of labelled nodes through the
graph. At each iteration, we first update Y
t
, then
input it to update Y
d
, therefore merge near dupli-
cate intent topics to update the whole graph.
4 Experiments
4.1 Data preparation
4.1.1 Search logs
We use AOL search log data for experiments. It
includes 20 million web queries collected covering
500K users over three months in 2006.
Table 1: The query set
# of sessions 35140
# of queries 271127
# of users 21378
# of urls 63019
We preprocess the query log by keeping urls oc-
curring more than 3 times and queries with 2 to
40 characters, then extract sessions considering 25
minutes duration. While user session segmenta-
tion can be improved with more sophisticated al-
gorithms, this simple low-cost heuristic performs
adequately for our purposes. We then move on to
map queries to Freebase and empirically filter ses-
sions that are less entity-centric. We use an anno-
tation tool especially for short text (Ferragina and
Scaiella, 2012) called Tagme
3
to recognize entities
and observe only 16% of all the queries are ex-
actly an entity itself, which means most of queries
do have refiner words to convey information need.
To ensure the precision of recognized entities, we
set a significant threshold and bottom line thresh-
old , queries should have at least one recognized
entity with a likelihood above significant level,
and those below bottom line are ignored. They
are 0.19 and 0.05 in our work, which may vary
with entity recognition method. The normalized
3
http://tagme.di.unipi.it/
1074
loca
?on
	  
orga
niza
?on
	  
busi
ness
	  
boo
k	  
inte
rnet
	  
trav
el	   film
	  
educ
a?o
n	  
mus
ic	  
spor
ts	  
gove
rnm
ent	  
broa
dcas
t	  
peo
ple	  
com
pute
r	   tv	  
avia
?on
	  
cele
bri?s	   med
icine
	  
fic?o
nal_
univ
erse
	  
peri
odic
als	  
biolo
gy	  
arch
itect
ure	   cvg	  
med
ia_c
omm
on	  
visu
al_a
rt	  
milit
ary	  
auto
mo?
ve	  
influ
ence
	  
food
	  
per
cen
tag
e 
Query	  set	  
Test	  session	  set	  
Freebase	  topics	  
Freebase	  facts	  
Figure 1: Unbalanced domain distributions in Freebase comparing against query set. Only domains with
top proportions are shown.
Table 2: Examples of labelled intent topic nodes with learned feature
Intent topic nodes Original in Freebase After propagation Annotation
travel.yahoo.com Yahoo! Travel
(internet, 0.87),
(projects, 0.13)
(location, 0.13),
(travel, 0.11),
(organization, 0.08),
(business, 0.08) ...
Yahoo! Travel offers
travel guides, booking
and reservation services.
map quest
www.mapquest.com
MapQuest
(organization, 0.6),
(book, 0.4)
(location, 0.13),
(organization, 0.09),
(travel, 0.09),
(automotive, 0.06)...
MapQuest is an Ameri-
can free online web map-
ping service.
likelihood is used as w
q
(e). Then we drop ses-
sions where tagged entity words weight less than
refiners as well as the ones with too many entity
words spotted indicating disperse intents. For each
recognized entity, only Freebase topics with rele-
vance over 0.3 are kept. The query set we finally
get is shown in Table 1.
4.1.2 Freebase
To enrich query representations, we collect a sub-
set of Freebase including more than 7 millions
facts and 4 millions topics in total which also
contain 150 thousand topical equivalent websites,
though less than 3% urls in query set are covered.
The facts and entities in Freebase is rather un-
balanced across domains especially against that of
recoginized entities in query set as shown in Fig-
ure 1. Thus the original global knowledge we use
about domain distribution may cause bias, which
makes tailoring necessary for intent understand-
ing.
For both generality and precision, we keep most
of Freebase domains except several extreme in-
complete ones, instead of retaining a small number
of representative domains like many researchers
do (Li et al., 2013; Yu et al., 2014; Lin et al.,
2012). But generality comes at a price that some
domains are confusing and mixed used which we
then choose to merge, like celebrities and people,
periodicals and books, tv and broadcast, etc. We
finally keep 50 of all 76 domains.
4.2 Intent topic graph
4.2.1 Building the graph
We leverage both Freebase and search sessions to
enrich intent topics. We set ? to 0.9 in calcula-
tion of session’s intent features. After labeling
the session log, we roughly make a graph with
335206 intent topic nodes, 119364 of them have
been labelled with Freebase topic feature, others
only have domain feature. Then we conduct a
merge process with ? set to 0.7, ? to 0.3 and ? to
0.75 in order to merge nodes with duplicate names
and similar contexts. We find 46659 duplicate sets
covering 140768 nodes. Then we ignore nodes
with few links and rare names to reduce sparsity.
Finally we’ve got a graph of 209351 intent topics
to initialize the propagation, including 78932 la-
belled nodes. The merge and propagation progress
get converged in less than 4 rounds.
We’ll further evaluate the graph with case study
and a session intent understanding task.
4.2.2 Case Study
We demonstrate intent features are good interpre-
tations for query intent, whether they’re labelled in
Section 2 or learned by propagation in Section 3.
We can see in Table 2 that as nodes’ original
1075
Table 3: Examples of unlabelled intent topic nodes with learned feature
Intent topic node intent features Annotation Similarity nodes
www.bnm.com (The Hertz Corporation, 0.25), (South-
west Florida International Airport,
0.17), (Punta Gorda Airport, 0.13),
(Supercar, 0.09), (Sports car, 0.08)...
(aviation, 0.23), (business, 0.21), (lo-
cation, 0.14), (automotive, 0.11)...
Online booking
of discount
rentals at ma-
jor airports,
worldwide.
www.arac.com
www.rentalcars.com
www.hertz.com
www.alamo.com
rent a car
cheap rental cars
www.mobtime.com (Software, 0.18), (Mobile phone,
0.11), (100% Totally Free Ringtones,
0.10), (Motorola, 0.09), (Free Cell,
0.08), (Verizon Wireless, 0.04)...
(computer, 0.23), (cvg, 0.21), (music,
0.19), (business, 0.11) ...
MobTime Cell
Phone Manager
is a PC soft-
ware to manage
or sync mobile
phones.
cellphones.about.com
cell software
cell to pc
reviews of
cellphone wallpaper
types in Freebase are not proper for describing in-
tent, the intent features they get after propagation
tend to be more explainable, such as the travel
site often co-occurs with city names, tourist attrac-
tions, hotels and so on, thus indicating its intent in
travel and location domain.
Table 3 shows examples which have no equiv-
alents in Freebase. Although some of them may
be accessible in other ontologies, we only take
them as examples to show our propagation method
makes it possible to depict intents behind urls and
words in a knowledge graph based way while be-
yond the capacity of knowledge graph.
4.3 Session intent understanding task
4.3.1 Experiment Setup
The evaluation of query understanding has long
been a challenging task. To judge whether the con-
cepts in query are successfully recognized seems
too straightforward, and it can hardly be consid-
ered understanding the intent until the big idea
about what kind of topics users emphasis is cap-
tured, which can be briefly sketched by distribu-
tion across Freebase domains. Also it is difficult to
translate results of previous log analysis methods
into knowledge graph domain information, thus
hardly fit into our evaluation schema. We take
popularity-based method as baseline.
We have few choices but to tag ground truth our-
selves for intent understanding evaluation.
We randomly select 150 sessions as test set,
the domain distribution of which agrees with the
whole query set as shown in Figure 1. As mas-
tering meanings of all Freebase domains is too
challenging, we ask 5 accessors to describe each
session’s intent broadly with a few natural lan-
guage terms, then an expert familiar with Freebase
schema translates the words into matched Free-
base domains. Each test session is tagged by 2
accessors and 1 expert, we choose to use the tags
of the cases in which the accessors reached agree-
ment as the gold stantard. For example, if acces-
sors tag session intent as pictures, then experts can
translate it into Freebase visual art domain. Each
session has 1?4 tags and 1.6 tags in average. The
tags cover 30 domains.
For each session, we derive the local intent do-
main vector d
s
following the method in Section 2.
Here we simply set quality function ?(r) to a con-
stant ?
r
for all refiners and?(c) to ?
c
for all clicks,
we’ll dive into more specialized weighting method
in future work. ?
r
and ?
c
are parameters to control
impact of different kinds of intent topics. Based on
whether to exploit global intent features of non-
entity words, we compare four variations against
one baseline.
• Popularity-based (GP). We use domains’ fre-
quency in the query set as a baseline.
• Entity-based (E). We only use entity nodes’
original intent features without propagation.
• Entity+Clicks (EC). Both intent features of
entity words and clicks are used, controlled
with ?
c
.
• Entity+Refiners (ER). Intent features of en-
tity words and refiner words are used, refin-
ers’ impact is controlled by ?
r
.
• Entity+Clicks+Refiners (ECR). All intent
topics are combined, controlled by ?
c
, ?
r
.
1076
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.672
0.678
0.684
0.690
0.696
0.702
0.708
0.714
0.720
(a) MAP@5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.18
0.21
0.24
0.27
0.30
0.33
0.36
0.39
(b) GMAP@5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.708
0.714
0.720
0.726
0.732
0.738
0.744
0.750
0.756
(c) MAP@10
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.375
0.400
0.425
0.450
0.475
0.500
0.525
0.550
0.575
(d) GMAP@10
Figure 2: The impact of ?
r
and ?
c
on ECR methods in four metrics, with vertical axis indicating ?
r
,
horizontal axis as ?
c
. The first column on the left denotes ER method, while the bottom row the EC
method.
4.3.2 Evaluation metrics
We use each approach to rank domains accord-
ing to its derived weight, then compare it with
golden standard set. It can be evaluated using
Mean Average Precision (MAP), Geometric MAP
and Precision@K. We use GMAP because it is
more robust to outliers than the arithmetic mean.
For test set of size N , the MAP and GMAP can
be calculated as follows:
MAP@k =
1
N
N
?
i=1
AP
i
@k (15)
GMAP@k =
N
?
?
?
?
N
?
i=1
AP
i
@k (16)
4.3.3 Results and analysis
We first study impact of parameters ?
r
and ?
c
,
which is shown in Figure 2.
It roughly demonstrates different combinations
of parameters’ impact on ECR methods, perfor-
mance is evaluated in four metrics, with deeper
color indicating better result.
Best results comes with a ?
c
larger than ?
r
in
all four subfigures. This trend seems more obvi-
ous in (d) where right part with larger ?
c
get better
results. Also, deeper colors around diagonal line
in (a) (c) indicate a more balanced combination
of refiners and urls are more likely to enhance in-
tent understanding. Thus we conclude clicks has a
weak advantage over refiners in improving the re-
sult, while combining both with proper parameters
can get the best result.
When comparing between MAP and GMAP, we
can see while GMAP stays a high value when am-
plifying the impact of clicks, MAP changes with
the variation of ?
r
for better or worse. As GMAP
is a more robust metric, we can then infer that in-
creasing weight of refiners could bring more out-
liers, implying refiners’ intent features are more
susceptible to noise.
Then we use ER with ?
r
= 0.5 as ER
opt
, EC
with ?
c
= 0.5 as EC
opt
and ECR with ?
r
=
0.2, ?
c
= 0.5 as ECR
opt
.
Figure 3 clearly shows the superior performance
of our model, especially at top positions. Table 4
shows the detailed comparisons between different
methods. We can see our knowledge graph based
intent representations perform well in session in-
tent understanding. And refiners’ and clicks’ in-
tent features which we learn by propagation con-
1077
0	  
0.1	  
0.2	  
0.3	  
0.4	  
0.5	  
0.6	  
0.7	  
0.8	  
1	   3	   5	   10	   20	   50	  
Prec
ision
@K 
K 
GL	  
E	  
ER	  
EC	  
ECR	  
Figure 3: Precision@K results for different ap-
proaches, by varying number of k
Table 4: Comparisons among different methods
K=5 K=10
MAP GMAP MAP GMAP
GP 0.177 0.000 0.232 0.002
E 0.676 0.166 0.707 0.355
EC
opt
0.708 0.412 0.739 0.579
ER
opt
0.688 0.227 0.723 0.421
ECR
opt
0.722 0.412 0.756 0.594
tribute a lot to improve naive entity-based method,
which do validate an complment effect of their
learned intent features.
5 Related Work
5.1 Query intent understanding
Query intent or search intent has been studied in-
tensively from various views.
A popular paradigm is to label several intents
for each query, also called facets subgoals and
subtopics in the literature, manully or by min-
ing methods and then do classification (Hu et al.,
2009; Li et al., 2008) based on that. Manually in-
tent schemas range from 3 top level (Broder, 2002)
to fine-grained subcatogories (Rose and Levinson,
2004) and taxonomy (Yin and Shah, 2010). Intent
tasks in NTCIR-10 (Sakai et al., 2013) also pro-
vide subtopic pools made by accessors.
Another view of intent is more generic, min-
ing or learning search intents without any kind of
pre-defined intent category and clustering method
is often used. Methods including (Sadikov et al.,
2010; Yamamoto et al., 2012; Cheung and Li,
2012) cast intent as represented by a pattern or
template consisting of a sequence of semantic con-
cepts or lexical items. (Tan et al., 2012) encode
intent in language models, aware of long-lasting
interests. (Ren et al., 2014) uses an unsupervised
heterogeneous clustering. (Yin and Shah, 2010)
capture generic intents around a certain named en-
tities and model their relationships in a tree tax-
onomy and (Wang et al., 2009) mine broad latent
modifiers of intent aspect , which are similar to
our motivation, while we model more than intent
phrases, but intent topics. We do not split queries
into clusters or subtopics relevant to the original
query to indicate a intent, but link them in an graph
with intent feature similarity, weakly or strongly,
in a holistical view.
On the other hand, previous research can be
categorized by what kind of resources they rely
on. Quite an amount of work leverage query logs
(Jiang et al., 2013), including query reformula-
tions (Radlinski et al., 2010), click-through data
(Li et al., 2008). There are also works using spon-
sered data (Yamamoto et al., 2012) and interactive
data (Ruotsalo et al., 2013). The new trend of in-
tegrating knowledge graph will be discussed next.
5.2 Knowledge graph on intent
understanding
Instead of summarizing queries into concepts by
clustering, recently there appears a tendency to use
concpets from knowledge graph resources. Some
researchers manage to build entity graph from
queries (Bordino et al., 2013a) (Bordino et al.,
2013b; Yu et al., 2014), some in a structure view,
interpret quries into knowledge base fit template
(Pound et al., 2012; Li et al., 2013). (Pantel et al.,
2012) models latent intent to mine entity type dis-
tributions. (Ren et al., 2014) utilizes knowledge
graph resources in a hetrogeneous view. (Lin et
al., 2012) also pays attention to refiners, but re-
stricted to limited domains, while our method is
more general.
6 Conclusion
In this paper, we tailor knowledge graph to rep-
resent query intent behind entity words, refiners
and clicked urls in a unified framework, taking
them as intent topic nodes connected in a large
graph. We manage to get a contextualized intent
depiction exploiting global knowledge in Free-
base, then propagate the feature to cover more in-
tent topics. We show in experiments the knowl-
edge graph enriched representation is reasonable
and explainable, and the intents feature of refiners
and clicks can better enhance intent understanding
than methods simply relying on entities.
1078
There are several directions for future work, in-
cluding using both types and domains in Free-
base schema, diving into refiners and looking for a
proper weighting method, developing a query rec-
ommendation framework based on the intent topic
graph and user interest modeling.
Acknowledgments
We sincerely thank all the anonymous reviewers
for their valuable comments, which have helped to
improve this paper greatly. This work is supported
by NSFC with Grant No.61370054, and 973 Pro-
gram with Grant No.2014CB340405.
References
Nicholas J Belkin, Robert N Oddy, and Helen M
Brooks. 1982. Ask for information retrieval: Part i.
background and theory. Journal of documentation,
38(2):61–71.
Ilaria Bordino, Gianmarco De Francisci Morales, Ing-
mar Weber, and Francesco Bonchi. 2013a. From
machu picchu to rafting the urubamba river: antici-
pating information needs via the entity-query graph.
In Proceedings of the sixth ACM international con-
ference on Web search and data mining, pages 275–
284. ACM.
Ilaria Bordino, Yelena Mejova, and Mounia Lalmas.
2013b. Penguins in sweaters, or serendipitous entity
search on user-generated content. In Proceedings
of the 22nd ACM international conference on Con-
ference on information & knowledge management,
pages 109–118. ACM.
Andrei Broder. 2002. A taxonomy of web search. SI-
GIR Forum, 36(2):3–10, September.
Moses S Charikar. 2002. Similarity estimation tech-
niques from rounding algorithms. In Proceedings of
the thiry-fourth annual ACM symposium on Theory
of computing, pages 380–388. ACM.
Jackie Chi Kit Cheung and Xiao Li. 2012. Sequence
clustering and labeling for unsupervised query intent
discovery. In Proceedings of the fifth ACM interna-
tional conference on Web search and data mining,
pages 383–392. ACM.
W Bruce Croft, Michael Bendersky, Hang Li, and
Gu Xu. 2010. Query representation and understand-
ing workshop. In SIGIR Forum, volume 44, pages
48–53.
Paolo Ferragina and Ugo Scaiella. 2012. Fast and
accurate annotation of short texts with wikipedia
pages. IEEE software, 29(1).
Jian Hu, Gang Wang, Fred Lochovsky, Jian-tao Sun,
and Zheng Chen. 2009. Understanding user’s query
intent with wikipedia. In Proceedings of the 18th
international conference on World wide web, pages
471–480. ACM.
Piotr Indyk and Rajeev Motwani. 1998. Approxi-
mate nearest neighbors: towards removing the curse
of dimensionality. In Proceedings of the thirtieth
annual ACM symposium on Theory of computing,
pages 604–613. ACM.
Daxin Jiang, Jian Pei, and Hang Li. 2013. Mining
search and browse logs for web search: A survey.
ACM Trans. Intell. Syst. Technol., 4(4):57:1–57:37,
October.
Xiao Li, Ye-Yi Wang, and Alex Acero. 2008. Learn-
ing query intent from regularized click graphs. In
Proceedings of the 31st Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, SIGIR ’08, pages 339–346,
New York, NY, USA. ACM.
Yanen Li, Bo-June Paul Hsu, and ChengXiang Zhai.
2013. Unsupervised identification of synonymous
query intent templates for attribute intents. In Pro-
ceedings of the 22nd ACM international conference
on Conference on information &#38; knowledge
management, CIKM ’13, pages 2029–2038, New
York, NY, USA. ACM.
Thomas Lin, Patrick Pantel, Michael Gamon, Anitha
Kannan, and Ariel Fuxman. 2012. Active objects:
Actions for entity-centric search. In Proceedings
of the 21st international conference on World Wide
Web, pages 589–598. ACM.
Patrick Pantel, Thomas Lin, and Michael Gamon.
2012. Mining entity types from query logs via user
intent modeling. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics: Long Papers-Volume 1, pages 563–571.
Association for Computational Linguistics.
Jeffrey Pound, Alexander K Hudek, Ihab F Ilyas, and
Grant Weddell. 2012. Interpreting keyword queries
over web knowledge bases. In Proceedings of the
21st ACM international conference on Information
and knowledge management, pages 305–314. ACM.
Filip Radlinski, Martin Szummer, and Nick Craswell.
2010. Inferring query intent from reformulations
and clicks. In Proceedings of the 19th international
conference on World wide web, pages 1171–1172.
ACM.
Xiang Ren, Yujing Wang, Xiao Yu, Jun Yan, Zheng
Chen, and Jiawei Han. 2014. Heterogeneous graph-
based intent learning with queries, web pages and
wikipedia concepts. In Proceedings of the 7th ACM
International Conference on Web Search and Data
Mining, WSDM ’14, pages 23–32, New York, NY,
USA. ACM.
Daniel E. Rose and Danny Levinson. 2004. Un-
derstanding user goals in web search. In Proceed-
ings of the 13th International Conference on World
1079
Wide Web, WWW ’04, pages 13–19, New York, NY,
USA. ACM.
Tuukka Ruotsalo, Jaakko Peltonen, Manuel Eugster,
Dorota G?owacka, Ksenia Konyushkova, Kumari-
paba Athukorala, Ilkka Kosunen, Aki Reijonen,
Petri Myllym¨aki, Giulio Jacucci, et al. 2013. Di-
recting exploratory search with interactive intent
modeling. In Proceedings of the 22nd ACM interna-
tional conference on Conference on information &
knowledge management, pages 1759–1764. ACM.
Eldar Sadikov, Jayant Madhavan, Lu Wang, and Alon
Halevy. 2010. Clustering query refinements by user
intent. In Proceedings of the 19th international con-
ference on World wide web, pages 841–850. ACM.
Tetsuya Sakai, Zhicheng Dou, Takehiro Yamamoto,
Yiqun Liu, Min Zhang, Ruihua Song, MP Kato, and
M Iwata. 2013. Overview of the ntcir-10 intent-2
task. Proceedings of NTCIR-10, pages 94–123.
Bin Tan, Yuanhua Lv, and ChengXiang Zhai. 2012.
Mining long-lasting exploratory user interests from
search history. In Proceedings of the 21st ACM in-
ternational conference on Information and knowl-
edge management, pages 1477–1481. ACM.
Xuanhui Wang, Deepayan Chakrabarti, and Kunal
Punera. 2009. Mining broad latent query aspects
from search sessions. In Proceedings of the 15th
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 867–876.
ACM.
Takehiro Yamamoto, Tetsuya Sakai, Mayu Iwata, Chen
Yu, Ji-Rong Wen, and Katsumi Tanaka. 2012. The
wisdom of advertisers: mining subgoals via query
clustering. In Proceedings of the 21st ACM inter-
national conference on Information and knowledge
management, pages 505–514. ACM.
Xiaoxin Yin and Sarthak Shah. 2010. Building taxon-
omy of web search intents for name entity queries.
In Proceedings of the 19th international conference
on World wide web, pages 1001–1010. ACM.
Xiao Yu, Hao Ma, Bo-June (Paul) Hsu, and Jiawei Han.
2014. On building entity recommender systems us-
ing user click log and freebase knowledge. In Pro-
ceedings of the 7th ACM International Conference
on Web Search and Data Mining, WSDM ’14, pages
263–272, New York, NY, USA. ACM.
Xiaojin Zhu and Zoubin Ghahramani. 2002. Learning
from labeled and unlabeled data with label propa-
gation. Technical report, Technical Report CMU-
CALD-02-107, Carnegie Mellon University.
Xiaojin Zhu, Zoubin Ghahramani, John Lafferty, et al.
2003. Semi-supervised learning using gaussian
fields and harmonic functions. In ICML, volume 3,
pages 912–919.
1080
