Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 85–95,
Gothenburg, Sweden, April 26-30 2014.
c
©2014 Association for Computational Linguistics
A Graph-Based Approach to String Regeneration
Matic Horvat
Computer Laboratory
University of Cambridge
15 JJ Thomson Avenue, CB3 0FD, U.K.
mh693@cam.ac.uk
William Byrne
Department of Engineering
University of Cambridge
Trumpington Street, CB2 1PZ, U.K.
wjb31@cam.ac.uk
Abstract
The string regeneration problem is the
problem of generating a fluent sentence
from a bag of words. We explore the N-
gram language model approach to string
regeneration. The approach computes the
highest probability permutation of the in-
put bag of words under an N-gram lan-
guage model. We describe a graph-based
approach for finding the optimal permuta-
tion. The evaluation of the approach on a
number of datasets yielded promising re-
sults, which were confirmed by conduct-
ing a manual evaluation study.
1 Introduction
The string regeneration problem can be stated as:
given a bag of words taken from a fluent grammat-
ical sentence, recover the original sentence. As it
is often difficult to recover the exact original sen-
tence based solely on a bag of words, the problem
is relaxed to generating a fluent version of the orig-
inal sentence (Zhang and Clark, 2011).
The string regeneration problem can generally
be considered a difficult problem even for humans.
Consider the following bag of words:
{ Iraq, list, in, a, third, joins, the, ., of,
Bush’s, of, critics, policy, senator, re-
publican }
and try to recover the original sentence or at least
a fluent grammatical sentence. The original sen-
tence was:
a third republican senator joins the list
of critics of Bush’s policy in Iraq.
The purpose of investigating and developing ap-
proaches to solving the string regeneration prob-
lem is grammaticality and fluency improvement
of machine generated text. The output of sys-
tems generating text, including SMT, abstract-like
text summarisation, question answering, and dia-
logue systems, often lacks grammaticality and flu-
ency (Knight, 2007; Soricut and Marcu, 2005).
The string regeneration problem is used as an
application-independent method of evaluating ap-
proaches for improving grammaticality and flu-
ency of such systems.
The string regeneration can also be viewed as
a natural language realization problem. The basic
task of all realization approaches is to take a mean-
ing representation as input and generate human-
readable output. The approaches differ on how
much information is required from the meaning
representation, ranging from semantically anno-
tated dependency graphs to shallow syntactic de-
pendency trees. A simple bag of words can then be
considered as the least constrained input provided
to a natural language realization system. The bag
of words can be combined with partial constraints
to form a more realistic meaning representation.
Wan et al. (2009) proposed an algorithm for
grammaticality improvement based on depen-
dency spanning trees and evaluated it on the string
regeneration task. They compared its performance
against a baseline N-gram language model genera-
tor. They found that their approach performs better
with regards to BLEU score. The latter approach
does well at a local level but nonetheless often pro-
duces ungrammatical sentences.
We argue that the authors have not fully ex-
plored the N-gram language model approach to
string regeneration. They used a Viterbi-like gen-
erator with a 4-gram language model and beam
pruning to find approximate solutions. Addition-
ally, the 4-gram language model was trained on
a relatively small dataset of around 20 million
words.
The N-gram language model approach finds the
highest probability permutation of the input bag
85
of words under an N-gram language model as the
solution to the string regeneration problem. In
this paper we describe a graph-based approach to
computing the highest probability permutation of
a bag of words. The graph-based approach models
the problem as a set of vertices containing words
and a set of edges between the vertices, whose
cost equals language model probabilities. Finding
the permutation with the highest probability in the
graph formulation is equal to finding the shortest
tour in the graph or, equally, solving the Travelling
Salesman Problem (TSP). Despite the TSP being
an NP-hard problem, state-of-the-art approaches
exist to solving large problem instances. An in-
troduction to TSP and its variants discussed in this
paper can be found in Applegate et al. (2006b).
In contrast to the baseline N-gram approach by
Wan et al. (2009), our approach finds optimal so-
lutions. We built several models based on 2-gram,
3-gram, and 4-gram language models. We exper-
imentally evaluated the graph-based approach on
several datasets. The BLEU scores and example
output indicated that our approach is successful
in constructing a fairly fluent version of the orig-
inal sentence. We confirmed the results of auto-
matic evaluation by conducting a manual evalua-
tion. The human judges were asked to compare the
outputs of two systems and decide which is more
fluent. The results are statistically significant and
confirm the ranking of the systems obtained us-
ing the BLEU scores. Additionally, we explored
computing approximate solutions with time con-
straints. We found that approximate solutions sig-
nificantly decrease the quality of the output com-
pared to optimal ones.
This paper describes work conducted in the
MPhil thesis by Horvat (2013).
2 Graph-Based Approach to String
Regeneration
The underlying idea of the approach discussed in
this paper is to use an N-gram language model to
compute the probabilities of permutations of a bag
of words and pick the permutation with the highest
probability as our solution.
The probability of a sequence of words under an
N-gram language model is computed as:
logP (w
n
1
) =
n
?
k=1
logP (w
k
|w
k?1
k?N+1
)
(1)
2.1 Naive Approach
A naive approach to finding the permutation with
the highest probability is to enumerate all permu-
tations, compute their probabilities using Equa-
tion 1, and choose the permutation with the highest
probability as the solution.
The time complexity of the naive approach is
O(n · n!) as we are enumerating all permuta-
tions of n words and multiplying n conditional
probabilities for each permutation. This means
that the naive approach is not viable for sen-
tences of even moderate length. For example,
there are 3,628,800 permutations of 10 words and
355,687,428,096,000 of 17 words.
2.2 Bigram Graph-Based Approach
In this section we define the graph-based approach
to finding the highest probability permutation and
consequently our solution to the string regenera-
tion problem. For a bag of words S we define a
set of symbols X , X = S ? {<s>,</s>}, which
contains all the words in S (with indexes appended
to distinguish repeated words) and the start and
end of sentence symbols. For a bigram language
model, N = 2, we define a directed weighted
graph G = (V,E), with the set of vertices defined
as V = {w
i
|w
i
? X}. Therefore, each symbol
in X is represented by a single vertex. Let the set
of edges E be a set of ordered pairs of vertices
(w
i
, w
j
), such that E = {(w
i
, w
j
)|w
i
, w
j
? V }.
The edge cost is then defined as:
c
ij
=
?
?
?
?
?
?
?
?
?
0
if w
i
= </s>
and w
j
= <s>,
? logP (w
j
|w
i
) if w
i
6= w
j
,
? otherwise.
(2)
The conditional log probabilities of the form
logP (w
j
|w
i
) are computed by a bigram language
model. Consequently, finding the sentence permu-
tation with the highest probability under the bi-
gram language model equals finding the shortest
tour in graph G or, equally, solving the Asymmet-
ric Travelling Salesman Problem (ATSP). A gen-
eral example graph for a sentence of length 3 is
shown in Figure 1a.
The individual cases of the edge cost function
presented in Equation 2 ensure that the solution
tour is a valid sentence permutation. The nega-
tion of log probabilities transforms the problem of
86
 -
 
l
o
g
 
P
 
(
 
w
1
 
|
 
<
s
>
)
- log P (</s> | w
3 
)
- log P ( w
2 
| <s>)
-
 
l
o
g
 
P
 
(
 
w
1
 
|
 
w
2
 
)
-
 
l
o
g
 
P
 
(
 
w
2
 
|
w
1
 
)
-
 
l
o
g
 
P
 
(
w
3
 
|
 
w
2
 
)
-
 
l
o
g
 
P
 
(
w
2
 
|
 
w
3
 
)
-
 
l
o
g
 
P
 
(
 
w
3
 
|
 
w
1
 
)
-
 
l
o
g
 
P
 
(
 
w
1
 
|
 
w
3
 
)
-
 
l
o
g
 
P
 
(
<
/
s
>
 
|
 
w
1
 
)
-
 
l
o
g
 
P
 
(
 
w
3
 
|
<
s
>
)
-
 
l
o
g
 
P
 
(
<
/
s
>
 
|
 
w
2
 
)
0
<s>
  w
1
  w
2
 w
3
</s>
(a) A general graph. The edge cost equals the negated bigram
conditional log probability of the destination vertex given the
origin vertex. Only edges with non-infinite edge cost are
shown in the graph. Finding the shortest tour in the graph
equals finding the sentence permutation with the highest prob-
ability.
 
0
3

2
3
0
0
2
0
1
2
2
2
0
1
0
1
2

0
2
3
3
 
 <s>
sHL]H
GD\
 </s> WKH
(b) An example graph for the bag of words { day, seize, the
}. The shortest tour is shown in bold and represents the word
sequence <s> seize the day </s> with the log probability of
?10.98. It is necessary to include the (</s> <s>) edge in
order to complete the tour.
Figure 1: Graphs modelling a general (Figure 1a) and an example (Figure 1b) bag of words of size three
under a bigram language model.
finding the longest tour in graph G to the common
problem of finding the shortest tour.
Figure 1b shows a graph for the example bag
of words { day, seize, the }. The shortest tour is
shown in bold and represents the word sequence
<s> seize the day </s>. The shortest tour equals
the sentence permutation with the highest proba-
bility under the bigram language model.
The number of vertices and edges in the graph
grows with the size n of the bag of words S rep-
resented by the graph G = (V,E). The size of
the set of vertices V in the graph is |V | = n + 2
and the size of the set of edges E is |E| = |V |
2
=
n
2
+ 4n+ 4.
We can draw several conclusions about the
graph-based approach from its equality to the TSP.
Firstly, we can observe that the problem of find-
ing the highest probability permutation is an NP-
hard problem. Secondly, modelling the problem
as a TSP still presents a large improvement on
the naive approach described in Section 2.1. The
time complexity of the naive approach for a bag of
words of size n equalsO(n ·n!). However, the al-
gorithm for solving the TSP with the best-known
running time guarantee has the time complexity of
O(n
2
2
n
) (Held and Karp, 1962; Applegate et al.,
2006b). Although the required time grows expo-
nentially with the length of the sentence, it grows
significantly slower than with the factorial time
complexity. This is illustrated in Table 1.
n 5 10 15
n
2
2
n
800 102,400 7,372,800
n · n! 600 36,288,000 19,615,115,520,000
Table 1: Illustration of problem size growth at in-
creasing values of n for algorithms with time com-
plexity of O(n
2
2
n
) and O(n · n!).
Finally, by modelling the problem as a TSP we
are able to take advantage of the extensive re-
search into the TSP and choose between hundreds
of algorithms for solving it. Even though no al-
gorithm with lower running time guarantee than
O(n
2
2
n
) has been discovered since the dynamic
programming algorithm described by Held and
Karp (1962), many algorithms that have no guar-
antees but perform significantly better with most
graph instances have been developed since. The
size of the largest optimally solved instance has
increased considerably over the years, reaching
85,900 vertices in 2006 (Applegate et al., 2009).
For a more complete overview of the history and
current state-of-the-art computational approaches
to solving the TSP we refer the reader to Apple-
gate et al. (2006b).
87
2.3 Higher N-gram Order Graph-Based
Approach
Higher order N-gram language models use longer
context compared to bigram language models
when computing the conditional probability of the
next word. This usually results in improved proba-
bility estimates for sequences of words. Therefore,
to improve our initial approach using bigrams, we
extend it to higher order N-grams. We first ex-
plain the intuition behind the approach and then
continue with the formal definition.
The higher N-gram Order Graph-Based Ap-
proach can be modelled as a Generalized Asym-
metric Travelling Salesman Problem (GATSP).
GATSP is the directed (asymmetric) version of
the Generalized Travelling Salesman Problem
(GTSP). GTSP generalizes the TSP by grouping
cities into sets called districts. GTSP can then be
described as finding the shortest tour of length s,
visiting exactly one city in each of the s districts.
In our formulation of the graph G, each vertex has
a word sequence associated with it and the districts
are defined by the first word in the sequence. This
means that each word appears exactly once in the
solution to the GATSP, ensuring that the solution
is a valid permutation. A general example graph
with districts for N = 3 and a bag of words of
size 3 is shown in Figure 2.
This is formally defined as follows. For a bag of
words S we define a set of symbols X as before.
For a general N-gram language model, N > 2,
and a set of n symbols X , |X| = n, we define
an n-partite directed weighted graph G = (V,E),
with the set of vertices defined as:
V = {w
i
|w
i
[j] ? X for 1 ? j ? N -1,
w
i
[j] 6= w
i
[k] for 1 ? j < k < N}
(3)
Each vertex therefore represents a sequence of
symbols w
i
[1..N -1] of length N ? 1 from the set
X , and the symbols occurring in the sequence
do not repeat themselves. The set of vertices V
is partitioned into n disjoint independent subsets,
V
i
= {w
j
|w
j
? V,w
j
[1] = i}, based on the first
word in the word sequence, w
j
[1].
Let the set of edges E be a set of ordered pairs
of vertices (w
i
, w
j
), such that:
E = {(w
i
, w
j
)|w
i
? V
k
, w
j
? V
l
, k 6= l,
w
i
[2..N -1] = w
j
[1..N -2],
w
i
[1] 6= w
j
[N -1]}
(4)
w
3 
<s>
w
3 
w
1
w
3 
w
2
w
3 
w
3
w
3 
</s>
<s> <s>
<s> w
1
<s> w
2
<s> w
3
<s> </s>
w
1 
<s>
w
1 
w
1
w
1 
w
2
w
1 
w
3
w
1 
</s>
w
2 
<s>
w
2 
w
1
w
2 
w
2
w
2 
w
3
w
2 
</s>
V!
Z

Z

Z

 
</s>
 
<s>
 
</s>
 
w
1
 
</s>
 
w
2
 
</s> w
3
 
</s>
 
</s>
V!
Figure 2: A general example graph for a bag of
words of size 3 using a trigram language model.
The graph consists of s = 5 districts. The vertices
are assigned to a district based on the first word of
the word sequence associated with the vertex. Two
vertices together form a word sequence of three
words. The cost of the edge between them equals
the conditional probability of the final word given
the context of the first two words and is provided
by the trigram language model. Only edges with
non-infinite cost are shown in the graph. Finding
the shortest tour of length s, visiting each district
exactly once, equals finding the sentence permuta-
tion with the highest probability.
88
cij
=
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
0 if w
i
[N -1] = </s> and w
j
[N -1] = <s>,
? logP (w
j
[N -1]|w
i
[1..N -1])
if w
i
[k] ? S, 2 ? k ? N -2
and w
i
[1] 6= </s> and w
j
[N -1] 6= <s>,
? logP (w
j
[N -1]|w
i
[x..N -1])
if x ? 2 and w
i
[x] = <s>
and w
i
[x-1] = </s>
? otherwise.
(5)
An edge therefore exists between two vertices if
they are parts of two different subsets of V (have
different first word in the sequence), have a match-
ing subsequence, and the words outside the match-
ing subsequence do not repeat between the two
vertices. The edge cost is defined in Equation 5.
The conditional log probabilities of the form
logP (w
j
[N -1]|w
i
[1..N -1]) are computed by an
N-gram language model. Consequently, finding
the highest probability permutation under an N-
gram language model equals solving the Gener-
alized Asymmetric Travelling Salesman Problem
(GATSP) modelled by graph G.
An important condition for an edge to exist be-
tween two vertices is that the word subsequences
associated with the vertices match. If two vertices
match, they form a word sequence of length N .
The conditional log probability of the last word
in the sequence given the previous N ? 1 words
equals the cost of the edge between the vertices.
An additional condition for an edge to exist be-
tween two vertices is that the words outside of the
required matching subsequence do not repeat be-
tween the vertices. For example, two sequences 1
2 3 4 and 2 3 4 1 match according to the condition
described above, but outside the required match-
ing subsequence (2 3 4), word 1 appears twice
which produces an invalid permutation.
The size of the vertex and edge set of the graph
G = (V,E) grows with the size n of the bag of
words S and the order N of the N -gram language
model. The size of the set of vertices V in the
graph is |V | = (n+2)
N?1
for all values of N . The
size of the set of edges E (including the infinite
cost edges between the full set of vertices) is |E| =
|V |
2
= (n+ 2)
2N?2
.
3 Implementation
The graph-based approach represents the problem
of finding the sentence permutation with the high-
est probability as an instance of the TSP. Using a
bigram language model, the problem equals solv-
ing the Asymmetric TSP. Using a higher order N-
gram language model, the problem equals solving
the Generalized Asymmetric TSP.
Both variations of the TSP are not as widely
studied as the basic TSP and fewer algorithms ex-
ist for solving them. Transforming the variations
of TSP to basic TSP is a solved problem that en-
ables us to use state-of-the-art algorithms for solv-
ing large problem instances of the TSP. We de-
cided to use the Concorde TSP Solver (Applegate
et al., 2006a), which is prominent for continuously
increasing the size of the largest optimally solved
TSP instance over the last two decades.
Alternatively, a heuristic algorithm for solving
the TSP can be used. Heuristic algorithms do not
guarantee finding the optimal solution, but attempt
to find the best possible solution given a time con-
straint. We used LKH as the heuristic TSP solver,
which is an effective implementation of the Lin-
Kernighan heuristic (Helsgaun, 2000). It currently
holds the record for many large TSP instances with
unknown optima.
The use of a TSP solver makes it necessary
to transform the instances of ATSP and GATSP
into regular TSP instances. We applied two
graph transformations as necessary: (1) GATSP
to ATSP transformation described by Dimitrijevi´c
and
?
Sari´c (1997) and (2) ATSP to TSP transfor-
mation described by Jonker and Volgenant (1983).
These transformations allow application of the
general TSP solver, although they each double the
number of vertices in the graph.
Table 2 shows the total size of the vertex set af-
ter applying the transformations.
LM 5 10 15 20
2-gram 14 24 34 44
3-gram 196 576 1,156 1,936
4-gram 1,372 6,912 19,652 42,592
Table 2: The vertex set size after applying
the transformations for several N-gram language
models at increasing sentence length.
89
4 Evaluation
We evaluated three different versions of the graph-
based approach based on 2-gram, 3-gram, and 4-
gram language models. We evaluated each version
of the system on three datasets of news sentences
by computing the dataset-wide BLEU scores.
4.1 Language models
For the experimental evaluation of our graph-
based approach we used 2-gram, 3-gram, and 4-
gram language models with interpolated modi-
fied Kneser-Ney smoothing (Chen and Goodman,
1998). They were built using the SRI Language
Modeling Toolkit (Stolcke, 2002) and KenLM
Language Model Toolkit (Heafield, 2011).
The language models were estimated on the
English Gigaword collection (V2, AFP and
XIN parts) and the NIST OpenMT12 Evaluation
Dataset (target sides of parallel data for Ar-Eng
and Ch-Eng tasks).
The total size of the corpus for estimating the lan-
guage models was 1.16 billion words.
4.2 Evaluation metric
The BLEU evaluation metric was developed by
Papineni et al. (2002) as an inexpensive and
fast method of measuring incremental progress of
SMT systems. BLEU measures closeness of a
candidate translation to a reference translation us-
ing N-gram precision. Similarly, in the string re-
generation problem we measure the closeness of
the regenerated sentence to the original sentence.
We used the case insensitive NIST BLEU script
v13 against tokenized references to compute the
BLEU scores.
Espinosa et al. (2010) have investigated the use
of various automatic evaluation metrics to mea-
sure the quality of NLG output. They found
that BLEU correlates moderately well with human
judgements of fluency and that it is useful for eval-
uation of NLG output, but should be used with
caution, especially when comparing different sys-
tems. As the string regeneration problem is a basic
form of NLG, BLEU is an appropriate measure of
the system’s performance with regards to fluency
of the output. We provide examples of output and
conduct a manual evaluation to confirm that the
BLEU scores of individual systems reflect actual
changes in output quality.
4.3 Automatic Evaluation
We evaluated the graph-based approach on three
datasets:
MT08 The target side of the Ar-Eng newswire
part of the NIST OpenMT08.
MT09 The target side of the Ar-Eng newswire
part of the NIST OpenMT09.
SR11 The plain text news dataset of the Surface
Realisation Task at GenChal’11.
The MT08, MT09, and SR11 datasets contain 813,
586, and 2398 sentences respectively.
We have taken preprocessing steps to chop long
sentences into manageable parts, which is a com-
mon practice in translation. Based on prelimi-
nary experiments we decided to limit the maxi-
mum length of the chopped sentence to 20 words.
N-gram models cannot be used to model sentences
shorter than N words in this approach. In or-
der to make the models comparable we ignored
short sentences containing 4 or fewer words. Each
chopped sentence was regenerated separately and
the regenerated chopped sentences were concate-
nated to form the original number of dataset sen-
tences. We expect that the preprocessing steps in-
creased the reported BLEU scores to a certain de-
gree. However, all systems compared in the exper-
imental evaluation were subject to the same condi-
tions and their scores are therefore comparable.
The graphs constructed under a 4-gram lan-
guage model are too large to solve optimally in
reasonable time (i.e. under half an hour per sen-
tence). Because of this, we employ two ap-
proaches to regenerate long sentences with the 4-
gram language model: (1) Use the LKH heuristic
algorithm with a set time limit, and (2) back-off to
the trigram language model. We refer the reader
to Horvat (2013) for details.
The BLEU scores for the four systems are re-
ported in Table 3. The 3-gram graph-based ap-
proach performed considerably better than the 2-
gram approach, increasing the BLEU score for
10 BLEU points or more on all three datasets.
The 4-gram approach augmented with a heuris-
tic TSP solver performed significantly worse than
the 3-gram approach on MT08 and MT09 datasets,
while performing better on SR11 dataset. The
reason for this difference is the different distri-
bution of chopped sentence lengths between the
three datasets. Around one fourth of all chopped
90
LM Solver MT08 MT09 SR11
2g opt 44.4 45.1 40.6
3g opt 57.9 58.0 50.2
4g opt +heur 44.8 42.6 51.7
4g +3g opt 59.1 59.5 51.8
Table 3: BLEU scores for four versions of the
graph-based approach, based on 2-gram, 3-gram,
and 4-gram language models. We used the 4-gram
approach on sentences of up to length 18. The re-
maining sentences were computed using either a
heuristic TSP solver (opt +heur) or by backing-off
to a 3-gram approach (4g +3g).
sentences in MT08 and MT09 datasets are longer
than 18 words. On the other hand, less than 1% of
chopped sentences of the SR11 dataset are longer
than 18 words. This means that significant parts
of the MT08 and MT09 datasets were solved us-
ing the heuristic approach, compared to a small
part of the SR11 dataset. Using a heuristic TSP
solver therefore clearly negatively affects the per-
formance of the system. The 4-gram approach
backing-off to the 3-gram approach achieved a
higher BLEU score than the 3-gram approach over
all datasets.
In Figure 3 we show examples of regenerated
sentences for three versions of the system. In
the first example, we can see the improvements
in the output fluency with better versions of the
system. The improvements are reflected by the
BLEU scores. The 4-gram output can be consid-
ered completely fluent. However, when compared
to the original sentence, its BLEU score is not 100,
due to the fact that the number of people killed and
people injured are switched. In this regard, BLEU
score is harsh and not an ideal evaluation metric
for the task. In the second example, the origi-
nal sentence contains complicated wording which
is reflected in poor performance of all three ver-
sions of the system, despite the high BLEU score
of the 3-gram system. In the final example, we can
observe the gradual improvement of fluency over
the three versions of the system. This is reflected
by the BLEU score, which reaches 100.0 for the
4-gram system, which produced an identical sen-
tence to the original.
4.4 Manual Evaluation
We manually evaluated three versions of the
graph-based approach: 2-gram, 3-gram, and 4-
gram system using 3-gram as back-off. We con-
ducted a pairwise comparison of the three sys-
tems: for each evaluation sentence, we compared
the output of a pair of systems and asked which
output is more fluent.
We used the crowdsourcing website Crowd-
Flower
1
to gather fluency judgments. Judges were
asked ‘Please read both sentences and compare the
fluency of sentence 1 and sentence 2.’ They were
given three options: ‘Sentence 1 is more fluent’,
‘Sentence 2 is more fluent’, ‘Sentence 1 and Sen-
tence 2 are indistinguishable in fluency’. The or-
der of presentation of the two systems was ran-
domized for each sentence.
100 sentences of length between 5 and 18 words
were chosen randomly from the combined MT08
and MT09 dataset. We gathered 5 judgements for
each sentence of a single pairwise comparison of
two systems. Each pairwise comparison of two
systems is therefore based on 500 human judge-
ments.
The platform measures the reliability of judges
by randomly posing gold standard questions in
between regular questions. If any judge incor-
rectly answered a number of gold standard ques-
tions, their judgements were deemed unreliable
and were not used in the final result set. A thor-
ough discussion of suitability and reliability of
crowdsourcing for NLP and SMT tasks and re-
lated ethical concerns can be found in: Snow et
al. (2008), Zaidan and Callison-Burch (2011), and
Fort et al. (2011).
The pairwise comparison results are shown in
Table 4. Each number represents the proportion of
the human judgements that rated the output of the
row system as better than the column system. The
raw numbers of pairwise comparison judgements
in favor of each system are shown in Table 5. A
one-sided sign test indicated that we can reject the
null hypothesis of the two systems being equal in
favor of the alternative hypothesis of the first sys-
tem being better than the second for all three sys-
tem pairings: 3g and 2g, 4g and 2g, and 4g and 3g,
p < 0.001 for all three comparisons. The man-
ual evaluation results therefore confirm the BLEU
score differences between the three graph-based
systems.
Interestingly, in automatic evaluation the differ-
ence in BLEU scores between 2g and 3g systems
was much bigger (around 10 BLEU points) than
1
http://crowdflower.com/
91
Hypothesis BLEU
1. REF meanwhile , azim stated that 10 people were killed and 94 injured in yesterday ’s clashes .
(a) meanwhile , azim and 10 people were injured in clashes yesterday ’s stated that killed 94 . 21.4
(b) azim , meanwhile stated that 94 people were killed and 10 injured in yesterday ’s clashes . 50.4
(c) meanwhile , azim stated that 94 people were killed and 10 injured in yesterday ’s clashes . 66.3
2. REF zinni indicated in this regard that president mubarak wants egypt to work with the west .
(a) egypt wants zinni in this regard to work with president mubarak indicated that the west . 24.9
(b) zinni wants egypt to work with the west that president mubarak indicated in this regard . 63.4
(c) work with zinni indicated that president mubarak wants the west to egypt in this regard . 30.6
3. REF he stressed that this direction is taking place in all major cities of the world .
(a) he stressed that the world is taking place in this direction of all major cities . 33.9
(b) he stressed that all major cities of the world is taking place in this direction . 58.0
(c) he stressed that this direction is taking place in all major cities of the world . 100.0
Figure 3: Output examples of three versions of the graph-based approach: (a) 2-gram, (b) 3-gram, and
(c) 4-gram with 3-gram back-off. The original sentence is given for each of the three examples. Sentence
BLEU scores are shown for each regenerated sentence.
LM 2g 3g 4g
2g - - -
3g 65.4 - -
4g 72.9 69.2 -
Table 4: Manual evaluation results of pairwise
comparison between three versions of the system:
2-gram, 3-gram, and the 4-gram system with 3-
gram back-off. The numbers represent the per-
centage of judgements in favor of the row system
when paired with the column system.
the difference between 3g and 4g systems (around
1 BLEU point). However, in manual evaluation
the difference between 3g and 4g systems is no-
ticeably bigger (69.2%) than the difference be-
tween 2g and 3g systems (65.4%).
sys1 sys2 sys1 equal sys2 Total
2g 3g 124 142 234 500
2g 4g 102 124 274 500
3g 4g 92 201 207 500
Table 5: The raw numbers of pairwise compari-
son judgements between the three systems. The
columns give the number of judgements in favor
of each of the three options.
5 Related Work
The basic task of all natural language realization
approaches is to take a meaning representation as
input and generate human-readable output. The
approaches differ on how much information is re-
quired from the meaning representation. Deep
representation include dependency graphs anno-
tated with semantic labels and other syntactic in-
formation (Belz et al., 2011). Shallow represen-
tations include syntactic dependency trees anno-
tated with POS tags and other syntactic informa-
tion (Belz et al., 2011), IDL-expressions (Soricut
and Marcu, 2005), and Abstract Meaning Repre-
sentation (Langkilde and Knight, 1998).
Soricut and Marcu (2005) consider NLG in
context of other popular natural language appli-
cations, such as Machine Translation, Summa-
rization, and Question Answering. They view
these as text-to-text applications that produce tex-
tual output from textual input. Because of this,
many natural language applications need to in-
clude some form of natural language generation
to produce the output text. However, the natu-
ral language generation in these applications is of-
ten handled in an application-specific way. They
propose to use IDL-expressions as an application-
independent representation language for text-to-
text NLG. The IDL-expressions are created from
strings using operators to combine them. The au-
thors evaluate their approach on the string regen-
eration task and achieve moderate BLEU scores.
Wan et al. (2009) approach the string regener-
ation problem using dependency spanning trees.
Their approach is to search for the most proba-
ble dependency tree containing each word in the
input or, equally, finding the optimal spanning
tree. Zhang and Clark (2011) propose a simi-
lar approach using Combinatory Categorial Gram-
mar (CCG) which imposes stronger category con-
straints on the parse structure compared to de-
pendency trees investigated by Wan et al. (2009).
They primarily focus on the search problem of
finding an optimal parse tree among all possible
92
trees containing any choice and ordering of the in-
put words. The CCG approach achieved higher
BLEU scores compared to the approach proposed
by Wan et al. (2009). Zhang et al. (2012) improve
the CCG approach by Zhang and Clark (2011) by
incorporating an N-gram language model. de Gis-
pert et al. (2014) present a similar N-gram lan-
guage model approach to ours with a different de-
coder that does not guarantee optimal results. In
their comparison with approach by Zhang et al.
(2012) they report gains of more than 20 BLEU
points.
The purpose of studying and building ap-
proaches to solving the string regeneration prob-
lem is to improve grammaticality and fluency of
machine generated text. An approach using a TSP
reordering model by Visweswariah et al. (2011)
focused on the preordering task in SMT. In the
preordering task the words of the source sentence
are reordered to reflect the word order expected in
the target sentence which helps improve the per-
formance of the SMT system.
6 Conclusions and Future Work
In the paper we explored the N-gram language
model approach to the string regeneration prob-
lem of recovering a fluent version of the original
sentence given a bag of words. The N-gram lan-
guage model approach computes the highest prob-
ability permutation of the input bag of words un-
der an N-gram language model. We described a
graph-based approach for finding the optimal per-
mutation. Finding the permutation with the high-
est probability in the graph formulation is equal to
finding the shortest tour in the graph or, equally,
solving the Travelling Salesman Problem.
We evaluated the proposed approach on three
datasets. The BLEU scores and example output
indicated that the graph-based approach is suc-
cessful in constructing a fairly fluent version of
the original sentence. The 2-gram based approach
performed moderately well but was surpassed by
the 3-gram based approach. The 4-gram based ap-
proach offered an improvement on the 3-gram but
is not of much practical use due to its long compu-
tation times. Approximate solutions computed us-
ing a heuristic TSP solver significantly reduced the
quality of the output and resulting BLEU score.
We confirmed the results of automatic evaluation
by conducting a manual evaluation.
The BLEU scores of our approach and the ap-
proach by Wan et al. (2009) can’t be directly com-
pared as we used different evaluation datasets and
preprocessing procedures. Nonetheless, the differ-
ence in BLEU scores is stark, our best system out-
performing theirs by more than 20 BLEU points.
The work presented in this paper can be ex-
tended in a number of ways. More extensive
comparison between optimal and approximate ap-
proaches would help draw stronger conclusions re-
garding the need for optimality. A direct compar-
ison between our N-gram language model based
approach and approaches presented by Wan et al.
(2009), Zhang et al. (2012), and others is needed
to determine its performance relative to other ap-
proaches.
The graph-based approach itself can be ex-
tended in a number of ways. Emulating meth-
ods from Statistical Machine Translation, the ap-
proach could be extended to generate an N-best
list of reorderings. A different method could then
be used to rerank the N-best list to choose the best
one. The methods can range from rescoring the
outputs with a higher-order language model or a
dependency language model, to using discrimina-
tive machine learning. The approach could also
be extended to handle additional constraints in the
input, such as phrases instead of words, by modi-
fying the edge weights of the graph.
Another interesting area of future research re-
lating to the wider string regeneration problem is
determining the human performance on the task.
Based on a simple trial of trying to regenerate a
long sentence by hand, it is clear that human per-
formance on the task would not equal 100 BLEU
points. It would therefore be interesting to deter-
mine the human performance on the string regen-
eration problem to provide a contrast and a point
of comparison to the performance of machine sys-
tems.
Finally, the string regeneration problem can be
viewed as a constraint satisfaction approach where
the constraints are minimal. However, in many
instances there is more information available re-
garding the final output of a system, for example
syntactic or semantic relationship between words.
This information introduces additional constraints
to the simple bag of words that need to be included
in the output. In future, we will explore methods
of generating from a set of constraints in a robust
manner to produce output that is fluent and gram-
matical.
93
Acknowledgments
We thank Juan Pino for his help with language
modeling and experiments. We thank Ann Copes-
take and the anonymous reviewers for their discus-
sions and suggestions.
Matic Horvat was supported by the Ad Futura
Scholarship during his work on the MPhil thesis.
References
David L. Applegate, Robert E. Bixby, Va?sek Chv´atal,
and William J. Cook. 2006a. Concorde TSP Solver.
David L. Applegate, Robert E. Bixby, Va?sek Chv´atal,
and William J. Cook. 2006b. The Traveling Sales-
man Problem: A Computational Study. Princeton
University Press.
David L. Applegate, Robert E. Bixby, Va?sek Chv´atal,
William Cook, Daniel G. Espinoza, Marcos Goy-
coolea, and Keld Helsgaun. 2009. Certification of
an optimal TSP tour through 85,900 cities. Opera-
tions Research Letters, 37(1):11–15, January.
Anja Belz, Michael White, Dominic Espinosa, Eric
Kow, Deirdre Hogan, and Amanda Stent. 2011. The
First Surface Realisation Shared Task : Overview
and Evaluation Results. In Proceedings of the 13th
European Workshop on Natural Language Genera-
tion (ENLG), volume 2, pages 217–226.
Stanley F. Chen and Joshua T. Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical report, Harvard Univer-
sity.
Adri`a de Gispert, Marcus Tomalin, and William Byrne.
2014. Word Ordering with Phrase-Based Gram-
mars. In Proceedings of the European Chapter of
the Association for Computational Linguistics, num-
ber 2009.
Vladimir Dimitrijevi´c and Zoran
?
Sari´c. 1997. An
Efficient Transformation of the Generalized Trav-
eling Salesman Problem into the Traveling Sales-
man Problem on DIgraphs. Information Sciences,
102:105–110.
Dominic Espinosa, Rajakrishnan Rajkumar, Michael
White, and Shoshana Berleant. 2010. Further Meta-
Evaluation of Broad-Coverage Surface Realization.
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages
564–574.
Kar¨en Fort, Adda Gilles, and K. Bretonnel Cohen.
2011. Amazon Mechanical Turk: Gold Mine or
Coal Mine? Computational Linguistics, 37(2):413–
420.
Kenneth Heafield. 2011. KenLM : Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
number 2009, pages 187–197.
Michael Held and Richard M. Karp. 1962. A Dy-
namic Programming Approach to Sequencing Prob-
lems. Society for Industrial and Applied Mathemat-
ics, 10(1):196–210.
Keld Helsgaun. 2000. An effective implementa-
tion of the LinKernighan traveling salesman heuris-
tic. European Journal of Operational Research,
126(1):106–130.
Matic Horvat. 2013. A Graph-Based Approach to
String Regeneration. Ph.D. thesis.
Roy Jonker and Ton Volgenant. 1983. Transform-
ing Asymmetric into Symmetric Traveling Salesman
Problems. Operations Research Letters, 2(4):161–
163.
Kevin Knight. 2007. Automatic language transla-
tion generation help needs badly. In MT Summit XI
Work- shop on Using Corpora for NLG: Keynote Ad-
dress, pages 5–8.
Irene Langkilde and Kevin Knight. 1998. Generation
that Exploits Corpus-Based Statistical Knowledge.
In Proceedings of the 17th international conference
on Computational linguistics, pages 704–710.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
jing Zhu. 2002. BLEU : a Method for Automatic
Evaluation of Machine Translation. In Proceed-
ings of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL), number July,
pages 311–318, Philadelphia.
Rion Snow, Brendan O Connor, Daniel Jurafsky, and
Andrew Y Ng. 2008. Cheap and Fast But is it Good
? Evaluating Non-Expert Annotations for Natural
Language Tasks. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, number October, pages 254–263.
Radu Soricut and Daniel Marcu. 2005. Towards
Developing Generation Algorithms for Text-to-Text
Applications. In Proceedings of the 43rd Annual
Meeting of the ACL, number June, pages 66–74, Ann
Arbor.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Process-
ing, pages 901–904.
Karthik Visweswariah, Rajakrishnan Rajkumar, Ankur
Gandhe, Ananthakrishnan Ramanathan, and Jiri
Navratil. 2011. A Word Reordering Model for Im-
proved Machine Translation. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 486–496.
Stephen Wan, Mark Dras, Robert Dale, and Cecile
Paris. 2009. Improving Grammaticality in Statis-
tical Sentence Generation : Introducing a Depen-
dency Spanning Tree Algorithm with an Argument
Satisfaction Model. In Proceedings of the 12th Con-
ference of the European Chapter of the ACL, number
April, pages 852–860.
94
Omar F Zaidan and Chris Callison-Burch. 2011.
Crowdsourcing translation: Professional quality
from non-professionals. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 1220–1229.
Yue Zhang and Stephen Clark. 2011. Syntax-
Based Grammaticality Improvement using CCG and
Guided Search. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 1147–1157.
Yue Zhang, Graeme Blackwood, and Stephen Clark.
2012. Syntax-Based Word Ordering Incorporating a
Large-Scale Language Model. In Proceedings of the
13th Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages 736–
746, Avignon, France.
95
