Representing Constraints with Automata 
Frank  Morawietz  and  Tom Corne l l  
Seminar  fiir Sprachwissenschaf t  
Un ivers i t£ t  T i ib ingen  
Wi lhe lmst r .  113 
72074 T i ib ingen,  Germany 
{frank, cornell}~sfs, nphil, uni-tuebingen, de 
Abst rac t  
In this paper we describe an approach to 
constraint based syntactic theories in terms 
of finite tree automata. The solutions to 
constraints expressed in weak monadic sec- 
ond order (MSO) logic are represented by 
tree automata recognizing the assignments 
which make the formulas true. We show 
that this allows an efficient representation 
of knowledge about the content of con- 
straints which can be used as a practical 
tool for grammatical theory verification. 
We achieve this by using the intertrans- 
latability of formulae of MSO logic and 
tree automata nd the embedding of MSO 
logic into a constraint logic programming 
scheme. The usefulness of the approach is 
discussed with examples from the realm of 
Principles-and-Parameters ba ed parsing. 
1 In t roduct ion  
In recent years there has been a continuing inter- 
est in computational linguistics in both model theo- 
retic syntax and finite state techniques. In this pa- 
per we attempt o bridge the gap between the two 
by exploiting an old result in logic, that the weak 
monadic second order (MSO) theory of two successor 
functions (WS2S) is decidable (Thatcher and Wright 
1968, Doner 1970). A "weak" second order theory is 
one in which the set variables are allowed to range 
only over finite sets. There is a more powerful result 
available: it has been shown (Rabin 1969) that the 
strong monadic second order theory (variables range 
over infinite sets) of even countably many successor 
functions is decidable. However, in our linguistic ap- 
plications we only need to quantify over finite sets, so 
the weaker theory is enough, and the techniques cor- 
respondingly simpler3 The decidability proof works 
by showing a correspondence b tween formulas in 
the language of WS2S and tree automata, devel- 
oped in such a way that the formula is satisfiable 
iff the set of trees accepted by the corresponding au- 
tomaton is nonempty. While these results were well 
known, the (rather surprising) suitability of this for- 
malism as a constraint language for Principles and 
Parameters (P&P) based linguistic theories has only 
recently been shown by Rogers (1994). 
It should be pointed out immediately that the 
translation from formulas to automata, while effec- 
tive, is just about as complex as it is possible to 
be. In the worst case, the number of states can be 
given as a function of the number of variables in 
the input formula with a stack of exponents as tall 
as the number of quantifier alternations in the for- 
mula. However, there is a growing body of work 
in the computer science literature motivated by the 
success of the MONA decision procedure (Henriksen 
et al. 1995) 2 on the application of these techniques 
in computer science (Basin and Klarlund 1995, Kelb 
et al. 1997), which suggests that in practical cases 
the extreme xplosiveness of this technique can be 
effectively controlled. It is one of our goals to show 
that this is the case in linguistic applications as well. 
The decidability proof for WS2S is inductive 
on the structure of MSO formulas. Therefore we 
can choose our particular tree description language 
rather freely, knowing (a) that the resulting logic 
1All of these are generalizations to trees of results 
on strings and the monadic second order theory of one 
successor function originally due to Biichi (1960). The 
applications we mention here could be adapted to strings 
with finite-state automata replacing tree automata. In 
general, all the techniques which apply to tree au- 
tomata re straightforward generalizations of techniques 
for FSAs. 
2The current version of the MONA tool works only on 
the MSO logic of strings. There is work in progress at the 
University of Aarhus to extend MONA to "MONA++", 
for trees (Biehl et al. 1996). 
468 
will be decidable and (b) that the translation to au- 
tomata will go through as long as the atomic formu- 
las of the language represent relations which can be 
translated (by hand if necessary) to tree automata. 
We will see how this is done ill the next section, 
but the point can be appreciated immediately. For 
example, Niehren and Podelski (1992) and Ayari et 
al. (1997) have investigated the usefulness of these 
techniques in dealing with feature trees which un- 
fold feature structures; there the attributes of an 
attribute-value t rm are translated to distinct suc- 
cessor functions. On the other hand, Rogers (1996) 
has developed a language rich in long-distance r la- 
tions (dominance and precedence) which is more ap- 
propriate for work in Government-Binding (GB) the- 
ory. Compact automata can be easily constructed 
to represent dominance and precedence relations. 
One can imagine other possibilities as well: as we 
will see, the automaton for Kayne-style asymmet- 
ric, precedence-restricted c-command (Kayne 1994) 
is also very compact, and makes a suitable primitive 
for a description language along the lines developed 
by Frank and Vijay-Shanker (1995). 
The paper is organized as follows. First we present 
some of the mathematical background, then we dis- 
cuss (na'ive) uses of the techniques, followed by 
the presentation of a constraint logic programming- 
based extension of MSO logic to avoid some of the 
problems of the naive approach, concluding with a 
discussion of its strengths and weaknesses. 
2 Def in ing  Automata  w i th  
Const ra in ts  
Tree automata .  For completeness, we sketch the 
definitions of trees and tree automata here. An in- 
troduction to tree automata can be found in G~cseg 
and Steinby (1984), as well as in Thatcher and 
Wright (1968) and Doner (1970). 
Assume an alphabet E = E0 LJ E2 with Eo = {A} 
and E2 being a set of binary operation symbols. We 
think of (binary) trees over E as just the set of terms 
Tr. constructed from this alphabet. That is, we let 
A be the empty tree and let a(tl,t2), for a E E2 
and tl,t2 E T~., denote the tree with label a and 
subtrees tl, t2. Alternatively, we can think of a tree 
t as a function from the addresses in a binary tree 
domain T to labels in E. 3 
A deterministic (bottom-up) tree automaton .4on 
binary trees is a tuple (A, E, a0, F, c~ / with A the set 
3The first approach is developed in Thatcher and 
Wright (1968), the second in Doner (1970). A tree do- 
main is a subset of strings over a linearly ordered set 
which is closed under prefix and left sister. 
of states, a0 E A the initial state, F C_ A the fi- 
nal states and a : (A x A x E) -+ A the transition 
function. The transition function can be thought of 
as a homomorphism on trees inductively defined as: 
h~(~) : a0 and h~(a(tl, t2)) = a(h~(tl), ha(t2), a). 
An automaton .4 accepts a tree t iff ha (t) E F. The 
language recognized by A is denoted by T(A) = 
{tlh,(t) E F}. 
Emptiness of the language T(,4) is decidable by a 
fixpoint construction computing the set of reachable 
states. The reachability algorithm is given below 
in Figure 1. R contains the reachable states con- 
structed so far, and R' contains possibly new states 
constructed on the current pass through the loop. 
T(A) is empty if and only if no final state is reach- 
1. R := {ao}, R' := 0. 
2. For all (ai,aj) E R x R, for all a E E, 
R' := R 'U {c~(ai,aj,a)}. 
3. If R r -  R = 0 then return R, 
else R := R U R', go to step 2. 
Figure 1: Reachable states algorithm. 
able. Naturally, if we want to test emptiness, we can 
stop the construction as soon as we encounter a final 
state in R r. Note that, given an automaton with k 
states, the algorithm must terminate after at most k 
passes through the loop, so the algorithm terminates 
after at most k 3 searches through the transition ta- 
ble. 
Sets of trees which are the language of some tree 
automaton are called recognizable. 4 The recogniz- 
able sets are closed under the boolean operations 
of conjunction, disjunction and negation, and the 
automaton constructions which witness these clo- 
sure results are absolutely straightforward general- 
izations of the corresponding better-known construc- 
tions for finite state automata. The recognizable s ts 
are also closed under projections (mappings from 
one alphabet o another) and inverse projections, 
and again the construction is essentially that for fi- 
nite state automata. The projection construction 
yields a nondeterministic automaton, but, again as 
for FSA's, bottom-up tree automata can be made 
deterministic by a straightforward generalization of
the subset construction. (Note that top-down tree 
automata do not have this property: determinis- 
tic top-down tree automata recognize a strictly nar- 
rower family of tree sets.) Finally, tree automata can 
4The recognizable sets of trees yield the context free 
string languages, so MSO logics are limited to context 
free power. However, the CLP extension discussed below 
can be used to amplify the power of the formalism where 
necessary. 
469 
be minimized by a construction which is, yet again, 
a straightforward generalization of well known FSA 
techniques. 
The weak  second order  theory  o f  two  succes -  
sor  funct ions .  One attraction of monadic second 
order tree logics is that they give us a principled 
means of generating automata from a constraint- 
based theory. The connection allows the linguist 
to specify ideas about natural anguage in a concise 
manner in logic, while at the same time providing 
a way of "compiling" those constraints into a form 
which can be efficiently used in natural anguage pro- 
cessing applications. 
The translation is provided via the weak monadic 
second order theory of two successor functions 
(WS2S). The structure of two successor functions, 
H2, has for its domain (N2) the infinite binary 
branching tree. Standardly the language of WS2S is 
based on two successor functions (left-daughter and 
right-daughter), but, as Rogers (1994) shows, this 
is intertranslatable with a language based on domi- 
nance and precedence relations. Because we choose 
the monadic second order language over whichever 
of these two signatures is preferred, we can quan- 
tify over sets of nodes in N2. So we can use these 
sets to pick out arbitrarily large finite trees embed- 
ded in N2. Second order variables can also be used 
to pick out other properties of nodes, such as cate- 
gory or other node-labeling features, and they can 
be used to pick out higher order substructures such 
as :~ projections or chains. 
As usual, satisfiability of a formula in the language 
of WS2S by Af2 is relative to an assignment function, 
mapping individual variables to members of N2 (as 
in first order logic) and mapping monadic predicate 
variables to subsets of N2. Following Biichi (1960), 
Doner (1970) and Thatcher and Wright (1968) show 
that assignment functions for such formulas can be 
coded by a labeling of the nodes in N2 in the follow- 
ing way. First, we treat individual variables as set 
variables which are constrained to be singleton sets 
(we can define the singletonhood property in MSO 
tree logic). So, without loss of generality, we can 
think of the domain of the assignment function as 
a sequence Xz , . . .  , X~ of the variables occurring in 
the given formula. We choose our labeling alphabet 
to be the set of length n bit strings: (0, 1} ~. Then, 
for every node n E N2, if we intend to assign n to 
the denotation of Xi, we indicate this by labeling n 
with a bit string in which the ith bit is on. (In effect, 
we are labelling every node with a list of the sets to 
which it belongs.) Now every assignment function 
we might need corresponds uniquely to a labeling 
function over N2. What Doner, and Thatcher and 
Wright (and, for strong $2S, Rabin) show is that 
each formula in the language of WS2S corresponds 
to a tree automaton which recognizes just the sat- 
isfying "assignment labelings", and we can thereby 
define a notion of "recognizable relation". So the 
formula is satisfiable just in case the corresponding 
automaton recognizes a nonempty language. Note 
that  any language whose formulas can be converted 
to automata in this way is therefore guaranteed to 
be decidable, though whether it is as strong as the 
language of WS2S must still be shown. 
This approach to theorem-proving is rather dif- 
ferent from more general techniques for higher-order 
theorem proving in ways that the formalizer must 
keep in mind. In particular, we are deciding mem- 
bership in the theory of a fixed structure, Af2, and 
not consequence of an explicit set of tree axioms. 
So, for example, the parse tree shows up in the for- 
malization as a second order variable, rather than 
simply being a satisfying model (cf. Johnson (1994), 
on "satisfiability-based" grammar formalisms). 
As an example consider the following formula 
denoting the relation of directed asymmetric - 
command 5 in the sense of Kayne (1994). We use the 
tree logic signature of Rogers (1994), which, in a sec- 
ond order setting, is interdefinable with the language 
of multiple successor functions. Uppercase letters 
denote second order variables, lowercase ones first 
order variables, <~* reflexive domination, <~+ proper 
domination and -4 proper precedence: 
AC-Com(xl, x2) 
% x c-commands y:
(Vz)\[z <~+ x =# z <~+ y\] A -~(x <1" y) A 
% y does not c-command x: 
4 + y z 4 + x\] A 4"  x)) A 
% x preceeds y: 
x-~y 
The corresponding tree automaton is shown in 
Figure 2. On closer examination of the transitions, 
we note that we just percolate the initial state as 
long as we find only nodes which are neither xl nor 
x2. From the initial state on both the left and the 
right subtree we can either go to the state denoting 
"found xl" (al) if we read symbol 10 or to the state 
denoting "found x2" (a2) if we read symbol 01. We 
can then percolate a2 as long as the other branch 
does not immediately dominate xl. When we have 
5This relation is not monadic, but reducible via syn- 
tactic substitution to an MSO signature. In fact, we can 
define relations of any arity as long as they are explicitly 
presentable in MSO logic. 
470 
,4 = (A,~,ao,F,a) ,  
A = {ao,al,a2,a3,a4}, 
= {11, 10, 01, 00} 
F = {a3}, 
 (ao,a0,00) = a0  (a0,a0, 10) = al  
 (a0,a0,01) = a2  (a0,a2,00) = 
 (a0, a3,00)  = a3  (a2, a0, 00) = 
 (al, a: ,  00) = a3 a0,00) = 
all other transitions are to a4 
Figure 2: The automaton for AC-Com(xl ,  x2) 
al on the left subtree and a2 on the right one, we go 
to the final state aa which again can be percolated 
as long as empty symbols are read. Clearly, the au- 
tomaton recognizes all trees which have the desired 
c-command relation between the two nodes. It com- 
pactly represents the (infinite) number of possible 
satisfying assignments. 
The proof of the decidability of WS2S furnishes 
a technique for deriving such automata for recog- 
nizable relations effectively. (In fact the above au- 
tomaton was constructed by a simple implementa- 
tion of such a compiler which we have running at the 
University of Tiibingen. See Morawietz and Cornell 
(1997).) The proof is inductive. In the base case, 
relations defined by atomic formulas are shown to 
be recognizable by brute force. Then the induction 
is based on the closure properties of the recognizable 
sets, so that logical operators correspond to automa- 
ton constructions in the following way: conjunction 
and negation just use the obvious corresponding au- 
tomaton operations and existential quantification is 
implemented w~th the projection construction. The 
inductive nature of the proof allows us a fairly free 
choice of signature, as long as our atomic relations 
are recognizable. We could, for example, investi- 
gate theories in which asymmetric c-command was 
the only primitive, or asymmetric c-command plus 
dominance, for example. 
The projection construction, as noted above, 
yields nondeterministic automata s output, and 
the negation construction requires deterministic au- 
tomata s input, so the subset construction must be 
used every time a negated existential quantifier is en- 
countered. The corresponding exponential blowup 
in the state space is the main cause of the non- 
elementary complexity of the construction. Since 
a quantifier prefix of the form 3- . .  3V. . .V3. . .  is 
equivalent o 3 . . .  373- - -373 . - -  we see that the 
stack of exponents involved is determined by the 
number of quantifier alternations. 
It is obviously desirable to keep the automata s 
small as possible. In our own prototype, we min- 
imize the outputs of all of our automata construc- 
tions. Note that this gives us another way of deter- 
mining satisfiability, since the minimal automaton 
recognizing the empty language is readily detectable: 
its only state is the initial state, and it is not final. 
3 Def in ing  Const ra in ts  w i th  
Automata  
An obvious goal for the use of the discussed ap- 
proach would be the (offline) generation of a tree 
automaton representing an entire grammar. That 
is, in principle, if we can formalize a grammar in 
an MSO tree logic, we can apply these compilation 
techniques to construct an automaton which recog- 
nizes all and only the valid parse trees. 6 In this set- 
ting, the parsing problem becomes the problem of 
conjoining an automaton recognizing the input with 
the grammar automaton, with the result being an 
automaton which recognizes all and only the valid 
parse trees. For example, assume that we have an 
automaton Gram(X)  such that X is a well-formed 
tree, and suppose we want to recognize the input 
John sees Mary. Then we conjoin a description of 
the input with the grammar automaton as given be- 
low. 
(3x, y,z  E X)\[x E John A y E Sees A z E Mary A 
x -< y -< z A Gram(X)\] 
The recognition problem is just the problem of deter- 
mining whether or not the resulting automaton rec- 
ognizes a nonempty language. Since the automaton 
represents he parse forest, we can run it to generate 
parse trees for this particular input. 
Unfortunately, as we have already noted, the 
problem of generating a tree automaton from an 
arbitrary MSO formula is of non-elementary com- 
plexity. Therefore, it seems unlikely that a formal- 
ization of a realistic principle-based grammar could 
be compiled into a tree automaton before the heat 
death of the universe. (The formalization of ideas 
from Relativized Minimality (Pdzzi 1990) presented 
in Rogers (1994) fills an entire chapter without spec- 
ifying even the beginning of a full lexicon, for ex- 
ample.) Nonetheless there are a number of ways 
in which these compilation techniques remain use- 
ful. First, though the construction of a grammar 
automaton is almost certainly infeasible for realis- 
tic grammars, the construction of a grammar-and- 
input automaton--which is a very much smaller 
6This is reminiscent of approaches associated with 
Bernard Lang. See van Noord (1995) and references 
therein. 
471 
machine--may not be. We discuss techniques based 
on constraint logic programming that are applicable 
to that problem in the next section. 
Another use for such a compiler is suggested by 
the standard divide-and-conquer strategy for prob- 
lem solving: instead of compiling an entire gram- 
mar formula, we isolate interesting subformulas, and 
attempt to compile them. Tree automata repre- 
sent properties of trees and there are many such 
properties less complex than global well-formedness 
which are nonetheless important to establish for 
parse trees. In particular, where the definition of 
a property of parse trees involves negation or quan- 
tification, including quantification over sets of nodes, 
it may be easier to express this in an MSO tree logic, 
compile the resulting formula, and use the resulting 
automaton as a filter on parse trees originally gen- 
erated by other means (e.g., by a covering phrase 
structure grammar). 
At the moment, at least, the question of which 
grammatical properties can be compiled in a reason- 
able time is largely empirical. It is made even more 
difficult by the lack of high quality software tools. 
This situation should be alleviated in the near future 
when work on MONA++ at the University of Aarhus 
is completed; the usefulness of its older sister MONA 
(Henriksen et al. 1995), which works on strings and 
FSA's, has been well demonstrated in the computer 
science literature. In the meantime, for tests, we are 
using a comparatively simple implementation f our 
own. Even with very low-power tools, however, we 
can construct automata for interesting rammatical 
constraints. 
For example, recall the definition of asymmetric c-
command and its associated automaton in Figure 2. 
In linguistic applications, we generally use versions 
of c-command which are restricted to be local, in the 
sense that no element of a certain type is allowed 
to intervene. The general form of such a locality 
condition LC might then be formalized as follows. 
LC(x,y) 
AC-Comm(x, y) A 
% there does not exist z with property P: 
(-~3z)\[z E P A 
% such that it intervenes between x and y: 
(3w) \ [w x A w ,a + z A z y\]\] 
Here property P is meant to be the property iden- 
tifying a relevant intervener for the relation meant 
to hold between x and y. Note that this property 
could include that some other node be the left suc- 
cessor of z with certain properties, that is, this gen- 
eral scheme fits cases where the intervening item is 
not itself directly on the path between x and y. This 
formula was compiled by us and yields the automa- 
ton in Figure 3. Here the first bit position indicates 
membership in P, the second is for x and the third 
for y. 
A = (A,E, ao,F,a), 
A = {no, al, a2, a3, a4 }, 
F = {a3},  
a(ao,ao,O00) = ao a(ao,ao, 100) = ao 
a(ao,ao,OlO) -- a2 (~(ao,ao,ll0) = a2 
a(ao, ao, 001) = al a(ao, ao, 101) = al 
a(ao,al ,000) -- al ~(ao,a3,000) = a3 
a(ao,a3,100) = a3 ~(al,ao,000) = al 
Ol(a2, al, 000) = a3 a(a2, al, I00) = a3 
o~(a3, ao, 000) = a3 a(a3, ao, 100) = a3 
all other transitions are to at 
Figure 3: Automaton for local c-command. 
This automaton could in turn be implemented it- 
self as Prolog code, and considered to be an op- 
timized implementation of the given specification. 
Note in particular the role of the compiler as an op- 
timizer. It outputs a minimized automaton, and the 
minimal automaton is a unique (up to isomorphism) 
definition of the given relation. Consider again the 
definition of AC-Command in the previous section. 
It is far from the most compact and elegant formula 
defining that relation. There exist much smaller for- 
mulas equivalent to that definition, and indeed some 
are suggested by the very structure of the automa- 
ton. That formula was chosen because it is an ex- 
tremely straightforward formalization of the prose 
definition of the relation. Nonetheless, the automa- 
ton compiled from a much cleverer formalization 
would still be essentially the same. So no particular 
degree of cleverness is assumed on the part of the 
formalizer; optimization is done by the compiler. 7 
4 MSO Log ic  and  Const ra in t  Log ic  
P rogramming 
The automaton for a grammar formula is presum- 
ably quite a lot larger than the parse-forest automa- 
ton, that is, the automaton for the grammar con- 
joined with the input description. So it makes sense 
to search for ways to construct he parse-forest au- 
tomaton which do not require the prior construction 
of an entire grammar automaton. In this section we 
consider how we might do this by by the embedding 
7The structure of the formula does often have an ef- 
fect on the time required by the compiler; in that sense 
writing MSO formalizations i  still Logic Programming. 
472 
of the MSO constraint language into a constraint 
logic programming scheme. The constraint base is 
an automaton which represents the incremental c- 
cumulation of knowledge about the possible valua- 
tions of variables. As discussed before, automata 
are a way to represent even infinite numbers of valu- 
ations with finite means, while still allowing for the 
efficient extraction of individual valuations. We in- 
crementally add information to this constraint base 
by applying and solving clauses with their associated 
constraints. That is, we actually use the compiler on 
line as the constraint solver. Some obvious advan- 
tages include that we can still use our succinct and 
flexible constraint language, but gain (a) a more ex- 
pressive language, since we now can include induc- 
tive definitions of relations, and (b) a way of guid- 
ing the compilation process by the specification of 
appropriate programs. 
We define a relational extension TC(WS2S) of 
our constraint language following the HShfeld and 
Smolka scheme (HShfeld and Smolka 1988). From 
the scheme we get a sound and complete, but now 
only semi-decidable, operational interpretation of a 
definite clause-based derivation process. The result- 
ing structure is an extension of the underlying con- 
straint structure with the new relations defined via 
fixpoints. 
As usual, a definite clause is an implication with 
an atom as the head and a body consisting of a sat- 
isfiable MSO constraint and a (possibly empty) con- 
junction of atoms. A derivation step consists of two 
parts: goal reduction, which substitutes the body 
of a goal for an appropriate head, and constraint 
solving, which means in our case that we have to 
check the satisfiability of the constraint associated 
with the clause in conjunction with the current con- 
straint store. For simplicity we assume a standard 
left-to-right, depth-first interpreter for the execution 
of the programs. The solution to a search branch of 
a program is a satisfiable constraint, represented in
"solved form" as an automaton. Note that automata 
do make appropriate solved forms for systems of con- 
straints: minimized automata re normal forms, and 
they allow for the direct and efficient recovery of par- 
ticular solutions. 
Intuitively, we have a language which has an op- 
erational interpretation similar to Prolog with the 
differences that we interpret it not on the Herbrand 
universe but on N2, that we use MS0 constraint 
solving instead of unification and that we can use 
defined (linguistic) primitives directly. 
The resulting system is only semi-decidable, due 
to the fact that the extension permits monadic sec- 
ond order variables to appear in recursively defined 
clauses. So if we view the inductively defined rela- 
tions as part of an augmented signature, this sig- 
nature contains relations on sets. These allow the 
specification of undecidable relations; for example, 
Morawietz (1997) shows how to encode the PCP. If 
we limit ourselves to just singleton variables in any 
directly or indirectly recursive clause, every relation 
we define stays within the capacity of MSO logic, s 
since, if they are first order inductively definable, 
they are explicitly second order definable (Rogers 
1994). Since this does not take us beyond the power 
of MSO logic and natural anguage is known not to 
be context-free, the extra power of TC(WS2S) offers 
a way to get past the context-free boundary. 
To demonstrate how we now split the work be- 
tween the compiler and the CLP interpreter, we 
present a simple example. Consider the following 
naive specification of a lexicon: 9
Lexicon(x) ~:~ (x  E Sees  A x E V A . . . ) 
V (xE JohnAxENA. . . )  
Y (xEMaryAxENA. . . )  
We have specified a set called Lexicon via a disjunc- 
tive specification of lexical labels, e.g. Sees, and the 
appropriate combination offeatures, e.g.V. Naively, 
at least, every feature we use must have its own bit 
position, since in the logic we treat features as set 
variables. So, the alphabet size with the encoding 
as bitstrings will be at least 2 IAlphabet\[. It is immedi- 
ately clear that the compilation of such an automa- 
ton is extremely unattractive, if at all feasible. 
We can avoid having to compile the whole lexi- 
con by having separate clauses for each lexical en- 
try in the CLP extension. Notational conventions 
will be that constraints associated with clauses are 
written in curly brackets and subgoals in the body 
are separated by &'s. Note that relations defined in 
TC(WS2S) are written lowercase. 
lexicon(x) t--- {x E Sees A x E V A . . . } 
lexicon(x) +-- {x E John A x E N A . . . } 
lexicon(x) e - -  {xEMaryAxENA. . .}  
This shifts the burden of handling disjunctions to the 
interpreter. The intuitive point should be clear: it 
8Relations on individuals describe sets which are ex- 
pressible as monadic predicates. 
9Here and in the following we treat free variables as 
being stored in a global table so that we do not have 
to present hem in each and every constraint. In par- 
ticular, without this lexicon would have the additional 
arguments Sees, V, John, N, Mary and all free vari- 
ables appearing in the other definitions. 
473 
is not the case that every constraint in the grammar 
has to be expressed in one single tree automaton. 
We need only compile into the constraint store those 
which are really needed. Note that this is true even 
for variables appearing in the global table. In the 
CLP extension the appearance in the table is not 
coupled to the appearance in the constraint store. 
Only those are present in both which are part of the 
constraint in an applied clause. 
We can also use offline compiled modules in a 
T~(WS2S) parsing program. As a source of simple 
examples, we draw on the definitions from the lec- 
tures on P&P parsing presented in Johnson (1995). 
In implementing a program such as Johnson's sim- 
plified parse relation--see Figure 4--we can in prin- 
ciple define any of the subgoals in the body either 
via precompiled automata (so they are essentially 
treated as facts), or else providing them with more 
standard efinite clause definitions. 
parse(Words, Tree) 
{Tree(Words)} & 
yield(Words, Tree) & 
xbar(Tree) & 
ecp(Tree) 
Figure 4: parse as in Johnson (1995) 
In more detail, Words denotes a set of nodes la- 
beled according to the input description. Our initial 
constraint base, which can be automatically gener- 
ated from a Prolog list of input words, is the corre- 
sponding tree automaton. The associated constraint 
Tree is easily compilable and serves as the initializa- 
tion for our parse tree. The yield and ecp predicates 
can easily be explicitly defined and, if practically 
compilable (which is certainly the case for yield), 
could then be treated as facts. The xbar predicate, 
on the other hand, is a disjunctive specification of 
licensing conditions depending on different features 
and configurations, e.g., whether we are faced with 
a binary-, unary- or non-branching structure, which 
is better expressed as several separate rules. In fact, 
since we want the lexicon to be represented as sev- 
eral definite clauses, we cannot have xbar as a sim- 
ple constraint. This is due to the limitation of the 
constraints which appear in the definite clauses to 
(pure) MSO constraints. 
We now have another well-defined way of using the 
offiine compiled modules. This, at least, separates 
the actual processing issues (e.g., parse) from the 
linguistically motivated modules (e.g., ecp). One can 
now see that with the relational extension, we can 
not only use those modules which are compilable di- 
rectly, but also guide the compilation procedure. In 
effect this means interleaving the intersection of the 
grammar and the input description such that only 
the minimal amount of information to determine the 
parse is incrementally stored in the constraint base. 
Furthermore, the language of 7~(WS2S) is suffi- 
ciently close to standard Prolog-like programming 
languages to allow the transfer of techniques and 
approaches developed in the realm of P&P-based 
parsing. In other words, it needs only little effort 
to translate a Prolog program to a T~(WS2S) one. 
5 Conc lus ions  and  Out look  
In this paper we presented a first step towards the re- 
alization of a system using automata-based theorem- 
proving techniques to implement linguistic process- 
ing and theory verification. Despite the staggering 
complexity bound the success of and the continu- 
ing work on these techniques in computer science 
promises a useable tool to test formalization of gram- 
mars. The advantages are readily apparent. The 
direct use of a succinct and flexible description lan- 
guage together with an environment to test the for- 
malizations with the resulting finite, deterministic 
tree automata offers a way of combining the needs 
of both formalization and processing. And further- 
more, the CLP extension offers an even more power- 
ful language which allows a clear separation of pro- 
cessing and specification issues while retaining the 
power and flexibility of the original. Since it allows 
the control of the generation process, the addition 
of information to the constraint base is dependent 
on the input which keeps the number of variables 
smaller and by this the automata more compact. 
Nevertheless it remains to be seen how far the 
system can be advanced with the use of an opti- 
mized theorem-prover. The number of variables our 
current prototype can handle lies between eight and 
eleven. 1° This is not enough to compile or test all 
interesting aspects of a formalization. So further 
work will definitly involve the optimization of the 
prototype implementation, while we await the devel- 
opment of more sophisticated tools like MONA++. 
It seems to be promising to improve the (very ba- 
sic) CLP interpreter, too. The HShfeld and Smolka 
scheme allows the inclusion of existential quantifi- 
cation into the relational extension. We intend to 
use this to provide the theoretical background of 
the implementation of a garbage collection proce- 
dure which projects variables from the constraint 
store which are either local to a definite clause or 
Z°Note that this corresponds to 256 to 2048 different 
bitstrings. 
474 
explicitly marked for projection in the program so 
that the constraint store can be kept as small as 
possible. 
6 Acknowledgements 
This work has been supported by the project A8 
of the SFB 340 of the Deutsche Forschungsgemein- 
schaft. We wish especially to thank Uwe MSnnich 
and Jim Rogers for discussions and advice. Needless 
to say, any errors and infelicities which remain are 
ours alone. 
Re ferences  
Ayari, A., Basin, D. and Podelski, A. (1997). LISA: 
A specification language based on WS2S, Ms, Uni- 
versit~it Freiburg. Submitted to CSL'97. 
Basin, D. and Klarlund, N. (1995). Hardware 
verification using monadic second-order logic, 
Computer-Aided Verification (CAV '95), LNCS 
939, Springer, pp. 31-41. 
Biehl, M., Klarlund, N. and Rauhe, T. (1996). Algo- 
rithms for guided tree automata, Proc. WIA '96, 
LNCS, Springer-Verlag. 
Biichi, J. R. (1960). Weak second-order arithmetic 
and finite automata, Zeitschrift fiir mathematis- 
ehe Logik und Grundlagen der Mathematik 6: 66- 
92. 
Doner, J. (1970). Tree acceptors and some of their 
applications, Journal of Computer and System 
Sciences 4: 406-451. 
Frank, R. and Vijay-Shanker, K. (1995). C- 
command and grammatical primitives, Presenta- 
tion at the 18th GLOW Colloquium. University 
of Troms0. 
G@cseg, F. and Steinby, M. (1984). Tree Automata, 
Akad~miai Kiad6, Budapest. 
Henriksen, J. G., Jensen, J., J¢rgensen, M., Klar- 
lund, N., Paige, R., Rauhe, T. and Sandhol, A. 
(1995). MONA: Monadic second-order logic in 
practice, in Brinksma, Cleaveland, Larsen, Mar- 
garia and Steffen (eds), TACAS '95, LNCS 1019, 
Springer, pp. 89-110. 
HShfeld, M. and Smolka, G. (1988). Definite rela- 
tions over constraint languages, LILOG Report 53, 
IBM Deutschland, Stuttgart, Germany. 
Johnson, M. (1994). Two ways of formalizing ram- 
mars, Linguistics and Philosophy 17: 221-248. 
Johnson, M. (1995). Constraint-based natural lan- 
guage parsing, ESSLLI '95, Barcelona, Course 
notes. 
Kayne, R. S. (1994). The Antisymmetry of Syntax, 
MIT Press, Cambridge, Mass. and London, Eng- 
land. 
Kelb, P., Margaria, T., Mendler, M. and Gsot- 
tberger, C. (1997). MOSEL: A flexible toolset for 
monadic second-order logic, in E. Brinksma (ed.), 
TACAS '97. 
Morawietz, F. (1997). Monadic second order logic, 
tree automata and constraint logic programming, 
Arbeitspapiere des SFB 340 86, SFB 340, Univer- 
sit~t Tiibingen. 
Morawietz, F. and Cornell, T. L. (1997). On the 
recognizability of relations over a tree definable in 
a monadic second order tree description language, 
Arbeitspapiere des SFB 340 85, SFB 340, Univer- 
sit,it Tfibingen. 
Niehren, J. and Podelski, A. (1992). Feature au- 
tomata nd recognizable sets of feature trees, in 
M.-C. Gandel and J.-P. Jouannaud (eds), Pro- 
ceedings of the 4th International Joint Conference 
on Theory and Practice of Software Development, 
Springer, LNCS 668, pp. 356-375. 
Rabin, M. O. (1969). Decidability of second-order 
theories and automata on infinite trees, Transac- 
tions of the AMS 141: 1-35. 
Rizzi, L. (1990). Relativized Minimality, MIT Press. 
Rogers, J. (1994). Studies in the Logic of Trees with 
Applications to Grammar Formalisms, PhD the- 
sis, University of Delaware. CS-Technical Report 
No. 95-04. 
Rogers, J. (1996). A model-theoretic framework for 
theories of syntax, Proc. of the 34th Annual Meet- 
ing of the ACL, Santa Cruz, USA. 
Thatcher, J. W. and Wright, J. B. (1968). Gener- 
alized finite automata theory with an application 
to a decision problem of second-order logic, Math- 
ematical Systems Theory 2(1): 57-81. 
van Noord, G. (1995). The intersection offinite state 
automata nd definite clause grammars, Proc. of 
the 33th Annual Meeting of the ACL, Boston. 
475 
