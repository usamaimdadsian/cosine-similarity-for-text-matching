Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 677–687, Jeju Island, Korea, 12–14 July 2012. c©2012 Association for Computational Linguistics
Joint Inference for Event Timeline Construction
Quang Xuan Do Wei Lu Dan Roth
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA
{quangdo2,luwei,danr}@illinois.edu
Abstract
This paper addresses the task of construct-
ing a timeline of events mentioned in a given
text. To accomplish that, we present a novel
representation of the temporal structure of a
news article based on time intervals. We then
present an algorithmic approach that jointly
optimizes the temporal structure by coupling
local classifiers that predict associations and
temporal relations between pairs of tempo-
ral entities with global constraints. Moreover,
we present ways to leverage knowledge pro-
vided by event coreference to further improve
the system performance. Overall, our experi-
ments show that the joint inference model sig-
nificantly outperformed the local classifiers by
9.2% of relative improvement in F1. The ex-
periments also suggest that good event coref-
erence could make remarkable contribution to
a robust event timeline construction system.
1 Introduction
Inferring temporal relations amongst a collection of
events in a text is a significant step towards vari-
ous important tasks such as automatic information
extraction and document comprehension. Over the
past few years, with the development of the Time-
Bank corpus (Pustejovsky et al., 2003) , there have
been several works on building automatic systems
for such a task (Mani et al., 2006; Chambers and
Jurafsky, 2008; Yoshikawa et al., 2009; Denis and
Muller, 2011).
Most previous works devoted much efforts to the
task of identifying relative temporal relations (such
as before, or overlap) amongst events (Chambers
•
??
|
•
t1
|
•
t2
|
•
t3
•
|
t4
|
•
+?
|
Time
??
I1
I2
I3
e1
e2
e4
e3/e5
e7 ? e6
Figure 1: A graphical illustration of our timeline representation.
The e’s, t’s and I’s are events, time points and time intervals,
respectively.
and Jurafsky, 2008; Denis and Muller, 2011), with-
out addressing the task of identifying correct asso-
ciations between events and their absolute time of
occurrence. Even if this issue is addressed, certain
restrictions are often imposed for efficiency reasons
(Yoshikawa et al., 2009; Verhagen et al., 2010). In
practice, however, being able to automatically infer
the correct time of occurrence associated with each
event is crucial. Such information not only leads to
better text comprehension, but also enables fusion
of event structures extracted from multiple articles
or domains.
In this work, we are specifically interested in map-
ping events into an universal timeline representa-
tion. Besides inferring the relative temporal rela-
tions amongst the events, we would also like to au-
tomatically infer a specific absolute time of occur-
rence for each event mentioned in the text. Unlike
previous work, we associate each event with a spe-
cific absolute time interval inferred from the text. An
example timeline representation is illustrated in Fig.
677
1. Further details of our timeline representation are
given in Sec. 2.3.
We perform global inference by combining a col-
lection of local pairwise classifiers through the use
of an Integer Linear Programming (ILP) formula-
tion that promotes global coherence among local de-
cisions. The formulation allows our model to pre-
dict both event-event relations and event-time inter-
val associations simultaneously. We show that, with
the use of time intervals instead of time points, our
approach leads to a more concise ILP formulation
with reduced number of variables and constraints.
Moreover, we observed that event coreference can
reveal important information for such a task. We
propose that different event mentions that refer to
the same event can be grouped together before clas-
sification and performing global inference. This can
reduce the amount of efforts in both classification
and inference stages and can potentially eliminate
mistakes that would be made otherwise without such
coreference information. To the best of our knowl-
edge, our proposal of leveraging event coreference
to support event timeline construction is novel.
Our experiments on a collection of annotated
news articles from the standard ACE dataset demon-
strate that our approach produces robust timelines of
events. We show that our algorithmic approach is
able to combine various local evidences to produce
a global coherent temporal structure, with improved
overall performance. Furthermore, the experiments
show that the overall performance can be further im-
proved by exploiting knowledge from event corefer-
ence.
2 Background
We focus on the task of mapping event mentions in
a news article to a timeline. We first briefly describe
and define several basic concepts.
2.1 Events
Following the annotation guidelines of the ACE
project, we define an event as an action or occur-
rence that happens with associated participants or
arguments. We also distinguish between events and
event mentions, where a unique event can be core-
ferred to by a set of explicit event mentions in an
article. Formally, an event Ei is co-referred to by
a set of event mentions (ei1, e
i
2, . . . , e
i
k). Each event
mention e can be written as p(a1, a2, . . . , al), where
the predicate p is the word that triggers the presence
of e in text, and a1, a2, . . . al are the arguments asso-
ciated with e. In this work we focus on four tempo-
ral relations between two event mentions including
before, after, overlap and no relation.
2.2 Time Intervals
Similar to Denis and Muller (2011), we define time
intervals as pairs of time endpoints. Each time in-
terval I is denoted by [t?, t+], where t? and t+ are
two time endpoints representing the lower and upper
bound of the interval I , respectively, with t? ? t+.
The general form of a time endpoint is written as
“YYYY-MM-DD hh:mm:ss”. An endpoint can be un-
defined, in which case it is set to an infinity value:
??, or +?. There are two types of time intervals:
Explicit intervals are time intervals that can be
extracted directly from a given text. For example,
consider the following snippet of an article in our
data set: The litigation covers buyers in auctions
outside the United States between January 1, 1993
and February 7, 2000. In this example, we can ex-
tract and normalize two time intervals which are ex-
plicitly written, including January 1, 1993? [1993-
01-01 00:00:00, 1993-01-01 23:59:59] and Febru-
ary 7, 2000 ? [2000-02-07 00:00:00, 2000-02-07
23:59:59]. Moreover, an explicit interval can also
be formed by one or more separate explicit temporal
expressions. In the example above, the connective
term between relates the two expressions to form a
single time interval: between January 1, 1993 and
February 7, 2000 ? [1993-01-01 00:00:00, 2000-
02-07 23:59:59]. To extract explicit time intervals
from text, we use the time interval extractor de-
scribed in Zhao et al. (2012).
Implicit intervals are time intervals that are not
explicitly mentioned in the text. We observed that
there are events that cannot be assigned to any pre-
cise time interval but are roughly known to occur
in the past or in the future relative to the Doc-
ument Creation Time (DCT) of the article. We
introduce two implicit time intervals to represent
the past and the future events as (??, t?DCT ] and
[t+DCT ,+?), respectively. In addition, we also al-
low an event mention to be assigned into the entire
timeline, which is denoted by (??,+?) if we can-
678
not identify its time of occurrence. We also consider
DCT as an implicit interval.
We say that the time interval Ii precedes the time
interval Ij on a timeline if and only if t
+
i ? t
?
j ,
which also implies that Ii succeeds Ij if and only if
t?i ? t
+
j . The two intervals overlap, otherwise.
2.3 Timeline
We define a timeline as a partially ordered set of time
intervals. Fig. 1 gives a graphical illustration of an
example timeline, where events are annotated and
associated with time intervals. Relations amongst
events can be properly reflected in the timeline rep-
resentation. For example, in the figure, the events e1
and e2 are both associated with the interval I1. The
relation between them is no relation, since it is un-
clear which occurs first. On the other hand, e5 and
e3 both happen in the interval I2 but they form an
overlap relation. The events e6 and e7 occur within
the same interval I3, but e7 precedes (i.e. before) e6
on the timeline. The event e4 is associated with the
interval (??,+?), indicating there is no knowl-
edge about its time of occurrence.
We believe that such a timeline representation
for temporally ordering events has several advan-
tages over the temporal graph representations used
in previous works (Chambers and Jurafsky, 2008;
Yoshikawa et al., 2009; Denis and Muller, 2011).
Unlike previous works, in our model the events are
partially ordered in a single timeline, where each
event is associated with a precise time interval. This
improves human interpretability of the temporal re-
lations amongst events and time. This property of
our timeline representation, thus, facilitates merg-
ing multiple timelines induced from different arti-
cles. Furthermore, as we will show later, the use
of time intervals within the timeline representation
simplifies the global inference formulation and thus
the inference process.
3 A Joint Timeline Model
Our task is to induce a globally coherent timeline
for a given article. We thus adopt a global infer-
ence model for performing the task. The model
consists of two components: (1) two local pairwise
classifiers, one between event mentions and time in-
tervals (the E–T classifier) and one between event
mentions themselves (the E–E classifier), and (2)
a joint inference module that enforces global co-
herency constraints on the final outputs of the two
local classifiers. Fig. 2 shows a simplified temporal
structure of event mentions and time intervals of an
article in our model.
Our E–T classifier is different from previous
work (Chambers and Jurafsky, 2008; Yoshikawa et
al., 2009; Denis and Muller, 2011), where such clas-
sifiers were trained to identify temporal relations be-
tween event mentions and a temporal expression. In
our work, in order to construct absolute timeline of
event mentions, temporal expressions are captured
and normalized as absolute time intervals. The E–T
classifiers are then used to assign event mentions to
their contextually corresponding time intervals.
We also lifted several restrictions imposed in pre-
vious work (Bethard et al., 2007; Yoshikawa et al.,
2009; Verhagen et al., 2010). Specifically, we do
not require that event mentions and time expressions
have to appear in the same sentence, and we do not
require two event mentions have to appear very close
to each other (e.g., main event mentions in adjacent
sentences) in order to be considered as candidate
pairs for classification. Instead, we performed clas-
sifications over all pairs of event mentions and time
intervals as well as over all pairs of event mentions.
We show through experiments that lifting these re-
strictions is indeed important (see Sec. 5).
Another important improvement over previous
work is our global inference model We would like
to highlight that our work is also distinct from most
previous works in the global inference component.
Specifically, our global inference model jointly op-
timizes the E-E relations amongst event mentions
and their associations, E-T, with temporal informa-
tion (intervals in our case). Previous work (Cham-
bers and Jurafsky, 2008; Denis and Muller, 2011),
on the other hand, assumed that the E-T information
is given and only tried to improve E-E.
3.1 The Pairwise Classifiers
We first describe our local classifiers that associate
event mention with time interval and classify tempo-
ral relations between event mentions, respectively.
CE?T : is the E–T classifier that associates an
event mention with a time interval. Given an event
mention and a time interval, the classifier predicts
679
e1
e
2
e
3
e
4
e
n-1
e
n
e
5
• • •
I
1
I
2
I
3
I
m• • •
Figure 2: A simplified temporal structure of an article. There
are m time intervals I1 · · · Im and n event mentions e1 · · · en.
A solid edge indicates an association between an interval and
an event mention, whereas a dash edge illustrates a temporal
relation between two event mentions.
whether the former associates with the latter.
CE?T (ei, Ij)? {0, 1},
?i, j, 1 ? i ? n, 1 ? j ? m, (1)
where n and m are the number of event mentions
and time intervals in an article, respectively.
CE?E : is the E–E classifier that identifies
the temporal relation between two event mentions.
Given a pair of event mentions, the classifier predicts
one of the four temporal relations between them:
b¯efore, a¯fter, o¯verlap and n¯o relation. Specifically:
CE?E(ei, ej)? {b¯, a¯, o¯, n¯},
?i, j, 1 ? i, j ? n, i 6= j, (2)
For training of the classifiers, we define a set of
features following some previous work (Bethard et
al., 2007; Chambers and Jurafsky, 2008; Yoshikawa
et al., 2009), together with some additional features
that we believe to be helpful for the interval-based
representation. We describe the base features below
and use † and ‡ to denote the features used for CE?T
and CE?E , respectively. We use the term temporal
entity (or entity, for short) to refer to either an event
mention or a time interval.
Lexical Features: A set of lexical features related
to the temporal entities: (i)†‡ the word, lemma and
part-of-speech of the input event mentions and the
context surrounding them, where the context is de-
fined as a window of 2 words before and after the
mention; (ii)† the modal verbs to the left and to the
right of the event mention; (iii)‡ the temporal con-
nectives between the event mentions1.
1We define a list of temporal connectives including before,
after, since, when, meanwhile, lately, etc.
Syntactic Features: (i)†‡ which entity appears
first in the text; (ii)†‡ whether the two entities appear
in the same sentence; (iii)†‡ the quantized number of
sentences between the two entities2; (iv)†‡ whether
the input event mentions are covered by preposi-
tional phrases and what are the heads of the phrases;
(v)†‡ if the entities are in the same sentence, what is
their least common constituent on the syntactic parse
tree; (vi)† whether there is any other temporal entity
that is closer to one of the two entities.
Semantic Features‡: A set of semantic features,
mostly related to the input event mentions: (i)
whether the input event mentions have a common
synonym from their synsets in WordNet (Fellbaum,
1998); (ii) whether the input event mentions have a
common derivational form derived from WordNet.
Linguistic Features†‡: The tense and the aspect
of the input event mentions. We use an in-house
rule-based recognizer to extract these features.
Time Interval Features†: A set of features re-
lated to the input time interval: (i) whether the
interval is implicit; (ii) if it is implicit, identify
its interval type: “dct” = [t?DCT , t
+
DCT ], “past” =
(??, t?DCT ], “feature” = [t
+
DCT ,+?), and “en-
tire” = (??,+?); (iii) the interval is before, after
or overlapping with the DCT.
We note that unlike many previous work (Mani et
al., 2006; Chambers and Jurafsky, 2008; Denis and
Muller, 2011), our classifiers do not use any gold
annotations of event attributes (event class, tense, as-
pect, modal and polarity) provided in the TimeBank
corpus as features.
In our work, we use a regularized averaged Per-
ceptron (Freund and Schapire, 1999) as our classifi-
cation algorithm3. We used the one-vs.-all scheme
to transform a set of binary classifiers into a multi-
class classifier (for CE?E). The raw prediction
scores were converted into probability distribution
using the Softmax function (Bishop 1996). If there
are n classes and the raw score of class i is acti, the
posterior estimation for class i is:
P˜ (i) =
eacti
?
1?j?n e
actj
2We quantize the number of sentences between two entities
to 0, 1, 2, less than 5 and greater than or equal to 5
3Other algorithm (e.g. SVM) gave comparable or worse re-
sults, so we only show the results from Averaged Perceptron.
680
3.2 Joint Inference for Event Timeline
To exploit the interaction among the temporal enti-
ties in an article, we optimize the predicted tempo-
ral structure, formed by predictions from CE?T and
CE?E , w.r.t. a set of global constraints that enforce
coherency on the final structure. We perform exact
inference using Integer Linear Programming (ILP)
as in (Roth and Yih, 2007; Clarke and Lapata, 2008).
We use the Gurobi Optimizer4 as a solver.
Let I = {I1, I2, . . . , Im} denote the set of time
intervals extracted from an article, and let E =
{e1, e2, . . . , en} denote all event mentions in the
same article. Let EI = {(ei, Ij) ? E × I|ei ?
E , Ij ? I} denote the set of all pairs of event
mentions and time intervals. We also denote the
set of event mention pairs by EE = {(ei, ej) ?
E × E|ei ? E , ej ? E , i 6= j}. The prediction prob-
ability of an association of a pair eI ? EI, given
by classifier CE?T , is denoted by p?eI,1?
5. Now, let
R = {b¯, a¯, o¯, n¯} be the set of temporal relations be-
tween two event mentions. The prediction proba-
bility of an event mention pair ee ? EE that takes
temporal relation r, given by CE?E , is denoted by
p?ee,r?. Furthermore, we define x?eI,1? to be a binary
indicator variable that takes on the value 1 iff an as-
sociation is predicted between e and I . Similarly,
we define a binary indicator variable y?ee,r? of a pair
of event mentions ee that takes on the value 1 iff ee
is predicted to hold the relation r.
The objective function is then defined as a linear
combination of the prediction probabilities from the
two local classifiers as follows:
arg max
x,y
[
?
?
eI?EI
p?eI,1? · x?eI,1?
+ (1? ?)
?
ee?EE
?
r?R
p?ee,r? · y?ee,r?
]
(3)
subject to the following constraints:
x?eI,1? ? {0, 1}, ?eI ? EI (4)
y?ee,r? ? {0, 1}, ?ee ? EE , r ? R (5)
?
r?R
y?ee,r? = 1, ?ee ? EE (6)
4http://gurobi.com/
5This value is complementary to the non-association proba-
bility, denoted by p?eI,0? = 1? p?eI,1?
We use the single parameter ? to balance the over-
all contribution of two components E-T and E-E.
? is determined through cross validation tuning on
a development set. We use (4) and (5) to make sure
x?eI,1? and y?ee,r? are binary values. The equality
constraint (6) ensures that exactly one particular re-
lation can be assigned to each event mention pair.
In addition, we also require that each event is as-
sociated with only one time interval. These con-
straints are encoded as follows:
?
I?I
x?eI,1? = 1, ?e ? E (7)
Our model also enforces reflexivity and transitiv-
ity constraints on the relations among event men-
tions as follows:
y?eiej ,r? ? y?ejei,rˆ? = 0,
?eiej = (ei, ej) ? EE , i 6= j (8)
y?eiej ,r1? + y?ejek,r2? ? y?eiek,r3? ? 1,
?eiej , ejek, eiek ? EE , i 6= j 6= k (9)
The equality constraints in (8) encode reflexive
property of event-event relations, where the rela-
tion rˆ denotes the inversion of the relation r. The
set of possible (r, rˆ) pairs is defined as follows:
{
(b¯, a¯), (a¯, b¯), (o¯, o¯), (n¯, n¯)
}
. Following the work
of (Bramsen et al., 2006; Chambers and Jurafsky,
2008), we encode transitive closure of relations be-
tween event mentions with inequality constraints in
(9), which states that if the pair (ei, ej) has a certain
relation r1, and the pair (ej , ek) has the relation r2,
then the relation r3 must be satisfied between ei and
ek. Examples of such triple (r1, r2, r3) include (b¯, b¯,
b¯) and (a¯, a¯, a¯).
Finally, to capture the interactions between our
local pairwise classifiers we add the following con-
straints:
x?eiIk,1? + x?ejIl,1? ? y?eiej ,b¯? ? 1,
?eiIk, ejIl ? EI, ?eiej ? EE ,
Ik precedes Il, i 6= j, k 6= l (10)
Intuitively, the inequality constraints in (10) spec-
ify that a temporal relation between two event men-
tions can be inferred from their respective associated
681
time intervals. Specifically, if two event mentions ei
and ej are associated with two time intervals Ik and
Il respectively, and Ik precedes Il in the timeline,
then ei must happen before ej .
It is important to note that our interval-based for-
mulation is more concise in terms of the number of
variables and constraints needed in the ILP relative
to time expression-based (or timepoint-based) for-
mulations used in previous work (Chambers and Ju-
rafsky, 2008). Specifically, in such timepoint-based
formulations, the relation between each event men-
tion and each time expression needs to be inferred,
resulting in |E||T ||RT | variables, where |E|, |T |,
and |RT | are the numbers of event mentions, time
points, and temporal relations respectively. In con-
trast, only |E||I| variables are required in our for-
mulation, where |I| is the number of intervals (since
we extract intervals explicitly, |I| is roughly equal
to |T |). Furthermore, performing inference with the
timepoint-based formulation would require |E||T |
equality constraints to enforce that each event men-
tion can take only one relation inRT for a particular
time point, whereas our interval-based model only
requires |E| constraints, since each event is strictly
associated with one interval (see Eqn. (7)). We jus-
tify the benefits of our formulation later in Sec. 5.4.
4 Incorporating Knowledge from Event
Coreference
One of the key contributions of our work is using
event coreference information to enhance the time-
line construction performance. This is motivated by
the following two principles:
(P1) All mentions of a unique event are associ-
ated with the same time interval, and overlap with
each other.
(P2) All mentions of an event have the same tem-
poral relation with all mentions of another event.
The example below, extracted from an article pub-
lished on 03/11/2003 in the Automatic Content Ex-
traction (ACE), 2005, corpus6 serves to illustrate the
significance of event coreference to our task.
6http://www.itl.nist.gov/iad/mig/tests/ace/2005/
The world’s most powerful fine art auction houses,
Sotheby’s and Christie’s, have agreed to [e11 =
pay] 40 million dollars to settle an international
price-fixing scam, Sotheby’s said. The [e12 = pay-
ment], if approved by the courts, would settle a
slew of [e21 = suits] by clients over auctions held
between 1993 and 2000 outside the US. ... Sotheby’s
and Christie’s will each [e13 = pay] 20 million dol-
lars,” said Sotheby’s, which operates in 34 countries.
In this example, there are 4 event mentions, whose
trigger words are highlighted in bold face. The un-
derlined text gives an explicit time interval: I1 =
[1993-01-01 00:00:00, 2000-12-31 23:59:59] (we
ignore 2 other intervals given by 1993 and 2000
to simplify the illustration). Now if we consider
the event mention e12, it actually belongs to the im-
plicit future interval I2 = [2003-03-11 23:59:59,
+?). Nevertheless, there is a reasonable chance
that CE?T associates it with I1, given that they both
appear in the same sentence, and there is no di-
rect evident feature indicating the event will actu-
ally happen in the future. In such a situation, using
a local classifier to identify the correct temporal as-
sociation could be challenging.
Fortunately, precise knowledge from event coref-
erence may help alleviate such a problem. The
knowledge reveals that the 4 event mentions can be
grouped into 2 distinct events: E1 = {e11, e
1
2, e
1
3},
E2 = {e21}. If CE?T can make a strong prediction
in associating the event mention e11 (or e
1
3) to I2, in-
stead of I1, the system will have a high chance to
re-assign e12 to I2 based on principle (P1). Similarly,
if CE?E is effective in figuring out that some men-
tion of event E1 occurs after some mention of E2,
then all the mentions of E1 would be predicted to
occur after all mentions in E2 according to (P2).
To incorporate knowledge from event coreference
into our classifiers and the joint inference model, we
use the following procedure: (1) performing classi-
fication with CE?T and CE?E on the data, (2) using
the knowledge from event coreference to overwrite
the prediction probabilities obtained by the two lo-
cal classifiers in step (1), and (3) applying the joint
inference model on the new prediction probabilities
obtained from (2). We note that if we stop at step (2),
we get the outputs of the local classifiers enhanced
by event coreference knowledge.
To overwrite the classification probabilities using
682
event coreference knowledge, we propose two ap-
proaches as follows:
MaxScore: We define the probability between
any mention e ? Ei and an interval I as follows:
p?eI,1? = max
e??Ei
P˜ (e?, I) (11)
where P˜ (e?, I) is the classifier (CE?T ) probability
for associating event mention e? to the time interval.
On the other hand, the probabilities for associat-
ing the set of temporal relations, R, to each pair of
mentions in Ei×Ej , is given by the following pair:
(ei, ej)? = arg max
(ei? ,ej? )?Ei×Ej ,r?R
P˜
(
(ei
?
, ej
?
), r)
)
p?ee,r? = P˜
(
(ei, ej)?, r
)
,?r ? R (12)
In other words, over all possible event mention
pairs and relations, we first pick the pair who glob-
ally obtains the highest probability for some rela-
tion. Next, we simply take the probability distri-
bution of that event mention pair as the distribution
over the relations, for the event pair.
SumScore: The probability between any mention
e ? Ei and an interval I is obtained by:
p?eI,1? =
1
|Ei|
?
e??Ei
P˜ (e?, I) (13)
To obtain the probability distribution over the set
of temporal relations,R, for any pair of mentions in
Ei × Ej , we used the following procedure:
r? = arg max
r?R
?
ei?Ei
?
ej?Ej
P˜
(
(ei, ej), r
)
(ei, ej)? = arg max
(ei? ,ej? )?Ei×Ej
P˜
(
(ei
?
, ej
?
), r?
)
p?ee,r? = P˜
(
(ei, ej)?, r
)
,?r ? R (14)
In other words, given two groups of event men-
tions, we first compute the total score of each rela-
tion, and select the relation which has the highest
score. Next from the list of pairs of event mentions
from the two groups, we select the pair which has the
relation r* with highest score compared to all other
pairs. The probability distribution of this pair will
be used as the probability distribution of all event
mention pairs between the two events.
In both approaches, we assign the overlap rela-
tions to all pairs of event mentions in the same event
with probability 1.0.
5 Experimental Study
We first describe the experimental data and then
present and discuss the experimental results.
5.1 Data and Setup
Most previous works in temporal reasoning used
the TimeBank corpus as a benchmark. The cor-
pus contains a fairly diverse collection of anno-
tated event mentions, without any specific focus on
certain event types. According to the annotation
guideline of the corpus, most of verbs, nominal-
izations, adjectives, predicative clauses and preposi-
tional phrases can be tagged as events. However, in
practice, when performing temporal reasoning about
events in a given text, one is typically interested in
significant and typed events, such as Killing, Leg-
islation, Election. Furthermore, event mentions in
TimeBank are annotated with neither event argu-
ments nor event coreference information.
We noticed that the ACE 2005 corpus contains the
annotation that we are interested in. The corpus con-
sists of articles annotated with event mentions (with
event triggers and arguments) and event coreference
information. To create an experimental data set for
our work, we selected from the corpus 20 newswire
articles published in March 2003. To extract time
intervals from the articles, we used the time inter-
val extractor described in (Zhao et al., 2012) with
minimal post-processing. Implicit intervals are also
added according to Sec. 2.2. We then hired an anno-
tator with expertise in the field to annotate the data
with the following information: (i) event mention
and time interval association, and (ii) the temporal
relations between event mentions, including {b¯, a¯,
o¯}. The annotator was not required to annotate all
pairs of event mentions, but as many as possible.
Next, we saturated the relations based on the ini-
tial annotations as follows: (i) event mentions that
had not been associated with any time intervals were
assigned to the entire timeline interval (??,+?),
and (ii) added inferred temporal relations between
event mentions with reflectivity and transitivity. Ta-
ble 1 shows the data statistics before and after sat-
uration. There are totally 8312 event pairs from 20
documents, including no relation pairs. We note that
in a separate experiment, we still evaluated CE?E
on the TimeBank corpus and got better performance
683
Data #Intervals #E-mentions #E-T #E-E
Initial 232 324 305 376
Saturated 232 324 324 5940
Table 1: The statistics of our experimental data set.
than a corresponding classifier in an existing work
(see Sec. 5.4).
We conducted all experiments with 5-fold cross
validation at the instance level on our data set after
saturation. The global inference model was applied
on a whole document. The results of the systems are
reported in averaged precision, recall and F1 score
on the association performance, for CE?T , and the
temporal relations (we excluded the n¯ relation, for
CE?E). We also measured the overall performance
of the systems by computing the average of the per-
formance of the classifiers.
5.2 A Baseline
We developed a baseline system that works as fol-
lows. It associates an event mention with the closest
time interval found in the same sentence. If such
an interval is not found, the baseline associates the
mention with the closest time interval to the left.
If the interval is again not found, the mention will
be associated with the DCT interval. The baseline
is based on the intuition of natural reading order:
events that are mentioned earlier are likely to pre-
cede those mentioned later. For the temporal rela-
tion between a pair of event mentions, the baseline
treats the event mention that appears earlier in the
text as temporally happening before the other men-
tion. The baseline performance is shown in the first
group of results in Table 2.
5.3 Our Systems
For our systems, we first evaluated the performance
of our local pairwise classifiers and the global in-
ference model. The second group of results in Ta-
ble 2 shows the systems’ performance. Overall,
the results show that our global inference model
relatively outperformed the baseline and the local
classifiers by 57.8% and 9.2% in F1, respectively.
We perform a bootstrap resampling significance test
(Koehn, 2004) on the output predictions of the lo-
cal classifiers with and without the inference model.
The test shows that the overall improvement with
the inference model is statistically significant (p <
0.01). This indicates the effectiveness of our joint
inference model with global coherence constraints.
Next, we integrated event coreference knowledge
into our systems (as described in Sec. 4) and eval-
uated their performance. Our experiments showed
that the SumScore approach works better for CE?T ,
while MaxScore is more suitable for CE?E . Our ob-
servations showed that event mentions of an event
may appear in close proximity with multiple time
intervals in the text, making CE?T produce high
prediction scores for many event mention-interval
pairs. This, consequently, confuses MaxScore on
the best association of the event and the time inter-
vals, whereas SumScore overcomes the problem by
averaging out the association scores. On the other
hand, CE?E gets more benefit from MaxScore be-
causeCE?E works better on pairs of event mentions
that appear closely in the text, which activate more
valuable learning features. We will report the results
using the best approach of each classifier.
To evaluate our systems with event coreference
knowledge, we first experimented our systems with
gold event coreference as given by the ACE 2005
corpus. Table 2 shows the contribution of event
coreference to our systems in the third group of the
results. The results show that injecting knowledge
from event coreference remarkably improved both
the local classifiers and the joint inference model.
Overall, the system that combined event corefer-
ence and the global inference model achieved the
best performance, which significantly overtook all
other compared systems. Specifically, it outper-
formed the baseline system, the local classifiers, and
the joint inference model without event coreference
with 80%, 25%, and 14% of relative improvement in
F1, respectively. It also consistently outperformed
the local classifiers enhanced with event corefer-
ence. We note that the precision and recall of CE?T
in the joint inference model are the same because
the inference model enforced each event mention to
be associated with exactly one time interval. This
is also true for the systems integrated with event
coreference because our integration approaches as-
sign only one time interval to an event mention.
We next move to experimenting with automati-
cally learned event coreference systems. In this ex-
684
Model
CE?T CE?E Overall
Prec. Rec. F1 Prec. Rec. F1 Prec. Rec. F1
1 Baseline 33.29 33.29 33.29 20.86 32.81 25.03 27.06 33.05 29.16
2
No Event Coref.
Local classifiers 62.70 34.50 43.29 40.46 42.42 40.96 51.58 38.46 42.13
Global inference 47.88 47.88 47.88 41.42 48.04 44.14 44.65 47.96 46.01
3
With Gold Event Coref.
Local classifiers 50.88 50.88 50.88 43.86 52.65 47.46 47.37 51.77 49.17
Global inference 50.88 50.88 50.88 48.04 62.45 54.05 49.46 56.67 52.47
4
With Learned Event Coref.
Local classifiers 46.37 46.37 46.37 40.83 45.28 42.60 43.60 45.83 44.49
Global inference 46.37 46.37 46.37 42.09 52.50 46.47 44.23 49.44 46.42
Table 2: Performance under various evaluation settings. All figures are averaged scores from 5-fold cross-validation experiments.
periment, we re-trained the event coreference sys-
tem described in Chen et al. (2009) on all arti-
cles in the ACE 2005 corpus, excluding the 20 ar-
ticles used in our data set. The performance of these
systems are shown in the fourth group of the re-
sults in Table 2. The results show that by using a
learned event coreference system, we achieved the
same improvement trends as with gold event coref-
erence. However, we did not obtain significant im-
provement when comparing with global inference
without event coreference information. This result
shows that the performance of an event coreference
system can have a significant impact on the over-
all performance. While this suggests that a better
event coreference system could potentially help the
task more, it also opens the question whether event
coreference can be benefited from our local classi-
fiers through the use of a joint inference framework.
We would like to leave this for future investigations.
5.4 Previous Work-Related Experiments
We also performed experiments using the same set-
ting as in (Yoshikawa et al., 2009), which followed
the guidelines of the TempEval challenges (Verha-
gen et al., 2007; Verhagen et al., 2010), on our sat-
urated data. Several assumptions were made to sim-
plify the task. For example, only main events in
adjacent sentences are considered when identifying
event-event relations. See (Yoshikawa et al., 2009)
for more details. We performed 5-fold cross valida-
tion without event coreference. Overall, the system
achieved 29.99 F1 for the local classifiers and 34.69
when the global inference is used. These results are
better than the baseline but underperform our full
models where those simplification assumptions are
not imposed, as shown in Table 2, indicating the im-
portance of relaxing their assumptions in practice.
We also evaluated our CE?E on the TimeBank
corpus. We followed the settings of Chambers and
Jurafsky (2008) to extract all event mention pairs
that were annotated with before (or ibefore, “imme-
diately before”) and after (or iafter) relations in 183
news articles in the corpus. We trained and evalu-
ated ourCE?E on these examples with the same fea-
ture set that we evaluated in our experiments above,
with gold tense and aspect features but without event
type. Following their work, we performed 10-fold
cross validation. Our classifier achieved a micro-
averaged accuracy of 73.45%, whereas Chambers
and Jurafsky (2008) reported 66.8%. We next in-
jected the knowledge of an event coreference sys-
tem trained on the ACE2005 corpus into our CE?E ,
and obtained a micro-averaged accuracy of 73.39%.
It was not surprising that event coreference did not
help in this dataset because: (i) different domains
– the event coreference was trained on ACE 05 but
applied on TimeBank, and (ii) different annotation
guidelines on events in ACE 2005 and TimeBank.
Finally, we conducted an experiment that justi-
fies the advantages of our interval-based inference
model over a time point-based inference. To do this,
we first converted our data in Table 1 from inter-
vals to time points and infer the temporal relations
between the annotated event mentions and the time
points: before, after, overlap, and unknown. We
modified the first component in the objective func-
tion in (3) to accommodate these temporal relations.
We also made several changes to the constraints,
including removing those in (7) since they are no
longer required, and adding constraints that ensure
685
the relation between a time point and an event men-
tion takes exactly one value. Proper changes were
also made to other constraints in (10) to reflect the
fact that time points are considered rather than inter-
vals. We observed that experiment with such a for-
mulation was unable to finish within 5 hours (we ter-
minated the ILP inference after waiting for 5 hours),
whereas our interval-based model finished the ex-
periment with an average of 21 seconds per article.
6 Related Work
Research in temporal reasoning recently received
much attention. Allen (1983) introduced an interval
based temporal logic which has been used widely
in the field. Recent efforts in building an annotated
temporal corpus (Pustejovsky et al., 2003) has pop-
ularized the use of machine learning techniques for
the task (Mani et al., 2006; Bethard et al., 2007).
This corpus was later used (with simplifications) in
two TempEval challenges (Verhagen et al., 2007;
Verhagen et al., 2010). In these challenges, several
temporal-related tasks were defined including the
tasks of identifying the temporal relation between an
event mention and a temporal expression in the same
sentence, and recognizing temporal relations of pairs
of event mentions in adjacent sentences. However,
with several restrictions imposed to these tasks, the
developed systems were not practical.
Recently, there has been much work attempting
to leverage Allen’s interval algebra of temporal re-
lations to enforce global constraints on local pre-
dictions. The work of Tatu and Srikanth (2008)
used global relational constraints to not only expand
the training data but also identifies temporal incon-
sistencies to improve local classifiers. They used
greedy search to select the most appropriate config-
uration of temporal relations among events and tem-
poral expressions. For exact inferences, Bramsen et
al. (2006), Chambers and Jurafsky (2008), Denis
and Muller (2011), and Talukdar et al. (2012) for-
mulated the temporal reasoning problem in an ILP.
However, the inference models in their work were
not a joint model involving multiple local classifiers
but only one local classifier was involved in their ob-
jective functions.
The work of Yoshikawa et al. (2009) did formu-
late a joint inference model with Markov Logic Net-
work (MLN). They, however, used the same setting
as the TempEval challenges, thus only pairs of tem-
poral entities in the same or adjacent sentences are
considered. Our work, on the other hand, focuses on
constructing an event timeline with time intervals,
taking multiple local pairwise predictions into a joint
inference model and removing the restrictions on the
positions of the temporal entities. Furthermore, we
propose for the first time to use event coreference
and evaluate the importance of its role in the task of
event timeline construction.
7 Conclusions and Future Work
We proposed an interval-based representation of the
timeline of event mentions in an article. Our rep-
resentation allowed us to formalize the joint infer-
ence model that can be solved efficiently, compared
to a time point-based inference model, thus open-
ing up the possibility of building more practical
event temporal inference systems. Our inference
model achieved significant improvement over the lo-
cal classifiers. We also showed that event coref-
erence can naturally support timeline construction,
and good event coreference led to significant im-
provement in the system performance. Specifically,
when such gold event coreference knowledge was
injected into the model, a significant improvement
in the overall performance could be obtained. While
our experiments suggest that the temporal classi-
fiers can potentially help enhance the performance
of event coreference, in future work we would like
to investigate into coupling event coreference with
other components in a global inference framework.
Acknowledgments
The authors gratefully acknowledge the support
of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air
Force Research Laboratory (AFRL) prime contract
No. FA8750-09-C-0181, and the Army Research
Laboratory (ARL) under agreement W911NF-09-2-
0053. The first author also thanks the Vietnam Ed-
ucation Foundation (VEF) for its sponsorship. Any
opinions, findings, and conclusion or recommenda-
tions expressed in this material are those of the au-
thors and do not necessarily reflect the view of the
VEF, DARPA, AFRL, ARL, or the US government.
686
References
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the ACM.
Steven Bethard, James H. Martin, and Sara Klingenstein.
2007. Timelines from text: Identification of syntactic
temporal relations. In ICSC.
P. Bramsen, P. Deshpande, Y. K. Lee, and R. Barzilay.
2006. Inducing temporal graphs. In EMNLP.
N. Chambers and D. Jurafsky. 2008. Jointly combin-
ing implicit constraints improves temporal ordering.
In EMNLP.
Zheng Chen, Heng Ji, and Robert Haralick. 2009. A
pairwise event coreference model, feature impact and
evaluation for event coreference resolution. In Work-
shop on Events in Emerging Text Types.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear programming
approach. Journal of Artificial Intelligence Research.
Pascal Denis and Philippe Muller. 2011. Predicting
globally-coherent temporal structures from texts via
endpoint inference and graph decomposition. In IJ-
CAI.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
Yoav Freund and Robert E. Schapire. 1999. Large mar-
gin classification using the perceptron algorithm. Ma-
chine Learning.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In EMNLP.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In ACL.
J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas,
A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro,
and M. Lazo. 2003. The TIMEBANK corpus. In
Corpus Linguistics.
D. Roth and W. Yih. 2007. Global inference for entity
and relation identification via a linear programming
formulation. In Introduction to Statistical Relational
Learning.
Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.
2012. Coupled temporal scoping of relational facts. In
WSDM.
Marta Tatu and Munirathnam Srikanth. 2008. Experi-
ments with reasoning for temporal relations between
events. In COLING.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. Semeval-2007 task 15: Tempeval temporal re-
lation identification. In SemEval-2007.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In SemEval-2010.
Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-
hara, and Yuji Matsumoto. 2009. Jointly identify-
ing temporal relations with markov logic. In ACL-
IJCNLP.
Ran Zhao, Quang Do, and Dan Roth. 2012. A robust
shallow temporal reasoning system. In NAACL-HLT
Demo.
687
