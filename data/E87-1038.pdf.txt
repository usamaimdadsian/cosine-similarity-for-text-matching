COPING WITH DYNAMIC SYNTACTIC STRATEGIES: AN EXPERIMENTAL ENVIRONMENT FOR AN 
EXPERIMENTAL PARSER 
Oliviero Stock 
I.P. - Consiglio Nazionale delle Ricerche 
Via dei Monti Tiburtini 509 
00157 Roma, Italy 
ABSTRACT 
An environment built around WEDNESDAY 2, a chart 
based parser is introduced. The env i ronment  is in 
particular oriented towards exploring dynamic aspects 
of parsing. It includses a number of specialized tools 
that  consent an easy, graphics-based interaction with 
the parser. It is shown in particular how a combination 
of the characteristics of the parser (based on the lexicon 
and on dynamic unification) and of the env i ronment  
allow a nonspecialized user to explore heuristics that  
may alter the basica control of the system. In this way, 
for instance, a psychol inguist  may explore ideas on 
human parsing strategies, or a "language engineer" may 
find useful heuristics for parsing within a particular 
application. 
1. Introduct ion 
Computer-based env i ronments  for the l inguist  are 
conceived as sophisticated workbenches, bu i l t  on AI 
workstat ions around a specif ic parser ,  where  the 
l inguist can try out his/her ideas about a grammar for a 
certain natural  anguage. In doing so, he/she can take 
advantage of rich and easy-to-use graphic interfaces 
that  "know" about linguistics. Of course behind all this 
lies the idea that cooperation with linguists will provide 
better esults in NLP. To substantiate his assumption it
may be recalled that  some of the most interesting recent 
ideas on syntax have been developed by means of joint 
cont r ibut ions  from l ingu is ts  and  computat iona l  
l inguists. Lexical -Funct ional  Grammar  \ [Bresnan &
Kap lan  1982\], GPSG \ [Gazdar  1981\], Funct iona l  
Grammar \[Kay 1979\], DCG \[Pereira & Warren 1980\], 
TAG \[Joshi & Levy 1982\] are some of these ideas. 
Instances of the tools introduced above are the LFG 
environment, which was probably the first of its kind, an 
env i ronment  bu i l t  by Ron Kap lan  for Lex ica l -  
Funct iona l  Grammars ,  DPATR,  bu i l t  by Laur i  
Karttunen and conceived as an environment that would 
suit  l inguists of a number  of di f ferent schools al l  
committed to a view of parsing as a" process that  makes 
use of an unification algorithm. 
We have developed an environment with a somewhat 
different purpose. Besides a number of tools for entering 
data  in graph ic  mode and inspect ing  resu l t ing  
structures, it provides a means for experimenting with 
strategies in the course of the parsing process. We think 
that  this can be a valuable tool for gaining insight in the 
cognitive aspects of language processing as well as for 
tailoring the behaviour of the processor when used with 
a particular (sub)language. 
In this way an attempt can be made to answer basic 
questions when following a nondeterministic approach: 
what heuristics to apply when facing a certain choice 
point, what to do when facing a failure point, i.e. which 
of the pending processes to activate, taking account of 
information resulting from the failure? 
Of course this kind of environment makes sense only 
because the parser it works on has some characteristics 
that  make it a psychologically interesting realization. 
2. Mot ivat ion of  the parser  
We shall classify psychologically motivated parsers in 
three main categories. First: those that  embody a strong 
claim on the specification of the general control structure 
of the human parsing mechanism. The authors usually 
consider the level of basic control of the system as the 
level they are simulating and are not concerned with 
more particular heuristics. An instance of this class of 
parsers is Marcus's parser \[Marcus 1979\], based on the 
claim that,  basically, parsing is a deterministic process: 
only sentences that  we perceive as "surprising" (the so 
called garden paths) actual ly imply backt rack ing .  
234 
Connectionist parsers are also instances of this category. 
The second category  refers to genera l  l inguist ic  
performance notions such as the "Lexical Preference 
Principle" and the "Final Argument Principle" \[Fodor, 
13resnan and Kaplan 19821. It includes theories of 
processing like the one expressed by Wanner  and 
Maratsos for ATNs in the mid Sevent ies .  In th is  
category the arguments  are at  the level of general  
structural preference analysis. A third category tends 
to consider at every moment of the parsing process, the 
full complexity of the data and the hypothesized partial 
internal representation of the sentence, including, at  
least in principle, interaction with knowledge of the 
world, aspects of memory, and particular task-oriented 
behaviour. 
Worth mentioning here is Church and Pati l 's \[1982\] 
work which at tempts  to put order in the chaos of 
complexity and "computational load". 
Our parser lies between the second and the third of the 
above categor ies .  The parser  is seen  as a 
nondeterministic apparatus  that  d isambiguates and 
gives a "shallow" interpretation and an incremental 
functional representation f each processed fragment of 
the sentence. The state of the parser is supposed to be 
cognitively meaningful at every moment ofthe process. 
Furthermore, in part icular ,  we are concerned with 
aspects of flexible word ordering. This phenomenon is
specially relevant in Italian, where, for declarat ive 
sentences, Subject-Verb-Object is only the most likely 
order - the other five permutations of Subject Verb and 
Object may occur as well. We shall briefly describe the 
parser and its environment and, by way of example, 
i l lustrate its behaviour  in analyz ing "osci l lat ing" 
sentences, i.e. sentences in which one first perceives a 
fragment in one way, then changes one's mind and takes 
it in a different way, then, as further input comes in, 
going back to the previous pat tern  (and posssib ly 
continuing like this till the end of the sentence). 
3. The  parser  
WEDNESDAY 2 \[Stock 1986\] is a parser based on 
l inguist ic  knowledge d is t r ibuted  fundamenta l ly  
through the lexicon. A word reading includes: 
- a semantic representation f the word, in the form of a 
semantic net shred; 
- static syntactic information, including the category, 
features, indication of l inguist ic functions that  are 
bound to part icular nodes in the net. One particular 
specification is the Main node, head of the syntact ic 
constituent the word occurs in; 
- dynamic syntactic information, including impulses to 
connect pieces of semant ic  information, guided by 
syntactic onstraints. Impulses look for "f i l lers" on a 
given search space (usually a substr ing).  They have 
a l ternat ives,  (for instance the word TELL has an 
impulse to merge its object node with the "main"  of 
either an NP or a subordinate clause). An alternative 
includes: a contextual  condition of appl icabi l i ty ,  a 
category, features, marking, side effects (through which, 
for example ,  coreference between subject  of a 
subordinate clause and a function of the main clause can 
be indicated). Impulses may also be directed to a 
different search space than the normal one (see below); 
- measures of likelihood. These are measures that  are 
used for deriving an overall measure of likelihood of a 
par t ia l  ana lys i s .  Measures  are inc luded for the  
likelihood of that  particular eading of the word and for 
aspects attached to an impulse: a) for one part icu lar  
alternative b) for the relative position the filler c) for the 
overall necessity of finding a filler. 
- a characterization f idioms involving that  word. (For a 
description of the part of the parser that  deals with the 
interpretation f flexible idioms see \[Stock 1987\]). 
The only other data are in the form of s imple (non 
augmented)  t rans i t ion networks that  only provide 
restrictions on search spaces where impulses can look 
for fillers. In more traditional words it deals with the 
distribution of constituents. A dist inguishing symbol, 
$EXP, indicates that  only the occurrence of something 
expected by preceding words (i.e. for which an impulse 
was set up) will allow the transition. 
The parser is based on of the idea of chart  parsing \[Kay 
1980, Kaplan 1973\] \[see Stock 1986\]. What is relevant 
here is the fact that  "edges" correspond to search spaces. 
Edges are complex data structures provided with a rich 
amount  of in fo rmat ion  inc lud ing  a semant ic  
interpretation of the fragment, syntactic data, pending 
impulses, an overall measure of likelihood, etc. Data on 
an edge are  "unified"dynamieally as indicated below 
An agenda is provided which includes four kinds of 
tasks: lexical tasks, traoersal tasks, insertion tasks, 
virtual tasks. A lexieal task specifies a possible reading 
of a word to be inserted in the chart. A traversal  task 
specifies an active edge and an inactive edge that  can 
extend it. An insertion task specifies a nondeterministie 
unification act, and a virtual task involves extension of 
an edge to include an inactive edge far away in the 
str ing (used for long distance dependencies). 
235 
LA.  
4~,  
~ ~o 
t 2 vv ,~ 2 
YtN I t  g; z n, 
l ~L p,kp  , , ,  = 
I ~ ~tPaaR~ to: 
I d v im+ l~+ 4 
• .+t l l l \ [  x :  4 • 
I 
'~ ++ . . . . .  
l l ?  i$ , i . kK  tO 6 
l I v  PI ' (PI /~RK t ,~  
Yl fM leg :  & m~o 
i 
t 14 ~,bUH\[I~II i~  5 
v t~ l tX :  • u ,  
I I~  P~(P  vo ? 
\[ I b  P I (P I~R~ fG  7 
Vth l t  X: ; I ,+  i me 
I :4  +IlIF roo  
Y ( I I LK :  8 
$1,¢~ J ~E|47ve  I 
m~ I lL  
~ i . , .  ml t .  
- . . '=  
m.~'"  
m 
I I 
• + P-PU I  c , .  Pe, P -&| -T~ C'O;~ 
¶ 
I 
The parser works asymmetrically with respect to the 
"arrival*' of the Main node: before the Main node 
arrives, an extension of an edge has almost no effect. On  
the arrival of the Main, all the present impulses are 
"unleashed" and must find satisfaction. If all this does 
not happen then the new edge supposedly to be added to 
the chart is not added: the situation is recognized as a 
failure. After the arrival of the Main, each new head 
must find an impulse to merge with, and each incoming 
impulse must find satisfaction. Again, if all this does not 
happen, the new edge will not be added to the chart.. 
4. Overv iew of the env i ronment  
WEDNESDAY 2 and its env i ronment  are  
imp lemented  on a Xerox  L isp Mach ine .  The 
environment is composed of a series of specialized tools, 
each one based on one or more windows (fig 1). 
Using a mouse the user selects a desired behaviour from 
menus attached to the windows. We have the following 
windows: 
Fig. I 
- the main WEDNESDAY 2 window, in which the 
sentence is entered. Menus attached to this window 
specify different modalities (including "through" and 
"stepping", "all parsings" or "one parsing") and a 
number of facilities; 
- a window where one can view, enter and modify 
transition networks graphically (fig. 2). 
- a window where one can view, enter and modify the 
lexicon. As a word entry is a complex object for 
WEDNESDAY 2, entering a new word can be greatly 
facilitated by a set of subwindows, each specialized in 
one aspect of the word, "knowing" how it may be and 
facilitating editing. The lexicon is a lexicon of roots: a 
morphological analyzer and a lexicon manager  are 
integrated in the system. Let us briefly describe this 
point. A lexicalist theory such as ours requires that a 
large quantity of information be included in the lexicon. 
This information has different origins: some comes from 
the root and some from the affixes. All the information 
must be put into a coherent data structure, through a a 
particularly constrained unification based process. 
236 
, . . .  ~, II I II I 
\ '  x 
I m 
,Z,°,,T 
Fig. 2 
¢¢~1 ~ave 
VlE~3-PP-O i - -0~'  
YERI~-O! l~-{l~l 
/ / \ 
1-01 - IIIF-OI~I V1E\]~3- I IO -AOC 
~1 PJ~O~ZXS ~m 
iii!ii~i 
Ct  NIL NIL  
ll-OOd ,'(3 NIL 
\[31BJ X2 NIL 
Test ~llP Beferel lke/~o¢i lFe4t l lcel  M4rk  ~det fec t  
aN 
I~ER 
(A-ObJ) 
( (T  PP/mARK I ~JL = 
(oea)  
( (T  NP .1 NIL NIL N\[ 
(SUBJ) 
(NUST .8) 
( (T  NP .~ N|L NIL NI 
Furthermore we must emphasize the fact that, just as in 
LFG, phenomena such as passivization are treated in 
Fig.3 
the lexicon (the Subject and Object functions and the 
related impulses attached to the active form are 
237 
rearranged). This is something that the morphological 
analyzer must deal with. The internal behaviour of the 
morphological analyzer  is beyond the scope of the 
present paper. We shal l  instead briefly discuss the 
lexicon manager, the role of which will be emphasized 
here. 
The lexicon manager deals with the complex process of 
enter ing data,  mainta in ing,  and .preprocessing the 
lexicon. One notable aspect is that  we have arranged the 
lexicon on a hierachical baseis according to inheritance, 
so that  properties of a particular word can be inherited 
from a word class and a word class can inherit aspects 
from another class. One consequence of this is that we 
can introduce a graphic aspect (fig 3) and the user can 
browse through the lattice (the lexicon appears as a tree 
of classes where one has special ized editors at  each 
level). What is even more relevant is the fact that  one 
can factorize knowledge that  is in the lexicon, so that  ff 
one par t i cu la r  phenomenon needs to be t reated  
differently, the change of information is immediate for 
the words concerned. Of course this means also that  
there is a space gain: the same information eeds not to 
be duplicated: complete word data are reconstructed 
when required. 
There is also a modality by which one can enter the 
syntactic aspects of a word through examples, a la 
TEAM \[Grosz 19841. The results are less precise, but 
may be useful in a more application-oriented use of the 
environment. 
- a window showing the present configuration of the 
chart; 
- a window that  permits zooming into one edge, showing 
several aspects of the edge, including: its s t ructura l  
aspect, its l ikel ihood, the  funct iona l  aspect ,  the 
specification of unrealized impulses etc. 
- a window displaying in graphic form the semant ic  
interpretation of an edge as a semantic net, o r ,  if one 
prefers so (this is usually the case when the net is too 
complex) in logic format; 
- a window where one can manipulate the agenda (fig 4). 
Attached to this window we have a menu including a set 
of functionalities that  the tasks included in the agenda 
to be manipulated: MOVE BEFORE, MOVE AFTER, 
DELETE, SWITCH,UNDO etc. One just  points to the 
two particular tasks one wishes to operate on with the 
mouse and then to the menu entry. In this way the 
desired effect is obtained. The effect corresponds to 
applying a different scheduling function: the tasks will 
be picked up in the order here prescribed by hand. This 
tool, when the parser is in the "stepping" modality, 
LT vertex: 8 ¢~Lt: PREPMARK - . :  1 
LT veMex: 6 ~ PREP LH: 1 
I"T A :9  a:15 t~WL.N: .56 NEWTr, 
LT  vertex: 5 ,;al; N LIt: . 2 
LI" vertex: 6 ¢a~ A0 J  Lq: . 6 
LI" vertex: 5 cJut: V LH: . 6 
L I  vertex: 4 caC PREPART eel: 1 
Llr vertex: 2 ~:ax: PREP LM: 1 
G4\ ]~ 
mmK-4rl~ 
sk~ 
mm 
R 
Fig. 4 
provides a very easy way of a l ter ing the de fau l t  
behav iour  of the sys tem and of t ry ing  out  new 
strategies. This modality of schedul ing by hand is 
complemented by a series of counters that  provide 
control over the penetrance of these strategies. (The 
penetrance of a nondeterministic algorithm is the ratio 
between the steps that  lead to the solution and the steps 
that  are carried out as a whole in trying to obtain the 
solution. Of course this measure is included between 0
and 1.) 
Dynamically, one tries to find sensible strategies,  by 
in teract ing  w i th  the  agenda.  When,  a f te r  
experimenting formalizable heuristics have been tried 
out, they can be introduced permanently into the system 
through a given specialized function. This is the only 
place where some knowledge of LISP and of the internal 
structure ofWEDNESAY 2 is required. 
5.  An  example  o f  exp lo ra t ion :osc i l l a t ing  sentences  
We shall  now briefly discuss a processing example that  
we have been able to understand using the environment 
ment ioned above. The following example is a good 
instance of flexibility and parsing problems present in 
Italian: 
a Napoli preferisco Romaa Milano. 
The complete sentence reads "while in Naples I prefer 
Rome to Milan". The problem arises during the parsing 
process with the fact that  the "to" argument of "prefer " 
in Ital ian may occur before the verb, and the locative 
preposition "in" is a, the same word as the mark ing  
preposition corresponding to "to". 
238 
The reader/hearer fi st takes a Napoli as an adverbial 
location , then, as the verb preferisc9 is perceived, a
Napoli is clearly reinterpreted as an argument of the 
verb, {with a sense of surprise). As the sentence proceeds 
after the object Rorna, the new word a_ causes things to 
change again and we go back with a sense of surprise to 
the first hypothesis. 
The following things should be noted: - when this 
second reconsideration takes place, we feel the surprise, 
but this does not cause us to reconsider the sentence, we 
only go back adding more to an hypothesis that we were 
already working at; -the surprise seems to be caused not 
by a heavy computat ional  load, but by a sudden 
readjustment of the weights of the hypotheses. In a sense 
it is a matter of memory, rather than computation. 
We have been in a position to get WEDNESDAY 2 to 
perform natural ly in such situations, taking advantage 
of the environment. The following simple heurist ics 
were found: a) try solutions that  satisfy the impulses (if 
there are alternatives consider likelihoods); b) maintain 
viscosity (prefer the path you are already following); and 
c) follow the alternative that  yields the edge with the 
greatest likelihood, among edges of comparable l ngths. 
The likelihood of an edge depends on: 1) the likelihood of 
the "included" edges; 2) the level ofobligatoriness of the 
filled impulses; 3) the likelihood of a particular elative 
position of an argument in the string; 4) the likelihood of 
that  t rans i t ion in the network, given the previous 
transition. 
The critical points in the sentence are the following 
(note that  we distinguish between a PP and a "marked 
NP" possible argument of a verb, where the preposition 
has no semantics asociated: 
i) At the beginning: only the PP edge is expanded, (not 
the one including a ~marked NP ' ,  because of stat ic 
preference for the former expressed in the lexicon and in 
the transition etwork. 
ii) After the verb is detected: on the one hand there is an 
edge that, if extended, would not satisfy an obligatory 
impulse, on the other hand, one that  would possibly 
satisfy one . The ~marked NP" alternative is chosen 
because of a) of the above heuristics. 
iii) After the object Roma: when the preposition a_ comes 
in, the edge that  may extend the sentence with a PP on 
the one hand, and on the other hand a cycling active 
edge that is a promising satisfaction for an impulse are 
compared. Since this relative position of the argument is
so favourable for the particular verb preferisco (.9 to .1 
for this position compared to the antecedent one), the 
parser proceeds with the a l ternat ive view, tak ing a 
Nap.o!i. as a modh'\]er So it goes on, after reentering that  
working hypothesis.  The object is a l ready  there ,  
analyzed for the other reading and does not need to be 
reanalyzed. So a Milano is taken as the filler for the 
impulse and the analysis is concluded properly. 
It should be noted that the Final Argument Principle 
\[Fodor, Kaplan and Bresnan 1982\] does not work with 
the flexibility characteristic of Italian. (The principle 
would cause the reading "I prefer \[Rome \[ in Milan\]\] to 
Naples" to be chosen at point iii) above). 
Conc lus ions  
We have introduced an env i ronment  bu i l t  a round 
WEDNESDAY 2, a nondeterministic parser, or iented 
towards experimenting with dynamic strategies.  The 
combination of interest ing theories and such tools 
realizes both meanings of the word "experimental": 1)
something that  implements new ideas in a prototype; 2) 
something built for the sake of making experiments. We 
th ink  that  this approach, possibly in tegrated wi th  
experiments in psycholinguistics, can help increase our 
understanding of parsing. 
Acknowledgements  
Federico Cecconi's help in the graphic aspects and 
lexicon management has been precious. 
References 
Church, K. & Patil, R. Coping with syntactic ambiguity 
or how to put the block in the box on the table. American 
Journal of Computational Linguistics, 8; 139o149 (1982) 
Ferrari,G. & Stock,O. Strategy selection for an ATN 
syntactic parser. Proceedings of the 18th Meeting of the 
Association for Computational Linguistics, Philadelphia 
(1980) 
Ford, M., Bresnan, J.  & Kaplan, R. A competence based 
theory of syntact ic closure. In Bresnan, J . ,  Ed. The 
Mental Representation f Grammatical Relations. The 
MIT Press, Cambridge, (1982) 
Gazdar, G. Phrase structure grammar. In Jacobson and 
Pul lman (Eds.), The Nature of Syntactic Representation. 
Dordrecht: Reidel ( 1981 )
239 
Grosz, B. TEAM, a transportable natural anguage 
interface system. In Proceedings of the Conference on 
Applied Natural Language Processing, Santa Monica 
~1983~ 
Joshi, A., & Levy, L. Phrase structure trees bear more 
fruits then you would have thought. American Journal 
of Computational Linguistics,8; 1-ll (1982) 
Kaplan, R. A general syntactic processor. In Rustin, R. 
{Ed.), Natural Language Processing. Englewood Cliffs, 
N.J.: Prentice-Hall (1973) 
Kaplan,R. & Bresnan,J. Lexical-Functional Grammar: a 
formal system for grammatical representation. In 
Bresnan,J . ,  Ed. The Mental Representation of 
Grammatical Relations. The MIT Press, Cambridge, 
173-281 (1982) 
Kay, M. Algorithm Schemata nd Data Structures in 
Syntactic Processing. Xerox, Palo Alto Research Center 
(October 1980) 
Kay, M. Functional Grammar. In Proceedings ofthe 5th 
Meeting of the Berkeley Linguistic Society, Berkeley, 
142-158(1979} 
Marcus, M. An overview of a theory of syntactic 
recognition for natural anguage. (AI memo 531). 
Cambridge, Mass: Artificial Intelligence Laboratory, 
(1979) 
Pereira, F. & Warren, D., Definite Clause Grammars for 
language analysis. A survey of the formalism and a 
comparison with Augmented Transition Networks. 
Artificial Intelligence, 13; 231-278 (1980) 
Small, S. Word expert parsing: a theory of distributed 
word-based natural language understanding. (Technical 
Report TR-954 NSG-7253). Maryland: University of 
Maryland (1980) 
Stock, O. Dynamic Unification in Lexieally Based 
Parsing. In Proceedings of the Seuenth European 
Conference on Artificial Intelligence. Brighton, 212-221 
(1986) 
Stock, O. Putting Idioms into a Lexicon Based Parser's 
Head. To appear in Proceedings of the 25th Meeting of 
the Association for Computational Linguistics. Stanford, 
Ca. \[1987\] 
Thompson, H.S. Chart parsing and rule schemata in 
GPSG. In Proceedings ofthe 19th Annual Meeting of the 
Association for Computational Linguistics. Alexandria, 
Va. (1981) 
240 
