Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 467–476,
October 25-29, 2014, Doha, Qatar.
c
©2014 Association for Computational Linguistics
Sentiment Analysis on the People’s Daily
Jiwei Li
1
and Eduard Hovy
2
1
Computer Science Department, Stanford University, Stanford, CA 94305, USA
2
Language Technology Institute, Carnegie Mellon University, PA 15213, USA
jiweil@stanford.edu ehovy@andrew.cmu.edu
Abstract
We propose a semi-supervised bootstrap-
ping algorithm for analyzing China’s for-
eign relations from the People’s Daily.
Our approach addresses sentiment tar-
get clustering, subjective lexicons extrac-
tion and sentiment prediction in a unified
framework. Different from existing algo-
rithms in the literature, time information
is considered in our algorithm through a
hierarchical bayesian model to guide the
bootstrapping approach. We are hopeful
that our approach can facilitate quantita-
tive political analysis conducted by social
scientists and politicians.
1 Introduction
“We have no permanent allies, no permanent friends, but only
permanent interests.”
-Lord Palmerston
Newspapers, especially those owned by official
governments, e.g., Pravda from Soviet Union,
or People’s Daily from P.R. China, usually pro-
vide direct information about policies and view-
points of government. As national policies change
over time, the tone that newspapers adopt, es-
pecially sentiment, changes along with the poli-
cies. For example, there is a stark contrast be-
tween the American newspapers’ attitudes towards
Afghanistan before and after 911. Similarly, con-
sider the following examples extracted from the
People’s Daily
1
:
• People’ Daily, Aug 29th, 1963
All those who are being oppressed and exploited, Unite
!! Beat US Imperialism and its lackeys.
• People’s Daily, Oct, 20th, 2002
A healthy, steady and developmental relationship be-
tween China and US, conforms to the fundamental in-
terests of people in both countries, and the trend of his-
torical development.
1
Due to the space constraints, we only show the translated
version in most of this paper.
Automatic opinion extraction from newspapers
such as people’s daily can facilitate sociologists
’or political scientists’ research or help political
pundits in their decision making process. While
our approach applies to any newspaper in princi-
ple, we focus here on the People’s Daily
2
(Renmin
Ribao), a daily official newspaper in the People’s
Republic of China.
While massive number of works have been in-
troduced in sentiment analysis or opinion target
extraction literature (for details, see Section 2), a
few challenges limit previous efforts in this spe-
cific task: First, the heavy use of linguistic phe-
nomenon in the People’s Daily including rhetoric,
metaphor, proverb, or even nicknames, makes ex-
isting approaches less effective for sentiment in-
ference as identifying these expressions is a hard
NLP problem in nature.
Second, as we are more interested in the degree
of sentiment rather than binary classification (i.e.,
positive versus negative) towards an entity (e.g.
country or individual) in the news article, straight-
forward algorithms to apply would be document-
level sentiment analysis approaches such as vector
machine/regression (Pang et al., 2002) or super-
vised LDA (Blei and McAuliffe, 2010). A single
news article, usually contains different attitudes
towards multiple countries or individuals simul-
taneously (say praising “friends” and criticizing
“enemies”), as shown in the following example
from the People’s Daily of Mar. 17th, 1966:
US imperialism set up a puppet regime in Vietnam and
sent expeditionary force. . . People of Vietnam prevailed over
the modern-equipped US troops with a vengeance. . . The re-
sult of Johnson Government’s intensifying invasion is that. . . .
There will be the day, when people from all over the world ex-
ecute the heinous US imperialism by hanging on a gibbet. . . .
The heroic people of Vietnam, obtained great victory in the
struggle against the USA imperialism. . .
The switching of praising of Vietnam and
criticizing of the USA would make aforemen-
2
paper.people.com.cn/rmrb/
467
tioned document-level machine learning algo-
rithms based on bags of words significantly less
effective if not separating attitudes towards Viet-
nam from toward the USA in the first place. Mean-
while, the separating task is by no means trivial in
news articles. While US imperialism, US troops,
Johnson Government, invaders, Ngo Dinh Diem
3
all point to the USA or its allies, People of Viet-
nam, the Workers’ party
4
, Ho Chi Minh
5
, Viet-
nam People’s Army point to North Vietnam side.
Clustering entities according to sentiment, espe-
cially in Chinese, is fundamentally a difficult task.
And our goal, trying to identify entities towards
whom an article holds the same attitudes, is dif-
ferent from standard coreference resolution, since
for us the co-referent group may include several
distinct entities.
To address the aforementioned problems, in this
paper, we propose a sentiment analysis approach
based on the following assumptions:
1. In a single news article, sentiment towards an
entity is consistent.
2. Over a certain period of time, sentiments to-
wards an entity are inter-related.
The assumptions will facilitate opinion analy-
sis: (1) if we can identify the attitude towards an
entity (e.g., Vietnam) in a news article as posi-
tive, then negative attitudes expressed in the arti-
cle are about other entities. (2) The assumption
enables sentiment inference for unseen words in a
bootstrapping way without having to employ so-
phisticated NLP algorithms. For example, from
1950s to 1960s, USA is usually referred to as “a
tiger made of paper” in translated version. It is
a metaphor indicating things that appear powerful
(tiger) but weak in nature (made of paper). If it is
first identified that during the designated time pe-
riod, China held a pretty negative attitude towards
the USA based on clues such as common nega-
tive expressions (e.g., “evil” or “reactionary”), we
can easily induce that “a tiger made of paper”, is a
negative word.
Based on aforementioned two assumptions,
we formulate our approach as a semi-supervised
model, which simultaneously bootstrap sentiment
target lists, extracts subjective vocabularies and
3
Leader of South Vietnam
4
Ruling political party of Vietnam.
5
One of Founders of Democratic Republic of Vietnam
(North Vietnam) and Vietnam Workers’ party.
performs sentiment analysis. Time information is
considered through a hierarchical bayesian model
to guide time-, document-, sentence- and term-
level sentiment inference. A small seed set of sub-
jective words constitutes our only source of super-
vision.
The main contributions of this paper can be
summarized as follows:
1. We propose a semi-supervised bootstrapping algorithm
tailored for sentiment analysis in the People’s daily
where time information is incorporated. We are hope-
ful that sentiment cues can shed insights on other NLP
tasks such as coreference or metaphor recognition.
2. In Analytical Political Science, the quantitative evalu-
ation of diplomatic relations is usually a manual task
(Robinson and Shambaugh, 1995). We are hopeful that
our algorithm can enable automated political analysis
and facilitate political scientists’ and historians’ work.
2 Related Works
Significant research efforts have been invested into
sentiment analysis and opinion extraction. In one
direction, researchers look into predicting over-
all sentiment polarity at document-level (Pang and
Lee, 2008), aspect-level (Wang et al., 2010; Jo
and Oh, 2011), sentence-level (Yang and Cardie,
2014) or tweet-level (Agarwal et al., 2011; Go
et al., 2009), which can be treated as a clas-
sification/regression problem by employing stan-
dard machine-learning techniques, such as Naive
Bayesian, SVM (Pang et al., 2002) or supervised-
LDA (Blei and McAuliffe, 2010) with different
types of features (i.e., unigram, bigram, POS).
Other efforts are focused on targeted sentiment
extraction (Choi et al., 2006; Kim and Hovy, 2006;
Jin et al., 2009; Kim and Hovy, 2006). Usu-
ally, sequence labeling models such as CRF (Laf-
ferty et al., 2001) or HMM (LIU et al., 2004) are
employed for identifying opinion holders (Choi
et al., 2005), topics of opinions (Stoyanov and
Cardie, 2008) or opinion expressions (e.g. (Breck
et al., 2007; Johansson and Moschitti, 2010; Yang
and Cardie, 2012)). Kim and Hovy (2004; 2006)
identified opinion holders and targets by exploring
their semantics rules related to the opinion words.
Choi et al. (2006) jointly extracted opinion expres-
sions, holders and their is-from relations using an
ILP approach. Yang and Cardie (2013) introduced
a sequence tagging model based on CRF to jointly
identify opinion holders, opinion targets, and ex-
pressions.
Methods that relate to our approach include
semi-supervised approaches such as pipeline or
468
propagation algorithms (Qiu et al., 2011; Qiu et
al., 2009; Zhang et al., 2010; Duyu et al., 2013).
Concretely, Qiu et al. (2011) proposed a rule-
based semi-supervised framework called double
propagation for jointly extracting opinion words
and targets. Compared to existing bootstrapping
approaches, our framework is more general one
with less restrictions
6
. In addition, our approach
harness global information (e.g. document-level,
time-level) to guide the bootstrapping algorithm.
Another related work is the approach introduced
by O’Connor et al. (O’Connor et al., 2013) that
extracts international relations from political con-
texts.
3 the People’s Daily
The People’s Daily
7
(Renmin Ribao), established
on 15 June 1946, is a daily official newspaper in
the People’s Republic of China, with a approxi-
mate circulation of 2.5 million worldwide. It is
widely recognized as the mouthpiece of the Cen-
tral Committee of the Communist Party of China
(CPC) (Wu, 1994). Editorials and commentaries
are usually regarded both by foreign observers and
Chinese readers as authoritative statements of gov-
ernment policy
8
. According to incomplete statis-
tics, there have benn at least 13 major redesigns
(face-liftings) for the People’s Daily in history, the
most recent in 2013.
4 Model
In this section, we present our model in detail.
4.1 Target and Expression extraction
We first extract expressions (attitude or sentiment
related terms or phrases) and target (entities to-
ward whom the opinion holder (e.g., the People’s
Daily) holds an attitude). See the following exam-
ples:
1. [Albania Workers’ party][T] is the [glorious][E]
[party][T] of [Marxism and Leninism][E].
2. The [heroic][E] [people of Vietnam][T] obtained
[great][E] [victory][E] against [the U.S. imperial-
ism][T,E].
3. We strongly [warn][E] Soviet Revisionism][E,T].
6
Qiu et al.’s rule base approach makes strong assumptions
that consider opinion word to adjectives and targets to be
nouns/noun, thus only capable of capturing sentences with
simple patterns.
7
paper.people.com.cn/rmrb/
8
http://en.wikipedia.org/wiki/People’
s_Daily
While the majority of subjective sentences omit
the opinion holder, as in Examples 1 and 2, there
are still a few circumstances where opinion hold-
ers (e.g., “we”, “Chinese people”, “Chinese gov-
ernment”) are retained (Example 3). Some words
(i.e. U.S. imperialism) can be both target and ex-
pression, and there can be multiple targets (Exam-
ple 2) within one sentence.
We use a semi-Markov Conditional Random
Fields (semi-CRFs) (Sarawagi and Cohen, 2004;
Okanohara et al., 2006) algorithm for target and
expression extraction. Semi-CRF are CRFs that
relax the Markovian assumptions and allow for se-
quence labeling at the segment level. It has been
demonstrated more powerful that CRFs in multi-
ple sequence labeling applications including NER
(Okanohara et al., 2006), Chinese word segmenta-
tion (Andrew, 2006) and opinion expression iden-
tification (Yang and Cardie, 2012). Our approach
is an extension of Yang and Cardie (2012)’s sys-
tem
9
. Features we adopted included:
• word, part of speech tag, word length.
• left and right context words within a window
of 2 and the correspondent POS tags.
• NER feature.
• subjectivity lexicon features from dictio-
nary
10
. The lexicon consists of a set of Chi-
nese words that can act as strong or weak
cues to subjectivity.
• segment-level syntactic features defined in
(Yang and Cardie, 2012).
Most existing NER systems can barely recog-
nize entities such as [ Vietnamese People’s Army ]
as a unified name entity in that Chinese parser usu-
ally divides them into a series of separate words,
namely [ Vietnamese/People’s Army ]. To han-
dle this problem, we first employ the Stanford
NER engine
11
and then iteratively ‘chunk’ con-
secutive words, at least one of which is labeled as
a name entity by the NER engine, before check-
ing whether the chunked entity matches a bag of
words contained in Chinese encyclopedia, e.g.,
Baidu Encyclopedia
12
and Chinese Wikipedia
13
.
9
Yang and Cardie’s system focuses on expression extrac-
tion (not target) and identifies direct subjective expression
(DSE) and expressive subjective expression (ESE).
10
http://ir.dlut.edu.cn/NewsShow.aspx?
ID=215
11
http://nlp.stanford.edu/downloads/
CRF-NER.shtml
12
http://baike.baidu.com/
13
http://zh.wikipedia.org/wiki/
Wikipedia
469
4.2 Notation
Here we describe the key variables in our model.
Let C
i
denote the name entity of country i, G
i
denote its corresponding collection of news ar-
ticles. G
i
is divided into 60*4=240 time spans
(one for each quarter of the year, 60 years in to-
tal), G
i
= {G
i,t
}. G
i,t
is composed of a series
of documents {d}, and d is composed of a series
of sentences {S}, which is represented as a tuple
S = {E
S
, T
S
}, where E
S
is the expression and
T
S
is the target of current sentence.
Sentiment Score m: As we are interested in the
degree of positiveness or negativeness, we divided
international relations into 7 categories: Antag-
onism (score 1), Tension (score 2), Disharmony
(score 3), Neutrality (score 4), Goodness (score
5), Friendliness (score 6), Brotherhood (Comrade-
ship) (score 7) based on researches in political sci-
ence literature
14
. Each of G
i,t
, document d, sen-
tence S and expression term w is associated with
a sentiment score m
i,t
, m
d
, m
S
and m
w
, respec-
tively. M denotes the list of subjective terms,
M = {w,m
w
}
Document Target List T
d
i
: We use T
d
i
to denote
the collection of entity targets in document d ? G
i
which the People’s daily holds similar attribute to-
wards. For example, suppose document d belongs
to Vietnam article collection (C
i
= V ietnam), T
d
i
can be {Vietnam, Workers’ party, People’s Army,
Ho Chi Minh}. While U.S., U.S. troops and Lyn-
don Johnson are also entity targets found in d, they
are not supposed to be included in T
d
i
since the au-
thor holds opposite attributes.
Sentence List d
i
: We further use d
i
denotes the
subset of sentences in d talking about entities from
target list T
d
i
. Similarly, in a Vietnam related arti-
cle, sentences talking about the U.S. are not sup-
posed to be included in d
i
.
4.3 Hierarchical Bayesian Markov Model
In our approach, time information is incorporated
through a hierarchical Bayesian Markov frame-
work where m
i,t
is modeled as a first-order Pois-
son Process given the coherence assumption in
time-dependent political news streams.
m
i,t
? Poisson(m
i,t
,m
i,t?1
) (1)
14
http://www.imir.tsinghua.edu.cn/
publish/iis/7522/20120522140122561915769
Figure 1: Hierarchical Bayesian Model for Infer-
ence
For each document d ? G
i,t
, m
d
is sampled from
a Poisson distribution with mean value of m
i,t
.
m
d
? Poisson(m
d
,m
i,t
) (2)
For sentence S ? d
i
,m
S
is sampled fromm
d
from
a Poisson distribution based on m
d
.
m
S
? Poisson(m
S
,m
d
) (3)
4.4 Intialization
Given a labeled subjective list M , for article d ?
G
i
, we initialize T
d
i
with the name of entity C
i
, d
i
with sentences satisfying T
S
= C
i
and E
S
? M .
m
S
for S ? d
i
, is initialized as the average score
of its containing expression E
s
based on M . Then
the MCMC algorithm is applied by iteratively up-
dating m
d
and m
i,t
according to the posterior dis-
tribution. Let P (m|·) denotes the probability of
parameter m given all other parameters and the
posterior distributions are given by:
P (m
d
= ?|·) ? Poisson(?,m
i,t
)
?
S?d
i
Poisson(?,m
S
)
P (m
i,t
= ?|·) ? Poisson(?,m
i,t?1
)
× Poisson(m
i,t+1
, ?) · ×
?
d?G
i,t
Poisson(m
d
, ?)
(4)
4.5 Semi-supervised Bootstrapping
Our semi-supervised learning algorithm updates
M , T
d
i
, d
i
, S
d
and S
d
i
iteratively. A brief inter-
pretation is shown in Figure 2 and the details are
shown in Figure 4. Concretely, for each sentence
S ? d ? d
i
, step 1 means, if its expression E
S
exists in subjective list M , we added its target T
S
to T
d
i
and S to d
i
. step 2 means if the target T
S
ex-
ists in T
d
i
, its expression,E
s
, is added to subjective
list M with score m
d
. As M and T
d
i
change in the
iteration, in step 3, we again go over all unconsid-
ered sentences with new M and T
d
i
. m
d
and m
i,t
are then updated based on new m
S
using MCMC
in Equ. 4. Note that sentences with pronoun target
are not involved in the bootstrapping procedure.
470
Figure 2: A brief demonstration of the adopted semi-supervised algorithm. (a)?(b): Sentence (2) is
added to d
i
due to the presence of already known subjective term “great” . Target B is added to target list
T
d
i
. (b)?(c): term “heroic” is added to subjective word list M with score 7 since it modifies target B.
Input: Entity C
i
, G
i
, subjective term list M
• for each entity i, each document d
T
d
i
= {C
i
}, d
i
= {S|S ? d,C
i
= T
S
, E
s
?M}
for each sentence S ? d
i
:
. m
s
=
1
|E
S
?M|
?
m
E
s
• Iteratively update m
i,t
, m
d
using MCMC based on
posterior probability shown in Equ.4.
Output: {d
i
}, {T
d
i
}, {m
i,t
} and {m
d
}
Figure 3: Initialization Algorithm.
4.6 Error Prevention in Bootstrapping
Error propagation is highly influential and damag-
ing in bootstrapping algorithms, especially when
extending very limited data to huge corpora. To
avoid the collapse of the algorithm, we select can-
didates for opinion analysis in a extremely strict
manner, at the sacrifice of many subjective sen-
tences
15
. Concretely, we only consider sentences
with exactly one target and at least one expression.
Sentences with multiple targets (e.g., Example 2
in Section 4.1) or no expressions, or no targets are
discarded.
In addition to the strict sentence selection ap-
proach, we adopt the following methods for self-
correction in the boot-strapping procedure:
1. For T
1
, T
2
? T
d
i
, (E
1
, T
1
) ? S
1
, (E
2
, T
2
) ?
S
2
, E
1
, E
2
?M , if |m
E
1
?m
E
2
| > 1: Expel
E
1
andE
2
fromM , expel T
1
and T
2
from T
d
i
,
with the exception of original labeled data.
Explanation: If sentiment scores for two ex-
pressions, whose correspondent targets both
15
Negative effect of strict sentence selection can be partly
compensated by the consideration of time-level information
Input: Entity {C
i
}, Articles Collections {G
i
}, subjective
term list M, sentiment score {m
d
}, {m
i,t
}, target list for
each document {T
d
i
}
Algorithm:
while not convergence:
• for each entity C
i
, document d:
for each sentence S ? d? d
i
1. if E
S
?M , T
s
6? T
d
i
T
d
i
= T
d
i
?
T
s
, d
i
= d
i
?
S, m
S
= m
d
2. if T
s
? T
t
i
, E
s
6?M
M = M
?
(E
s
, S
d
), d
i
= d
i
?
S, m
s
= m
d
3. if E
S
?M,T
S
? T
d
i
d
i
= d
i
?
S, m
S
= m
E
s
•Iteratively update m
i,t
, m
d
using MCMC based on
posterior probability shown in Equ.4 .
end while:
Output: subjective term list M, score {m
i,t
}
Figure 4: Semi-supervised learning algorithm.
belong to the target list T
d
i
, diverge enough,
we discard both expressions and targets based
according to Assumption 1: sentiments to-
wards one entity (or its allies) in an article
should be consistent.
2. ?S ? d, T
S
? T
d
i
, |m
E
S
? m
d
| > 1, T
S
is
expelled from T
d
i
.
Explanation: If target T
S
for sentence S be-
longs to T
d
i
, but its corresponding expression
E
s
is not consistent with article-level senti-
ment m
d
, T
S
is expelled from T
d
i
.
5 Experiment
5.1 Data and Preprocessing
Our data set is composed of the People’s daily
from 1950 to 2010, across a 60-year time span.
471
antagonism (m=1) ??(extremely cruel),??(enemy)
tension (m=2) ??(indignation),??(offend)
disharmony (m=3) ??(disappointed),??(regret)
neutrality (m=4) ??,??(concern)
goodness (m=5) ???(developmental),??(respect)
friendship (m=6) ??(friendship),??(friend)
brotherhood (m=7) ??(firmly),??(brother)
Table 1: Illustration of subjective list M
News articles are first segmented using ICTCLAS
Chinese segmentation word system
16
(Zhang et
al., 2003). Articles with fewer than 200 Chi-
nese words are discarded. News articles are clus-
tered by the presence of a country’s name more
than 2 times based on a country name list from
Wikipedia
17
. Articles mentioning more than 5 dif-
ferent countries are discarded since they usually
talk about international conferences. Note that one
article can appear in different collections (example
in Section 1 will appear in both Vietnam and the
U.S. collection).
Compound sentences are segmented into
clauses based on dependency parse tree. Then
those containing more than 50 characters or
less than 4 characters are discarded. To avoid
complicated inference, sentences with negation
indicators are discarded.
5.2 Obtaining Subjectivity Word List
Since there are few Chinese subjectivity lexicons
(with degrees) available and those exist may not
serve our specific purpose, we manually label a
small number of Chinese subjective terms as seed
corpus. We divided the labeling process into 2
steps rather than directly labeling vocabularies
18
.
We first selected 100 news articles and assigned
each of them (as well as the appropriate coun-
try entity C
i
) to 2 students majoring in Interna-
tional Studies, asking them to give a label sen-
timent score (1 to 7) according to the rules de-
scribed in Section 4.2. 20 students participated
in the procedure. Since annotators have plenty of
background knowledge, they agreed on 98 out of
100. Second, we selected out subjectivity lexicons
by matching to a comprehensive subjectivity lex-
icons list
19
. and ask 2 students select the candi-
dates that signal the document-level label from the
16
http://ictclas.org/
17
http://zh.wikipedia.org/wiki/????-(????)
18
We tried direct vocabulary labeling in the first place, but
got low score for inter agreement, where value of Cohen
?
s ?
is only 0.43.
19
http://ir.dlut.edu.cn/NewsShow.aspx?
ID=215
P R F
Total
semi-CRF 0.74 0.78 0.76
CRF 0.73 0.66 0.68
Single
semi-CRF 0.87 0.92 0.90
CRF 0.80 0.87 0.83
Table 2: Results for Expressions/Targets extrac-
tion.
first step. According to whether a word a selected
or not, the value of Cohen
?
s ? is 0.78, showing
substantial agreement. For the small amount of la-
bels on which the judges disagree, we recruited an
extra judge and to serve as a tie breaker. Table 1
shows some labeled examples.
5.3 Targets and Expressions Extraction
As the good performance of semi-CRF in opinion
extraction has been demonstrated in previous work
(Yang and Cardie, 2012), we briefly go over model
evaluation in this subsection for brevity. We man-
ually labeled 600 sentences and performed 5-fold
cross validation for evaluation. We compare semi-
CRF to Standard CRF. We report performances on
two settings in Table 2. The first setting, Total,
corresponds to performance on the whole dataset,
while second one Single, denotes the performance
on the set of sentences with only one target, which
we are more interested in because multiple-target
sentences are discarded in our algorithm. It turned
out that semi-CRF significantly outputs standard
CRF, approaching 0.90 F-1 score on Single setting.
5.4 Foreign Relation Evaluation
Gold-standard foreign relations are taken from Po-
litical Science research at the Institute of Modern
International Relations, Tsinghua University, ex-
tracted from monthly quantitative China foreign
relations reports with 7 countries (U.S., Japan,
Russia/Soviet, England, France, India, and Ger-
many) from 1950 to 2012
20
.
We consider several baselines. For fair compar-
ison, we use identical processing techniques for
each approach. Some baselines make article-level
predictions, for which we obtain time-period level
relation prediction by averaging the documents.
Coreference+Bootstrap (CB): We first imple-
mented Ngai and Wang’s Chinese coreference sys-
20
Details found here http://www.imir.tsinghua.
edu.cn/publish/iisen/7523/index.html.
472
Model Ours CB No-time
Pearson 0.895 0.753 0.808
Model SVR-d SLDA SVR-S
Pearson 0.482 0.427 0.688
Table 3: Pearson Correlation with Gold Standard.
tem (2007). We then bootstrap sentiment terms
and score based on entity coreference.
No-time: A simplified version of our approach
where each article is considered as an independent
unit and no time-level information is considered.
m
d
is obtained by averaging its containing sen-
tences and used for later bootstrapping.
SVR-d: Uses SVM
light
(Joachims, 1999) to
train a linear SVR (Pang and Lee, 2008) for
document-level sentiment prediction using the un-
igram feature. The 100 labeled documents are
used as training data.
SLDA: supervised-LDA (Blei and McAuliffe,
2010) for document-level label prediction. Topic
number is set to 10, 20, 50, 100 respectively and
we report the best result.
SVR-S: Sentence-level SVR to sentences with
presence of entityC
i
21
. We obtain document-level
prediction by averaging its containing sentences
and then time-period level prediction by averaging
its containing documents.
We report the Pearson Correlation with gold
standards in table 3. As we can observe, simple
document-level regression models, i.e., SVR and
SLDA do not fit this task. The reason is sim-
ple: one article d can appear in different collec-
tions. Recall the Vietnam example in Section 1,
it appears in both G
V ietnam
and G
the U.S.
. Sen-
timent prediction for d should be totally opposite
in the two document collections: very positive in
G
V ietnam
and very negative in G
USA
. But doc-
ument level prediction would treat them equally.
Our approach outperforms No-Time, illustrating
the meaningfulness of exploiting time-level infor-
mation in our task. Our system approaches around
0.9 correlation with the gold standards. The reason
why No-Time is better than CB is also simple: CB
includes only coreferent entities in the target list
(e.g., America for the USA article collection), and
therefore overlooks rich information provided by
non-coreferent entities (e.g., President Nixon or
21
Features we explore include word entities in current sen-
tence, POS, a window of k ? {1, 2} words from the target
and the expression and corresponding POS, and the depen-
dency path between target and expression.
Nixon Government). No-Time instead groups en-
tities according to attitude, thereby enabling more
information to be harnessed. For SVR-S, as the
regression model trained from limited labeled data
can hardly cover unseen terms during testing, the
performance is just OK. SVR-S also suffers from
overlooking rich sources of information since it
only considers sentences with exact mention of the
name entity of the corresponding country.
Figure 5: Examples of China’s Foreign Relations.
6 Diplomatic Relations
“The enemy of my enemy is my friend”
—Arabic proverb
A central characteristic of post-World War Second
international system with which China had to deal
would be overwhelming preeminence of the USA
and USSR as each of the superpowers stood at
the center of a broad alliance system who was en-
gaged in an intense and protracted global conflict
with the other. We choose 6 countries and report
results in Figure 5. One of interesting things we
can observe from Figure 5 is that foreign attitudes
are usually divergent towards two opposing forces:
Sino-American relation (see Figure 5(a)) began to
improve when the Sino-Soviet relation (see Figure
5(b)) reached its bottom at the beginning of 1970s.
Similar patterns appear for Sino-Pakistan (see Fig-
ure 5(c)), Sino-India relations (see Figure 5(d))
473
Figure 6: Top coreference terms Towards USA and Soviet Union/Russia versus time. Blue denotes words
that are both Target and positive words in M . Red denotes words that are both Target and negative words
in M
in early 1960s
22
, and Sino-Vietnam 5(f)), Sino-
American relations in late 1970s. On the con-
trast, attitudes are usually consistent toward allied
forces: Sino-Japan relations with Sino-USA re-
lations before 1990s, and Sino-Vietnam relations
with Sino-Soviet relations in late 1970s and 1980s.
Figure 6 presents top clustering target (T
d
i
) in
the USA and Soviet Union/Russia article collec-
tion. As some of vocabulary terms can be both
target and expression, we use blue to label terms
with positive sentiment, red to label negative ones.
As we can see from Figure 6, targets(T ) extracted
by our model show a very clear pattern where al-
lies and co-referent entities are grouped. Another
interesting thing is, the subjectivity of target words
from different times is generally in accord with the
relation curves shown in Figure 5.
7 Conclusion and Discussion
In this paper, we propose a sentiment analy-
sis algorithm to track China’s foreign relations
from the People’s Daily. Our semi-supervised al-
gorithm harnesses higher level information (i.e.,
document-level, time-level) by incorporating a hi-
erarchical Bayesian approach into the framework,
to resolve sentiment target clustering, create sub-
jective lexicons, and perform sentiment prediction
simultaneously. While we focus here on the Peo-
ple’s Daily for diplomatic relation extraction, the
idea of our approach is general and can be ex-
tended broadly. Another contribution of this work
is the creation a comprehensive Chinese subjec-
22
A fan of history can trace the crucial influence of the
USSR in Sino-India relation in 1960s
tive lexicon list. We are hopeful that our approach
can not only facilitate quantitative research by po-
litical scientists, but also shed light on NLP appli-
cations such as coreference and metaphor, where
sentiment clues can be helpful.
It is worth noting that, while harnessing time-
level information can indeed facilitate opinion
analysis, especially when labeled data is limited in
our specific task, it is not a permanent-perfect as-
sumption, especially considering the diversity and
treacherous currents at the international political
stage.
At algorithm-level, to avoid error propagation
due to limitations of current sentiment analysis
tools (even though semi-CRF produces state-of-art
performance in target and expression extraction
task, a performance of 0.8 F-value, when applied
to the whole corpus, can by no means satisfy
our requirements), we discard a great number of
sentences, among which is contained much useful
information. How to resolve these problems
and improve opinion extraction performance is
our long-term goal in sentiment analysis/opinion
extraction literature.
Acknowledgements
The authors want to thank Bishan Yang and Claire
Cardie for useful comments and discussions. The
authors are thankful for suggestions offered by
EMNLP reviewers.
References
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-
bow, and Rebecca Passonneau. 2011. Sentiment
474
analysis of twitter data. In Proceedings of the Work-
shop on Languages in Social Media.
Galen Andrew. 2006. A hybrid markov/semi-markov
conditional random field for sequence segmentation.
In EMNLP.
David M Blei and Jon D McAuliffe. 2010. Supervised
topic models. arXiv preprint arXiv:1003.0783.
Eric Breck, Yejin Choi, and Claire Cardie. 2007. Iden-
tifying expressions of opinion in context. In IJCAI.
Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth
Patwardhan. 2005. Identifying sources of opinions
with conditional random fields and extraction pat-
terns. In EMNLP.
Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint
extraction of entities and relations for opinion recog-
nition. In EMNLP.
Tang Duyu, Qin Bing, Zhou LanJun, Wong KamFai,
Zhao Yanyan, and Liu Ting. 2013. Domain-specific
sentiment word extraction by seed expansion and
pattern generation. arXiv preprint arXiv:1309.6722.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
CS224N Project Report, Stanford.
Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009.
A novel lexicalized hmm-based learning framework
for web opinion mining. In ICML.
Yohan Jo and Alice H Oh. 2011. Aspect and senti-
ment unification model for online review analysis.
In ICWSM.
Thorsten Joachims. 1999. Making large scale svm
learning practical.
Richard Johansson and Alessandro Moschitti. 2010.
Syntactic and semantic structure for opinion ex-
pression detection. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning.
Soo-Min Kim and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the 20th international conference on Computational
Linguistics, page 1367. Association for Computa-
tional Linguistics.
Soo-Min Kim and Eduard Hovy. 2006. Extracting
opinions, opinion holders, and topics expressed in
online news media text. In Proceedings of the Work-
shop on Sentiment and Subjectivity in Text.
John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data.
Yun-zhong LIU, Ya-ping LIN, and Zhi-ping CHEN.
2004. Text information extraction based on hid-
den markov model [j]. Acta Simulata Systematica
Sinica.
Tie-Yan Liu. 2009. Learning to rank for information
retrieval. Foundations and Trends in Information
Retrieval.
Grace Ngai and Chi-Shing Wang. 2007. A knowledge-
based approach for unsupervised chinese corefer-
ence resolution. Computational Linguistics and
Chinese Language Processing, 12(4):459–484.
Daisuke Okanohara, Yusuke Miyao, Yoshimasa Tsu-
ruoka, and Jun’ichi Tsujii. 2006. Improving
the scalability of semi-markov conditional random
fields for named entity recognition. In ACL.
Brendan O’Connor, Brandon M Stewart, and Noah A
Smith. 2013. Learning to extract international rela-
tions from political context. In ACL.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In EMNLP.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding domain sentiment lexicon through
double propagation. In IJCAI.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extrac-
tion through double propagation. Computational
linguistics.
Thomas W Robinson and David L Shambaugh. 1995.
Chinese foreign policy: theory and practice. Oxford
University Press.
Sunita Sarawagi and William W Cohen. 2004. Semi-
markov conditional random fields for information
extraction. In NIPS.
Veselin Stoyanov and Claire Cardie. 2008. Topic iden-
tification for fine-grained opinion analysis. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics.
Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010.
Latent aspect rating analysis on review text data: a
rating regression approach. In SIGKDD.
Guoguang Wu. 1994. Command communication: The
politics of editorial formulation in the people’s daily.
China Quarterly, 137:194–211.
Bishan Yang and Claire Cardie. 2012. Extracting opin-
ion expressions with semi-markov conditional ran-
dom fields. In EMNLP.
Bishan Yang and Claire Cardie. 2014. Context-aware
learning for sentence-level sentiment analysis with
posterior regularization. ACL.
Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun
Liu. 2003. Hhmm-based chinese lexical analyzer
ictclas. In Proceedings of the second SIGHAN work-
shop on Chinese language processing-Volume 17.
475
Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn
O’Brien-Strain. 2010. Extracting and ranking prod-
uct features in opinion documents. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics: Posters.
476
