Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 90–94,
Gothenburg, Sweden, April 26-30 2014.
c
©2014 Association for Computational Linguistics
Inference of Phrase-Based Translation Models
via Minimum Description Length
Jes´us Gonz
´
alez-Rubio and Francisco Casacuberta
Departamento de Sistemas Inform´aticos y Computaci´on
Universitat Polit`ecnica de Val`encia, Camino de Vera s/n, 46021 Valencia (Spain)
{jegonzalez, fcn}@dsic.upv.es
Abstract
We present an unsupervised inference pro-
cedure for phrase-based translation mod-
els based on the minimum description
length principle. In comparison to cur-
rent inference techniques that rely on
long pipelines of training heuristics, this
procedure represents a theoretically well-
founded approach to directly infer phrase
lexicons. Empirical results show that the
proposed inference procedure has the po-
tential to overcome many of the prob-
lems inherent to the current inference ap-
proaches for phrase-based models.
1 Introduction
Since their introduction at the beginning of the
twenty-first century, phrase-based (PB) transla-
tion models (Koehn et al., 2003) have become the
state-of-the-art for statistical machine translation
(SMT). PB model provide a big leap in translation
quality with respect to the previous word-based
translation models (Brown et al., 1990; Vogel et
al., 1996). However, despite their empirical suc-
cess, inference procedures for PB models rely on
a long pipeline of heuristics (Och and Ney, 2003)
and mismatched learning models, such as the long
outperformed word-based models. Latter stages
of the pipeline cannot recover mistakes or omis-
sions made in earlier stages which forces the indi-
vidual stages to massively overgenerate hypothe-
ses. This manifests as a huge redundancy in the
inferred phrase lexicons, which in turn largely pe-
nalizes the efficiency of PB systems at run-time.
The fact that PB models usually cannot generate
the sentence pairs in which they have been trained
in, or that it is even possible to improve the perfor-
mance of a PB system by discarding most of the
learned phrases are clear indicators of these defi-
ciencies (Sanchis-Trilles et al., 2011).
We introduce an unsupervised procedure to in-
fer PB models based on the minimum descrip-
tion length (MDL) principle (Solomonoff, 1964;
Rissanen, 1978). MDL, formally described in
Section 2, is a general inference procedure that
“learns” by “finding data regularities”. MDL takes
its name from the fact that regularities allow to
compress the data, i.e. to describe it using fewer
symbols than those required to describe the data
literally. As such, MDL embodies a form of Oc-
cam’s Razor in which the best model for a given
data is the one that provides a better trade-off be-
tween goodness-of-fit on the data and “complex-
ity” or “richness” of the model.
MDL has been previously used to infer mono-
lingual grammars (Gr¨unwald, 1996) and inversion
transduction grammars (Saers et al., 2013). Here,
we adapt the basic principles described in the lat-
ter article to the inference of PB models. The
MDL inference procedure, described in Section 3,
learns PB models by iteratively generalizing an
initial model that perfectly overfits training data.
An MDL objective is used to guide this process.
MDL inference has the following desirable prop-
erties:
• Training and testing are optimized upon the
same model; a basic principle of machine learn-
ing largely ignored in PB models.
• It provides a joint estimation of the structure
(set of bilingual phrases) and the parameters
(phrase probabilities) of PB models.
• It automatically protects against overfitting by
implementing a trade-off between the expres-
siveness of the model and training data fitting.
The empirical evaluation described in Section 4
focuses on understanding the behavior of MDL-
based PB models and their specific traits. That
is, in contrast to a typical PB system building pa-
per, we are not exclusively focused on a short
term boost in translation quality. Instead, we aim
at studying the adequacy and future potential of
MDL as inference procedure for PB models.
90
2 The MDL Principle
Given a set of data D, the MDL principle aims at
obtaining the simplest possible model ? that de-
scribes D as well as possible (Solomonoff, 1964;
Rissanen, 1978). Central to MDL is the one-
to-one correspondence between description length
functions and probability distributions that follows
from the Kraft-McMillan inequality (McMillan,
1956). For any probability distribution Pr(·), it
is possible to construct a coding scheme such that
the length (in bits) of the encoded data is mini-
mum and equal to? log
2
(Pr(D)). In other words,
searching for a minimum description length re-
duces to searching for a good probability distribu-
tion, and vice versa. Taking these considerations
into account, MDL inference is formalized as:
?
? = argmin
?
DL(?,D) (1)
= argmin
?
DL(?) + DL(D | ?) (2)
where DL(?) denotes the description length of
the model, and DL(D | ?) denotes the descrip-
tion length of the data given the model. A com-
plete introductory tutorial of the MDL principle
and methods can be found in (Gr¨unwald, 2004).
3 MDL Phrase-Based Models
3.1 Description Length Functions
We start by defining how to compute DL(?) and
DL(D | ?) for any PB model and data set.
Let Pr
?
(D) be the probability of data set
D according to PB model ?. We follow the
Kraft-McMillan inequality and define the de-
scription length of the data given the model as
DL(D | ?) = ? log
2
(Pr
?
(D)), which it is the
lower bound for the description length of the data.
Regarding the description length of the PB
model, DL(?), we compute it by serializing ?
into a sequence of symbols and then computing
the length of the optimal encoding of such se-
quence. To do that, we need one symbol for each
word in the source and target languages, another
symbol to separate the source and target sides in
a phrase pair, and one additional symbol to dis-
tinguish between the different pairs in the phrase
lexicon. For example, the following toy PB model
La|||The casa|||house azul|||blue
is serialized as La|The•casa|house•azul|blue,
where symbol • separates the phrase pairs, and |
separates the two sides of each pair. Assuming a
uniform distribution over the K different symbols,
each symbol would require ? log
2
(
1
K
) bits to en-
code. We will thus require 3 bits to encode each
of the 8 symbols in the example, and 33 bits to en-
code the whole serialized PB model (11 symbols).
3.2 Inference Procedure
We now describe how to perform the maximiza-
tion in Equation (2). In the case of PB models,
this reduces to a search for the optimal phrase lex-
icon. Obviously, an exhaustive search over all pos-
sible sets of phrase pairs in the data is unfeasible
in practice. Following the ideas in (Vilar and Vi-
dal, 2005), we implement a search procedure that
iteratively generalizes an initial PB model that per-
fectly fits the data. Let D = {f
n
, e
n
}
N
n=1
be a
data set with N sentence pairs, where f
n
are sen-
tences in the source language and e
n
are their cor-
responding translation in the target language. Our
initial PB model will be as follows:
f
1
||| e
1
· · · f
n
||| e
n
· · · f
N
||| e
N
where the probability of each pair is given by the
number of occurrences of the pair in the data di-
vided by the number of occurrences of the source
(or target) language sentence.
To generalize this initial PB model, we need
to identify parts of the existing phrase pairs that
could be validly used in isolation. As a result, the
PB model will be able to generate new transla-
tions different from the ones in the training data.
From a probabilistic point of view, this process
moves some of the probability mass which is con-
centrated in the training data out to other data still
unseen; the very definition of generalization. Con-
sider a PB model such as:
La casa azul|||The blue house
Esta casa azul|||This blue house
Esta casa verde|||This green house
It can be segmented to obtain a new PB model:
La|||The casa azul|||blue house
Esta|||This casa verde|||green house
which is able to generate one new sentence pair
(La casa verde?The green house) and has a
shorter description length (19 symbols) in compar-
ison to the original model (23 symbols). We only
consider segmentations that bisect the source and
target phrases. More sophisticated segmentation
approaches are beyond the scope of this article.
Algorithm 1 describes the proposed PB infer-
ence by iterative generalization. First, we col-
lect the potential segmentations of the current PB
91
Algorithm 1: Iterative inference procedure.
input : ? (initial PB model)
output : ?? (generalized PB model)
auxiliary : collect(?) (Returns the set of possible
segmentations of model ?)
?DL(s,?) (Returns variation in DL when
segmenting ? according to s)
sort(S) (Sorts segmentation set S by
variation in DL)
commit(S,?) (Apply segmentations in S
to ?, returns variation in DL)
begin1
repeat2
S ? collect(?);3
candidates? [];4
for s ? S do5
?
?
? ?DL(s,?);6
if ?
?
? 0 then7
candidates .append({?
?
, s});8
sort(candidates);9
?? commit(candidates,?);10
until ? > 0 ;11
return?;12
end13
model (line 3). Then, we estimate the variation in
description length due to the application of each
segmentation (lines 4 to 8). Finally, we sort the
segmentations by variation in description length
(line 9) and commit to the best of them (line 10).
Specifically, given that different segmentations
may modify the same phrase pair, we apply each
segmentation only if it only affect phrase pairs
unaffected by previous segmentations in S . The
algorithm stops when none of the segmentations
lead to a reduction in description length. Saers
et al., (2013) follow a similar greedy algorithm to
generalize inversion transduction grammars.
The key component of Algorithm 1 is function
?DL(s,?) that evaluates the impact of a candi-
date segmentation s on the description length of
PB model ?. That is, ?DL(s,?) computes the
difference in description length between the cur-
rent model ? and the model ?
?
that would result
from committing to s:
?DL(s,?) = DL(?
?
)?DL(?)
+ DL(D | ?
?
)?DL(D | ?) (3)
The length difference between the phrase lexi-
cons (DL(?
?
)?DL(?)) is trivial. We merely have
to compute the difference between the lengths of
the phrase pairs added and removed. The differ-
ence for the data is given by ? log
2
(
Pr
?
?
(D)
Pr
?
(D)
)
,
where Pr
?
?
(D) and Pr
?
(D) are the probability
of D according to ?
?
and ? respectively. These
EuTransI (Sp / En)
train tune test
#Sentences 10k 2k 1k
#Words 97k / 99k 23k / 24k 12k / 12k
Vocabulary 687 / 513 510 / 382 571 / 435
OOV – / – 0 / 0 0 / 0
Perplexity – / – 8.4 / 3.4 8.1 / 3.3
News Commentary (Sp / En)
train tune test
#Sentences 51k 2k 1k
#Words 1.4M / 1.2M 56k / 50k 30k / 26k
Vocabulary 47k / 35k 5k / 5k 8k / 7k
OOV – / – 390 / 325 832 / 538
Perplexity – / – 136.2 / 197.9 144.2 / 206.0
Table 1: Main figures of the experimental corpora.
M and k stand for millions and thousands of ele-
ments respectively. Perplexity was calculated us-
ing 5-gram language models.
probabilities can be computed by translating the
training data. However, this is a very expensive
process that we cannot afford to perform for each
candidate segmentation. Instead, we estimate the
description length of the data in closed form based
on the probabilities of the phrase pairs involved.
The probability of a phrase pair {
˜
f, e˜} is computed
as the the number of occurrences of the pair di-
vided by the number of occurrences of the source
(or target) phrase. We thus estimate the probabil-
ities in the segmented model ?
?
by counting the
occurrences of the replaced phrase pairs as occur-
rences of the segmented pairs. Let {
˜
f
0
, e˜
0
} be
the phrase pair we are splitting into {
˜
f
1
, e˜
1
} and
{
˜
f
2
, e˜
2
}. The direct phrase probabilities in ?
?
will
be identical to those in ? except that:
P
?
?
(e˜
0
|
˜
f
0
) = 0
P
?
?
(e˜
1
|
˜
f
1
) =
N
?
({
˜
f
1
, e˜
1
}) + N
?
({
˜
f
0
, e˜
0
})
N
?
(
˜
f
1
) + N
?
({
˜
f
0
, e˜
0
})
P
?
?
(e˜
2
|
˜
f
2
) =
N
?
({
˜
f
2
, e˜
2
}) + N
?
({
˜
f
0
, e˜
0
})
N
?
(
˜
f
2
) + N
?
({
˜
f
0
, e˜
0
})
where N
?
(·) are counts in ?. Inverse probabilities
are computed accordingly. Finally, we compute
the variation in data description length using:
Pr
?
?
(D)
Pr
?
(D)
?
P
?
?
(e˜
1
|
˜
f
1
) · P
?
?
(e˜
2
|
˜
f
2
)
P
?
(e˜
0
|
˜
f
0
)
·
P
?
?
(
˜
f
1
| e˜
1
) · P
?
?
(
˜
f
2
| e˜
2
)
P
?
(
˜
f
0
| e˜
0
)
(4)
92
EUtransI News Commentary
BLEU [%]
Size
BLEU [%]
Size
(tune/test) (tune/test)
SotA 91.6 / 90.9 39.1k 31.4 / 30.7 2.2M
MDL 88.7 / 88.0 2.7k 24.8 / 24.6 79.1k
Table 2: Size (number of phrase pairs) of the
MDL-based PB models, and quality of the gener-
ated translations. We compare against a state-of-
the-art PB inference pipeline (SotA).
For a segmentation set, we first estimate the new
model ?
?
to reflect all the applied segmentations,
and then sum the differences in description length.
4 Empirical Results
We evaluated the proposed inference procedure
on the EuTransI (Amengual et al., 2000) and the
News Commentary (Callison-Burch et al., 2007)
corpora. Table 1 shows their main figures.
We inferred PB models (set of phrase pairs and
their corresponding probabilities) with the training
partitions as described in Section 3.2. Then, we
included these MDL-based PB models in a con-
ventional log-linear model optimized with the tun-
ing partitions (Och, 2003). Finally, we generated
translations for the test partitions using a conven-
tional PB decoder (Koehn et al., 2007).
Table 2 shows size (number of phrase pairs) of
the inferred MDL-based PB models, and BLEU
score (Papineni et al., 2002) of their translations of
the tune and test partitions. As a comparison, we
display results for a state-of-the-art (SotA) PB sys-
tem (Koehn et al., 2007). These results show that
MDL inference obtained much more concise mod-
els (less than one tenth the number of phrases) than
the standard inference pipeline. Additionally, the
translations of the simple EuTransI corpus were of
a similar quality as the ones obtained by the SotA
system. In contrast, the quality of the translations
for News Commentary was significantly lower.
To better understand these results, Figure 1 dis-
plays the histogram of phrase lengths (number of
source words plus target words) of the SotA model
and the MDL-based model for the News Commen-
taries corpus. We first observed that the length of
the phrase pairs followed a completely different
distribution depending on the inference procedure.
Most of the phrase pairs of the MDL-based model
translated one source word by one target word
with an exponential decay in frequency for longer
phrase pairs; a typical distribution of events in nat-
 0
 10
 20
 30
 0  10  20  30  40  50  60  70  80
 
Length of the phrase pair (words)
R
e
l
a
t
i
v
e
 
f
r
e
q
u
e
n
c
y
 
[
%
] SotAMDL
Figure 1: Histogram of lengths (source plus target
words) for the phrase pairs in the inferred models.
ural language (Zipf, 1935). Longer phrase pairs,
about 45% of the total, contain sequences of words
that only appear once in the corpus, and thus, they
cannot be segmented in any way that leads to a re-
duction in description length. Although formally
correct, long phrase pairs generalize poorly which
explains the comparatively poor performance of
MDL inference for the News Commentaries cor-
pus. This problem was largely attenuated for Eu-
TransI due to its simplicity.
5 Conclusions and Future Developments
We have described a simple, unsupervised infer-
ence procedure for PB models that learns phrase
lexicons by iteratively splitting existing phrases
into smaller phrase pairs using a theoretically
well-founded minimum description length objec-
tive. Empirical results have shown that the in-
ferred PB models, far from the artificial redun-
dancy of the conventional PB inference pipeline,
are very parsimonious and provide competitive
translations for simple translation tasks.
The proposed methodology provides a solid
foundation from where to develop new PB infer-
ence approaches that overcome the problems in-
herent to the long pipeline of heuristics that nowa-
days constitute the state-of-the-art. Future devel-
opments in this direction will include:
• A more sophisticated segmentation procedure
that allow to divide the phrases into more that
two segments.
• A hybrid approach where the long phrase pairs
remaining after the MDL inference are further
segmented, e.g., according to a word lexicon.
• The inclusion of lexical models in the definition
of the PB model.
93
Acknowledgments
Work supported by the European Union 7
th
Framework Program (FP7/2007-2013) under the
CasMaCat project (grans agreement n
o
287576),
by Spanish MICINN under grant TIN2012-31723,
and by the Generalitat Valenciana under grant
ALMPR (Prometeo/2009/014).
References
Juan-Carlos Amengual, M. Asunci´on Casta˜no, Anto-
nio Castellanos, V´?ctor M. Jim´enez, David Llorens,
Andr´es Marzal, Federico Prat, Juan Miguel Vilar,
Jos´e-Miguel Bened´?, Francisco Casacuberta, Mois´es
Pastor, and Enrique Vidal. 2000. The eutrans spo-
ken language translation system. Machine Transla-
tion, 15(1-2):75–103.
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Fredrick Jelinek, John D.
Lafferty, Robert L. Mercer, and Paul S. Roossin.
1990. A statistical approach to machine translation.
Computational Linguistics, 16:79–85.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-) evaluation of machine translation. In Pro-
ceedings of the Workshop on Statistical Machine
Translation, pages 136–158.
Peter Gr¨unwald. 1996. A minimum description length
approach to grammar inference. Connectionist, Sta-
tistical, and Symbolic Approaches to Learning for
Natural Language Processing, pages 203–216.
Peter Gr¨unwald. 2004. A tutorial introduc-
tion to the minimum description length principle.
http://arxiv.org/abs/math/0406077.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the North American Chapter of the As-
sociation for Computational Linguistics on Human
Language Technology, pages 48–54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the Association for Computational
Linguistics, demonstration session, June.
Brockway McMillan. 1956. Two inequalities implied
by unique decipherability. IRE Transactions on In-
formation Theory, 2(4):115–116.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
Meeting on Association for Computational Linguis-
tics, pages 160–167. Association for Computational
Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic eval-
uation of machine translation. In Proceedings of the
Meeting on Association for Computational Linguis-
tics, pages 311–318. Association for Computational
Linguistics.
Jorma Rissanen. 1978. Modeling by shortest data de-
scription. Automatica, 14(5):465 – 471.
Markus Saers, Karteek Addanki, and Dekai Wu. 2013.
Iterative rule segmentation under minimum descrip-
tion length for unsupervised transduction grammar
induction. In Statistical Language and Speech Pro-
cessing, volume 7978 of Lecture Notes in Computer
Science, pages 224–235. Springer.
Germ´an Sanchis-Trilles, Daniel Ortiz-Mart´?nez, Jes´us
Gonz´alez-Rubio, Jorge Gonz´alez, and Francisco
Casacuberta. 2011. Bilingual segmentation for
phrasetable pruning in statistical machine transla-
tion. In Proceedings of the 15th Conference of the
European Association for Machine Translation.
Ray Solomonoff. 1964. A formal theory of inductive
inference, parts 1 and 2. Information and Control,
7:1–22, 224–254.
Juan Miguel Vilar and Enrique Vidal. 2005. A recur-
sive statistical translation model. In Proceedings of
the ACL Workshop on Building and Using Parallel
Texts, pages 199–207.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical
translation. In Proceedings of the 16th conference
on Computational linguistics, pages 836–841.
George Kingsley Zipf. 1935. The Psychobiology of
Language. Houghton-Mifflin.
94
