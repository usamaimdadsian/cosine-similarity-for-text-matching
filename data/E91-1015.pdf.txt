A TASK INDEPENDENT ORAL D IALOGUE MODEL 
Er ie  Bil~nge 
CAP GEMINI ~NNOVATION 
118, rue de Tocque~|!!~ 75017 Paris. France 
and IRISA Lannion 
e-mail: bilanp~¢rp.capsogeti.fr 
ABSTRACT 
This paper presents a human-machine dia- 
logue model in the field of task-oriented dialogues. 
The originality of this model resides in the clear 
separation of dialogue knowledge from task knowl- 
edge in order to facilitate for the modeling of di- 
alogue strategies and the maintenance of dialogue 
coherence. These two aspects are crucial in the 
field of oral dialogues with a machine consider- 
ing the current state of the art in speech recogni- 
tion and understanding techniques. One impor- 
tant theoretical innovation is that our dialogue 
model is based on a recent linguistic theory of di- 
alogue modeling. The dialogue model considers 
real-life situations, as our work was based on a 
real man-machine corpus of dialogues. 
In this paper we describe the model and the de- 
signed formalisms used in the implementation f a 
dialogue manager module inside an oral dialogue 
system. An important outcome and proof of our 
model is that it is able to dialogue on three differ- • 
ent applications. 
1 In t roduct ion  
The work presented here is a dialogue model for  
oral task oriented dialogues. This model is used 
and under development in the SUNDIAL ESPRIT 
project I whose aim is to develop an oral coopera- 
tive dialogue system. 
Many researchers have observed that oral dia- 
logue is not merely organized as a cascade of ad- 
jacency pairs as Schlegoff and Sacks {1973} sug. 
gested. Task oriented dialogues have been ana- 
lyzed from different point of view: discourse seg- 
mentation {Grosz & Sidner, 1986}, exchange seg- 
mentation with a triplet organization {Moeschler, 
19891, initiative in dialogue {Walker & Whittaker, 
1990}, etc. 
From a computational point of view, in task ori~ 
• : r:; 
1This project is partially funded by the Commission for 
the European Communities ESPRIT programme, as pro- " 
ject 2218. The partners in this project are CAP GEMINI 
INNOVATION, CNET, CSELT, DAIMLER-BENZ, ER- . . . .  
LANGEN University, INFOVOXj IRISA, LOGICA, PO-~ 
LITECHNICO DI TORINOj SARIN, SIEMENS, SUR-  , 
REY University 
ented dialogues planning techniques have received 
a fair amount of attention {Allen et al, 1982; Lit- 
man & Allen, 1984). 
In the latter approach there is no means to de- 
scribe and deal with pure discursive phenom- 
ena {meta-communication) such as oral misunder- 
standing, initiative keeping, initiative giving etc, 
Whilst in the first approaches there is no attempt 
to develop a full dialogue system, except in Grosz's 
and Sidner's {1986) model that unfortunately does 
not cover all oral dialogue phenomena (Bilange et 
al, 1990b). 
In oral conversation, meta-communication rep- 
resents a large proportion of all possible phenom- 
ena and is not simple to deal with, especially if 
we strive to obtain natural dialogues. Therefore, 
we developed a computational model able to have 
clear views on happenings at the task level and at 
the level of the communication itself. This model 
is not based on pure intuition but has been val- 
idated in a semi-automatic human-machine dia- 
logue simulation {Ponamal~ et al, 1990). The aim 
is to obtain a dialogue manager capable of natural 
behaviour during a conversation allowing the user 
to express himself and without being forced to re- 
spect the system behaviour. Thus we endow the 
system with the capabilities of a fully interactive 
dialogue. 
Moreover, as a strategic hoice, we decided to have 
a predictive system, as it has been shown crucial 
for oral dialogue system {Guyomard et al, 1990; 
Young, 1989}, to guide the speech understanding 
mechanisms whenever possible. These predictions 
result from an analysis of our corpus and gener- 
alized by endowing the system with the capacity 
to judge the degree of dialogue openness. As a 
results predicting the user's possible interventions 
doesn't mean that the system will predict all pos- 
sibilities - only relevant ones. This presupposes 
cooperative users. 
2 Overv iew of  the  D ia logue  
manager  
The architecture of the SUNDIAL Dialogue Man- 
ager is presented in Fig. 1. It is a kind of dis- 
_ S•3. 
tributed architecture where sub-modules are in- 
dependent agents. 
P . . . . . . . . . . . . . . . . . . . . . . .  ' ' T -= 
I T- Mo.u,. I li 
Module  
L . . . . . .  ~ . . . . . . . .  . _ .  . . . . . .  d.~- - |  
S~h Speoch 
Un&rstan~lin~ S l r~ 
Figure I. Architecture of the Dialogue Manager 
Let us briefly present how the dialogue man- 
ager works as a whole. At each turn in the di- 
alogue, the dialogue module constructs dialogue 
allotvance8 on the basis of the current dialogue 
structure. Depending on whose turn it is to speak, 
these dialogue allowances provide either: dialogic 
descriptions of the next possible system utterance 
or dialogic predictions about the next possible 
user utterance(s). When it is the system's turn, 
messages from the task module, such as requests 
for missing task parameters, message8 from the 
linguistic interface module such as requests for the 
repetition of missing words, and messages from the 
belief module arising, for example, from referential 
failure, are ordered and merged with the dialogue 
allowances by the dialogue module to produce the 
next relevant system dialogue act(8) 2. The result- 
Lug acts are then sent to message generator. 
When it is the user's turn to talk, task and 
belief goals are ordered and merged with the di- 
alogue allowances to form predictions. They are 
sent, via the linguistic interface module, to the 
linguistic processor. When the user speaks, a rep- 
resentation of the user's utterance is passed from 
the linguistic processor to the linguistic interface 
module and then on to the belief module. The be- 
lief module assigns it a context-dependent refer- 
ential interpretation suitable for the task module 
to make a task interpretation a d for the dialogue 
module to make a dialogic interpretation (e.g. as- 
sign the correct dialogue act(s) and propagate the 
effects on the dialogue history). This results in 
the construction of new dialogue allowances. The 
cycle is then repeated, to generate the next system 
turn. 
This is necessarily a simplified overview of the 
processing which takes place inside the Dialogue 
Manager. A detailed escription of the dialogue 
manager can be found in (Bilange et al, 1990a). 
The purpose of this paper is to describe some fun- 
aThis terminology is defined later. 
damental aspects of the dialogue module. It is 
however important to state that the task module 
should use planning techniques similar to Litman's 
(1984))  
3 Basis of the dialogue 
model 
Task oriented ialogues mainly consist of negoti- 
ations. These negotiations are organized in two 
possible patterns: 
1. Negotiation opening + Reaction 
2. Negotiation opening + Reaction + Evaluation 
Moreover negotiations may be detailed which 
causes ub-negotiations. Also, in a full dialogue, 
conversational exchanges occur for clarifying com- 
munication problems, and for opening and closing 
the dialogue. This description is then recursive 
with different possible dialogic functions. 
A dialogue model should take into account 
these phenomena keeping in mind the task that 
must be achieved. An oral dialogue system should 
also take into consideration acoustic problems due 
to the limitation of the speech understanding tech- 
niques (soft-as well as hardware) e.g. repairing 
techniques to avoid misleading situations due to 
misunderstandings should be provided. Finally, as 
a cooperative principle, the model must be hab- 
itable and thus not rigid so that the two locutors 
can take initiative whenever they want or need. 
These bases lead us to define a model which 
consists of four decision layers: 
s Rules of conversation, 
• System dialogue act computation, 
o User dialogue act interpretation, 
• Strategic decision level. 
Now let us describe ach layer. 
3.1  Rules  o f  conversat ion  
The structural description of a dialogue consists of 
four levels similar to the linguistic model of Roulet 
and Moeschler (1989). In each level specific func- 
tional aspects are assigned: 
s ~ransaction level : informative dialogues are 
a collection of transactions. In the domain 
of travel planning, transactions could be : 
book a one-way, a return, etc. The trans- 
action level is then tied to the plan/sub-plan 
paradigm. A transaction can be viewed as a 
discourse segment (Grosz & Sidner~ 1986). 
• Ezchange level: transactions are achieved 
through exchanges which may be considered 
- 84 -  
Dialogue xcerpt of example in section 4 
$2 when would you like to leave 7 
U2 next thursday 
Sa next tuesday the 30th of November ; 
and at what time 7 
Us no, thursday december the 2nd 
towards the end of the afternoon 
St ok december the 2nd around six ... 
initiative(system, \[open_request, get_paranteter( dep.date)\]) 
reaction(user, \[answer, \[dep_date : #1\]\]) 
El \[ initiative( s#stem, \[echo, #1\]) 
evaluation : E2 \] reaction(user, \[correct, \[#I, #2\]\]) 
Tl L evaluation(system, \[echo, #2\ ] )  
initiative(system, \[open_request, get_parameter(dep_time)\]) 
Ea reaction(user, \[answer, \[dep_time : #3\]\]) 
e~aluation(s~ste,,~, \[echo, #$\]) 
El : exchange(Owner: system, Intention: get(dep.date), Attention: {departure, date)) 
E2 exchange(Owner: system, Intention: clarify(value(dep.date)), Attention: {departure, date)) 
Ea exchange(Owner: system, Intention: get(dep_time), Attention: {departure, time)) 
Tl = transaction(Intention:problem.description, 
Attention:(departure, a rival, city, date, time, flight)) 
Figure 2. Dialogue history representation 
as negotiations. Exchanges may be embedded 
(sub-exchanges). During an exchange, nego- 
tiations occur concerning task objects or the 
dialogue itself (meta-communication). 
Intervention level : An exchange is made up 
of interventions. Three possible illocutionaxy 
functions axe attached to interventions: ini- 
tiative, reaction, and evaluation. 
Dialogue acts : A dialogue act could be de- 
fined as a speech act (Senile, 1975) augmented 
with structural effects on the dialogue (thus 
on the dialogue history) (Bunt, 1989). There 
axe one or more main dialogue acts in an in- 
tervention. Possible secondary dialogue acts 
denote the argumentation attached to the 
main ones. 
Dialogue acts represent he minimal entities 
of the conversation. 
The rules of conversation use this dialogue de- 
composition and axe organised as a dialogue gram- 
max. Dialogue is then represented in a tree struc- 
ture to reflect he hieraxchica\] dialogue aspect aug- 
mented with dialogic functions. An example is 
given in Fig. 2. Now let us describe conversa- 
tional rules through a detailed description of the 
functional aspects of the intervention level. 
• Initiatives axe often tied to task informa- 
tion requests, in task-oriented ialogues. Initia- 
tives axe the first intervention of an exchange but 
may be used to reintroduce a topic during an ex- 
change. Intentional and attentional information is
attached to initiatives and exchanges as in (Gross 
& Sidner, 1986). When a locutor perforn'ts an ini- 
tiative the exchange is attributed to him, and he 
retains the initiative, since there is no need for 
discourse clarification, for the duration of the ex- 
change. This is important as according to the 
analysis of our corpus the owner of an exchange 
is responsible for properly closing it and he has 
many possibilities to either keep the initiative or 
give it back. 
The simplest initiative allowance rule initia- 
tive_taking, presented in Fig 3, means that the 
speaker X who has just evaluated the exchange 
Sub-ezchange is allowed to open a new exchange 
such as it is a new sub-exchange of the exchange 
Ezchange ({_} means any well-formed sequence 
according to the dialogue grammar). Moreover, 
the new exchange can be used to enter a new 
transaction. In this case the newly created ex- 
change will not be linked as a sub-exchange (see 
section 3.2 below). 
initiative.taking --> 
\[Exchange, {.}, \[Sub-exchange, {_}, evaluation(X,_)\]\] 
dialogue (\[initiative (X,_),_\], Exchange). 
evaluation ---> 
\[ Exchange, initiative(X,N), {_), reaction(Y,_) \] 
dialogue(evaluation (X,_), Exchange) 
<- not meta-diecursive(Exchange). 
Figure 3. Two dialogue grammar ules 
. Reactions obey the adjacency pair theory. 
Reactions always give relevant information to the 
initiative answered. 
® Evaluations, both by the machine and the hu- 
man, axe crucial. To evaluate an exchange means 
evaluating whether or not the underlying inten- 
tion is reached. In task-oriented dialogues evalu- 
- ,~5  - 
ations may serve task evaluations or comprehen- 
sion evaluations in cases of speech degradations. 
An  example of an evaluation dialogue rule is given 
in Fig 3. The rule evaluation permits when X 
has initiated an exchange and Y reacted that X 
evaluates this exchange. The evaluation cannot 
be made whilst there is no reaction taking place. 
This rule (as any other) is bidirectional : if X is in- 
stantiated by "user" then the generated ialogue 
'allowance' is a prediction of what the user can 
utter. On the other hand, if X is instantiated 
by "system" then the rule is one of a "strategic 
generation". Evaluations are very important in 
oral conversation and coupled with the principle 
of bidirectional rules, this allows to foresee possi- 
ble user contentions and to handle them directly 
as clarifying subexchanges. The dialogue flavour 
is that the system implicitly offers initiative to the 
user if necessary, keeping a cooperative attitude, 
and thus avoids systematic onfirmations which 
can be annoying (see example in section 4). 
The structural effects of evaluations are not 
necessarily evident. When an evaluation is ac- 
knowledged (with cue expressions like "yes", "ok ~ 
or echoing what has been said) the exchange can 
be closed in which case the exchange is explic- 
itly closed. The acknowledgement may not have 
a concrete realization in which case the exchange 
is implicitly closed. In the latter case, closings 
axe effective when the next initiative is accepted 
by the addressee. It is unlikely, according to our 
corpus of dialogues, that one speaker will contest 
an evaluation later in the dialogue. In the exam- 
ple in section 4, Sa initiative is accepted because 
U2 answers the question - the effect is then: U's 
reaction implicitly accepts the initiative which im- 
plicitly accepts the S's evaluation. Therefore, the 
exchange, concerning the destination and  arrival 
cities, can be closed. We will describe later how 
such effects are modelled. 
During one cycle, every possible dialogue al- 
lowance is generated even if some are conflicting. 
Conflicts are solved in the next two layers of the 
model. 
3.2  D ia logue  acts  computat ion  
Once the general perspective of the dialogue con- 
tinuation has been hypothesised, dialogue acts axe 
instantiated according to task and communication 
management needs. A dialogue act definition is 
described in Fig 4. 
The premises state the list of messages the 
dialogue act copes with s. The conclusions axe 
twofold: there is a description of the dialogic ef- 
fect of the act and of its mental effect on the two 
aWe recall that these messages are received by the di- 
alogue module internally (see section 3) or externally (see 
section 2) 
Dialogue act label ==> 
message_l, . . . ,  msssagsn 
=:=> Description of the dialogue act 
Effects of the dialogue act 
<- preconditions and/or actions 
Figure 4. Dialogue act representation 
open_request ==> 
diaiogue(\[initiative(system,ld),Exchgl\], Exchange) , 
task(get_parameter(Oh j)) 
ereate_exchange({initiative(system,Id) ,Exehgl\], 
father_exchange:Exchange, 
• \[intention:get.pararneter(Obj), attention:Obj\]), 
create_move(Id,system,initiative, open_request,Obj, Exchgl) 
<- attentional_state(Exchange, Attention), 
in_attention(Attention, Ohj). 
Figure 5. The open_request dialogue act 
speakers. We do not describe this last part as 
our model does no more than what exists in Allen 
etal's work (82 I. Lastly, the preconditions are 
a list of tests concerning the current intentional 
and attentional states in order to respect he dia- 
logue coherence and/or actions used for example 
to signal explicit topic shifts. Signaling this means 
introducing features in order that once the act is 
to be generated some rhetorical cues are included: 
"Now let's talk about the return when do you want 
to come back?", or simply: aand at what time?" 
when the discursive context states that the system 
has the initiative. 
At this level all possible dialogue acts accord- 
ing to the dialogue allowances issued by the previ- 
ous level axe hypothesised. Discursive and meta- 
discursive acts are planned and the next layer will 
select the relevant acts according to the dialogue 
strategy. 
In the next paragraphs, we describe the most im- 
portant dialogue acts the system knows and clas- 
sify them according to the function they achieve. 
Combin ing  task  messages  and  d ia logue  al- 
lowances : 
The dialogue model considers the task as an in- 
dependent agent in a system. The task module 
sends relevant requests whenever it needs infor- 
mation, or information whenever asked by the di- 
alogue module. 
* Initiatives and Parameter equests : an initia- 
tive can be used to ask for one task parameter. 
The intention of the new created exchange is then 
tagged as "get_parameter" whereas the attention 
is the requested object 4. The act is presented in 
Fig. 5. 
. The other identified possibilities are initiative 
tThis is a very simplified description. One can refer to 
(Sadek, 1990) to have a more precise view of what could 
be done. 
- 86  - 
and non topical information; initiative and task 
solution(n); trannaction opening, initiative, and 
task plan opening; reaction and parameter value; 
transaction closing, evaluation and task plan clos- 
ing in which case the act may not have a surface 
realization since exchanges in the transaction may 
have been evaluated which implicitly allows the 
transaction closing. 
Dia logue progression control : 
s Confirmation handling: Representations com- 
ing from the speech understanding module contain 
recognition scores s. According to the score rate, 
confirmations are generated with different inten- 
sity. The rules are : 
s Low score : realize only the evaluation goal 
entering a clarifying exchange. 
* Average score : a combination of evaluation 
and initiative is allowed, splitting them into 
two sentences as in "Paris Brest ; when would 
like to leave ?" 
• High score : in that case, the evaluation can 
be merged with the next initiative as in "when 
would you like to leave for Bonn?". 
• Contradiction handling. When the addressee ut- 
ters a contradiction to an evaluation if any initia- 
tive has been uttered by the system, it is marked 
as "postponed". The exchange in which the con- 
test occurs is then reentered and the evaluation 
part becomes a sub-exchange. 
• Communication management. Requests for 
pauses or for repetition postpone every kind of 
dialogue goal. The adopted strategy is to achieve 
the phatic management and then reintroduce the 
goals in the next system utterance. 
• Reintroducing old goals. As long ~ the current 
transaction is not closed the system tries to real- 
ize postponed goals if a dialogue opportunity (e.g. 
a dialogue allowance} arrives. When realizing the 
opportunity a marker is used to reintroduce the 
communicative goal if it has been postponed for a 
long time ("long time" refers to the length in the 
discourse structure from the postponement and 
the point where it is reintroduced). This involves 
the tactical generation of using a special case of 
rhetoric formulation. 
• Abandoning previous goals. The concrete real- 
ization of dropping an exchange occurs when goals 
have been postponed and the transaction to which 
they belong is closed. The justification is simple : 
a transaction close is submitted to the addressee 
for evaluation. If he does not contest this closing 
then this implicitly allows the drop. 
Only non crucial exchanges are dropped. If they 
SScores may be fuzzy. They only represent the confusion 
rate which occurs during the lexicalization of the acoustic 
signal. 
were crucial to the transaction then they wouldn't 
have been dropped. 
These communication management acts illus- 
trate the interest of our dialogue model and of- 
fer new means to cope with dialogue failure com- 
paring with recent techniques (Jullien & Marty, 
1989). 
3.3 D ia logue  s t ra tegy  mode l ing  
In one running cycle, more than one dialogue act 
can be a candidate, this is due to the nondeter- 
ministic nature of the dialogue which is preserved 
until this step. For example, it is possible that the 
dialogue rules allow the system to take an initia- 
tive, evaluate an exchange, or react. Consequently 
a third layer of rules has been designed, in order to 
select the best candidate according to a general di- 
alogue strategy. As our system is dedicated to oral 
dialogues the strategy is firstly oriented toward a 
systematic confirmation of system's understand- 
ings and secondly, as a general strategy, we de- 
cided to avoid too many embedded subexchanges. 
This avoids numerous topic shifts, especially im- 
plicit ones. The concrete realization of the latter 
is done by forcing the user to give explicit answers 
to problematic goals with utterances like "please 
answer yes or no ~. 
4 A dialogue example 
We present here a dialogue example obtained with 
our system in the field of flight reservations 6. At 
present, there is no oral recognition system; user's 
utterances are entered manually in predefined for- 
mat, including hypothesised acoustic scores and 
voluntary misrecognition. 
$I  flight booking service, how can I help you? 
0"i one ticket to Brest, please 
$2 Paris, Brest, when would you like to leave7 
U2 next thursday 
$3 next tuesday the 30th of November ; and at 
what time? 
U3 no, thursday december the 2nd towards the 
end of the afternoon 
$4 ok december the 2nd around six ,~ just a 
moment  please 
U4 thank you 
$5 there is one flight at six and another at nine 
thirty 
Us nine thirty 
$6 ok nine thirty, Paris Brest, one-way or re- 
turn? 
U0 no I'd prefer six o'clock 
6Punctuation is here as oral transcription conventions. 
Therefore we suppressed some of them in user's utterances 
as we are not able, at present, to deal with them. Ques- 
tion marks mean that intonation rises and commas denote 
pauses. 
- 87  - 
57 ok, I'll book you on the six o'clock flight 
/\]7 fine 
Ss one-way or return ? 
Us no, just one-way thanks 
Normally, the dialogue continues with the ac- 
quisition of the passenger name and address but 
now this is not included in the task management. 
5 Conclus ion 
The exposed model and system takes into ac- 
count previous works done in the field of dialogue 
management augmenting them with a more sub- 
tle description of dialogues. This allows us to re- 
spect our aims which were to obtain a generic dia- 
logue module adaptable to different applications, 
a model well suited to oral communication and 
lastly a model capable of handling dialogue fail- 
ures without any ad-hoc procedures. 
The system is currently under development in
Quintus Prolog on a Sun Sparc Station. We now 
have a first integrated small prototype which runs 
in three languages (English, French and German) 
and for three different applications: flight reser- 
vation, flight enquiries, and train timetable en- 
quiries. This emphasizes the task independent 
and language independent aspects of the model 
presented here. At present, we have about 20 dia- 
logue rules, 35 dialogue acts and limited strategy 
modeling. 
6 Acknowledgements  
I would like to thank Jacques Siroux, Marc Guy- 
omaxd, Norman Fraser, Nigel Gilbert, Paul Heis- 
terkamp, Scott McGlashan, Jutta Unglaub, Robin 
Wooffitt and Nick Youd for their discussion, com- 
ments and improvements on this research. 
7 References 
Allen, J.F., Frisch, A.M., Litman, D.J. (1982) 
"ARGOT: the Rochester dialogue system ~. In 
Proceedings Nat'l. Conferences on Artificial In- 
telligence, Pittsburgh, August. 
Bilange, E., Fraser, N., Gilbert, N., Guyomard, 
M., Heisterkamp, P., McGlashan, S., Siroux, 
J., Unglaub, J., Woofiitt, R., Youd, N. (1990a} 
"WP6: Dialogue Manager Functional Specifica- 
tion ~. ESPRIT SUNDIAL WP6 first deliverable, 
June. 
Bilange, E., Guyomard, M., Siroux, J. (1990b) 
"Separating dialogue knowledge from task knowl- 
edge for oral dialogue management s , In Proceed- 
ings of COGNITIVA90, Madrid, November. 
Bunt, H. (1989) "Information dialogues as com- 
municative action in relation to partner modelling 
and information processing, s In M. M. Taylor, 
F. N~el, and D. G. Bouwhuis, editors, The struc- 
ture of multimodal dialogue, pp. 47-71. North- 
Holland. 
Gross, B.J. and C.L. Sidner (1986) "Attention, 
Intentions, and the structure of discourse s . Com- 
putational Linguistics, Vol. 12, No 3, July- 
September, 1986, pp. 175-204. 
Guyomard, M., Siroux, J., Cozannet, A. (1990) 
"Le r61e du dialogue pour la reconnaissance d  la 
parole. Le cas du syst~me des Pages Jaunes. ~ In 
Proceedings of18th JEP, Montreal, May, pp. 322- 
326. 
Jullien, C., Marty, J.C. (1989) "Plan revision in 
Person-Machine Dialogue s . In Proceedings of the 
Jth European Chapter of ACL, April. 
Litman, D., Allen, J.P. (1984} "A plan recognition 
model subdialogues in conversations ~. University 
of Rochester report TR 141, November. 
Moeschler, J. (1989) "Mod~lisation du dia- 
logue, representation de l'inf~rence argumenta- 
tive =. Hermes pub. 
Ponamal~, M., Bilange, E., Choukri, K., Soudo- 
platoff, S. (1990) "A computer-aided approach 
to the design of an oral dialogue system ~. In 
Proceedings ofEastern Multiconference, Nashville, 
Tenessee, April. 
Sadek, M.D. (1990) "Logical Task Modelling 
for Man-Machine Dialogue s . In Proceedings of 
AAAI, August. 
Schlegoff, E. A. and H. Sacks (1973). "Opening 
up closings s. Semiotica, 7(4):289-327. 
Searle, J.R. (!975) "Indirect speech acts . In: P. 
Cole and J.L. Morgan, Eds., Syntax and Seman- 
tics, Vol. 3: Speech Acts (Academic Press, New 
York, 1975). • 
Walker, M., Whittaker, S. (1990) "Mixed initia- 
tive in dialogue: an investigation into discourse 
segmentation s . In Proceedings of the Association 
of Computational Linguistics A CL. 
Young, S.R. (1989) "Use of dialogue, pragmatics 
and semantics to enhance speech recognition s . In 
Proceedings of Eurospeech, Paris, September. 
- 88  - 
