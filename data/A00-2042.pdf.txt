Understanding "Each Other" 
Cla i re  Gardent  
Computat iona l  L ingu is t i cs  
Un ivers i ty  of  the  Saar land  
Saarbr f i cken ,  Germany 
claire@coli, uni-sb, de 
Kars ten  Konrad  
Computer  Sc ience  
Un ivers i ty  of  the  Saar land  
Saarbr i i cken ,  Germany 
konrad©ags, un i - sb ,  de 
Abst ract  
Although natural anguage is ambiguous, vari- 
ous linguistic and extra-linguistic factors often 
help determine a preferred reading. In this pa- 
per, we show that model generation can be used 
to model this process in the case of reciprocal 
statements. The proposed analysis builds on in- 
sights from Dalrymple t al. 98 and is shown to 
provide an integrated, computational ccount 
of the interplay between model theoretic inter- 
pretation, knowledge-based reasoning and pref- 
erences that characterises the interpretation of
reciprocals. 
1 In t roduct ion  
Although there is widespread agreement that 
inference is an essential component of natural 
language processing, little work has been done 
so far on whether existing automated reason- 
ing systems uch as theorem provers and model 
builders could be fruitfully put to work in the 
area of natural anguage interpretation. 
In this paper, we focus on the inference prob- 
lems raised by the reciprocal expression each 
other and show that model generation provides 
an adequate tool for modeling them. 
The paper is structured as follows. Section 3 
discusses the meaning of reciprocal statements 
and proposes a formal semantics for each other. 
Section 2 shows how model generation can be 
used to provide this semantics with a compu- 
tational interpretation. Section 4 compares our 
approach with the account of reciprocals which 
inspired it in the first place namely, (Dalrymple 
et al., 1998). Section 5 concludes with pointers 
for further esearch. 
2 The  mean ing  of  rec ip roca l  
s ta tements  
In the linguistic literature, the reciprocal ex- 
pression each other is often taken to denote a 
dyadic quantifier over a first-order set, which we 
will call the antecedent  set, and a binary first- 
order relation, which we will call the scope re- 
lation. In what follows, we assume an approach 
of this type and will use the symbol RcP for 
such reciprocal quantifiers o that the seman- 
tic representation f e.g. Jon and Bill saw each 
other will be: 
(1) RcP({jon, saw(x, y)) 
When antecedent sets of just two members 
are considered, each set member is required to 
stand in the scope relation to each other mem- 
ber. For larger sets however, research on recip- 
rocal statements has uncovered a variety of log- 
ical contributions that the reciprocal can pro- 
vide. Here are some examples. 
(2) The students like each other. 
Vx (std(x) -+ Vy ( x  y A std(y) -+ 
like(x,y)) 
(3) The students tare at each other in sur- 
prise. 
Vx (std(x) -+ ~y (x ¢ y A std(y) A 
stare_at(x, y ) ) 
(4) The students gave each other measles. 
Vx (std(x) -+ 3y (x ¢ y A std(y) A 
(gave_measles(x, y) V gave_measle(y, x)))) 
We can accept (2) to be true only if for each 
pair x and y of two students it holds that x 
likes y. But an analogous interpretation would 
be invalid in the case of (3) and (4) where not 
all pairs in the antecedent set the students can 
consistently stand in the scope relation (one can 
only stare at most at one person at a time, and 
319 
one can only get measles from at most one per- 
son). More generally, (Langendoen, 1978; Dal- 
rymple et al., 1998) convincingly argues that 
different reciprocal statements can have very 
different ruth conditions. The challenge to be 
addressed is thus the following: How can we 
determine a (computational) semantics for the 
reciprocal expressions each other that accounts 
for these multiplicity of meanings while predict- 
ing the specific meaning of a particular ecipro- 
cal statement? 
Clearly knowledge based reasoning plays an 
important role: only those readings are possible 
that are consistent with our knowledge about 
the situation and the world. Specifically, knowl- 
edge based reasoning constrains the strength of 
the truth conditions of a reciprocal statement. 
Thus if we abstract away from the specific scope 
relations, the truth conditions of examples uch 
as (2),(3) and (4) are ordered through entail- 
ment as follows (with A the antecedent set and 
R the scope relation): 
Vx (A(x) --~ Vy (A(y) --). R(xy)) 
Vx (A(x) ~ 9y (A(y) A e(xy)) 
Vx (A(x) --~ 3y (A(y) A (e(xy) V (e(yx))) 
Specifically, example (2), which does not in- 
volve any strong knowledge based constraint, 
has the strongest truth-conditions of the three 
examples. By contrast in (3), the knowledge 
that one can stare at most at one person, forces 
a V3 reading while in (4), a weaker meaning still 
is imposed by knowledge based constraints: the 
x gave y measles relation is asymmetric hence 
the k~/reading is ruled out; moreover, since one 
cannot be infected twice, some students in the 
group will be infected but not pass on the dis- 
ease to anyone. Hence the strongest truth con- 
ditions that can be assigned the sentence are the 
VS disjunctive reading indicated in (4). 
But are there any other constraints on the 
interpretation process than these knowledge 
based constraints? And which meaning shall 
we assign a reciprocal expression? The compu- 
tational semantics we will propose is inspired 
from (Dalrymple t al., 1998) and relies on the 
following observations. 
First, we note that (Dalrymple t al., 1998) 
identifies a lower bound for the truth conditions 
of reciprocal sentences which they dub Inclusive 
Alternative Ordering (IAO). It is exemplified by 
sentence (4) above and corresponds to the fol- 
lowing definition of RcP. 
(5) RCPIAO ~-- APAR (\[P\[ > 2 A Vx (P(x) =v 
3y p(y) ^  x # y ^  (R(x, v) v R(V, x)))) 
This definition only adequately characterises x- 
amples such as (4). It does not cover the 
stronger meanings of the reciprocal in sentences 
such as (2) and (3). However, each known form 
of reciprocity entails RCPIAO'S truth conditions, 
and RCPIAO therefore provides us with a mini- 
mal semantics for reciprocals. 
Further, we observe that given a particular 
reciprocal statement, here seems to be a pref- 
erence for consistent interpretations where the 
number of pairs that are in the scope relation 
is as large as possible. For instance in (3), not 
every student can stare at every other student 
(one can stare at at most one person), but intu- 
itively, the sentence requires that every student 
stares at some other student. While such an 
interpretation is much weaker than that of (2), 
this maximisation of the scope relation yields a 
reading that is also much stronger than the min- 
imal IAO interpretation of (4). More generally, 
while IAO provides us with a lower bound for 
the interpretation of reciprocal statements, we 
will see in section 3 that the maximisation ofthe 
scope relation that is consistent with contextual 
knowledge yields the upper bound for the inter- 
pretation of a particular eciprocal statement 
i.e., its meaning. 
Based on these observations, the principle de- 
termining the actual logical contribution of a 
reciprocal statement can be stated as follows: 
Maximise Meaning Hypothesis 
(MMH) :  The valid interpretations of 
a reciprocal sentence S in a context F 
(where I" includes knowledge about the 
previous discourse, the discourse situ- 
ation and the world) are those which 
(a) are consistent both with the IAO 
form of reciprocity and the informa- 
tion provided by F, and (b) whose con- 
tributions to the scope relation are the 
strongest. 
The MMH selects from the set of interpreta- 
tions that are consistent with IAO and contex- 
tual knowledge, those that maximise the scope 
relation. Crucially, this view of reciprocals leads 
320 
to an inference method that can actually com- 
pute the preferred interpretations of reciprocal 
sentences. We now turn to this. 
3 In terpretat ion  as Mode l  
Generat ion  
In Discourse Representation Theory (DRT, 
(Kamp, 1981; Kamp and Reyle, 1993)), a sen- 
tence with semantic representation (I) is true 
with respect o a model M iff there is an embed- 
ding of (I) onto M. Intuitively, this requirement 
says that a sub-model M'  of M must be found 
which satisfies (I). So for instance, sentence (6a) 
is true in M iff there are two individuals bugs 
and bunny in M such that bugs and bunny stand 
in the love relation; or in other words, iff the 
partial model sketched in (6b) is part of M. 
(6) a. Bugs likes Bunny. 
b. {love(bugs, bunny)} 
As shown in (Gardent and Konrad, To ap- 
pear), model generators (i.e., programs that 
compute some of the models satisfying a finite 
set of logical formulas) can be used to provide 
DRT, and more generally model-theoretic ap- 
proaches to natural anguage semantics, with a 
procedural interpretation: Given the semantic 
representation of a discourse and the relevant 
world knowledge (I) (i.e., a finite set of logical 
formulas), a model generator proves that (I) is 
satisfiable by generating some of its models. 
Intuitively, satisfying models explain how dis- 
courses can be made true. They give an 
abstract representation of how (part of) the 
world should be for a discourse to be true. 
Concretely, satisfying models can be seen as 
capturing the meaning of discourses: data-  
bases that can be queried e.g. as part of 
a query/answer system or to interpret subse- 
quent discourse. Satisfying models are also 
remininiscent of Johnson-Laird's mental mod- 
els (Johnson-Laird and Byrne, 1991) and in 
essence, mental models are very much like the 
Herbrand models we are making use of here. 
Formally, a mode l  is a mathematical struc- 
ture that describes how the symbols of a logi- 
cal theory are interpreted. Given a first-order 
language £, a model is a pair (I, D) with D a 
non-empty set of entities (the domain  o f  indi-  
v iduals)  and I an interpretation function which 
maps relation symbols in £ to relations of ap- 
propriate arity in D and constant symbols in £: 
to elements of D. Here we identify these mod- 
els with sets of positive assumptions that unam- 
biguously define the interpretation of the rela- 
tion symbols and fix the interpretation of terms 
to first-order entities that carry a unique name. 
These are known in the literature as Herbrand 
models. 
The set (7c) is such a model for the logical 
form (7b) which is a semantic representation f 
the sentence (7a). 
(7) a. Jon likes his cousin. 
b. 3x cousin_of(x, jon) A like(ion, x) 
c. ~'il = {cousin_of(cl,jon), 
like (jon, cl) } 
The model A41 defines an interpretation of 
the predicates cousin and like over the universe 
of discourse 7) = {jon, cl }. It can also be taken 
as a valid interpretation of (7a).There are, how- 
ever, infinitely many models for (7b) that do 
not correspond to such interpretations e.g. 
(8) .M2 = {cousin_of(jon, jon), like(jon, j on)}  
(9) Ad3 = {cousin_of(c1, jon), fike(jon, C1) , 
like( cl , jon ) } 
The model ..A42 explains the truth of (Ta) by 
declaring Jon as his own cousin. This is a re- 
sult of the inappropriate semantic representa- 
tion (7b) which fails to specify that the relation 
expressed by the noun cousin is irreflexive. In 
the case of A43, the model contains uperfluous 
information. While it is consistent o assume 
like(cl,jon) it is not necessary for explaining 
the truth of the input. 
3.1 M in imal i ty  
For applications to natural-language, weare in- 
terested in exactly those models that capture 
the meaning of a discourse, or at least capture 
the preferred interpretations that a hearer asso- 
ciates with it. As discussed in (Gardent and 
Webber, January 2000), obtaining only these 
models requires eliminating both models that 
are "too small" (e.g. A42) and models that are 
"too big" (e.g. J~43). 
Models such as A42 can be eliminated simply 
by using more appropriate truth conditions for 
NL expressions (e.g. 3x cousin(x) A of(x, jon) A 
x ~ jon A like(jon, x) for (7a)). In general how- 
ever, eliminating models that are "too small" 
is a non-trivial task which involves the interac- 
tion of model-theoretic interpretation not only 
321 
with world knowledge reasoning but also with 
syntax, prosody and pragmatics. The issue is 
discussed at some length (though not solved) in 
(Gardent and Webber, January 2000). 
To eliminate models that are "too big", some 
notion of minimality must be resorted to. For 
instance, (Gardent and Konrad, 1999; Gardent 
and Konrad, To appear) argues that local min- 
imality is an adequate form of minimality for 
interpreting definite descriptions. Local mini- 
mality is defined as follows. 
Local  Min imal i ty :  Let ~ be a set of first- 
order formulas and D be the set of Herbrand 
models of  that use some finite domain D 
whose size is minimal. Then a model ( I ,D) E 
D is locally min imal  iff there is no other 
model (I t, D ~) E D such that I I C I. 
Locally minimal models are models that sat- 
isfy some input  within a minimal domain :D of 
individuals and are subset-minimal with respect 
to all other domain minimal models. These 
models are the simplest in the sense of Occam's 
Razor and often the best explanation for the 
truth of an observation. In particular, if we as- 
sume that A42 is ruled out by a more appro- 
priate semantics for the word cousin, local min- 
imality rules out -1~3 as non locally minimal and 
therefore A41 is correctly identified as giving the 
preferred interpretation for example (7). 
3.2 The  MMH as a M in ima l i ty  
Constra int  
In the case of reciprocals, local minimality 
is clearly not a characterisation of preferred 
interpretations. Our semantic representation 
RCPIA 0 will only capture a reciprocal's mean- 
ing if the reciprocal group has exactly two mem- 
bers or if the input meets IAO, the weakest form 
of reciprocity. For instance, the locally minimal 
model (10c) of formula (10b) is too weak to con- 
stitute an acceptable interpretation f (10a). In- 
stead, the model capturing the meaning of (10a) 
is the model given in (10d). 
(10) a. Jon, Bill and Dan like each other. 
b. RCPIAO({jon, bill, dan})()~y)~x like(x, y)) 
c. {like(yon, bill), like(bill, dan)} 
d. {like(ion, bill), like(jon, dan), like(bill, dan), 
like(bill, jon), like (dan, bill), like(dan, ion)} 
Since the MMH ma.ximises rather than min- 
imises the logical contribution of formulas, it 
seems at first sight incompatible with local min- 
imality. However, a simple method to combine 
the MMH and model minimality is to consider 
the maximisation of reciprocal relations as a 
minimisation of their complement sets. After 
all, the difference in acceptability between (10c) 
and (10d) as models for (10a) is due to exactly 
those pairs (x, y) (with x ~ y) that are not in 
the like relation. To capture this intuition, we 
introduce a special predicate $R that indicates 
assumptions whose truth is considered "costly". 
In our case, these assumptions correspond to the 
pairs of individuals that are not in the scope re- 
lation. The semantic representation f recipro- 
cal each other is then as follows. 
(11) RcP =__ )~P)~R (RCPIAo(P)(R) A 
VxVy (e(x) A P(y) A x ¢ y A -~R(x, y) ~=~ 
$R(x, y))) 
The first conjunct says that a reciprocal sen- 
tence has as weakest possible meaning an IAO 
reading. Since IAO is entailed by other identi- 
fied meaning for reciprocal statements, this is 
compatible with the fact that reciprocal sen- 
tences can have other, stronger meanings. The 
second conjunct says that each pair (x, y) (with 
x ¢ y) that is not  in the like relation is in 
the $R relation. This encoding leads to mod- 
els like (12b) and (12c) for (12a). We say that 
model (125) has a $R-cost of 4 ($R4), while 
model (12c) has a cost of 0. 
(12) a. RcP({jon, bill, dan})(XyXx like(x, y)) 
b. {like(ion, bill), like(ion, dan), $R(bill, dan), 
$R(bill, jon), SR(dan, bill), SR(dan, ion)} 
$R4 
c. {like(ion, bill), like(ion, dan), like(bill, dan), 
like(bill, ion), like(dan, bill), like(dan, ion)} 
$RO 
We now introduce a new form of minimality 
whose definition is as follows. 
Conservat ive  Min imal i ty :  Let ~ be a set 
of first-order formulas and D be the set of Her- 
brand models of ~2 with a minimal domain T). 
Then D has a subset C of models that carry 
a minimal cost. A model ( I ,D) E C is con- 
servative minimal iff there is no other model 
(I', D') E C such that I' C. I. 
Conservative minimality is a conservative ex- 
tension of local minimality: if there are no 
costs at all, then all local minimal models are 
322 
also conservative models. Conservative mini- 
reality is a combination of local minimality and 
cost minimisation that correctly identifies the 
preferred interpretation of reciprocal sentences. 
For instance since (12c) carries a minimal cost, 
it is a conservative minimal model for (12a) 
whereas (12b) isn't. Intuitively the approach 
works as follows: the more pairs there are that 
do not stand in the scope relation of the re- 
ciprocal, the bigger the SR predicate and the 
more costly (i.e. the least preferred) the model. 
That is, the combined use of a $R-predicate and 
of conservative minimality allows us to enforce 
a preference for interpretations (i.e. models) 
maximising R. 
3.3 The  System 
KIMBA (Konrad and Wolfram, 1999) is a finite 
model generator for first-order and higher-order 
logical theories that is based on a translation 
of logics into constraint problems over finite- 
domain integer variables. KIMBA uses an effi- 
cient constraint solver to produce solutions that 
can be translated back into Herbrand models of 
the input. 
We have tailored KIMBA such that it enumer- 
ates the conservative models of its input. In- 
tuitively, this works as follows. First, KIMBA 
searches for some arbitrary model of the input 
that mentions a minimum number of individu- 
als. Then, it takes the SR-cost of this model 
as an upper bound for the cost of all successor 
models and further minimises the cost as fax 
as possible by branch-and-bound search. After 
KIMBA has determined the lowest cost possi- 
ble, it restarts the model search and eliminates 
those models from the search space that have 
a non-minimal cost. For each model .h/\[ that 
it identifies as a cost-minimal one, it proves by 
refutation that there is no other cost-minimal 
model A/l t that uses only a subset of the pos- 
itive assumptions in A/\[. Each succesful proof 
yields a conservative minimal model. 
All the examples discussed in this paper have 
been tested on Kimba and can be tried out at: 
http://www.coli.uni-sb.de/cl/ 
projects /lisa/kimba.html 
3.4 A spect rum of possib le mean ings  
Let us see in more detail what the predictions of 
our analysis are. As we saw in section 2, recip- 
rocal statements can have very different ruth 
conditions. Intuitively, these truth-conditions 
lie on a spectrum from the weakest IAO inter- 
pretation (A is the antecedent set and R the 
scope relation): 
IAl >_ 2 A Vx E A(x) 3y (A(y) A x ¢ y 
^(R(x, y) v R(y, 
to the strongest so-called Strong Reciprocity 
(SR) interpretation namely: 
IAI > 2AVx g(x)Vy A(y)(x ~ y ==v R(x,y)) 
We now see how the MMH allows us to cap- 
ture this spectrum. 
Let us start with example (2) whose truth- 
conditions are the strongest Strong Reciprocity 
conditions: every distinct x and y in the an- 
tecedent set are related to each other by the 
scope relation. In this case, there is no con- 
straining world knowledge hence the content of 
the like relation can be fully maximised. For 
instance if there are five students, the cheapest 
model is one in which the cardinality of like is 
twenty (and consequently the cardinatity of $R 
is zero). 
(13) {like(sl, s2),/ike(sl, s3), like(sl, s4), 
/ike(sl, sh),/ike(s2, sl),/ike(s2, s3), 
like(s2, s4), like(s2, sh), like(s3, sl),  
like(s3, s2 ) , like(s3, s4), like(s3, sh), 
I;ke(s4, sl), like(s4, s3), like(s4, s2), 
like(s4, sh), like(sh, sl),  like(sh, s3), 
like( sh, s2), like( sh, s4) 
} $RO 
By contrast, example (3) has a much weaker 
meaning. In this case there is a strong world 
knowledge constraint at work, namely that one 
can stare at only one other person at some 
time. The cheapest models compatible with this 
knowledge are models in which every student 
stare at exactly one other student. Thus in a 
universe with five students, the preferred inter- 
pretations are models in which the cardinality 
of the scope relation x stares at y in surprise 
is five. The following are example models. For 
simplicity we ommit the $R propositions and 
give the cost of the model instead (i.e. the car- 
dinality of the complement set of the scope re- 
lation). 
(14) {stare_at(sl, s2), stare_at(s2, s3), 
stare_at(s3, s4), stare_at(s4, sh), 
stare_at( sh, s3)} $R15 
323 
(15) (stare_at(sl, s2), stare_at(s2, s3), 
stare_at(s3, s4), stare_at(s4, s5), 
stare_at(s5, sl)} $R15 
Sentence (4) illustrates an intermediate case 
with respect to strength of truth conditions. 
World knowledge implies that the scope rela- 
tion x give y measles is assymetric and further 
that every individual is given measles by at most 
one other individual. Given a set of five stu- 
dents, model (16) and (17) are both acceptable 
interpretations of (4), (16) being the preferred 
interpretation. 
(16) {gave_measles(sl, s2), gave_meas\]es(sl, s3), 
gave_measles(s2, s4), gave_measles(s3, s5)} 
$R16 
(17) (gave_measles(sl, s2), gave_measles(s2, 4), 
gave_measles(s3, s5)~} $R17 
In short, these examples how the MMH at 
work. They show how given a single seman- 
tic representation for reciprocals, a variety of 
meanings can be derived as required by each 
specific reciprocal statement. Two elements are 
crucial to the account: the use of model build- 
ing, and that of minimality as an implemen- 
tation of preferences. Model building allows 
us to compute all the finite interpretations of
a sentence that are consistent with contextual 
knowledge and with an IAO interpretation of
the reciprocal expression. Preferences on the 
other hand (i.e. the use of the cost predicate 
$R and the search for conservative mininal mod- 
els), permits choosing among these interpreta- 
tions the most likely one(s) namely, the inter- 
pretation(s) maximising the scope relation. 
4 Re la ted  Work  
(Dalrymple t al., 1998) (henceforth DKKMP) 
proposes the following taxonomy of mean- 
ings for reciprocal statements (A stands for 
the antecedent set and R for the scope relation): 
Strong Reciprocity (SR) 
Vx, y E A(x ¢ y ~ xRy). 
Intermediate reciprocity (IR) 
Vx, y E A 3zl , . . .3Zm E A(x 
xRzl  A . . . A ZmRy) 
~= y --+ 
One-way Weak Reciprocity (OWR) 
Vx E A 3y e A (xRy) 
Intermediate Alternative Reciprocity (IAR) 
Vx, y E A3zl, . . . 3Zm E A(x ~ y -+ 
(xRzl Y zlRx) A ... A (zmRy Y yRzm)) 
Inclusive Alternative Ordering (IAO) 
Vx E A Sy E A(xRy Y yRx) 
To predict the meaning of a specific recip- 
rocal sentence, DKKMP then postulate the 
Strongest Meaning Hypothesis which says that 
the meaning of a reciprocal sentence is the log- 
ically strongest meaning consistent with world 
and contextual knowledge. 
The main difference between the DKKMP ap- 
proach and the present approach lies in how 
the best reading is determined: it is the logi- 
cally strongest of the five postulated meanings 
in DKKMP, whereas in our approach, it is that 
reading which maximises the scope relation of 
the reciprocal. This difference has both empiri- 
cal and computational consequences. 
Empirically, the predictions are the same in 
most cases because maximising the scope rela- 
tion often results in yielding a logically stronger 
meaning. In particular, as is illustrated by the 
examples in section 2, the present approach cap- 
tures the five meanings postulated by DKKMP. 
Thus model (13) exemplifies an SR reading, 
model (15) an IR reading and model (14) an 
OWR reading. Further, model (16) is an IAR 
interpretation while model (17) shows an IAO 
reading. 
But as the examples also show there are 
cases where the predictions differ. In particu- 
lar, in the DKKMP approach, sentence (3) is 
assigned the IR reading represented by model 
(15). However as they themselves observe, the 
sentence also has a natural OWR interpretation 
namely, one as depicted in model (14), in which 
some pairs of students reciprocally stare at each 
other. This is predicted by the present approach 
which says that models (14) and (15) are equally 
plausible since they both maximise the stare at 
relation to cardinality five. 
On the other hand, the DKKMP account is 
more appropriate for examples uch as: 
(18) The students at next to each other 
a. forming a nice cercle. 
324 
b. filling the bench. 
c. some to the front and others to the back 
of the church. 
An IR interpretation is predicted for (18) 
which is compatible with both continuation 
(18a) and continuation (18b). By contrast, the 
model generation approach predicts that the 
preferred interpretation is a model in which the 
students form a circle, an interpretation com- 
patible with continuation (18a) but not with 
continuations (18b-c). 
However, both approaches fail to predict he 
reading made explicit by continuation (18c) 
since this corresponds to the weaker OWR in- 
terpretation under the DKKMP account and to 
a model which fails to maximise the scope re- 
lation under the present approach. More gen- 
erally, both approaches fail to capture the se- 
mantic vagueness of reciprocal statements illus- 
trated by the following examples1: 
(19) a. The students often help each other with 
their homework. 
b. In the closing minutes of the game, the 
members of the losing team tried to encour- 
age each other. 
In both cases, the sentences can be true with- 
out maximising either the strength of its truth 
conditions (Strong Reciprocity) or the scope re- 
lation. This suggests that an empirically more 
correct analysis of reciprocals hould involve 
prototypical and probabilistic knowledge - as 
it is essentially a computational pproximation 
of the DKKMP approach, the present account 
does not integrate such information though it is 
compatible with it: just as we restrict the set 
of generated models to the set of conservative 
minimal models, we could restrict it to the set 
of models having some minimal probability. 
Computationally, the difference between the 
DKKMP and the present approach is as fol- 
lows. In essence, the DKKMP approach re- 
quires that each of the five possible readings 
(together with the relevant world knoweldge) 
be checked for consistency: some will be con- 
sistent, others will not. Since the first order 
consistency and validity problems are not de- 
cidable, we know that there can be no method 
1I am thankfu l  to an anonymous NAACL referree for 
these examples. 
guaranteed to always return a result. In order 
to implement the DKKMP approach, one must 
therefore resort to the technique advocated in 
(Blackburn et al., 1999) and use both a theo- 
rem prover and a model builder: for each possi- 
ble meaning Mi, the theorem is asked to prove 
~Mi and the model builder to satisfy Mi. Mi is 
inconsistent if the theorem prover succeeds, and 
consistent if the model builder does. Theoreti- 
cally however, cases may remain where neither 
theorem proving nor model building will return 
an answer. If these cases occur in practice, the 
approach simply is not an option. Further, the 
approach is linguistically unappealing as it in 
essence requires the reciprocal each other to be 
five-way ambiguous. 
By contrast, the model generation approach 
assigns a single semantic representation to each 
other. The approach strengthens the logical 
contribution of the weak semantic representa- 
tion as a process based on computational con- 
straints on a set of effectively enumerable mod- 
els. As a result, we will never encounter un- 
decidable logical problems as long as the repre- 
sented iscourse is consistent. The model gener- 
ator is the only computational tool that we need 
for determining preferable readings, and our ex- 
periment shows that for the examples discussed 
in this paper, it returns preferred readings in 
a few seconds on standard PCs as long as the 
background theory and the size of the domain 
remain managably small. 
5 Conc lus ion  
We have argued that model building can be used 
to provide a computational pproximation of 
DKKMP's analysis of reciprocals. 
One crucial feature of the account is that 
it permits building, comparing and ranking of 
natural-language interpretations against each 
other. In the case of reciprocals, the ranking is 
given by the size of the scope relation, but other 
ranking criteria have already been identified in 
the literature as well. For instance, (Gardent 
and Konrad, To appear) shows that in the case 
of definite descriptions, the ranking defined by 
local minimality permits capturing the prefer- 
ence of binding over bridging, over accomoda- 
tion. Similarly (Baumgartner and Kiihn, 1999) 
shows that a predicate minimisation together 
with a preference for logically consequent reso- 
325 
lutions can be used to model the interpretation 
of pronominal anaphora. 
This suggests that one of the most promising 
application of model generators i  as a device for 
developing and testing preference systems for 
the interpretation of natural language. Infer- 
ence and knowledge based reasoning are needed 
in NLP not only to check for consistency and 
informativity (as illustrated in e.g. (Blackburn 
et al., 1999)), but also to express preferences 
between, or constraints on, possible interpreta- 
tions. For this, finite model builders are natural 
tools. 
Another area that deserves further investi- 
gation concerns the use of minimality for dis- 
ambiguation. In this paper, conservative min- 
imality is used to choose among the possible 
interpretations of a particular eciprocal state- 
ment. On the other hand, (Gardent and Web- 
ber, January 2000) shows that minimality is 
also an important tool for disambiguating oun- 
compounds, logical metonymy and definite de- 
scriptions. As the paper shows though, many 
questions remains open about this use of mini- 
mality for disambiguation which are well worth 
investigating. 
In further work, we intend to look at other 
ambiguous natural anguage constructs and to 
identify and model the ranking criteria deter- 
mining their preferred interpretation. Plurals 
are a first obvious choice. But more generally, 
we hope that looking at a wider range of data 
will unveil a broader picture of what the gen- 
eral biases are which help determine a preferred 
reading - -  either in isolation, as here, or in con- 
text, as in (Gardent and Webber, January 2000) 
- -  and of how these biases can be modelled us- 
ing automated reasoning systems. 
Acknowledgement  s 
We are grateful to audiences from ITRI- 
Brighton, the Edinburgh School of Cognitive 
Science, the Paris VI TALANA seminar and the 
Amsterdam DIP colloquium for helpful com- 
ments and discussion on the material presented 
here as well as to the three NAACL anony- 
mous referrees for constructive feedback. This 
work was partially supported by the Project 
C2 (LISA) in SFB-378, grant by the Deutsche 
Forschungsgemeinschaft to the University of 
Saarbriicken. 
References  
Peter Baumgartner and Michael Kiihn. 1999. 
Abductive coreference by model construction. 
In ICoS-1 Inference in Computational Se- 
mantics, Institute for Logic, Language and 
Computation, University of Amsterdam, Au- 
gust. 
P. Blackburn, J. Bos, M. Kohlhase, and 
H. de Neville. 1999. Inference and Com- 
putational Semantics. In Third Interna- 
tional Workshop on Computational Seman- 
tics (IWCS-3), Tilburg, The Netherlands. 
Mary Dalrymple, Makoto Kanasawa, Yookyung 
Kim, Sam Mchombo, and Stanley Peters. 
1998. Reciprocal expressions and the con- 
cept of reciprocity. Linguistics and Philoso- 
phy, 21(2):159-210, April. 
Claire Gardent and Karsten Konrad. 1999. 
Definites and the proper treatment of rabbits. 
In Proceedings of ICOS. Also CLAUS Report 
111, http://www.coli.uni-sb.de/claus/. 
Claire Gardent and Karsten Konrad. To ap- 
pear. Interpreting Definites using Model 
Generation. Journal of Language and Com- 
putation. 
Claire Gardent and Bonnie Webber. Jan- 
uary 2000. Automated deduction and 
discourse disambiguation. Submitted for 
Publication. Also CLAUS Report 113, 
http://www.coli, uni-sb.de/claus/. 
P.N. Johnson-Laird and Ruth M.J. Byrne. 
1991. Deduction. Lawrence Erlbaum Asso- 
ciates Publishers. 
Hans Kamp and Uwe Reyle. 1993. From Dis- 
course to Logic. Kluwer, Dordrecht. 
Hans Kamp. 1981. A theory of truth and 
semantic representation. In J. Groenendijk, 
Th. Janssen, and M. Stokhof, editors, Formal 
Methods in the Study of Language, pages 277 
- 322. Mathematisch Centrum Tracts, Ams- 
terdam. 
Karsten Konrad and D. A. Wolfram. 1999. 
Kimba, a model generator for many-valued 
first-order logics. In Proc., 16th Interna- 
tional Conference on Automated Deduction, 
CADE 99, LNCS, forthcoming, Trento, Italy. 
Springer. 
D. Terence Langendoen. 1978. The logic of reci- 
procity. Linguistic Inquiry, 9(2):177-197. 
326 
