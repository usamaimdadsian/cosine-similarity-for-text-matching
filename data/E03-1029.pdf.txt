Automatic Construction of Machine Translation Knowledge
Using Translation Literalness
Kenji Imamura, Eiichiro Sumita
ATR Spoken Language Translation
Research Laboratories
Seika-cho, Soraku-gun, Kyoto, Japan
{kenji.imamura,eiichiro.sumita}@atrcojp
Yuji Matsumoto
Nara Institute of
Science and Technology
Ikoma-shi, Nara, Japan
matsu@is.aist-nara.acjp
Abstract
When machine translation (MT) knowl-
edge is automatically constructed from
bilingual corpora, redundant rules are
acquired due to translation variety.
These rules increase ambiguity or cause
incorrect MT results. To overcome
this problem, we constrain the sentences
used for knowledge extraction to "the
appropriate bilingual sentences for the
MT." In this paper, we propose a method
using translation literalness to select ap-
propriate sentences or phrases. The
translation correspondence rate (TCR)
is defined as the literalness measure.
Based on the TCR, two automatic con-
struction methods are tested. One is to
filter the corpus before rule acquisition.
The other is to split the acquisition pro-
cess into two phases, where a bilingual
sentence is divided into literal parts and
the other parts before different gener-
alizations are applied. The effects are
evaluated by the MT quality, and about
4.9% of MT results were improved by
the latter method.
1 Introduction
Along with the efforts made to accumulate bilin-
gual corpora for many language pairs, quite a few
machine translation (MT) systems that automati-
cally construct their knowledge from corpora have
been proposed (Brown et al., 1993; Menezes and
Richardson, 2001; Imamura, 2002). However,
if we use corpora without any restriction, redun-
dant rules are acquired due to translation varieties.
Such rules increase ambiguity and may cause in-
appropriate MT results.
Translation variety increases with corpus size.
For instance, large corpora usually contain mul-
tiple translations of the same source sentences.
Moreover, peculiar translations that depend on
context or situation proliferate in large corpora.
Our targets are corpora that contain over one hun-
dred thousand sentences.
To reduce the influence of translation vari-
ety, we attempt to control the bilingual sentences
that are appropriate for machine translation (here
called "controlled translation"). Among the mea-
sures that can be used for controlled translation,
we focus on translation literalness in this pa-
per. By restricting bilingual sentences during MT
knowledge construction, the MT quality will be
improved.
The remainder of this paper is organized as fol-
lows. Section 2 describes the problems caused by
translation varieties. Section 3 discusses the kinds
of translations that are appropriate for MTs. Sec-
tion 4 introduces the concept of translation literal-
ness and how to measure it. Section 5 describes
construction methods using literalness, and Sec-
tion 6 evaluates the construction methods.
2 Problems Caused by Translation
Variety
First, we describe the problems inherent in bilin-
gual corpora when we automatically construct MT
knowledge.
2.1 Context/Situation-dependent Translation
Some bilingual sentences in corpora depend on the
context or situation, and these are not always cor-
rect in different contexts.
155
For instance, the English determiner 'the' is not
generally translated into Japanese. However, when
a human translator cannot semantically identify
the following noun, a determinant modifier such
as `watashi-no (my)' or 'son° (its)' is supplied.
As an example of a situation-dependent trans-
lation, the Japanese sentence "Shashin wo tot-te
itadake masu ka? (Could you take our photo-
graph?)" is sometimes translated into an English
sentence as "Could you press this shutter button?"
This translation is correct from the viewpoint of
meaning, but it can only be applied when we want
a photograph to be taken. Such examples show
that most context/situation-dependent translations
are non-literal.
MT knowledge constructed from
context/situation-dependent translations cause
incorrect target sentences, which may contain
omissions or redundant words, when it is applied
to an inappropriate context or situation.
2.2 Multiple Translations
Generally speaking, a single source expression
can be translated into multiple target expressions.
Therefore, a corpus contains multiple translations
even though they are translated from the same
source sentence. For example, the Japanese sen-
tence "Kono toraberaazu chekku wo genkin ni
shite kudasai" can be translated into English any
of the following sentences.
• I'd like to cash these traveler's checks.
• Could you change these traveler's checks into
cash?
• Please cash these traveler's checks.
These translations are all correct. Actually, the
corpus of Takezawa et al. (2002) contains ten dif-
ferent translations of this source sentence. When
we construct MT knowledge from corpora that
contain such variety, redundant rules are acquired.
For instance, a pattern-based MT system described
in Imamura (2002) acquires different transfer rules
from each multiple translations, although only one
rule is necessary for translating a sentence. Redun-
dant rules increase ambiguity or decrease transla-
tion speed (Meyers et al., 2000).
3 Appropriate Translation for MTs
3.1 Controlled Translation
Controlled language (Mitamura et al., 1991; Mi-
tamura and Nyberg, 1995) is proposed for mono-
lingual processing in order to reduce variety.
This method allows monolingual texts within a
restricted vocabulary and a restricted grammar.
Texts written by the controlled language method
have fewer semantic and syntactic ambiguities
when they are read by a human or analyzed by a
computer.
A similar idea can be applied to bilingual cor-
pora. Namely, the expressions in bilingual corpora
should be restricted, and "translations that are ap-
propriate for the MT" should be used in knowl-
edge construction. This approach assumes that
context/situation-dependent translations should be
removed before construction so that ambiguities
in MT can be decreased. Restricted bilingual sen-
tences are called controlled translations in this pa-
per.
The following measures are assumed to be
available for controlled translation. First three
measures are for each of the bilingual sentences in
the corpus and the fourth measure is for the whole
corpus:
• Literalness: Few omissions or redundant
words appear between the source and target
sentences. In other words, most words in the
source sentence correspond to some words in
the target sentence.
• Context-freeness: Source word sequences
correspond to the target word sequences inde-
pendent of the contextual information. With
this measure, partial translation can be reused
in other sentences.
• Word-order Agreement: The word order of
a source sentence agrees substantially with
that of a target sentence. This measure en-
sures that the cost of word order adjustment
is small.
•
Word Translation Stability: A source word
is better translated into the same target word
through the corpus.
For example, the Japanese adjectival verb
`hitstiyoo-da' can be translated into the En-
156
glish adjective 'necessary,' the verb 'need,'
or the verb 'require.' It is better for an
MT system to always translate this word into
'necessary,' if possible.
Effective measures of controlled translation de-
pend on MT methods. For example, word-level
statistical MT (Brown et al., 1993) translates a
source sentence with a combination of word trans-
fer and word order adjustment. Thus, word-
order agreement is an important measure. On the
other hand, this is not important for transfer-based
MTs because the word order can be significantly
changed through syntactic transfer. A transfer-
based MT method using the phrase structure is
studied here.
3.2 Base MT System
We use Hierarchical Phrase Alignment-based
Translator (HPAT) (Imamura, 2002) as the tar-
get transfer-based MT system. HPAT is an new
version of Transfer Driven Machine Translator
(TDMT) (Furuse and Iida, 1994). Transfer rules
of HPAT are automatically acquired from a paral-
lel corpus, but those of TDMT were constructed
manually.
The procedure of HPAT is briefly described as
follows (Figure 1). First, phrasal correspondences
are hierarchically extracted from a parallel cor-
pus using Hierarchical Phrase Alignment (Ima-
mura, 2001). Next, the hierarchical correspon-
dences are transferred into patterns, and transfer
rules are generated. At the time of translation, the
input sentence is parsed by using source patterns
in the transfer rules. The MT result is generated
by mapping the source patterns to the target pat-
terns. Ambiguities, which occur during parsing or
mapping, are solved by selecting the patterns that
minimize the semantic distance between the input
sentence and the source examples (real examples
in the training corpus).
3.3 Appropriate Translation for
Transfer-based MT
In order to verify effective measures of controlled
translation for transfer-based MTs, we review the
fundamentals of TDMT in this section.
TDMT was trained by human rule writers. They
selected bilingual sentences from a corpus one by
Parallel Corpus
Input Sentence
Source Sentence Target Sentence
Hierarchical
Phrase Alignment Knowledge-
Phr sal MT Engine
Cor
and
espondences
Its Hierarchy Transfer Rules
MT ResultTransfer Rule
Generation Transfer Rules
Knowledge Construction 	 Machine Translation
Figure 1: Overview of HPAT: Knowledge Con-
struction and Translation Process
one and added or arranged the transfer rules in or-
der to translate the sentences. The target sentences
were then rewritten with the aim of minimizing the
number of transfer rules. We believe that this way
of rewritten translation is appropriate examples for
TDMT.
We compared 6,304 bilingual sentences rewrit-
ten for an English-to-Japanese version of TDMT
and the original translations in the corpus 1 . The
statistics in Table 1 show that the following mea-
sures are effective for transfer-based MT. Note
that these data were calculated from the results of
morphological analysis and word alignment (c.f.,
Section 6). The correspondences output from the
word aligner are called word links.
Literalness Focusing on the number of linked
target words, the value of the rewritten transla-
tions is considerably higher than that of the origi-
nal translations. This result shows that the words
of source sentences are translated into target words
more directly in the case of the rewritten transla-
tions. Thus, the rewritten translations are more lit-
eral.
Word Translation Stability Focusing on the
number of different words in the target language
and the mean number of translation words, both
values of the rewritten translations are lower than
those of the original translations. This is because
1 When TDMT translates input sentences already trained,
the MT results become identical to the objective translations
for the rule writer. Therefore, the rewritten translations were
acquired by translating trained sentences by TDMT.
157
# of Linked Target Words
# of Different Words in Target Language
Mean # of Translation Words per Source Word
Mean Context-freeness (# of Word Link = 4)
28,300 words (49.5%)
3,107 words
1.51 trans./word
4.45
20,722 words (34.0%)
3,601 words
1.94 trans./word
4.21
Rewritten Translations	 Original Translations
Table 1: Comparison of TDMT Training Translations and Original Translations
the rule writers rewrote translations to make tar-
get words as simple as possible, and thus the vari-
ety of target words was decreased. In other words,
the rewritten translations are more stable from the
viewpoint of word translation.
Context-freeness Mean context-freeness in Ta-
ble 1 denotes the mean number of word-link com-
binations in which word sequences of the source
and the target contain word links only between
their constituents (cross-links are allowed). If a
bilingual sentence can be divided into many trans-
lation parts, this value become high. This value
depends on the number of word links When it
is calculated only from the sentences that contain
four word links, the value of the rewritten transla-
tions is higher than that of the original translations.
4 Translation Literalness
We particularly focus on the literalness among
the controlled translation measures in order
to reduce the incorrect rules that result from
context/situation-dependent translations. Word
translation stability and context freeness must
serve as countermeasures for multiple translations,
since they ensure that word translations and struc-
tures are steady throughout the corpus. However,
the reduction of incorrect translations is done prior
to the reduction of ambiguities.
4.1 Literalness Measure
A literal translation means that source words are
translated one by one to target words. Therefore, a
bilingual sentence that has many word correspon-
dences is literal. The word correspondences can
be acquired by referring to translation dictionaries
or using statistical word aligners (e.g., (Melamed,
2000)).
However, not all source words always have an
exact corresponding target word. For example, in
the case of English and Japanese, some preposi-
tions are not translated into Japanese. On the con-
trary, the preposition 'after' may be translated into
Japanese as the noun `ato.' These examples show
that some functional words have to be translated
while others do not. Thus, literalness is not deter-
mined only by counting word correspondences but
also by estimating how many words in the source
and target sentences have to be translated.
Based on the above discussion, the translation
literalness of a bilingual sentence is measured by
the following procedure. Note that a translation
dictionary is utilized in this procedure. The dic-
tionary is automatically constructed by gathering
the results of word alignment at this time, though
hand-made dictionaries may also be utilized. In
this process, we assume that one source word cor-
responds to one target word.
1. Look up words in the translation dictionary
by the source word. T, denotes the number of
source words found in the dictionary entries.
2. Look up words in the dictionary by target
words. Tt denotes the number of target words
found in the definition parts of the dictionary.
3. If there is an entry that includes both the
source and target word, the word pair is re-
garded as the word link L denotes the num-
ber of word links.
4. Calculate the literalness with the following
equation, which we call the Translation Cor-
respondence Rate (TCR) in this paper.
TCR =
2L (1)Ts + Tt
The TCR denotes the portion of the directly
translated words among the words that should
be translated. This definition is bi-directional,
158
Target 1 (English)
Source (Japanese:
Target 2 (English)
Word Links and Words in the Dictionary
4111M va	 wo
is Cihfferet from what 0
Ts,Tt TCR
dei muse
ordere
Figure 2: Example of Measuring Literalness Using Translation Correspondence Rate
(Circled words denote words found in the dictionary.
Lines between sentences denote word links.)
so omission and redundancy can be measured
equally. Moreover, the influence of the dictionary
size is low because the words that do not appear in
the dictionary are ignored.
For example, suppose that a Japanese source
sentence (Source) and its English translations
(Targets 1 and 2) are given as shown in Figure 2.
Target 1 is a literal translation, and Target 2 is a
non-literal translation, while the meaning is equiv-
alent. When the circled words are those found in
the dictionary, Ts is five, and TL of Target 1 is also
five. There are five word links between Source and
Target 1, so the TCR is 1.0 by Equation (1).
On the other hand, in the case of Target 2, four
words are found in the dictionary (Tt = 4), and
there are three word links. Thus, the TCR is
*3 
"' 0.67, and Target 1 is judged as more lit-5+4 —
eral than Target 2.
The literalness based on the TCR is judged from
a tagged result and a translation dictionary. In
other words, 'deep analyses' such as parsing are
not necessary.
5 Knowledge Construction Using
Translation Literalness
In this section, two approaches for constructing
translation knowledge are introduced. One is
bilingual corpus filtering, which selects highly lit-
eral bilingual sentences from the corpus. Filtering
is done as preprocessing before rule acquisition.
The other is split construction, which divides a
bilingual sentence into literal and non-literal parts
and applies different generalization strategies to
these parts.
5.1 Bilingual Corpus Filtering
We consider two approaches to corpus filtering.
Filtering Based on Threshold A partial cor-
pus is created by selecting bilingual sentences
with TCR values higher than a threshold, and MT
knowledge is constructed from the extracted cor-
pus. By making the threshold higher, the coverage
of MT knowledge will decrease because the size
of the extracted corpus becomes smaller.
Filtering Based on Group Maximum First,
sentences that have the identical source sentence
are grouped together, and a partial corpus is cre-
ated by selecting the bilingual sentences that have
the maximal TCR from each group. As opposed
to filtering based on a threshold, all source sen-
tences are used for knowledge construction, so the
coverage of MT knowledge can be maintained.
However, some context/situation-dependent trans-
lations remain in the extracted corpus when only
one non-literal translation is in the corpus.
5.2 Split Construction into Literal and Other
Parts
The TCR can be calculated not only for sentences
but also for phrases. In the case of filtering,
the coverage of the MT knowledge is decreased
by limiting translation to highly literal sentences.
However, even though they are non-literal, such
sentences may contain literal translations at the
phrase level. Thus, the coverage can be main-
tained if we extract literal phrases from non-literal
sentences and construct knowledge from them.
A problem with this approach is that non-literal
bilingual sentences sometimes contain idiomatic
159
Source (Japanese) 	 Shinai no kankoo tsucta wa an masu ka
Target 1 (English) 	 Target 2 (English)
I want to look around the city. 	 Do you have any sightseeing tours of the city?
Phrase TCR Generated Transfer Rule 	 Phrase TCR Generated Transfer Rule
(A-1) S 0.25 X/NP no kankoo tsuaa wa an masu ka 	 (B-1) S 1.0 X/VP tnasu ka => Do you X/VP
=> I want to look around X/NP 	 (B-2) VP 1.0 X/NP wa Y/VP => Y/VP X/NP
(A-2) NP 1.0 shinai => the city	 (B-3) NP 1.0 X/NP no Y/NP => Y/NP Of X/NP
(B-4) NP 1.0 shinai => the city
(B-5) NP 1.0 kankoo tsuaa => any sightseeing tours
(B-6) VP 1.0 an => have
(A) Non-literal Translation
	 (B) Literal Translation
Figure 3: Examples of Generated Rules for Japanese-to-English Translation
(A) from Non-literal Translation by Split Construction (B) from Literal Translation.
translations that should not be translated literally.
For example, the Japanese greeting "Hajime mashi
te" should be translated into "How do you do," not
into its literal translation, "For the first time." Such
idioms are usually represented by a long word se-
quence.
To cope with literal and idiomatic translations,
a sentence is divided into literal and non-literal
parts, and a different construction is applied. Short
rules, which are more generalized and easier to
reuse, are generated from the literal parts. Long
rules, which are more strict in their use in MT, are
generated from the non-literal parts. The proce-
dure is described as follows.
1. Phrasal correspondences are acquired by Hi-
erarchical Phrase Alignment.
2. The hierarchy is traced from top to bottom,
and the literalness of each correspondence is
measured. If the TCR is equal to or higher
than the threshold, the phrase is judged as
a literal phrase and the tracing stops before
reaching the bottom.
3. If the phrase is literal, transfer rules that in-
clude its lower hierarchy are generalized.
4. If the top structure (i.e., entire sentence) is
not literal, a rule is generated in which only
the literal parts are generalized.
For example, suppose that different target sen-
tences from the same source are given as shown
in Figure 3. The phrase (A-1 )S has low TCR, but
the TCR of the noun phrase pair shinai' and 'the
city' has 1.0. Thus, the phrase (A-2)N P is gener-
alized, and the long transfer rule (A-1 )S is gener-
ated from the non-literal translation. On the con-
trary, the TCR of the top phrase (B-1 )S is 1.0, so
all phrases in (B) are generalized and totally six
rules are generated. The rules generated from lit-
eral translations are general, and they will be used
for the translation of the other sentences.
Thus, by using the split construction, rules like
templates are generated from non-literal transla-
tions and primary rules for transfer-based MT are
generated only from literal phrases. Rules gen-
erated from non-literal translations are used only
when the input word sequence exactly matches
the sequence in the rule. In other words, they are
hardly used in different contexts.
6 Translation Experiments
In order to evaluate the effect of literalness in MT
knowledge construction, we constructed knowl-
edge by using the methods described in Section
5 and evaluated the MT quality of the resulting
English-to-Japanese translation.
6.1 Experimental Settings
Bilingual Corpus We used as the training set
149,882 bilingual sentences from the Basic Travel
Expression Corpus (Takezawa et al., 2002). This
corpus is a collection of Japanese sentences and
their English translations based on expressions
that are usually found in phrasebooks for foreign
tourists. There are many bilingual sentences in
160
which the source sentences are the same but the
targets are not. About 13% of different English
sentences have multiple Japanese translations.
Translation Dictionary: Extraction of Word
Correspondence For word correspondences
that occur more than nine times in the corpus,
statistical word alignment was carried out by a
similar method to Melamed (2000). When words
for which the correspondence could not be found
remain, a thesaurus (Ohno and Hamanishi, 1984)
was used to create correspondences to the words
of the same group. A translation dictionary was
constructed as a collection of the word correspon-
dences. The accuracy of this word aligner is about
90% for precision and 73% for recall by a closed
test of content words.
Evaluation for MT Quality We used the fol-
lowing two methods to evaluate MT quality.
1. Automatic Evaluation
We used BLUE (Papineni et al., 2002) with
10,150 sentences that were reserved for the test
set. The number of references was one for each
sentence, and a range from uni-gram to four-
gram was used.
2. Subjective Evaluation
From the above-mentioned test set, 510 sen-
tences were evaluated by paired comparison.
In detail, the source sentences were translated
using the base rule set created from the en-
tire corpus, and the same sources were trans-
lated using the rules constructed with literal-
ness. One by one, a Japanese native speaker
judged which MT result was better or that they
were of the same quality. Subjective quality is
represented by the following equation, where I
denotes the number of improved sentences and
D denotes the number of degraded sentences.
— D
Subj. Quality =  	 (2)
# of test sentences
6.2 MT Quality vs. Construction Methods
The level of MT quality achieved by each of
the construction methods is compared in Table
2. Coverage of exact rules denotes the portion of
sentences that were translated by using only the
rules that require the source example to exactly
match the input sentence. In addition, the thresh-
old TCR > 0.4 was used for filtering because
it was experimentally shown to be the best value.
In the case of split construction, we used the ex-
tracted corpus after filtering based on the group
maximum, and phrases that were TCR > 0.8
were judged to be literal phrases.
First, focusing on the filtering, the subjective
qualities or the BLEU scores are better than the
base in both methods. Comparing the threshold
with the group maximum, the BLEU score is in-
creased by the group maximum. The coverage of
the exact rules is higher even if the corpus size de-
creases. Filtering based on the group maximum
improves the quality while maintaining the cover-
age of the knowledge.
Although we used a high-density corpus where
many English sentences have multiple Japanese
translations, the quality improved by only about
1%. It is difficult to significantly improve the qual-
ity by bilingual corpus filtering because it is dif-
ficult to both remove insufficiently literal transla-
tions and maintain coverage of MT knowledge.
On the other hand, the BLEU score and the sub-
jective quality both improved in the case of split
construction, even though the coverage of the ex-
act rules decreased. In particular, the subjective
quality improved by about 4.9%. Incorrect trans-
lations were suppressed because the rules gener-
ated from non-literals are restricted when the MT
system applies them.
In summary, all construction methods helped to
improve the BLEU scores or the subjective quali-
ties; therefore, construction with translation liter-
alness is an effective way to improve MT quality.
7 Conclusions
In this paper, we proposed restricting the trans-
lation variety in bilingual corpora by controlled
translation, which limits bilingual sentences to the
appropriate translations for MT. We focused on
literalness from among the various measures for
controlled translation and defined a Translation
Correspondence Rate for calculating literalness.
Less literal translations could be removed by fil-
161
Entire Corpus
Base
Filtering Split Construction
(TCR> 0.8)Threshold
(TCR> 0.4)
Group
Maximum
# of Translations (Size Ratio) 149,882 (100%) 129,069(86.1%) 118,686(79.2%) 118,686(79.2%)
Coverage of Exact Rules 67.1 % 65.1 % 66.3 % 60.6 %
BLEU Score 0.225 0.224 0.231 0.240
Subjective Quality
# of Improved Sentences
# of Same Quality (Same Results)
# of Degraded Sentences
+1.4 %
26
465 (421)
19
+0.6 %
31
451 (393)
28
+4.9 %
116
303 (182)
91
Table 2: MT Quality vs. Construction Methods
tering according to the TCR, and this slightly im-
proved the MT quality.
The TCR is capable of measuring literalness not
only for bilingual sentences but also for phrases.
In other words, a bilingual sentence can be divided
into literal phrases and other phrases. Using this
feature, sentences were divided into literal parts
and non-literal parts, and transfer rules that could
be applied with strong conditions were generated
from the non-literal parts. As a result, MT qual-
ity as judged by subjective evaluation improved in
about 4.9% of the sentences.
Word translation stability and context-freeness
were also effective measures. MT quality is ex-
pected to be further improved by using these mea-
sures because they reduce multiple translations.
Acknowledgment
The research reported here is supported in part by
a contract with the Telecommunications Advance-
ment Organization of Japan entitled, "A study of
speech dialogue translation technology based on a
large corpus."
References
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993. The
mathematics of machine translation: Parameter esti-
mation. Computational Linguistics, l 9(2):263-31 .
Osamu Furuse and Hitoshi Iida. 1994. Constituent
boundary parsing for example-based machine trans-
lation. In Proceedings of COLING-94, pages 105-
111.
Kenji Imamura. 2001. Hierarchical phrase align-
ment harmonized with parsing. In Proceedings of
NLPRS-2001, pages 377-384.
Kenji Imamura. 2002. Application of translation
knowledge acquired by hierarchical phrase align-
ment for pattern-based MT. In TMI-2002, pages 74-
84.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics,
26(2):221-249, June.
Arul Menezes and Stephen D. Richardson. 2001. A
best first alignment algorithm for automatic extrac-
tion of transfer mappings from bilingual corpora.
In Proceedings of the 'Workshop on Example-Based
Machine Translation' in MT Summit VIII, pages 35-
42.
Adam Meyers, Michiko Kosaka, and Ralph Grishman.
2000. Chart-based translation rule application in
machine translation. In Proceedings of COLING-
2000, pages 537-543.
Teruko Mitamura and Eric H. Nyberg. 1995. Con-
trolled English for knowledge-based MT: Experi-
ence with the KANT system. In Proceedings of
TMI-95.
Teruko Mitamura, Eric H. Nyberg, and Jamie G. Car-
bonell. 1991. An efficient interlingua translation
system for multi-lingual document production. In
Proceedings of MT Summit III, pages 55-61.
Susumu Ohno and Masato Hamanishi. 1984. Ruigo-
Shin-Jiten. Kadokawa, Tokyo (in Japanese).
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In ACL-2002, pages
311-318.
Toshiyuki Takezawa, Eiichiro Sumita, Fumiaki Sug-
aya, Hirofumi Yamamoto, and Seiichi Yamamoto.
2002. Toward a broad-coverage bilingual corpus for
speech translation of travel conversations in the real
world. In LREC 2002, pages 147-152.
162
