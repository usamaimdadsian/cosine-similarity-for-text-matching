Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 930–940,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics
Improving Bilingual Projections via Sparse Covariance Matrices
Jagadeesh Jagarlamudi
University of Maryland
College Park, USA
jags@umiacs.umd.edu
Raghavendra Udupa
Microsoft Research
Bangalore, India
raghavu@microsoft.com
Hal Daume´ III
University of Maryland
College Park, USA
hal@umiacs.umd.edu
Abhijit Bhole
Microsoft Research
Bangalore, India
v-abbhol@microsoft.com
Abstract
Mapping documents into an interlingual rep-
resentation can help bridge the language bar-
rier of cross-lingual corpora. Many existing
approaches are based on word co-occurrences
extracted from aligned training data, repre-
sented as a covariance matrix. In theory, such
a covariance matrix should represent seman-
tic equivalence, and should be highly sparse.
Unfortunately, the presence of noise leads to
dense covariance matrices which in turn leads
to suboptimal document representations. In
this paper, we explore techniques to recover
the desired sparsity in covariance matrices in
two ways. First, we explore word association
measures and bilingual dictionaries to weigh
the word pairs. Later, we explore different
selection strategies to remove the noisy pairs
based on the association scores. Our experi-
mental results on the task of aligning compa-
rable documents shows the efficacy of sparse
covariance matrices on two data sets from two
different language pairs.
1 Introduction
Aligning documents from different languages arises
in a range of tasks such as parallel phrase extrac-
tion (Gale and Church, 1991; Rapp, 1999), mining
translations for out-of-vocabulary words for statis-
tical machine translation (Daume III and Jagarla-
mudi, 2011) and document retrieval (Ballesteros and
Croft, 1996; Munteanu and Marcu, 2005). In this
task, we are given a comparable corpora and some
documents in one language are assumed to have a
comparable document in the other language and the
goal is to recover this hidden alignment. In this pa-
per, we address this problem by mapping the docu-
ments into a common subspace (interlingual repre-
sentation). This common subspace generalizes the
notion of vector space model for cross-lingual ap-
plications (Turney and Pantel, 2010).
Most of the existing approaches use manually
aligned document pairs to find a common subspace
in which the aligned document pairs are maximally
correlated. The sub-space can be found using ei-
ther generative approaches based on topic modeling
(Mimno et al., 2009; Jagarlamudi and Daume´ III,
2010; Zhang et al., 2010; Vu et al., 2009) or dis-
criminative approaches based on variants of Princi-
pal Component Analysis (PCA) and Canonical Cor-
relation Analysis (CCA) (Susan T. Dumais, 1996;
Vinokourov et al., 2003; Platt et al., 2010; Haghighi
et al., 2008). Both styles rely on document level
term co-occurrences to find the latent representation.
The discriminative approaches capture essential
word co-occurrences in terms of two monolingual
covariance matrices and a cross-covariance matrix.
Subsequently, they use these covariance matrices to
find projection directions in each language such that
aligned documents lie close to each other (Sec. 2).
The strong reliance of these approaches on the co-
variance matrices leads to problems, especially with
the noisy data caused either by the noisy words
in a document or the noisy document alignments.
Noisy data is not uncommon and is usually the case
with data collected from community based resources
such as Wikipedia. This degrades performance of a
930
variety of tasks, such as transliteration Mining (Kle-
mentiev and Roth, 2006; Hermjakob et al., 2008;
Ravi and Knight, 2009) and multilingual web search
(Gao et al., 2009).
In this paper, we address the problem of identi-
fying and removing noisy entries in the covariance
matrices. We address this problem in two stages.
In the first stage, we explore the use of word asso-
ciation measures such as Mutual Information (MI)
and Yule’s ? (Reis and Judd, 2000) in computing
the strength of a word pair (Sec. 3.1). We also
explore the use of bilingual dictionaries developed
from cleaner resources such as parallel data. In the
second stage, we use the association strengths in fil-
tering out the noisy word pairs from the covariance
matrices. We pose this as a word pair selection prob-
lem and explore multiple strategies (Sec. 3.2).
We evaluate the utility of sparse covariance ma-
trices in improving the bilingual projections incre-
mentally (Sec. 4). We first report results on syn-
thetic multi-view data where the true correspon-
dences between features of different views are avail-
able. Moreover, this also lets us systematically ex-
plore the effect of noise level on the accuracy. Our
experimental results show a significant improvement
when the true correspondences are available. Later,
we report our experimental results on the document
alignment task on Europarl and Wikipedia data sets
and on two language pairs. We found that sparsify-
ing the covariance matrices helps in general, but us-
ing cleaner resource such bilingual dictionaries per-
formed best.
2 Canonical Correlation Analysis (CCA)
In this section, we describe how Canonical Correla-
tion Analysis is used to solve the problem of align-
ing bilingual documents. We mainly focus on repre-
senting the solution of CCA in terms of covariance
matrices. Since most of the existing discriminative
approaches are variants of CCA, showing the advan-
tage of recovering sparseness in CCA makes it appli-
cable to the other variants as well.
Given a training data of n aligned document pairs,
CCA finds projection directions for each language,
so that the documents when projected along these di-
rections are maximally correlated (Hotelling, 1936).
Let X (d1×n) and Y (d2×n) be the representation
of data in both the languages and further assume that
the data is centered (subtract the mean vector from
each document i.e. xi?xi?µx and yi ? yi?µy).
Then CCA finds projection directions a and b which
maximize:
aTXY Tb?
aTXXTa
?
bTY Y Tb
s.t. aTXXTa = 1 & bTY Y Tb = 1
The projection directions are obtained by solving the
generalized eigen system:
[
0 Cxy
Cyx 0
] [
a
b
]
=
[
(1-?)Cxx+?I 0
0 (1-?)Cyy+?I
] [
a
b
]
(1)
where Cxx = XXT , Cyy = Y Y T are the monolin-
gual covariance matrices, Cxy = XY T is the cross-
covariance matrix and ? is the regularization param-
eter. Using these eigenvectors as columns, we form
the projection matrices A and B. These projection
matrices are used to map documents in both the lan-
guages into interlingual representation.
Given any new pair of documents, their similarity
is computed by first mapping them into the lower di-
mensions space and computing the cosine similarity
between their projections. In general, using all the
eigenvectors is sub optimal and thus retaining top
eigenvectors leads to better generalizability.
3 Covariance Selection
As shown above, the underlying objective function
in most of the discriminative approaches is of the
form aTXY Tb. This can be rewritten as :
aTXY Tb =
n?
k=1
?xk,a??yk,b?
=
n?
k=1
( d1?
i=1
Xi,kai ·
d2?
j=1
Yj,kbj
)
=
d1?
i=1
d2?
j=1
aibj
( n?
k=1
Xi,kYj,k
)
=
d1,d2?
i,j=1
aibjCxyij (2)
Similarly, the constraints can also be rewritten as?d1
i,j=1 aiajCxxij = 1 and
?d2
i,j=1 bibjC
yy
ij = 1.
931
Maximizing this objective function, under the
constraints, involves a careful selection of the vec-
tors a and b such that aibj is high whenever Cxyij
is high. So, every non-zero entry of the cross-
covariance matrix restricts the choice of the pro-
jection directions. While this may not be a severe
problem when the training data is clean, but this is
very uncommon especially in the case of high di-
mensional data like text documents. Moreover, the
inherent ambiguity of natural languages increases
the chances of seeing a noisy word in any docu-
ment. Every occurrence of a noisy word will have a
non-zero contribution towards the covariance matrix
making it dense, which in turn prevents the selection
of appropriate projection directions.
In this section, we describe some techniques to
recover the sparsity by removing the noisy entries
from the covariance matrices. We break this task
into two sub problems: computing an association
score for every word pair and then using an appro-
priate strategy to identify the noisy pairs based on
their weights. We explore multiple ways to address
both the steps in the following two sections. For
the sake of convenience and clarity, we describe our
techniques in the context of cross-covariance ma-
trix between English and Spanish language pair. But
these techniques extend directly to monolingual co-
variance matrices, and to different language pairs as
well.
3.1 Computing Word Pair Association
The first step in filtering out the noisy word co-
occurrences is to use an appropriate measure to com-
pute the strength of word pairs (English and Span-
ish words). This is a well studied problem and sev-
eral association measures have been proposed in the
NLP literature (Dunning, 1993; Inkpen and Hirst,
2002; Moore, 2004). These association measures
can be divided into groups based on the statistics
they use (Hoang et al., 2009). Here we explore a few
of them for sparsifying the cross-covariance matrix.
3.1.1 Covariance
The first option is to use the cross-covariance
matrix itself. As noted above, when the data ma-
trix is centered, the cross-covariance of an English
word (ei) with a Spanish word (fj) is given by?n
k=1 XikYjk. It measures the strength with which
two words co-occur together. This measure uses in-
formation about the occurrence of a word pair in
aligned documents and doesn’t use other statistics
such as ‘how often this pair doesn’t co-occur to-
gether’ and so on.
3.1.2 Mutual Information
Association measures like covariance and Point-
wise Mutual Information, which only use the fre-
quency with which a word pair co-occurs, often
overestimate the strength of low frequent words
(Moore, 2004). On the other hand, measures
like Log-likelihood ratio (Dunning, 1993) and Mu-
tual Information (MI) use other statistics like the
marginal probabilities of each of the words.
For any two words, ei and fj , let n11, n10, n01
and n00 denote the number of documents in which
both the words co-occur, only English word occurs,
only Spanish word occurs and none of the words oc-
cur. Then the Mutual Information of this word pair
is given by:
MI(ei, fj) =
1
n
?
i,j?{0,1}
nij log
nij × n
ninj
(3)
where ni and nj denote the number of documents
in which the English and the Spanish word occurs
and n is the total number of documents. We treat
the occurrence of a word in a document slightly dif-
ferent from others, we treat a word as occurring in
a document if it has occurred more than its average
frequency in the corpus. Log-likelihood ratio and
the MI differ only in terms of the constant they use,
so we use only MI in our experiments.
3.1.3 Yule’s ?
Yule’s ? is another popular association measure
used in psychology (Reis and Judd, 2000). It uses
same statistics used by Mutual Information but dif-
fers in the way in which they are combined. MI con-
verts the frequencies into probabilities before com-
puting the association measure where as Yule’s ?
uses the observed frequencies directly, and doesn’t
make any assumptions about the underlying proba-
bility distributions. Given the same interpretation of
the variables as introduced in the previous section,
the Yule’s ? is estimated as:
? =
?n00n11 ?
?n01n10?n00n11 +
?n01n10
(4)
932
This way of combining the frequencies bears simi-
larity with the log-odds ratio.
3.1.4 Bilingual Dictionary
The above three association measures use the
same training data that is available to compute the
covariance matrices in CCA. Thus, their utility in
bringing additional information, which is not cap-
tured by the covariance matrices, is arguable (our
experiments show that they are indeed helpful).
Moreover, they use document level co-occurrence
information which is coarse compared to the co-
occurrence at sentence level or the translational in-
formation provided by a bilingual dictionary. So,
we use bilingual dictionaries as our final resource to
weigh the word co-occurrences. Notice that, using
bilingual information brings in information gleaned
from an external corpus.
We use translation tables learnt using Giza++
(Och and Ney, 2003) on Europarl data set. Since the
translation tables are asymmetric, we combine trans-
lation tables from both the directions. We first use a
threshold on the conditional probability to filter out
the low probability ones and then convert them into
joint probabilities before combining. For each word
pair (ei, fj), we compute the score as:
1
2
(
P (ei|fj)P (fj) + P (fj|ei)P (ei)
)
While the first three association measures can also
be applied to monolingual data, bilingual dictionary
can’t be used for weighting monolingual word pairs.
So in this case, we use either of the above mentioned
techniques for weighting monolingual word pairs.
3.2 Selection Strategies
The next step after computing association measure
for all word pairs is to use them in selecting the pairs
that need to be retained. In this section, we describe
some approaches such as thresholding and matching
for the word pair selection.
3.2.1 Thresholding
A straight forward way to remove the noisy word
co-occurrences is to zero out the entries of the
cross-covariance matrix that are lower than a thresh-
old. To understand the motivation, consider the
rewritten objective function of CCA, aTXY Tb =
?
ij C
xy
ij aibj . This is linear in terms of the individ-
ual components of the cross-covariance matrix. So,
if we want to remove some of the entries of the co-
variance matrix with minimal change in the value of
the objective function, then the optimal choice is to
sort the entries of the covariance matrix and filter out
the less confident word pairs.
3.2.2 Relative Thresholding
While the thresholding strategy described in the
above section is very simple, it is often biased by
the frequent words. Since a frequent word co-occurs
with other words often, it naturally tends to have
high association with most of the other words. As
a result, absolute thresholding tends to remove all
the less frequent word pairs while leaving the co-
occurrences of the frequent words untouched. Even-
tually, this may lead to zeroing out some of the rows
or the columns of the cross-covariance matrix.
To circumvent this, we try thresholding at word
level. For every English word, we choose a few
Spanish words that have high association and vice
versa. Since the nearest neighbour property is asym-
metric, we take the union of all the selected word
pairs. That is, we retain a word pair, if either the
Spanish word is in the top ranked list of the English
word or vice versa.
3.2.3 Maximal Matching
Though relative thresholding overcomes the prob-
lem of zeroing out entire rows or columns posed by
direct thresholding, it is still biased by the frequent
words. The high association measure of a frequent
English word with many Spanish words, makes it a
nearest neighbour for lot of Spanish words. One way
to prevent this is to discourage an already selected
English word from associating with a new Spanish
word. This requires a global knowledge of all the
selected pairs and can not be done by looking at the
individual words, as is the case with the greedy strat-
egy employed by the relative thresholding.
We use matching to solve this problem. We for-
mulate the selection of the word pairs as a network
flow problem (Jagarlamudi et al., 2011). The objec-
tive is to select word pairs that have high association
measure while constraining each word to be asso-
ciated with only a few words from other language.
Let Iij denote an indicator variable taking a value of
933
0 or 1 depending on if the word pair (ei, fj) is se-
lected or not. We want each word to be associated
with k words from other language, i.e.?j Iij = k
and
?
i Iij = k. Moreover, we want word pairs
with high association score to be selected. We can
encode this objective and the constraints as the fol-
lowing optimization problem:
argmax
I
d1,d2?
i,j=1
Cxyij Iij (5)
?i
?
j
Iij = k; ?j
?
i
Iij = k; ?i, j Iij ? {0, 1}
If k = 1, then this problem reduces to a linear as-
signment problem and can be solved optimally us-
ing the Hungarian algorithm (Jonker and Volgenant,
1987). For other values of k, this can be solved by
relaxing the constraint Iij ? {0, 1} to 0 ? Iij ? 1.
The optimal solution of the relaxed problem can be
found efficiently using linear programming (Ravin-
dra et al., 1993). The uni-modular nature of the
constraints guarantees an integral solution (Schri-
jver, 2003), so relaxing the original integer problem
doesn’t introduce any error in the optimal solution.
3.2.4 Monolingual Augmentation
The above three selection strategies operate on the
covariance matrices independently. In this section
we propose to combine them. Specifically, we pro-
pose to augment the set of selected bilingual word
pairs using the monolingual word pairs. We first use
any of the above mentioned strategies to select bilin-
gual and monolingual word pairs. Let Ixy, Ixx and
Iyy be the binary matrices that indicate the selected
word pairs based on the bilingual and monolingual
association scores. Then the monolingual augmen-
tation strategy updates Ixy in the following way:
Ixy ? Binarize(IxxIxyIyy)
i.e., we multiply Ixy with the monolingual selection
matrices and then binarize the resulting matrix. Our
monolingual augmentation is motivated by the fol-
lowing probabilistic interpretation:
P (x, y) =
?
x?,y?
P (x|x?)P (y|y?)P (x?, y?)
which can be rewritten as P ? T xP (T y)T where
T x and T y are monolingual state transition matrices.
3.3 Our Approach
In this section we summarize our approach for the
task of finding aligned documents from a cross-
lingual comparable corpora. The training phase in-
volves finding projection directions for documents
of both the languages. We compute the covariance
matrices using the training data. Then we use any
of the word association measures (Sec. 3.1) along
with a selection criteria (Sec. 3.2) to recover the
sparseness in either only the cross-covariance or all
of the covariance matrices. Let Ixy, Ixx and Iyy
be the binary matrices which represent the word
pairs that are selected based on the chosen sparsi-
fication technique. Now, we replace the covariance
matrices in Eq. 1 as follows: Cxx ? Cxx ? Ixx,
Cyy ? Cyy ? Iyy and Cxy ? Cxy ? Ixy where
? denotes the element-wise matrix product. Subse-
quently, we solve the generalized eigenvalue prob-
lem shown in Eq. 1 to obtain the projection direc-
tions. Let A and B be the matrices formed with top
eigenvectors of Eq. 1 as the columns. These pro-
jection matrices are used to map documents into the
interlingual representation. Such an interlingual rep-
resentation is useful in many tasks like cross-lingual
text categorization (Bel et al., 2003) multilingual
web search (Gao et al., 2009) and so on.
During the testing, given an English document x,
finding an aligned Spanish document involves solv-
ing:
argmax
y
xT
(
(ABT )? Ixy
)
y
?
xT
(
(AAT )? Ixx
)
x
?
yT
(
(BBT )? Iyy
)
y
If the documents are normalized before hand, then
the above equation reduces to computing only the
numerator.
4 Experiments
4.1 Experimental Setup
We experiment with the task of finding aligned doc-
uments from a cross-lingual comparable corpora. In
this task, we are given comparable corpora consist-
ing of two document collections, each in a differ-
ent language. As the corpora are comparable, some
documents in one collection have a comparable doc-
ument in the other collection. The task is to recover
934
this hidden alignment. The recovered alignment is
compared against the ground truth.
We evaluate our idea of sparsifying the covari-
ance matrices incrementally. We first evaluate the
effectiveness of our approach on synthetic data, as
it enables us to systematically study the effect of
noise. Subsequently, we evaluate each of the above
discussed sparsification strategies on real world data
sets. We have discussed four possible ways for
computing word association measure and three ap-
proaches for word pair selection. That leaves us 12
different ways for sparsifying the covariance matri-
ces, with each method having parameters to control
the amount of sparseness. We use a small amount of
development data for model selection and parameter
tuning and choose a few promising models. Finally,
we compare these selected models with state-of-the-
art baselines on two language pairs and on two dif-
ferent data sets.
In each case, we use the training data to learn
the projection directions. And then, for each of the
test documents, we find the aligned document from
other language. We report average accuracy of the
top ranked document and also the Mean Reciprocal
Rank (MRR) of the true aligned document.
4.2 Synthetic Data
We follow the generative story introduced in Bach
and Jordan (2005) to generate synthetic multi-view
data. Their method does not assume any correspon-
dence between the feature dimensions of both the
views. We modify their approach slightly so that
we know the actual correspondence between the fea-
tures. We use these true feature correspondences for
sparsification of the cross-covariance matrix.
We first generate a d dimensional vector in the
common latent space and then use the projection
matrices to map it into the individual feature spaces
as follows:
z ? N (0, Id)
x|z ? (W1z + µ1) + ? N (0, Id1)
y|z ? (W1z + µ2) + ? N (0, Id2)
Notice that we use the same projection matrix W1
for both the views, this ensures a one-to-one corre-
spondence between the features of both the spaces.
Moreover, we also introduce a parameter ? which
controls the amount of noise in the data.
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 1  1.5  2  2.5  3  3.5  4
Sparse MRR
Sparse Accuracy
CCA MRR
CCA Accuracy
Figure 1: Accuracy of CCA and our sparsified version
with the noise parameter.
We generate a total of 3000 pairs of points and use
2000 of them for training the models and the rest
for evaluation. We use the true feature correspon-
dences to form the cross-covariance selection ma-
trix Ixy (Sec. 3.3). For this experiment, we use the
full monolingual covariance matrices. We train both
CCA and our sparse version on the training data and
evaluate them on the test data. We repeat this mul-
tiple times and report the average accuracies. Fig. 1
shows the performance of CCA and our sparse CCA,
as we vary the noise parameter ? from 1 to 4. It
is very clear that the sparse version performs sig-
nificantly better than CCA. As the noise increases,
the performance of CCA drops quickly. This exper-
iment demonstrates a significant performance gain
when the true correspondences are available. But
this information is not available in the case of real
world data sets, so we try to approximate it.
4.3 Model Selection
As we have discussed, there are several choices for
computing the association measure and for selecting
the word pairs to be retained. And each of them have
sparsity parameters, giving raise to many possible
models. For model selection, we use approximately
5000 document pairs collected from the Wikipedia
between English and Spanish. We use the cross-
language links provided as the ground truth. We to-
kenize the documents, retain only the most frequent
2000 words in each language and convert the docu-
935
 0.4
 0.45
 0.5
 0.55
 0.6
 0.65
 2000  4000  6000  8000  10000  12000  14000  16000  18000  20000
MI+Match
Yule+Match
Cov+Match
MI+RelThreshold
Yule+RelThreshold
Cov+RelThreshold
MI+Threshold
Yule+Threshold
Cov+Threshold
CCA
Figure 2: Comparison of the word association measures
along with different selection criteria. The x-axis plots
the number of non-zero entries in the covariance matrices
and the y-axis plots the accuracy of top-ranked document.
ments into TFIDF vectors. We use 60% of the data
for training different models and the rest for evaluat-
ing the models. We choose a few promising models
based on this development set results and evaluate
them on bigger data sets.
4.3.1 Selection Strategies
In the first experiment, we combine the three
association measures, Covariance (Cov), MI and
Yule’s ?, with the three selection criteria, Thresh-
old, Relative Threshold (RelThreshold) and Match-
ing (Match). Fig. 2 shows the performance of these
different combinations with varying levels of spar-
sity in the covariance matrices. The horizontal line
represents the performance of CCA on this data set.
We start with 2000 non-zero entries in the covari-
ance matrices and experiment up to 20,000 non-zero
entries. Since our data set has 2000 words in each
language, 2000 non-zero entries in a covariance ma-
trix implies that, on an average, every word is as-
sociated with only one word. This results in highly
sparse covariance matrices.
Overall, we observe that reducing the level of
sparsity , i.e. selecting more number of elements in
the covariance matrices, increases the performance
slightly and then decreases again. From the figure, it
seems that sparsifying the covariance matrices might
help in improving the performance of the task. But
it is interesting to note that not all the models per-
form better than CCA. In fact, both the models that
achieve better scores use Matching as the selection
criteria. This suggests that, apart from the weighting
of the word pairs, appropriate selection of the word
pairs is also equally important. In the rest of the ex-
periments we mainly report results with Matching as
the selection criterion. From this figure, we observe
that Mutual Information and Yule’s ? perform com-
petitively but they consistently outperform models
that use covariance as the association measure. So
in the rest of the experiments we report results with
MI or Yule’s ?.
4.3.2 Amount of Sparsity
In the previous experiment, we used same level
of sparsity for all the covariance matrices, i.e. same
number of associations were selected for each word
in all the three covariance matrices. In the following
experiment, we use different levels of sparsity for
the individual covariance matrices. Fig. 3 shows the
performance of Yule+Match and Dictionary+Match
combinations with different levels of sparsity. In
the Yule+Match combination, we use Yule’s ? as-
sociation measure for weighting the word pairs and
use matching for selection. In the Dictionary+Match
combination, we use bilingual dictionary for sparsi-
fying cross-covariance matrix, i.e. we keep all the
word pairs whose conditional translation probabil-
ity is above a threshold. And for monolingual word
pairs, we use MI for weighting and matching for
word pair selection.
For each level of sparsity of the cross-covariance
matrix, we experiment with different levels of spar-
sity on the monolingual covariance matrices. ‘Only
XY’ indicates we use the full monolingual covari-
ance matrices. In ‘Match(k)’ runs, we allow each
word to be associated with a total of k words (Eq. 5).
‘Aug’ indicates that we use monolingual augmen-
tation to refine the sparsity of the cross-covariance
matrix (Sec. 3.2.4).
From both the figures 3(a) and 3(b), we observe
that ‘Only XY’ run (dark blue) performs poorly
compared to the other runs, indicating that sparsify-
ing all the covariance matrices is better than spar-
sifying only the cross-covariance matrix. In the
936
(a) Performance of Yule+Match combination. The x-axis plots
the number of Spanish words selected per each English word
and vice versa. This determines the sparsity of Cxy. Matching
is used as selection criteria for all the covariance matrices.
(b) Performance of Dictionary+Match combination. The x-axis
plots the threshold on bilingual translation probability and it deter-
mines the sparsity of Cxy. Matching is used to select only the mono-
lingual sparsity.
Figure 3: Comparison of Yule+Match and Dictionary+Match combination with different levels of sparsity for the
covariance matrices. In both the figures, the x-axis plots the sparsity of the cross-covariance matrix and for each
value we try different levels of sparsity on the monolingual covariance matrices (which are grouped together). The
description of these individual runs is provided in the relevant parts of the text. The y-axis plots the accuracy of the
top-ranked document. CCA achieves 61% accuracy on this data set.
Yule+Match combination, Fig. 3(a), all the runs
seem to be performing better when each English
word is allowed to associate with 2 or 3 Spanish
words and vice versa. Among different ways of se-
lecting the monolingual word pairs, Match(2)+Aug
performs better than the remaining runs. So we use
Match(2)+Aug combination for the Yule’s ? mea-
sure.
Unlike the Yule+Match combinations, there is no
clear winner for Dictionary+Match combinations.
First of all, the performance increase as we increase
the translation probability threshold and then de-
creases again (indicated by the ‘Average’ perfor-
mance in Fig. 3(b)). On an average, all the sys-
tems perform better with a threshold of 0.01, which
we use in our final experiments. In this case, both
Match(1) and Match(2)+Aug runs (orange and green
bars respectively) perform competitively so we use
both of these models in our final experiments.
In both the above experiments, the performance
bars are very similar when we use MI instead of
Yule and vice versa for weighting monolingual word
pairs. Thus, to illustrate the main ideas we chose
Yule’s ? for the former combination and MI for the
latter combination.
4.3.3 Promising Models
Based on the above experiments, we choose the
following combinations for our final experiments.
Yule(l)+Match(k), where l ? {2, 3} is the number
of Spanish words allowed for each English word
and vice versa and k=2 is the number of monolin-
gual word associations for each word. We also run
both these combinations with monolingual augmen-
tation, indicated by Yule(l)+Match(k)+Aug. For
dictionary based weighting, Dictionary+Match(k),
we choose a translation probability threshold of 0.01
and try k ? {1, 2}. Again, we run these combina-
tions with monolingual augmentation identified by
Dictionary+Match(k)+Aug.
4.4 Results
For our final results, we choose data in two language
pairs (English-Spanish and English-German) from
two different resources, Europarl (Koehn, 2005) and
Wikipedia. For Europarl data sets, we artificially
make them comparable by considering the first half
937
Wikipedia Europarl
English-Spanish English-German English-Spanish English-German
Acc. MRR Acc. MRR Acc. MRR Acc. MRR
CCA 0.776 0.852 0.570 0.699 0.872 0.920 0.748 0.831
OPCA 0.781 0.856 0.570 0.700 0.870 0.920 0.748 0.831
Yule(2)+Match(2) 0.798? 0.866? 0.576 0.703 0.901? 0.939? 0.780? 0.853?
Yule(2)+Match(2)+Aug 0.811? 0.876? 0.602? 0.723? 0.883 0.927 0.771? 0.847?
Yule(3)+Match(2) 0.803? 0.870? 0.572 0.700 0.856 0.907 0.747 0.830
Yule(3)+Match(2)+Aug 0.793? 0.861? 0.610? 0.726? 0.878+ 0.925+ 0.763+ 0.843?
Dictionary+Match(1) 0.811? 0.875? 0.656? 0.762? 0.928? 0.957? 0.874? 0.922?
Dictionary+Match(2) 0.811? 0.876? 0.623? 0.736? 0.923? 0.955? 0.853? 0.907?
Dictionary+Match(2)+Aug 0.825? 0.885? 0.630? 0.735? 0.897? 0.935? 0.866? 0.917?
Table 1: Performance of our models in comparison with CCA and OPCA on English-Spanish and English-German
language pairs. ? and + indicate statistical significance measured by paired t-test at p=0.01 and 0.05 levels respectively.
When an improvement is significant at p=0.01 it is automatically significant at p=0.05 and hence is not shown.
of English document and the second half of its
aligned foreign language document (Mimno et al.,
2009). For Wikipedia data set, we use the cross-
language link as the ground truth. For each of these
data sets, we choose approximately 5000 aligned
document pairs. We remove the stop words and keep
all the words that occur in at least five documents.
After the preprocessing, on an average, we are left
with 4700 words in each language. Subsequently we
convert the documents into their TFIDF representa-
tion.
In Platt et al. (2010), the authors compare differ-
ent systems on the comparable document retrieval
task and show that discriminative approaches work
better compared to their generative counter parts.
So, here we compare only with the state-of-the-
art discriminative systems such as CCA and OPCA
(Platt et al., 2010). For each of the systems, we re-
port the average results of five-fold cross validation.
We divide the data into 3:1:1 ratio for training, vali-
dation and test sets. The validation data set is used to
select the best number of dimensions of the common
sub space. For both CCA and our models, we set the
regularization parameter ? to 0.3 which we found
works well in a relevant but different experiments.
For OPCA, we manually tried different regulariza-
tion parameters ranging from 0.0001 to 1 and found
that a value of 0.001 worked best.
The results are shown in Table 1. On these data
sets, both CCA and OPCA performed competitively.
OPCA takes advantage of the common vocabulary
in both the languages. But in our data sets, vocab-
ulary of both the languages is treated differently, so
it is not surprising that they give almost the same
results. From the results, it is clear that sparsify-
ing the covariance matrices helps improving the ac-
curacies significantly. In all the four data sets, the
best performing method always used dictionary for
cross-lingual sparsity selection. This indicates that
using fine granular information such as a bilingual
dictionary gleaned from an external source is very
helpful in improving the accuracies. Among the
models that rely solely on the training data, models
that use monolingual augmentation performed bet-
ter on Wikipedia data set, while models that do not
use augmentation performed better on Europarl data
sets. This suggests that, when the aligned documents
are clean (closer to being parallel) the statistics com-
puted from cross-lingual corpora are trustworthy. As
the documents become comparable, we need to use
monolingual statistics to refine the bilingual statis-
tics. Moreover, these models achieve higher gains in
the case of Wikipedia data set compared to the gains
in Europarl. This conforms with our initial hunch
that, when the training data is clean the covariance
matrices tend to be less noisy.
5 Discussion
In this paper, we have proposed the idea of sparsi-
fyng covariance matrices to improve bilingual pro-
938
jection directions. We are not aware of any NLP
research that attempts to recover the sparseness of
the covariance matrices to improve the projection
directions. Our work is different from the sparse
CCA (Hardoon and Shawe-Taylor, 2011; Rai and
Daume´ III, 2009) proposed in the Machine Learning
literature. Their objective is to find projection di-
rections such that the original documents are repre-
sented as a sparse vectors in the common sub-space.
Another seemingly relevant but different direction
is the sparse covariance matrix selection research
(Banerjee et al., 2005). The objective in this work
is to find matrices such that the inverse of the co-
variance matrix is sparse which has applications in
Gaussian processes.
In this paper, we tried sparsification in the con-
text of CCA only but our technique is general and
can be applied to its variants like OPCA. Our ex-
perimental results show that using external informa-
tion such as bilingual dictionaries which is gleaned
from cleaner resources brings significant improve-
ments. Moreover, we also observe that computing
word pair association measures from the same train-
ing data along with an appropriate selection criteria
can also yield significant improvements. This is cer-
tainly encouraging and in future we would like to
explore more sophisticated techniques to recover the
sparsity based on the training data itself.
6 Acknowledgments
We thank the anonymous reviewers for their help-
ful comments. This material is partially supported
by the National Science Foundation under Grant No.
1139909.
References
Francis R. Bach and Michael I. Jordan. 2005. A proba-
bilistic interpretation of canonical correlation analysis.
Technical report, Dept Statist Univ California Berke-
ley CA Tech.
Lisa Ballesteros and W. Bruce Croft. 1996. Dictio-
nary methods for cross-lingual information retrieval.
In Proceedings of the 7th International Conference
on Database and Expert Systems Applications, DEXA
’96, pages 791–801, London, UK. Springer-Verlag.
Onureena Banerjee, Alexandre d’Aspremont, and Lau-
rent El Ghaoui. 2005. Sparse covariance selection
via robust maximum likelihood estimation. CoRR,
abs/cs/0506023.
Nuria Bel, Cornelis H. A. Koster, and Marta Villegas.
2003. Cross-lingual text categorization.
Hal Daume III and Jagadeesh Jagarlamudi. 2011. Do-
main adaptation for machine translation by mining un-
seen words. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 407–412, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Comput. Linguist.,
19(1):61–74, March.
William A. Gale and Kenneth W. Church. 1991. A pro-
gram for aligning sentences in bilingual corpora. In
Proceedings of the 29th annual meeting on Associ-
ation for Computational Linguistics, pages 177–184,
Morristown, NJ, USA. Association for Computational
Linguistics.
Wei Gao, John Blitzer, Ming Zhou, and Kam-Fai Wong.
2009. Exploiting bilingual information to improve
web search. In Proceedings of Human Language Tech-
nologies: The 2009 Conference of the Association for
Computational Linguistics, ACL-IJCNLP ’09, pages
1075–1083, Morristown, NJ, USA. ACL.
Aria Haghighi, Percy Liang, Taylor B. Kirkpatrick, and
Dan Klein. 2008. Learning bilingual lexicons from
monolingual corpora. In Proceedings of ACL-08:
HLT, pages 771–779, Columbus, Ohio, June. Associa-
tion for Computational Linguistics.
David R. Hardoon and John Shawe-Taylor. 2011. Sparse
canonical correlation analysis. Journal of Machine
Learning, 83(3):331–353.
Ulf Hermjakob, Kevin Knight, and Hal Daume´ III. 2008.
Name translation in statistical machine translation -
learning when to transliterate. In Proceedings of ACL-
08: HLT, pages 389–397, Columbus, Ohio, June. As-
sociation for Computational Linguistics.
Hung Huu Hoang, Su Nam Kim, and Min-Yen Kan.
2009. A Re-examination of Lexical Association Mea-
sures. In Proceedings of ACL-IJCNLP 2009 Workshop
on Multiword Expressions: Identification, Interpre-
tation, Disambiguation and Applications, Singapore,
August. Association for Computational Linguistics.
H. Hotelling. 1936. Relation between two sets of vari-
ables. Biometrica, 28:322–377.
Diana Zaiu Inkpen and Graeme Hirst. 2002. Ac-
quiring collocations for lexical choice between near-
synonyms. In Proceedings of the ACL-02 workshop
on Unsupervised lexical acquisition - Volume 9, ULA
’02, pages 67–76, Stroudsburg, PA, USA. Association
for Computational Linguistics.
939
Jagadeesh Jagarlamudi and Hal Daume´ III. 2010. Ex-
tracting multilingual topics from unaligned compara-
ble corpora. In Advances in Information Retrieval,
32nd European Conference on IR Research, ECIR,
volume 5993, pages 444–456, Milton Keynes, UK.
Springer.
Jagadeesh Jagarlamudi, Hal Daume III, and Raghavendra
Udupa. 2011. From bilingual dictionaries to interlin-
gual document representations. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies,
pages 147–152, Portland, Oregon, USA, June. Associ-
ation for Computational Linguistics.
R. Jonker and A. Volgenant. 1987. A shortest augment-
ing path algorithm for dense and sparse linear assign-
ment problems. Computing, 38(4):325–340.
Alexandre Klementiev and Dan Roth. 2006. Weakly
supervised named entity transliteration and discovery
from multilingual comparable corpora. In Proceed-
ings of the 21st International Conference on Compu-
tational Linguistics and the 44th annual meeting of the
Association for Computational Linguistics, ACL-44,
pages 817–824, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Conference
Proceedings: the tenth Machine Translation Summit,
pages 79–86, Phuket, Thailand. AAMT, AAMT.
David Mimno, Hanna M. Wallach, Jason Naradowsky,
David A. Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 2 - Volume 2, EMNLP ’09,
pages 880–889, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Robert C. Moore. 2004. On Log-Likelihood-Ratios
and the Significance of Rare Events. In Dekang Lin
and Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 333–340, Barcelona, Spain, July. Association
for Computational Linguistics.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving machine translation performance by exploit-
ing non-parallel corpora. Comput. Linguist., 31:477–
504, December.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
John C. Platt, Kristina Toutanova, and Wen-tau Yih.
2010. Translingual document representations from
discriminative projections. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, EMNLP ’10, pages 251–261,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Piyush Rai and Hal Daume´ III. 2009. Multi-label pre-
diction via sparse infinite cca. In Advances in Neural
Information Processing Systems, Vancouver, Canada.
Reinhard Rapp. 1999. Automatic identification of word
translations from unrelated english and german cor-
pora. In Proceedings of the 37th annual meeting
of the Association for Computational Linguistics on
Computational Linguistics, ACL ’99, pages 519–526,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Sujith Ravi and Kevin Knight. 2009. Learning phoneme
mappings for transliteration without parallel data. In
Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 37–45, Boulder, Colorado, June. Association for
Computational Linguistics.
K. Ahuja Ravindra, L. Magnanti Thomas, and B. Orlin
James. 1993. Network Flows: Theory, Algorithms,
and Applications. Prentice-Hall, Inc.
Harry T Reis and Charles M Judd. 2000. Handbook of
Research Methods in Social and Personality Psychol-
ogy. Cambridge University Press.
Alexander Schrijver. 2003. Combinatorial Optimization.
Springer.
Michael L. Littman Susan T. Dumais, Thomas K. Lan-
dauer. 1996. Automatic cross-linguistic information
retrieval using latent semantic indexing. In Working
Notes of the Workshop on Cross-Linguistic Informa-
tion Retrieval, SIGIR, pages 16–23, Zurich, Switzer-
land. ACM.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of semantics.
J. Artif. Intell. Res. (JAIR), 37:141–188.
Alexei Vinokourov, John Shawe-taylor, and Nello Cris-
tianini. 2003. Inferring a semantic representation
of text via cross-language correlation analysis. In
Advances in Neural Information Processing Systems,
pages 1473–1480, Cambridge, MA. MIT Press.
Thuy Vu, AiTi Aw, and Min Zhang. 2009. Feature-based
method for document alignment in comparable news
corpora. In EACL, pages 843–851.
Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai. 2010.
Cross-lingual latent topic extraction. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 1128–1137, Up-
psala, Sweden, July. Association for Computational
Linguistics.
940
