Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1059–1065,
Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.
Hierarchical Incremental Adaptation for Statistical Machine Translation
Joern Wuebker
Lilt Inc.
joern@lilt.com
Spence Green
Lilt Inc.
spence@lilt.com
John DeNero
Lilt Inc.
john@lilt.com
Abstract
We present an incremental adaptation ap-
proach for statistical machine translation
that maintains a flexible hierarchical do-
main structure within a single consistent
model. Both weights and rules are updated
incrementally on a stream of post-edits. Our
multi-level domain hierarchy allows the sys-
tem to adapt simultaneously towards local
context at different levels of granularity, in-
cluding genres and individual documents.
Our experiments show consistent improve-
ments in translation quality from all com-
ponents of our approach.
1 Introduction
Suggestions from a machine translation system can
increase the speed and quality of professional hu-
man translators (Guerberof, 2009; Plitt and Mas-
selot, 2010; Green et al., 2013a, inter alia). How-
ever, querying a single fixed model for all different
documents fails to incorporate contextual informa-
tion that can potentially improve suggestion quality.
We describe a model architecture that adapts simul-
taneously to multiple genres and individual docu-
ments, so that translation suggestions are informed
by two levels of contextual information.
Our primary technical contribution is a hierarchi-
cal adaptation technique for a post-editing scenario
with incremental adaptation, in which users request
translations of sentences in corpus order and pro-
vide corrected translations of each sentence back
to the system (Ortiz-Martínez et al., 2010). Our
learning approach resembles Hierarchical Bayesian
Domain Adaptation (Finkel and Manning, 2009),
but updates both the model weights and translation
rules in real time based on these corrected transla-
tions (Mathur et al., 2013; Denkowski et al., 2014).
Our adapted system can provide on-demand trans-
lations for any genre and document to which it has
ever been exposed, using weights and rules for do-
mains associated with each translation request.
Our weight adaptation is performed using a hier-
archical extension to fast and adaptive online train-
ing (Green et al., 2013b), a technique based on Ada-
Grad (Duchi et al., 2011) and forward-backward
splitting (Duchi and Singer, 2009) that can accu-
rately set weights for both dense and sparse fea-
tures (Green et al., 2014b). Rather than adjusting
all weights based on each example, our extension
adjusts offsets to a fixed baseline system. In this
way, the system can adapt to multiple genres while
preventing cross-genre contamination.
In large-scale experiments, we adapt a multi-
genre baseline system to patents, lectures, and news
articles. Our experiments show that sparse mod-
els, hierarchical updates, and rule adaptation all
contribute consistent improvements. We observe
quality gains in all genres, validating our hypothe-
sis that document and genre context are important
additional inputs to a machine translation system
used for post-editing.
2 Background
The log-linear appoach to statistical machine trans-
lation models the predictive translation distribution
p(e|f ;w) directly in log-linear form (Och and Ney,
2004):
p(e|f ;w) =
?
r:
src(r)=f
tgt(r)=e
1
Z(f)
exp
[
w
>
?(r; c)
]
(1)
1059
where f ? F is a string in the set of all source
language strings F , e ? E is a string in the set of
all target language strings E , r is a phrasal deriva-
tion with source and target projections src(r) and
tgt(r), w ? R
d
is the vector of model parameters,
?(·) ? R
d
is a feature map computed using corpus
c, and Z(f) is an appropriate normalizing constant.
During search, the maximum approximation is ap-
plied rather than summing over the derivations r.
Model. We extend a phrase-based system for which
?(r; c) includes 16 dense features:
• Two phrasal channel models and two lexical
channel models (Koehn et al., 2003), the (log)
count of the rule in the training corpus c, and
an indicator for singleton rules in c.
• Six orientation models that score ordering con-
figurations in r by their frequency in c (Koehn
et al., 2007).
• A linear distortion penalty that promotes
monotonic translation.
• An n-gram language model score, p(e), which
scores the target language projection of r using
statistics from a monolingual corpus.
• Fixed-value phrase and word penalties.
The elements of ?(r; c) may also include sparse
features that have non-zero values for only a subset
of rules, but typically do not depend on c (Liang
et al., 2006). In this paper, we use four types of
sparse features: rule indicators, discriminative lexi-
calized reordering indicators, rule shape indicators
and alignment features (Green et al., 2014b).
The model parametersw are chosen to maximize
translation quality on a tuning set.
Adaptation. Domain adaptation for machine trans-
lation has improved quality using a variety of ap-
proaches, including data selection (Ceau?fu et al.,
2011), regularized online learning (Simianer et al.,
2012; Green et al., 2013b), and input classification
(Xu et al., 2007; Banerjee et al., 2010; Wang et
al., 2012) and has also been investigated for multi-
domain tasks (Sennrich et al., 2013; Cui et al., 2013;
Simianer and Riezler, 2013). Even without domain
labels at either training or test time, multi-task learn-
ing can boost translation quality in a batch setting
(Duh et al., 2010; Song et al., 2011).
Post-editing with incremental adaptation de-
scribes a particular mixed-initiative setting (Ortiz-
Martínez et al., 2010; Hardt and Elming, 2010). For
each f in a corpus, the machine generates a hypothe-
sis e, then a human provides a corrected translation
e
?
to the machine. Observing e
?
can affect both the
Root Domain
Patents Genre News Genre Lectures Genre
Each document has 3 domains: root, its genre, & the document itself
Figure 1: The weights used to translate a document
in the patent genre include three domains.
model weights w and corpus c used for rule extrac-
tion and dense feature estimation.
1
To translate the
ith sentence f
i
, the system uses weights w
i?1
and
corpus c
i?1
. The new corpus c
i
results from adding
(f
i
, e
?
i
) to c
i?1
. For incremental adaptation, speed
is essential, and so w
i
is typically computed with
a single online update from w
i?1
using (f
i
, e
?
i
) as
the tuning example.
To alleviate the need for human intervention in
the experiment cycle, simulated post-editing (Hardt
and Elming, 2010; Denkowski et al., 2014) replaces
each e
?
with a reference that is not a corrected vari-
ant of e. Thus, a standard test corpus can be used as
an adaptation corpus. Prior work on online learn-
ing from post-edits has demonstrated the benefit of
adjusting only c (Ortiz-Martínez et al., 2010; Hardt
and Elming, 2010) and further benefit from adjust-
ing both c and w (Mathur et al., 2013; Denkowski
et al., 2014). Incremental adaptation of both c and
the weightsw for sparse features is reported to yield
large quality gains by Wäschle et al. (2013).
2
3 Hierarchical Incremental Adaptation
Our hierachical approach to incremental adaptation
uses document and genre information to adapt ap-
propriately to multiple contexts. We assume that
each sentence f
i
has a known set D
i
of domains,
which identify the genre and individual document
origin of the sentence. This set could be extended
to include topics, individual translators, etc.
Figure 1 shows the domains that we apply in
experiments. All sentences in the baseline training
corpus, the tuning corpus, and the adaptation corpus
share a root domain.
1
For the purpose of our description, the corpus c is equiva-
lent to the set of phrases and their scores in the rule table. We
prefer this notation because it is consistent with our stream-
based rule table, where the models are computed on-the-fly
from the indexed training corpus c.
2
Language model adaptation also has a rich literature, but
it is beyond the scope of this paper.
1060
Our adaptation is conceptually similar to hier-
archical Bayesian domain adaptation (Finkel and
Manning, 2009), but both weights and feature val-
ues depend on D
i
, and we use L
1
regularization.
Weight Updates. Model tuning and adaptation are
performed with AdaGrad, an online subgradient
method with an adaptive learning rate that comes
with good theoretical guarantees. AdaGrad makes
the following update:
w
t
= w
t?1
? ??
1/2
t
?`
t
(w
t?1
) (2)
?
?1
t
= ?
?1
t?1
+?`
t
(w
t?1
)?`
t
(w
t?1
)
>
=
t
?
i=1
?`
i
(w
i?1
)?`
i
(w
i?1
)
>
(3)
The loss function ` reflects the pairwise ordering
between hypotheses. For feature selection, we ap-
ply an L
1
penalty via forward-backward splitting
(Duchi and Singer, 2009). ? is the initial learning
rate. See (Green et al., 2013b) for details.
Our adaptation schema is an extension of frustrat-
ingly easy domain adaptation (FEDA) (Daumé III,
2007) to multiple domains with different regular-
ization parameters, similar to (Finkel and Manning,
2009). Each feature value is replicated for each do-
main. LetD denote the set of all domains present in
the adaptation set. Given an original feature vector
?(r; c) for derivation r of sentence f
i
withD
i
? D,
the replicated feature vector includes |D| copies of
?(r; c), one for each d ? |D|, such that
?
d
(r; c) =
{
?(r; c), d ? D
i
0, otherwise.
(4)
The weights of this replicated feature space are ini-
tialized using the weights w tuned for the baseline
?(r; c).
w
d
=
{
w, d is root
0, otherwise.
(5)
In this way, the root domain corresponds to the un-
adapted baseline weights, denoted as ?
?
in (Finkel
and Manning, 2009). The idea is that we simultane-
ously maintain a generic set of weights that applies
to all domains as well as their domain-specific “off-
sets”, describing how a domain differs from the
generic case. Model updates during adaptation are
performed according to the same procedure as tun-
ing updates, but now in the replicated space.
Different from (Finkel and Manning, 2009), this
generalized FEDA model does not restrict the do-
mains to be strictly hierarchically structured. We
could, for example, include a domain for each trans-
lator that crossed different genres. However, all of
our experimental evaluations maintain a hierarchi-
cal domain structure, leaving more general setups
to future work.
Rules and Feature Values. A derivation r of sen-
tence f
i
has features that are computed from the
combination of the baseline training corpus c
0
and
a genre-specific corpus that includes all sentence
pairs from the tuning corpus as well as from the
adaptation corpus (f
j
, e
?
j
) with j < i sharing f
i
’s
genre. We refer to this combined corpus as c
i
. The
tuning corpus is the same that is used for parameter
tuning in the baseline system. The adaptation cor-
pus is our test set. Note that in our evaluation, each
sentence is translated before it is used for adaptation,
so that there is no contamination of results.
In order to extend the model efficiently within
a streaming data environment, we make use of a
suffix-array implementation for our phrase table
(Levenberg et al., 2010).
Rather than combining corpus counts across
these different sources, separate rules extracted
from the baseline corpus and the genre-specific
corpus exist independently in the derivation space,
and features of each are computed only with one
corpus. In this configuration, a large amount of out-
of-domain evidence from the baseline model will
not dampen the feature value adaptation effects of
adding new sentence pairs from the adaptation cor-
pus. The genre-specific phrases are distinguished
by an additional binary provenance feature.
In order to extract features from the genre-
specific corpus, a word-level alignment must be
computed for each (f
j
, e
?
j
). We force decode using
the adapted translation model for f
j
. In order to
avoid decoding failures, we insert high-cost single-
word translation rules that allow any word in f
j
to
align to any word in e
?
j
.
Sparse Features. Applying a large number of
sparse features would compromise responsiveness
of our translation system and is thus a poor fit
for real-time adaptive computer-assisted transla-
tion. However, features that can be learned on a
single document are limited in number and can be
discarded after the document has been processed.
Therefore, document-level sparse features are a
powerful means to fit our model to local context
with a comparatively small impact on efficiency.
1061
4 Experiments
We performed two sets of German?English exper-
iments; Table 1 contains the results for both. Our
first set of experiments was performed on the PatTR
corpus (Wäschle and Riezler, 2012). We divided
the corpus into training and development data by
date and selected 2.4M parallel segments dated be-
fore 2000 from the “claims” section as bilingual
training data, taking equal parts from each of the
eight patent types A–H as classified by the Cooper-
ative Patent Classification (CPC). From each type
we further drew separate test sets and a single tune
set, selecting documents with at least 10 segments
and a maximum of 150 source words per segment,
with around 2,100 sentences per test set and 400
sentences per type for the tune set. The “claims”
section of this corpus is highly repetitive, which
makes it ideal for observing the effects of incremen-
tal adaptation techniques.
To train the language and translation model we
additionally leveraged all available bilingual and
monolingual data provided for the EMNLP 2015
Tenth Workshop on Machine Translation
3
. The to-
tal size of the bitext used for rule extraction and
feature estimation was 6.4M sentence pairs. We
trained a standard 5-gram language model with
modified Kneser-Ney smoothing (Kneser and Ney,
1995; Chen and Goodman, 1998) using the KenLM
toolkit (Heafield et al., 2013) on 4 billion running
words. The bitext was word-aligned with mgiza
(Och and Ney, 2003), and we used the phrasal de-
coder (Green et al., 2014a) with standard German-
English settings for experimentation.
Our second set of experiments was performed on
a mixed-genre corpus containing lectures, patents,
and news articles. The standard dev and test sets
of the IWSLT 2014 shared task
4
were used for
the lecture genre. Each document corresponded
to an entire lecture. For the news genre, we used
newstest2012 for tuning, newstest2013 for meta-
parameter optimization, and newstest2014 for test-
ing. The tune set for the patent genre is identical
to the first set of experiments, while the test set
consists of the first 300 sentence pairs of each of
the patent type specific test sets of the previous ex-
periment. The documents in the news and patent
genres contain around 20 segments on average.
Our evaluation proceeded in multiple stages. We
first trained a set of background weights on the
3http://www.statmt.org/wmt15/
4http://workshop2014.iwslt.org/
PatTR heterogeneous data
avg lecture news patent
repetition rate 27.80 5.46 3.13 27.42
baseline 48.89 25.82 24.92 48.97
+ genre weights 49.05 26.64 25.12 49.39
+ genre TM 53.25 27.67 25.66 53.22
+ doc. weights 53.56 27.98 25.71 53.40
+ sparse features 54.53 28.09 25.89 54.30
Table 1: Results in uncased Bleu [%]. Each com-
ponent is added on top of the previous line. All
results in line + genre TM and below are statisti-
cally significant improvements over the baseline
with 95% confidence. We also report the repetition
rate of the test corpora as propsed by Bertoldi et al.
(2013).
concatenated tune sets (baseline). Keeping these
weights fixed, we performed an additional tun-
ing run to estimate genre-level weights (+ genre
weights).
5
In the patent-only setup, we used patent
CPC type as genre. Next, we trained a genre-
specific translation model for each genre by first
feeding the tune set and then the test set into our
incremental adaptation learning method as a contin-
uous stream of simulated post edits (+ genre TM).
After each sentence, we performed an update on the
genre-specific weights. In separate experiments, we
also included document-level weights as an addi-
tional domain (+ doc. weights) and included sparse
features at the document level (+ sparse features).
6
Table 1 demonstrates that each component of
this approach offered consistent incremental qual-
ity gains, but with varying magnitudes. For the
patent experiments we report the average over our
eight test sets (A-H) due to lack of space, but to-
tal improvement varied from +4.92 to +6.46 Bleu.
In the mixed-genre experiments, Bleu increased
by +2.27 on lectures, +0.97 on news, and +5.33
on patents. On all tasks, we observed statistically
significant improvements over the baseline (95%
confidence level) in the + genre TM, + doc. weights
and + sparse features experiments using bootstrap
resampling (Koehn, 2004).
These results demonstrate the efficacy of hierar-
chical incremental adaptation, although we would
like to stress that the patent data was selected specif-
ically for its high level of repetitiveness, and the
5
Learning rates and regularization weights for this step
were selected on newstest2013.
6
Learning rates and regularization weights for each genre
were selected on the genre-specific tune sets.
1062
-2
 0
 2
 4
 6
 8
 10
 12
 2  4  6  8  10  12  14  16  18  20
B
L
E
U
 
[
%
]
 
d
i
f
f
e
r
e
n
c
e
 
t
o
 
b
a
s
e
l
i
n
e
i-th sentence in document
news + genre TMnews + doc. weightsnews + sparse featurespatent + genre TMpatent + doc. weightspatent + sparse features
Figure 2: Bleu difference between baseline + genre
weights and our incremental adaptation approach,
computed on a single segment from each document
according to their order, i.e. the first segment from
each document, then the second segment from each
document, etc.
large improvement in this genre would only be ex-
pected to arise in similarly structured domains. This
property is quantified by the repetition rate mea-
sure (RR) (Bertoldi et al., 2013) reported in Table 1,
which confirms the finding by Cettolo et al. (2014)
that RR correlates with the effectiveness of adapta-
tion.
Analysis. Figure 2 shows Bleu score differences
to the baseline + genre weights system for different
subsets of the news and patent test sets. Each point
is computed by document slicing, i.e. on a single
segment from each document. The rightmost data
point is the Bleu score we obtain by evaluating on
the 20th segment of each document, grouped into a
pseudo-corpus. Note that this group does not cor-
respond to any number in Table 1, which reports
Bleu on the entire test sets. Thus, we evaluate on all
sentences that have learned from exactly (i?1) seg-
ments of the same document, with i = 1, . . . , 19.
Although the graph is naturally very noisy (each
score is computed on roughly 150 segments), we
can clearly see that incremental adaptation learns
on the document level: on average, the improve-
ment over the baseline increases when proceeding
further into the document.
Decoding speed. In our real-time computer-
assisted translation scenario, a certain translation
speed is required to allow for responsive user in-
teraction. Table 2 reports the speed in words per
second on the lecture data. Adding a genre-specific
translation model results in a speed reduction by a
factor of 12.6 due to the additional (forced) decod-
words / sec
baseline 177.6
+ genre weights 58.5
+ genre TM 14.1
+ doc. weights 9.8
+ sparse features 5.8
Table 2: Decoding speed on the lecture data.
ing run and weight updates. Sparse features slows
the system down further by a factor of 2.4. However,
the largest part of the computation time incurs only
when the user has finalized collaborative translation
of one sentence and is busy reading the next source
sentence. Further, the speed/quality tradeoff can be
adjusted with pruning parameters.
5 Conclusion
We have presented an incremental learning ap-
proach for MT that maintains a flexible hierarchical
domain structure within a single consistent model.
In our experiments, we define a three-level hierar-
chy with a global root domain as well as genre- and
document-level domains. Further, we perform in-
cremental adaptation by training a genre-specific
translation model on the stream of incoming post-
edits and adding document-level sparse features that
do not significantly compromise efficiency. Our re-
sults show consistent contributions from each level
of adaptation across multiple genres.
References
Pratyush Banerjee, Jinhua Du, Baoli Li, Sudip Kr.
Naskar, Andy Way, and Josef van Genabith. 2010.
Combining multi-domain statistical machine transla-
tion models using automatic classifiers. In Proceed-
ings of the Association for Machine Translation in
the Americas, Denver, Colorado, October.
Nicola Bertoldi, Mauro Cettolo, andMarcello Federico.
2013. Cache-based online adaptation for machine
translation enhanced computer assisted translation.
In Proceedings of the XIV Machine Translation Sum-
mit, pages 36–42, Nice, France, September.
Alexandru Ceau?fu, John Tinsley, Jian Zhang, and
Andy Way. 2011. Experiments on domain adap-
tation for patent machine translation in the PLuTO
project. In Mikel L. Forcada, Heidi Depraetere, and
Vincent Vandeghinste, editors, Proceedings of the
15th International Conference of the European Asso-
ciation for Machine Translation (EAMT), pages 21–
28, Leuven, Belgium.
1063
Mauro Cettolo, Nicola Bertoldi, andMarcello Federico.
2014. The repetition rate of text as a predictor of the
effectiveness of machine translation adaptation. In
Conference of the Association for Machine Transla-
tion in the Americas (AMTA), pages 166–179, Van-
couver, Canada, October.
Stanley F. Chen and Joshuo Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, August.
Lei Cui, Xilun Chen, Dongdong Zhang, Shujie Liu,
Mu Li, andMing Zhou. 2013. Multi-domain adapta-
tion for SMT using multi-task learning. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing, pages 1055–1065,
Seattle, Washington, USA, October.
Hal Daumé III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
256–263, Prague, Czech Republic, June.
Michael Denkowski, Chris Dyer, and Alon Lavie. 2014.
Learning from post-editing: Online model adapta-
tion for statistical machine translation. In Proceed-
ings of the 14th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 395–404, Gothenburg, Sweden, April.
John Duchi and Yoram Singer. 2009. Efficient online
and batch learning using forward backward splitting.
Journal of Machine Learning Research, 10:2899–
2934, December.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research, 12:2121–2159, July.
Kevin Duh, Katsuhito Sudoh, Hajime Tsukada, Hideki
Isozaki, and Masaaki Nagata. 2010. N-best rerank-
ing by multitask learning. In Proceedings of the
Joint Fifth Workshop on Statistical Machine Trans-
lation and MetricsMATR, pages 375–383, Uppsala,
Sweden, July.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Hierarchical bayesian domain adaptation. In Pro-
ceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 602–610, Boulder, Colorado.
Spence Green, Sida Wang, Daniel Cer, and Christo-
pher D. Manning. 2013a. The efficacy of human
post-editing for language translation. In ACM CHI
Conference on Human Factors in Computing Sys-
tems, Paris, France, April.
Spence Green, Sida Wang, Daniel Cer, and Christo-
pher D. Manning. 2013b. Fast and adaptive on-
line training of feature-rich translation models. In
51st Annual Meeting of the Association for Compu-
tational Linguistics, pages 311–321, Sofia, Bulgaria,
August.
Spence Green, Daniel Cer, , and Christopher D. Man-
ning. 2014a. Phrasal: A Toolkit for New Directions
in Statistical Machine Translation. In Proceedings
of the Ninth Workshop on Statistical Machine Trans-
lation, pages 114–121, Baltimore, Maryland USA,
June.
Spence Green, Daniel Cer, and Christopher D. Man-
ning. 2014b. An empirical comparison of features
and tuning for phrase-based machine translation. In
Proceedings of the NinthWorkshop on StatisticalMa-
chine Translation, pages 466–476, Baltimore, Mary-
land, USA, June.
A. Guerberof. 2009. Productivity and quality in the
post-editing of outputs from translation memories
and machine translation. International Journal of
Localization, 7(1):11–21.
Daniel Hardt and Jakob Elming. 2010. Incremental
re-training for post-editing SMT. In Proceedings of
the Ninth Conference of the Association for Machine
Translation in the Americas, Denver, Colorado, Oc-
tober.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690–696,
Sofia, Bulgaria, August.
Reinerd Kneser and Hermann Ney. 1995. Improved
backing-off for M-gram language modeling. In Pro-
ceedings of the International Conference on Acous-
tics, Speech, and Signal Processing, volume 1, pages
181–184, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In
Proc. of the Human Language Technology Conf.
(HLT-NAACL), pages 127–133, Edmonton, Canada,
May/June.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?ej Bojar, Alexandra
Constantine, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
pages 177–180, Prague, Czech Republic, June.
Philipp Koehn. 2004. Statistical Significance Tests
for Machine Translation Evaluation. In Proc. of the
Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 388–395, Barcelona,
Spain, July.
Abby Levenberg, Chris Callison-Burch, and Miles Os-
borne. 2010. Stream-based translation models for
statistical machine translation. In Human Language
Technologies: The 2010 Annual Conference of the
1064
North American Chapter of the Association for Com-
putational Linguistics, pages 394–402, Los Angeles,
California, June.
Percy Liang, Alexandre Buchard-Côté, Dan Klein, and
Ben Taskar. 2006. An End-to-End Discriminative
Approach toMachine Translation. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the As-
sociation for Computational Linguistics, pages 761–
768, Sydney, Australia.
Prashant Mathur, Cettolo Mauro, and Marcello Fed-
erico. 2013. Online learning approaches in com-
puter assisted translation. In Proceedings of the
Eighth Workshop on Statistical Machine Translation,
pages 301–308, Sofia, Bulgaria, August.
Franz Josef Och and Hermann Ney. 2003. A Sys-
tematic Comparison ofVarious Statistical Alignment
Models. Computational Linguistics, 29(1):19–51,
March.
F. J. Och and H. Ney. 2004. The Alignment Template
Approach to Statistical Machine Translation. Com-
putational Linguistics,, 30(4):417–450.
Daniel Ortiz-Martínez, Ismael García-Varea, and Fran-
cisco Casacuberta. 2010. Online learning for inter-
active statistical machine translation. InHuman Lan-
guage Technologies: The 2010 Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 546–554, Los An-
geles, California, June.
M. Plitt and F. Masselot. 2010. A productivity test of
statistical machine translation post-editing in a typ-
ical localisation context. The Prague Bulletin of
Mathematical Linguistics, 93:7–16.
Rico Sennrich, Holger Schwenk, and Walid Aransa.
2013. A multi-domain translation model framework
for statistical machine translation. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics, pages 832–840, Sofia, Bul-
garia, August.
Patrick Simianer and Stefan Riezler. 2013. Multi-
task learning for improved discriminative training in
SMT. In Proceedings of the EighthWorkshop on Sta-
tistical Machine Translation, pages 292–300, Sofia,
Bulgaria, August.
Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012.
Joint Feature Selection in Distributed Stochastic
Learning for Large-Scale Discriminative Training in
SMT. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics, pages
11–21, Jeju Island, Korea, July.
Linfeng Song, Haitao Mi, Yajuan Lü, and Qun Liu.
2011. Bagging-based system combination for do-
main adaption. In Proceedings of the 13th Machine
Translation Summit (MT Summit XIII), pages 293–
299, Xiamen, China.
Wei Wang, Klaus Macherey, Wolfgang Macherey,
Franz Och, and Peng Xu. 2012. Improved domain
adaptation for statistical machine translation. In Pro-
ceedings of the Tenth Conference of the Association
for Machine Translation in the Americas (AMTA),
San Diego, California.
Katharina Wäschle and Stefan Riezler. 2012. Ana-
lyzing Parallelism and Domain Similarities in the
MAREC Patent Corpus. Multidisciplinary Informa-
tion Retrieval, pages 12–27.
Katharina Wäschle, Patrick Simianer, Nicola Bertoldi,
Stefan Riezler, and Marcello Federico. 2013. Gener-
ative and DiscriminativeMethods for Online Adapta-
tion in SMT. In Proceedings of Machine Translation
Summit XIV, Nice, France.
Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann
Ney. 2007. Domain dependent statistical machine
translation. In Proceedings of the MT Summit, pages
515–520, Copenhagen, Denmark, September.
1065
