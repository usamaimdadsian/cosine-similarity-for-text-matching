Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 808–817,
Avignon, France, April 23 - 27 2012. c©2012 Association for Computational Linguistics
Composing extended top-down tree transducers?
Aure´lie Lagoutte
E´cole normale supe´rieure de Cachan, De´partement Informatique
alagoutt@dptinfo.ens-cachan.fr
Fabienne Braune and Daniel Quernheim and Andreas Maletti
University of Stuttgart, Institute for Natural Language Processing
{braunefe,daniel,maletti}@ims.uni-stuttgart.de
Abstract
A composition procedure for linear and
nondeleting extended top-down tree trans-
ducers is presented. It is demonstrated that
the new procedure is more widely applica-
ble than the existing methods. In general,
the result of the composition is an extended
top-down tree transducer that is no longer
linear or nondeleting, but in a number of
cases these properties can easily be recov-
ered by a post-processing step.
1 Introduction
Tree-based translation models such as syn-
chronous tree substitution grammars (Eisner,
2003; Shieber, 2004) or multi bottom-up tree
transducers (Lilin, 1978; Engelfriet et al., 2009;
Maletti, 2010; Maletti, 2011) are used for sev-
eral aspects of syntax-based machine transla-
tion (Knight and Graehl, 2005). Here we consider
the extended top-down tree transducer (XTOP),
which was studied in (Arnold and Dauchet,
1982; Knight, 2007; Graehl et al., 2008; Graehl
et al., 2009) and implemented in the toolkit
TIBURON (May and Knight, 2006; May, 2010).
Specifically, we investigate compositions of linear
and nondeleting XTOPs (ln-XTOP). Arnold and
Dauchet (1982) showed that ln-XTOPs compute
a class of transformations that is not closed under
composition, so we cannot compose two arbitrary
ln-XTOPs into a single ln-XTOP. However, we
will show that ln-XTOPs can be composed into a
(not necessarily linear or nondeleting) XTOP. To
illustrate the use of ln-XTOPs in machine transla-
tion, we consider the following English sentence
together with a German reference translation:
? All authors were financially supported by the EMMY
NOETHER project MA / 4959 / 1-1 of the German Research
Foundation (DFG).
RC
PREL
that
C
NP VP
7?
C
NP VP
C
NP VP
VAUX VPART NP
7?
C
NP VP
VAUX NP VPART
Figure 1: Word drop [top] and reordering [bottom].
The newswire reported yesterday that the Serbs have
completed the negotiations.
Gestern [Yesterday] berichtete [reported] die [the]
Nachrichtenagentur [newswire] die [the] Serben
[Serbs] ha¨tten [would have] die [the] Verhandlungen
[negotiations] beendet [completed].
The relation between them can be described
(Yamada and Knight, 2001) by three operations:
drop of the relative pronoun, movement of the
participle to end of the clause, and word-to-word
translation. Figure 1 shows the first two oper-
ations, and Figure 2 shows ln-XTOP rules per-
forming them. Let us now informally describe
the execution of an ln-XTOP on the top rule ?
of Figure 2. In general, ln-XTOPs process an in-
put tree from the root towards the leaves using
a set of rules and states. The state p in the left-
hand side of ? controls the particular operation of
Figure 1 [top]. Once the operation has been per-
formed, control is passed to states pNP and pVP,
which use their own rules to process the remain-
ing input subtree governed by the variable below
them (see Figure 2). In the same fashion, an ln-
XTOP containing the bottom rule of Figure 2 re-
orders the English verbal complex.
In this way we model the word drop by an ln-
XTOP M and reordering by an ln-XTOP N . The
syntactic properties of linearity and nondeletion
yield nice algorithmic properties, and the mod-
808
pRC
PREL
that
C
y1 y2
?
C
pNP
y1
pVP
y2
q
C
z1 VP
z2 z3 z4
?
C
qNP
z1
VP
qVA
z2
qVP
z4
qNP
z3
Figure 2: XTOP rules for the operations of Figure 1.
ular approach is desirable for better design and
parametrization of the translation model (May et
al., 2010). Composition allows us to recombine
those parts into one device modeling the whole
translation. In particular, it gives all parts the
chance to vote at the same time. This is especially
important if pruning is used because it might oth-
erwise exclude candidates that score low in one
part but well in others (May et al., 2010).
Because ln-XTOP is not closed under compo-
sition, the composition ofM andN might be out-
side ln-XTOP. These cases have been identified
by Arnold and Dauchet (1982) as infinitely “over-
lapping cuts”, which occur when the right-hand
sides of M and the left-hand sides of N are un-
boundedly overlapping. This can be purely syn-
tactic (for a given ln-XTOP) or semantic (inher-
ent in all ln-XTOPs for a given transformation).
Despite the general impossibility, several strate-
gies have been developed: (i) Extension of the
model (Maletti, 2010; Maletti, 2011), (ii) online
composition (May et al., 2010), and (iii) restric-
tion of the model, which we follow. Composi-
tions of subclasses in which the XTOP N has at
most one input symbol in its left-hand sides have
already been studied in (Engelfriet, 1975; Baker,
1979; Maletti and Vogler, 2010). Such compo-
sitions are implemented in the toolkit TIBURON.
However, there are translation tasks in which the
used XTOPs do not fulfill this requirement. Sup-
pose that we simply want to compose the rules of
Figure 2, The bottom rule does not satisfy the re-
quirement that there is at most one input symbol
in the left-hand side.
We will demonstrate how to compose two lin-
ear and nondeleting XTOPs into a single XTOP,
which might however no longer be linear or non-
deleting. However, when the syntactic form of
?(?)
q(1)
x(11)1
?(2)
?(21) q(22)
x(221)2
?(3)
?(31)
p(311)
x(3111)3
?
q
x1
? ?
?
p
x3
Figure 3: Linear normalized tree t ? T?(Q(X)) [left]
and t[?]2 [right] with var(t) = {x1, x2, x3}. The posi-
tions are indicated in t as superscripts. The subtree t|2
is ?(?, q(x2)).
the composed XTOP has only bounded overlap-
ping cuts, post-processing will get rid of them
and restore an ln-XTOP. In the remaining cases,
in which unbounded overlapping is necessary or
occurs in the syntactic form but would not be nec-
essary, we will compute an XTOP. This is still
an improvement on the existing methods that just
fail. Since general XTOPs are implemented in
TIBURON and the new composition covers (essen-
tially) all cases currently possible, our new com-
position procedure could replace the existing one
in TIBURON. Our approach to composition is the
same as in (Engelfriet, 1975; Baker, 1979; Maletti
and Vogler, 2010): We simply parse the right-
hand sides of the XTOP M with the left-hand
sides of the XTOP N . However, to facilitate this
approach we have to adjust the XTOPs M and N
in two pre-processing steps. In a first step we cut
left-hand sides of rules of N into smaller pieces,
which might introduce non-linearity and deletion
into N . In certain cases, this can also intro-
duce finite look-ahead (Engelfriet, 1977; Graehl
et al., 2009). To compensate, we expand the rules
of M slightly. Section 4 explains those prepa-
rations. Next, we compose the prepared XTOPs
as usual and obtain a single XTOP computing the
composition of the transformations computed by
M and N (see Section 5). Finally, we apply a
post-processing step to expand rules to reobtain
linearity and nondeletion. Clearly, this cannot be
successful in all cases, but often removes the non-
linearity introduced in the pre-processing step.
2 Preliminaries
Our trees have labels taken from an alphabet ?
of symbols, and in addition, leaves might be
labeled by elements of the countably infinite
809
?x1 ?
?
? ? x2
?
7?
?
? ?
?
? ? x2
?
?[
?
? x3
Figure 4: Substitution where ?(x1) = ?, ?(x2) = x2,
and ?(x3) = ?(?(?, ?, x2)).
set X = {x1, x2, . . . } of formal variables. For-
mally, for every V ? X the set T?(V ) of
?-trees with V -leaves is the smallest set such that
V ? T?(V ) and ?(t1, . . . , tk) ? T?(V ) for all
k ? N, ? ? ?, and t1, . . . , tk ? T?(V ). To avoid
excessive universal quantifications, we drop them
if they are obvious from the context.
For each tree t ? T?(X) we identify nodes by
positions. The root of t has position ? and the po-
sition iw with i ? N and w ? N? addresses the
position w in the i-th direct subtree at the root.
The set of all positions in t is pos(t). We write
t(w) for the label (taken from ? ?X) of t at po-
sition w ? pos(t). Similarly, we use
• t|w to address the subtree of t that is rooted
in position w, and
• t[u]w to represent the tree that is ob-
tained from replacing the subtree t|w at w
by u ? T?(X).
For a given set L ? ? ?X of labels, we let
posL(t) = {w ? pos(t) | t(w) ? L}
be the set of all positions whose label belongs
to L. We also write posl(t) instead of pos{l}(t).
The tree t ? T?(V ) is linear if |posx(t)| ? 1 for
every x ? X . Moreover,
var(t) = {x ? X | posx(t) 6= ?}
collects all variables that occur in t. If the vari-
ables occur in the order x1, x2, . . . in a pre-order
traversal of the tree t, then t is normalized. Given
a finite set Q, we write Q(T ) with T ? T?(X)
for the set {q(t) | q ? Q, t ? T}. We will treat
elements of Q(T ) as special trees of T??Q(X).
The previous notions are illustrated in Figure 3.
A substitution ? is a mapping ? : X ? T?(X).
When applied to a tree t ? T?(X), it will return
the tree t?, which is obtained from t by replacing
all occurrences of x ? X (in parallel) by ?(x).
This can be defined recursively by x? = ?(x) for
all x ? X and ?(t1, . . . , tk)? = ?(t1?, . . . , tk?)
qS
S
x1 VP
x2 x3
?
S’
qV
x2
qNP
x1
qNP
x1
t
qS
S
t1
VP
t2 t3
?
t
S’
qV
t2
qNP
t1
qNP
t1
Figure 5: Rule and its use in a derivation step.
for all ? ? ? and t1, . . . , tk ? T?(X). The effect
of a substitution is displayed in Figure 4. Two
substitutions ?, ?? : X ? T?(X) can be com-
posed to form a substitution ??? : X ? T?(X)
such that ???(x) = ?(x)?? for every x ? X .
Next, we define two notions of compatibility
for trees. Let t, t? ? T?(X) be two trees. If there
exists a substitution ? such that t? = t?, then t? is
an instance of t. Note that this relation is not sym-
metric. A unifier ? for t and t? is a substitution ?
such that t? = t??. The unifier ? is a most gen-
eral unifier (short: mgu) for t and t? if for every
unifier ??? for t and t? there exists a substitution ??
such that ??? = ???. The set mgu(t, t?) is the set of
all mgus for t and t?. Most general unifiers can be
computed efficiently (Robinson, 1965; Martelli
and Montanari, 1982) and all mgus for t and t?
are equal up to a variable renaming.
Example 1. Let t = ?(x1, ?(?(?, ?, x2))) and
t? = ?(?, x3). Then mgu(t, t?) contains ? such
that ?(x1) = ? and ?(x3) = ?(?(?, ?, x2)). Fig-
ure 4 illustrates the unification.
3 The model
The discussed model in this contribution is an
extension of the classical top-down tree trans-
ducer, which was introduced by Rounds (1970)
and Thatcher (1970). The extended top-down
tree transducer with finite look-ahead or just
XTOPF and its variations were studied in (Arnold
and Dauchet, 1982; Knight and Graehl, 2005;
810
qS
S
x1 VP
x2 x3
S’
qV
x2
qNP
x1
qNP
x3
?
qS
S’
x2 x1 x3
S
qNP
x1
VP
qV
x2
qNP
x3
?
Figure 6: Rule [left] and reversed rule [right].
Knight, 2007; Graehl et al., 2008; Graehl et
al., 2009). Formally, an extended top-down tree
transducer with finite look-ahead (XTOPF) is a
system M = (Q,?,?, I, R, c) where
• Q is a finite set of states,
• ? and ? are alphabets of input and output
symbols, respectively,
• I ? Q is a set of initial states,
• R is a finite set of (rewrite) rules of the form
` ? r where ` ? Q(T?(X)) is linear and
r ? T?(Q(var(`))), and
• c : R × X ? T?(X) assigns a look-ahead
restriction to each rule and variable such that
c(?, x) is linear for each ? ? R and x ? X .
The XTOPF M is linear (respectively, nondelet-
ing) if r is linear (respectively, var(r) = var(`))
for every rule ` ? r ? R. It has no look-ahead
(or it is an XTOP) if c(?, x) ? X for all rules
? ? R and x ? X . In this case, we drop the look-
ahead component c from the description. A rule
` ? r ? R is consuming (respectively, produc-
ing) if pos?(`) 6= ? (respectively, pos?(r) 6= ?).
We let Lhs(M) = {l | ?q, r : q(l)? r ? R}.
Let M = (Q,?,?, I, R, c) be an XTOPF. In
order to facilitate composition, we define senten-
tial forms more generally than immediately nec-
essary. Let ?? and ?? be such that ? ? ??
and ? ? ??. To keep the presentation sim-
ple, we assume that Q ? (?? ? ??) = ?. A
sentential form of M (using ?? and ??) is a
tree of SF(M) = T??(Q(T??)). For every
?, ? ? SF(M), we write ? ?M ? if there exist a
positionw ? posQ(?), a rule ? = `? r ? R, and
a substitution ? : X ? T?? such that ?(x) is an in-
stance of c(?, x) for every x ? X and ? = ?[`?]w
and ? = ?[r?]w. If the applicable rules are re-
stricted to a certain subset R? ? R, then we also
write ? ?R? ?. Figure 5 illustrates a derivation
step. The tree transformation computed by M is
?M = {(t, u) ? T? × T? | ?q ? I : q(t)?
?
M u}
where ??M is the reflexive, transitive closure
of?M . It can easily be verified that the definition
p
C
y1 y2
?
RC
PREL
that
C
pNP
y1
pVP
y2
Figure 7: Top rule of Figure 2 reversed.
of ?M is independent of the choice of ?? and ??.
Moreover, it is known (Graehl et al., 2009) that
each XTOPF can be transformed into an equiva-
lent XTOP preserving both linearity and nondele-
tion. However, the notion of XTOPF will be con-
venient in our composition construction. A de-
tailed exposition to XTOPs is presented by Arnold
and Dauchet (1982) and Graehl et al. (2009).
A linear and nondeleting XTOP M with
rules R can easily be reversed to obtain
a linear and nondeleting XTOP M?1 with
rules R?1, which computes the inverse transfor-
mation ?M?1 = ?
?1
M , by reversing all its rules.
A (suitable) rule is reversed by exchanging the
locations of the states. More precisely, given
a rule q(l) ? r ? R, we obtain the rule
q(r?) ? l? of R?1, where l? = l? and r? is the
unique tree such that there exists a substitution
? : X ? Q(X) with ?(x) ? Q({x}) for every
x ? X and r = r??. Figure 6 displays a rule
and its corresponding reversed rule. The reversed
form of the XTOP rule modeling the insertion op-
eration in Figure 2 is displayed in Figure 7.
Finally, let us formally define composition.
The XTOP M computes the tree transformation
?M ? T? × T?. Given another XTOP N that
computes a tree transformation ?N ? T? × T?,
we might be interested in the tree transforma-
tion computed by the composition of M and N
(i.e., running M first and then N ). Formally, the
composition ?M ; ?N of the tree transformations
?M and ?N is defined by
?M ; ?N = {(s, u) | ?t : (s, t) ? ?M , (t, u) ? ?N}
and we often also use the notion ‘composition’ for
XTOP with the expectation that the composition
of M and N computes exactly ?M ; ?N .
4 Pre-processing
We want to compose two linear and nondelet-
ing XTOPs M = (P,?,?, IM , RM ) and
811
LHS(M?1) LHS(N)
C
y1 y2
C
z1 VP
z2 z3 z4
Figure 8: Incompatible left-hand sides of Example 3.
N = (Q,?,?, IN , RN ). Before we actually per-
form the composition, we will prepare M and N
in two pre-processing steps. After these two steps,
the composition is very simple. To avoid com-
plications, we assume that (i) all rules of M are
producing and (ii) all rules of N are consuming.
For convenience, we also assume that the XTOPs
M and N only use variables of the disjoint sets
Y ? X and Z ? X , respectively.
4.1 Compatibility
In the existing composition results for subclasses
of XTOPs (Engelfriet, 1975; Baker, 1979; Maletti
and Vogler, 2010) the XTOP N has at most one
input symbol in its left-hand sides. This restric-
tion allows us to match rule applications of N to
positions in the right-hand sides of M . Namely,
for each output symbol in a right-hand side of M ,
we can select a rule of N that can consume that
output symbol. To achieve a similar decompo-
sition strategy in our more general setup, we in-
troduce a compatibility requirement on right-hand
sides of M and left-hand sides of N . Roughly
speaking, we require that the left-hand sides of N
are small enough to completely process right-
hand sides of M . However, a comparison of
left- and right-hand sides is complicated by the
fact that their shape is different (left-hand sides
have a state at the root, whereas right-hand sides
have states in front of the variables). We avoid
these complications by considering reversed rules
of M . Thus, an original right-hand side of M is
now a left-hand side in the reversed rules and thus
has the right format for a comparison. Recall that
Lhs(N) contains all left-hand sides of the rules
of N , in which the state at the root was removed.
Definition 2. The XTOP N is compatible to M
if ?(Y ) ? X for all unifiers ? ? mgu(l1|w, l2)
between a subtree at a ?-labeled position
w ? pos?(l1) in a left-hand side l1 ? Lhs(M
?1)
and a left-hand side l2 ? Lhs(N).
Rule of M?1 Rule of N
?
p1
y1
p2
y2
? ?
p
?
y1 y2
q
?
? ?
z1 z2
?
?
q1
z1
q2
z2
Figure 9: Rules used in Example 5.
Intuitively, for every ?-labeled position w in a
right-hand side r1 of M and any left-hand side l2
of N , we require (ignoring the states) that either
(i) r1|w and l2 are not unifiable or (ii) r1|w is an
instance of l2.
Example 3. The XTOPs for the English-to-
German translation task in the Introduction are
not compatible. This can be observed on the
left-hand side l1 ? Lhs(M?1) of Figure 7
and the left-hand side l2 ? Lhs(N) of Fig-
ure 2[bottom]. These two left-hand sides are il-
lustrated in Figure 8. Between them there is an
mgu such that ?(Y ) 6? X (e.g., ?(y1) = z1 and
?(y2) = VP(z2, z3, z4) is such an mgu).
Theorem 4. There exists an XTOPF N ? that is
equivalent to N and compatible with M .
Proof. We achieve compatibility by cutting of-
fending rules of the XTOP N into smaller pieces.
Unfortunately, both linearity and nondeletion
of N might be lost in the process. We first let
N ? = (Q,?,?, IN , RN , cN ) be the XTOPF such
that cN (?, x) = x for every ? ? RN and x ? X .
If N ? is compatible with M , then we are done.
Otherwise, let l1 ? Lhs(M?1) be a left-hand side,
q(l2) ? r2 ? RN be a rule, and w ? pos?(l1)
be a position such that ?(y) /? X for some
? ? mgu(l1|w, l2) and y ? Y . Let v ? posy(l1|w)
be the unique position of y in l1|w.
Now we have to distinguish two cases: (i) Ei-
ther var(l2|v) = ? and there is no leaf in r2 la-
beled by a symbol from ?. In this case, we have
to introduce deletion and look-ahead into N ?. We
replace the old rule ? = q(l2) ? r2 by the new
rule ?? = q(l2[z]v) ? r2, where z ? X \ var(l2)
is a variable that does not appear in l2. In addition,
we let cN (??, z) = l2|v and cN (??, x) = cN (?, x)
for all x ? X \ {z}.
(ii) Otherwise, let V ? var(l2|v) be a maximal
set such that there exists a minimal (with respect
to the prefix order) position w? ? pos(r2) with
812
Another rule of N
q
?
z1 ?
z2 z3
?
?
q1
z1
q2
z2
q3
z3
Figure 10: Additional rule used in Example 5.
var(r2|w?) ? var(l2|v) and var(r2[?]w?)?V = ?,
where ? ? ? is arbitrary. Let z ? X \ var(l2) be
a fresh variable, q? be a new state of N , and
V ? = var(l2|v) \ V . We replace the rule
? = q(l2)? r2 of RN by
?1 = q(l2[z]v)? trans(r2)[q
?(z)]w?
?2 = q
?(l2|v)? r2|w? .
The look-ahead for z is trivial and other-
wise we simply copy the old look-ahead, so
cN (?1, z) = z and cN (?1, x) = cN (?, x) for all
x ? X \ {z}. Moreover, cN (?2, x) = cN (?, x)
for all x ? X . The mapping ‘trans’ is given for
t = ?(t1, . . . , tk) and q??(z??) ? Q(Z) by
trans(t) = ?(trans(t1), . . . , trans(tk))
trans(q??(z??)) =
{
?l2|v, q??, v??(z) if z?? ? V ?
q??(z??) otherwise,
where v? = posz??(l2|v).
Finally, we collect all newly generated states
of the form ?l, q, v? in Ql and for every such
state with l = ?(l1, . . . , lk) and v = iw, let
l? = ?(z1, . . . , zk) and
?l, q, v?(l?)?
{
q(zi) if w = ?
?li, q, w?(zi) otherwise
be a new rule of N without look-ahead.
Overall, we run the procedure until N ? is com-
patible with M . The procedure eventually ter-
minates since the left-hand sides of the newly
added rules are always smaller than the replaced
rules. Moreover, each step preserves the seman-
tics of N ?, which completes the proof.
We note that the look-ahead ofN ? after the con-
struction used in the proof of Theorem 4 is either
trivial (i.e., a variable) or a ground tree (i.e., a tree
without variables). Let us illustrate the construc-
tion used in the proof of Theorem 4.
µ1 :
q
C
z1 z
?
C
qNP
z1
q?
z
µ2 :
q?
VP
z2 z3 z4
?
VP
qVA
z2
qVP
z4
qNP
z3
Figure 11: Rules replacing the rule in Figure 7.
Example 5. Let us consider the rules illustrated
in Figure 9. We might first note that y1 has to
be unified with ?. Since ? does not contain any
variables and the right-hand side of the rule of N
does not contain any non-variable leaves, we are
in case (i) in the proof of Theorem 4. Conse-
quently, the displayed rule of N is replaced by a
variant, in which ? is replaced by a new variable z
with look-ahead ?.
Secondly, with this new rule there is an mgu,
in which y2 is mapped to ?(z1, z2). Clearly, we
are now in case (ii). Furthermore, we can select
the set V = {z1, z2} and position w? = . Cor-
respondingly, the following two new rules for N
replace the old rule:
q(?(z, z?))? q?(z?)
q?(?(z1, z2))? ?(q1(z1), q2(z2)) ,
where the look-ahead for z remains ?.
Figure 10 displays another rule of N . There is
an mgu, in which y2 is mapped to ?(z2, z3). Thus,
we end up in case (ii) again and we can select the
set V = {z2} and position w? = 2. Thus, we
replace the rule of Figure 10 by the new rules
q(?(z1, z))? ?(q1(z1), q
?(z), q3(z)) (?)
q?(?(z2, z3))? q2(z2)
q3(?(z1, z2))? q3(z2) ,
where q3 = ??(z2, z3), q3, 2?.
Let us use the construction in the proof of The-
orem 4 to resolve the incompatibility (see Exam-
ple 3) between the XTOPs presented in the Intro-
duction. Fortunately, the incompatibility can be
resolved easily by cutting the rule of N (see Fig-
ure 7) into the rules of Figure 11. In this example,
linearity and nondeletion are preserved.
813
4.2 Local determinism
After the first pre-processing step, we have the
original linear and nondeleting XTOP M and
an XTOPF N ? = (Q?,?,?, IN , R?N , cN ) that is
equivalent to N and compatible with M . How-
ever, in the first pre-processing step we might
have introduced some non-linear (copying) rules
in N ? (see rule (?) in Example 5), and it is known
that “nondeterminism [in M ] followed by copy-
ing [inN ?]” is a feature that prevents composition
to work (Engelfriet, 1975; Baker, 1979). How-
ever, our copying is very local and the copies
are only used to project to different subtrees.
Nevertheless, during those projection steps, we
need to make sure that the processing in M pro-
ceeds deterministically. We immediately note that
all but one copy are processed by states of the
form ?l, q, v? ? Ql. These states basically pro-
cess (part of) the tree l and project (with state q)
to the subtree at position v. It is guaranteed that
each such subtree (indicated by v) is reached only
once. Thus, the copying is “resolved” once the
states of the form ?l, q, v? are left. To keep the
presentation simple, we just add expanded rules
to M such that any rule that can produce a part of
a tree l immediately produces the whole tree. A
similar strategy is used to handle the look-ahead
of N ?. Any right-hand side of a rule of M that
produces part of a left-hand side of a rule of N ?
with look-ahead is expanded to produce the re-
quired look-ahead immediately.
Let L ? T?(Z) be the set of trees l such that
• ?l, q, v? appears as a state of Ql, or
• l = l2? for some ?2 = q(l2) ? r2 ? R?N
of N ? with non-trivial look-ahead (i.e.,
cN (?2, z) /? X for some z ? X), where
?(x) = cN (?2, x) for every x ? X .
To keep the presentation uniform, we assume
that for every l ? L, there exists a state of the
form ?l, q, v? ? Q?. If this is not already the
case, then we can simply add useless states with-
out rules for them. In other words, we assume that
the first case applies to each l ? L.
Next, we add two sets of rules to RM , which
will not change the semantics but prove to be use-
ful in the composition construction. First, for
every tree t ? L, let Rt contain all the rules
p(l) ? r, where p = p(l) ? r is a new state
with p ? P , minimal normalized tree l ? T?(X),
and an instance r ? T?(P (X)) of t such that
q
p
?
y1 y2
?
i
ps
y1
q
?
y2
q?
?
y2
?
i
ps
s?
y1
?
s
i
ps
y1
i
ps

? 
q
?s
?
y1 y2
i
ps
y1
?
q?
?s
?
y1 y2
q
p
y2
?
q
?s,s?/??s,s?
?
y1 y2 y3
i
ps
y1
?
q?
??s,s?
?
y1 y2 y3
?
i
ps?
y2
i
p?
y3
?
q?
?s,s?
?
y1 y2 y3
?
i
ps?
y2
q
?
y3
q?
?
y3
?
Figure 12: Useful rules for the composition M ? ;N ? of
Example 8, where s, s? ? {?, ?} and ? ? P?(z2,z3).
p(l) ??M ? ? ?M ? r for some ? that is not an
instance of t. In other words, we construct each
rule of Rt by applying existing rules of RM in
sequence to generate a (minimal) right-hand side
that is an instance of t. We thus potentially make
the right-hand sides of M bigger by joining sev-
eral existing rules into a single rule. Note that
this affects neither compatibility nor the seman-
tics. In the second step, we add pure ?-rules
that allow us to change the state to one that we
constructed in the previous step. For every new
state p¯ = p(l) ? r, let base(p¯) = p. Then
R?M = RM ? RL ? RE and P
? = P ?
?
t?L Pt
where
RL =
?
t?L
Rt and Pt = {`(?) | `? r ? Rt}
RE = {base(p¯)(x1)? p¯(x1) | p¯ ?
?
t?L
Pt} .
Clearly, this does not change the semantics be-
cause each rule of R?M can be simulated by a
chain of rules of RM . Let us now do a full ex-
ample for the pre-processing step. We consider a
nondeterministic variant of the classical example
by Arnold and Dauchet (1982).
Example 6. Let M = (P,?,?, {p}, RM )
be the linear and nondeleting XTOP such that
P = {p, p?, p?}, ? = {?, ?, ?, ?, }, and
RM contains the following rules
p(?(y1, y2))? ?(ps(y1), p(y2)) (†)
814
p(?(y1, y2, y3))? ?(ps(y1), ?(ps?(y2), p(y3)))
p(?(y1, y2, y3))? ?(ps(y1), ?(ps?(y2), p?(y3)))
ps(s
?(y1))? s(ps(y1))
ps()? 
for every s, s? ? {?, ?}. Similarly, we let
N = (Q,?,?, {q}, RN ) be the linear and non-
deleting XTOP such thatQ = {q, i} andRN con-
tains the following rules
q(?(z1, z2))? ?(i(z1), i(z2))
q(?(z1, ?(z2, z3)))? ?(i(z1), i(z2), q(z3)) (‡)
i(s(z1))? s(i(z1))
i()? 
for all s ? {?, ?}. It can easily be verified that
M and N meet our requirements. However, N is
not yet compatible with M because an mgu be-
tween rules (†) of M and (‡) of N might map y2
to ?(z2, z3). Thus, we decompose (‡) into
q(?(z1, z))? ?(i(z1), q(z), q
?(z))
q?(?(z2, z3))? q(z3)
q(?(z1, z2))? i(z1)
where q = ??(z2, z3), i, 1?. This newly obtained
XTOP N ? is compatible with M . In addition, we
only have one special tree ?(z2, z3) that occurs in
states of the form ?l, q, v?. Thus, we need to com-
pute all minimal derivations whose output trees
are instances of ?(z2, z3). This is again simple
since the first three rule schemes ?s, ?s,s? , and
??s,s? of M create such instances, so we simply
create copies of them:
?s(?(y1, y2))? ?(ps(y1), p(y2))
?s,s?(?(y1, y2, y3))? ?(ps(y1), ?(ps?(y2), p(y3)))
??s,s?(?(y1, y2, y3))? ?(ps(y1), ?(ps?(y2), p?(y3)))
for all s, s? ? {?, ?}. These are all the rules
of R?(z2,z3). In addition, we create the following
rules of RE :
p(x1)? ?s(x1) p(x1)? ?s,s?(x1)
p(x1)? ?
?
s,s?(x1)
for all s, s? ? {?, ?}.
Especially after reading the example it might
seem useless to create the rule copies inRl [in Ex-
ample 6 for l = ?(z2, z3)]. However, each such
rule has a distinct state at the root of the left-hand
side, which can be used to trigger only this rule.
In this way, the state selects the next rule to apply,
which yields the desired local determinism.
?q, p?
RC
PREL
that
C
x1 x2
?
C
?qNP, pNP?
x1
?q?, pVP?
x2
Figure 13: Composed rule created from the rule of Fig-
ure 7 and the rules of N ? displayed in Figure 11.
5 Composition
Now we are ready for the actual composition. For
space efficiency reasons we reuse the notations
used in Section 4. Moreover, we identify trees of
T?(Q?(P ?(X))) with trees of T?((Q? × P ?)(X)).
In other words, when meeting a subtree q(p(x))
with q ? Q?, p ? P ?, and x ? X , then we also
view this equivalently as the tree ?q, p?(x), which
could be part of a rule of our composed XTOP.
However, not all combinations of states will be
allowed in our composed XTOP, so some combi-
nations will never yield valid rules.
Generally, we construct a rule ofM ? ;N ? by ap-
plying a single rule of M ? followed by any num-
ber of pure ?-rules of RE , which can turn states
base(p) into p. Then we apply any number of
rules of N ? and try to obtain a sentential form that
has the required shape of a rule of M ? ;N ?.
Definition 7. Let M ? = (P ?,?,?, IM , R?M ) and
N ? = (Q?,?,?, IN , R?N ) be the XTOPs con-
structed in Section 4, where
?
l?L Pl ? P
? and
?
l?LQl ? Q
?. Let Q?? = Q? \
?
l?LQl. We con-
struct the XTOPM ? ;N ? = (S,?,?, IN×IM , R)
where
S =
?
l?L
(Ql × Pl) ? (Q
?? × P ?)
and R contains all normalized rules `? r (of the
required shape) such that
`?M ? ? ?
?
RE ? ?
?
N ? r
for some ?, ? ? T?(Q?(T?(P ?(X)))).
The required rule shape is given by the defi-
nition of an XTOP. Most importantly, we must
have that ` ? S(T?(X)), which we identify
with a certain subset of Q?(P ?(T?(X))), and
r ? T?(S(X)), which similarly corresponds to
a subset of T?(Q?(P ?(X))). The states are sim-
ply combinations of the states of M ? and N ?, of
815
qp
?
y1 ?
y2 y3
?
?
i
ps
y1
i
ps
y2
q
p
y3
Figure 14: Successfully expanded rule from Exam-
ple 9.
which however the combinations of a state q ? Ql
with a state p /? Pl are forbidden. This reflects the
intuition of the previous section. If we entered a
special state of the form ?l, q, v?, then we should
use a corresponding state p ? Pl of M , which
only has rules producing instances of l. We note
that look-ahead of N ? is checked normally in the
derivation process.
Example 8. Now let us illustrate the composition
on Example 6. Let us start with rule (†) of M .
q(p(?(x1, x2)))
?M ? q(?(ps(x1), p(x2)))
?RE q(?(ps(x1), ?s?,s??(x2)))
?N ? ?(i(ps(x1)), q(?s?,s??(x2)), q
?(?s?,s??(x2)))
is a rule of M ? ; N ? for every s, s?, s?? ? {?, ?}.
Note if we had not applied the RE-step, then we
would not have obtained a rule of M ; N (be-
cause we would have obtained the state combina-
tion ?q, p? instead of ?q, ?s?,s???, and ?q, p? is not a
state of M ? ; N ?). Let us also construct a rule for
the state combination ?q, ?s?,s???.
q(?s?,s??(?(x1, x2, x3)))
?M ? q(?(ps?(x1), ?(ps??(x2), p(x3))))
?N ? q
?(ps?(x1))
Finally, let us construct a rule for the state combi-
nation ?q??, ?s?,s???.
q??(?s?,s??(?(x1, x2, x3)))
?M ? q(?(ps?(x1), ?(ps??(x2), p(x3))))
?RE q(?(ps?(x1), ?(ps??(x2), ?s(x3))))
?N ? q(?(ps??(x2), ?s(x3)))
?N ? ?(q
?(ps??(x1)), q(?s(x2)), q
??(?s(x2)))
for every s ? {?, ?}.
After having pre-processed the XTOPs in our
introductory example, the devices M and N ? can
be composed into M ; N ?. One rule of the com-
posed XTOP is illustrated in Figure 13.
q
p
?
y1 ?
y2 y3 y4
?
?
i
ps
y1
i
ps?
y2
?
i
ps??
y3
q
??
y4
q?
??
y4
Figure 15: Expanded rule that remains copying (see
Example 9).
6 Post-processing
Finally, we will compose rules again in an ef-
fort to restore linearity (and nondeletion). Since
the composition of two linear and nondeleting
XTOPs cannot always be computed by a single
XTOP (Arnold and Dauchet, 1982), this method
can fail to return such an XTOP. The presented
method is not a characterization, which means it
might even fail to return a linear and nondelet-
ing XTOP although an equivalent linear and non-
deleting XTOP exists. However, in a significant
number of examples, the recombination succeeds
to rebuild a linear (and nondeleting) XTOP.
Let M ? ;N ? = (S,?,?, I, R) be the composed
XTOP constructed in Section 5. We simply in-
spect each non-linear rule (i.e., each rule with a
non-linear right-hand side) and expand it by all
rule options at the copied variables. Since the
method is pretty standard and variants have al-
ready been used in the pre-processing steps, we
only illustrate it on the rules of Figure 12.
Example 9. The first (top row, left-most) rule of
Figure 12 is non-linear in the variable y2. Thus,
we expand the calls ?q, ??(y2) and ?q?, ??(y2). If
? = ?s for some s ? {?, ?}, then the next rules
are uniquely determined and we obtain the rule
displayed in Figure 14. Here the expansion was
successful and we could delete the original rule
for ? = ?s and replace it by the displayed ex-
panded rule. However, if ? = ??s?,s?? , then we can
also expand the rule to obtain the rule displayed in
Figure 15. It is still copying and we could repeat
the process of expansion here, but we cannot get
rid of all copying rules using this approach (as ex-
pected since there is no linear XTOP computing
the same tree transformation).
816
References
Andre´ Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d’arbres. Theoretical Computer
Science, 20(1):33–93.
Brenda S. Baker. 1979. Composition of top-down
and bottom-up tree transductions. Information and
Control, 41(2):186–213.
Jason Eisner. 2003. Learning non-isomorphic tree
mappings for machine translation. In Proc. ACL,
pages 205–208. Association for Computational Lin-
guistics.
Joost Engelfriet, Eric Lilin, and Andreas Maletti.
2009. Composition and decomposition of extended
multi bottom-up tree transducers. Acta Informatica,
46(8):561–590.
Joost Engelfriet. 1975. Bottom-up and top-down
tree transformations—A comparison. Mathemati-
cal Systems Theory, 9(3):198–231.
Joost Engelfriet. 1977. Top-down tree transducers
with regular look-ahead. Mathematical Systems
Theory, 10(1):289–303.
Jonathan Graehl, Kevin Knight, and Jonathan May.
2008. Training tree transducers. Computational
Linguistics, 34(3):391–427.
Jonathan Graehl, Mark Hopkins, Kevin Knight, and
Andreas Maletti. 2009. The power of extended top-
down tree transducers. SIAM Journal on Comput-
ing, 39(2):410–430.
Kevin Knight and Jonathan Graehl. 2005. An over-
view of probabilistic tree transducers for natural
language processing. In Proc. CICLing, volume
3406 of LNCS, pages 1–24. Springer.
Kevin Knight. 2007. Capturing practical natural
language transformations. Machine Translation,
21(2):121–133.
Eric Lilin. 1978. Une ge´ne´ralisation des transduc-
teurs d’e´tats finis d’arbres: les S-transducteurs.
The`se 3e`me cycle, Universite´ de Lille.
Andreas Maletti and Heiko Vogler. 2010. Composi-
tions of top-down tree transducers with ?-rules. In
Proc. FSMNLP, volume 6062 of LNAI, pages 69–
80. Springer.
Andreas Maletti. 2010. Why synchronous tree sub-
stitution grammars? In Proc. HLT-NAACL, pages
876–884. Association for Computational Linguis-
tics.
Andreas Maletti. 2011. An alternative to synchronous
tree substitution grammars. Natural Language En-
gineering, 17(2):221–242.
Alberto Martelli and Ugo Montanari. 1982. An effi-
cient unification algorithm. ACM Transactions on
Programming Languages and Systems, 4(2):258–
282.
Jonathan May and Kevin Knight. 2006. Tiburon: A
weighted tree automata toolkit. In Proc. CIAA, vol-
ume 4094 of LNCS, pages 102–113. Springer.
Jonathan May, Kevin Knight, and Heiko Vogler. 2010.
Efficient inference through cascades of weighted
tree transducers. In Proc. ACL, pages 1058–1066.
Association for Computational Linguistics.
Jonathan May. 2010. Weighted Tree Automata and
Transducers for Syntactic Natural Language Pro-
cessing. Ph.D. thesis, University of Southern Cali-
fornia, Los Angeles.
John Alan Robinson. 1965. A machine-oriented logic
based on the resolution principle. Journal of the
ACM, 12(1):23–41.
William C. Rounds. 1970. Mappings and grammars
on trees. Mathematical Systems Theory, 4(3):257–
287.
Stuart M. Shieber. 2004. Synchronous grammars as
tree transducers. In Proc. TAG+7, pages 88–95.
James W. Thatcher. 1970. Generalized2 sequential
machine maps. Journal of Computer and System
Sciences, 4(4):339–367.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proc. ACL,
pages 523–530. Association for Computational Lin-
guistics.
817
