Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 221–226,
October 25-29, 2014, Doha, Qatar.
c
©2014 Association for Computational Linguistics
Two Improvements to Left-to-Right Decoding for Hierarchical
Phrase-based Machine Translation
Maryam Siahbani and Anoop Sarkar
School of Computing Science
Simon Fraser University
Burnaby BC. Canada
msiahban,anoop@cs.sfu.ca
Abstract
Left-to-right (LR) decoding (Watanabe et
al., 2006) is promising decoding algorithm
for hierarchical phrase-based translation
(Hiero) that visits input spans in arbitrary
order producing the output translation in
left to right order. This leads to far fewer
language model calls, but while LR decod-
ing is more efficient than CKY decoding,
it is unable to capture some hierarchical
phrase alignments reachable using CKY
decoding and suffers from lower transla-
tion quality as a result. This paper in-
troduces two improvements to LR decod-
ing that make it comparable in translation
quality to CKY-based Hiero.
1 Introduction
Hierarchical phrase-based translation (Hi-
ero) (Chiang, 2007) uses a lexicalized syn-
chronous context-free grammar (SCFG) extracted
from word and phrase alignments of a bitext. De-
coding for Hiero is typically done with CKY-style
decoding with time complexity O(n
3
) for source
input with n words. Computing the language
model score for each hypothesis within CKY de-
coding requires two histories, the left and the right
edge of each span, due to the fact that the target
side is built inside-out from sub-spans (Heafield
et al., 2011; Heafield et al., 2013).
LR-decoding algorithms exist for phrase-
based (Koehn, 2004; Galley and Manning, 2010)
and syntax-based (Huang and Mi, 2010; Feng et
al., 2012) models and also for hierarchical phrase-
based models (Watanabe et al., 2006; Siahbani et
al., 2013), which is our focus in this paper.
Watanabe et al. (2006) first proposed left-to-
right (LR) decoding for Hiero (LR-Hiero hence-
forth) which uses beam search and runs in O(n
2
b)
in practice where n is the length of source sentence
and b is the size of beam (Huang and Mi, 2010).
To simplify target generation, SCFG rules are con-
strained to be prefix-lexicalized on target side aka
Griebach Normal Form (GNF). Throughout this
paper we abuse the notation for simplicity and use
the term GNF grammars for such SCFGs. This
constraint drastically reduces the size of gram-
mar for LR-Hiero in comparison to Hiero gram-
mar (Siahbani et al., 2013). However, the orig-
inal LR-Hiero decoding algorithm does not per-
form well in comparison to current state-of-the-art
Hiero and phrase-based translation systems. Siah-
bani et al. (2013) propose an augmented version
of LR decoding to address some limitations in the
original LR-Hiero algorithm in terms of transla-
tion quality and time efficiency.
Although, LR-Hiero performs much faster than
Hiero in decoding and obtains BLEU scores com-
parable to phrase-based translation system on
some language pairs, there is still a notable gap be-
tween CKY-Hiero and LR-Hiero (Siahbani et al.,
2013). We show in this paper using instructive ex-
amples that CKY-Hiero can capture some complex
phrasal re-orderings that are observed in language
pairs such as Chinese-English that LR-Hiero can-
not (c.f. Sec.3).
We introduce two improvements to LR decod-
ing of GNF grammars: (1) We add queue diversity
to the cube pruning algorithm for LR-Hiero, and
(2) We extend the LR-Hiero decoder to capture all
the hierarchical phrasal alignments that are reach-
able in CKY-Hiero (restricted to using GNF gram-
mars). We evaluate our modifications on three
language pairs and show that LR-Hiero can reach
the translation scores comparable to CKY-Hiero in
two language pairs, and reduce the gap between
Hiero and LR-Hiero on the third one.
2 LR Decoding with Queue Diversity
LR-Hiero uses a constrained lexicalized SCFG
which we call a GNF grammar: X ? ??,
¯
b ??
where ? is a string of non-terminal and terminal
symbols,
¯
b is a string of terminal symbols and ? is
a possibly empty sequence of non-terminals. This
ensures that as each rule is used in a derivation,
221
Algorithm 1: LR-Hiero Decoding
1: Input sentence: f = f
0
f
1
. . . f
n
2: F = FutureCost(f) (Precompute future cost
1
for spans)
3: S
0
= {} (Create empty initial stack)
4: h
0
= (?s?, [[0, n]], ?,F
[0,n]
) (Initial hypothesis 4-tuple)
5: Add h
0
to S
0
(Push initial hyp into first Stack)
6: for i = 1, . . . , n do
7: cubeList = {} (MRL is max rule length)
8: for p = max(i? MRL, 0), . . . , i? 1 do
9: {G} = Grouped(S
p
) (based on the first uncovered
span)
10: for g ? {G} do
11: [u, v] = g
span
12: R = GetSpanRules([u, v])
13: for R
s
? R do
14: cube = [g
hyps
, R
s
]
15: Add cube to cubeList
16: S
i
= Merge(cubeList,F) (Create stack S
i
and add
new hypotheses to it, see Figure 1)
17: return argmax(S
n
)
18: Merge(CubeList,F)
19: heapQ = {}
20: for each (H,R) in cubeList do
21: hypList = getBestHypotheses((H,R),F , d) (d
best hypotheses of each cube)
22: for each h
?
in hypList do
23: push(heapQ, (h
?
c
, h
?
, [H,R]) (Push new hyp
in queue)
24: hypList = {}
25: while |heapQ| > 0 and |hypList| < K do
26: (h
?
c
, h
?
, [H,R]) = pop(heapQ) (pop the best
hypothesis)
27: push(heapQ,GetNeighbours([H,R]) (Push
neighbours to queue)
28: Add h
?
to hypList
29: return hypList
the target string is generated from left to right.
The rules are obtained from a word and phrase
aligned bitext using the rule extraction algorithm
in (Watanabe et al., 2006).
LR-Hiero decoding uses a top-down depth-first
search, which strictly grows the hypotheses in tar-
get surface ordering. Search on the source side
follows an Earley-style search (Earley, 1970), the
dot jumps around on the source side of the rules
based on the order of nonterminals on the target
side. This search is integrated with beam search
or cube pruning to find the k-best translations.
Algorithm 1 shows the pseudocode for LR-
Hiero decoding with cube pruning (Chiang, 2007)
(CP). LR-Hiero with CP was introduced in (Siah-
bani et al., 2013). In this pseudocode, we have in-
troduced the notion of queue diversity (explained
below). However to understand our change we
need to understand the algorithm in more detail.
1
The future cost is precomputed in a way similar to the
phrase-based models (Koehn et al., 2007) using only the ter-
minal rules of the grammar.
9.18.2
8.3 8.58.05
8.1 8.48.68.88.9
3.21.30.9 6.66.76.9
8.9
7.1 8.58.7
9.39.08.17.2
1.51.31.26.76.86.9
...
S i
Figure 1: Cubes (grids) are fed to a priority queue (trian-
gle) and generated hypotheses are iteratively popped from the
queue and added to stack S
i
. Lower scores are better. Scores
of rules and hypotheses appear on the top and left side of the
grids respectively. Shaded entries are hypotheses in the queue
and black ones are popped from the queue and added to S
i
.
Each source side non-terminal is instantiated with
the legal spans given the input source string, e.g.
if there is a Hiero rule ?aX
1
, a
?
X
1
? and if a only
occurs at position 3 in the input then this rule can
be applied to span [3, i] for all i, 4 < i ? n for in-
put of length n and source side X
1
is instantiated
to span [4, i]. A worked out example of how the
decoder works is shown in Figure 2. Each partial
hypothesis h is a 4-tuple (h
t
, h
s
, h
cov
, h
c
): con-
sisting of a translation prefix h
t
, a (LIFO-ordered)
list h
s
of uncovered spans, source words coverage
set h
cov
and the hypothesis cost h
c
. The initial hy-
pothesis is a null string with just a sentence-initial
marker ?s? and the list h
s
containing a span of the
whole sentence, [0, n]. The hypotheses are stored
in stacks S
0
, . . . , S
n
, where S
p
contains hypothe-
ses covering p source words just like in stack de-
coding for phrase-based SMT (Koehn et al., 2003).
To fill stack S
i
we consider hypotheses in each
stack S
p
2
, which are first partitioned into a set of
groups {G}, based on their first uncovered span
(line 9). Each group g is a 2-tuple (g
span
, g
hyps
),
where g
hyps
is a list of hypotheses which share the
same first uncovered span g
span
. Rules matching
the span g
span
are obtained from routine GetSpan-
Rules. Each g
hyps
and possible R
s
create a cube
which is added to cubeList.
The Merge routine gets the best hypotheses
from all cubes (see Fig.1). Hypotheses (rows) and
columns (rules) are sorted based on their scores.
GetBestHypotheses((H,R),F , d) uses current
hypothesis H and rule R to produce new hypothe-
ses. The first best hypothesis, h
?
along with its
score h
?
c
and corresponding cube (H,R) is placed
in a priority queue heapQ (triangle in Figure 1
and line 23 in Algorithm 1). Iteratively the K best
2
As the length of rules are limited (at most MRL), we can
ignore stacks with index less than i? MRL
222
rules
hypotheses
?s?[0, 15]
G 1)?Taiguo shi X
1
/Thailand X
1
? ?s? Thailand [2,15]
G 2)?yao X
1
/wants X
1
?
G 3)?liyong X
1
/to utilize X
1
?
4)?zhe bi qian X
1
/this money X
1
?
5)?X
1
zhuru geng duo X
2
/to inject more X
2
X
1
?
6)?liudong X
1
/circulating X
1
?
G 7)?zijin X
1
/capital X
1
?
8)?./.?
9)?xiang jingji/to the economy?
?s?Thailand wants [3,15]
?s?Thailand wants to utilize [4,15]
?s?Thailand wants to utilize this money [7,15]
?s?Thailand wants to utilize this money to inject more [12,15][7,9]
?s?Thailand wants to utilize this money to inject more circulating [13,15][7,9]
?s?Thailand wants to utilize this money to inject more circulating capital [14,15][7,9]
?s?Thailand wants to utilize this money to inject more circulating capital . [7,9]
?s?Thailand wants to utilize this money to inject more circulating capital . to the economy?/s?
Figure 2: The process of translating the Chinese sentence in Figure 3(b) in LR-Hiero. Left side shows the rules used in the
derivation (G indicates glue rules as defined in (Watanabe et al., 2006)). The hypotheses column shows the translation prefix
and the ordered list of yet-to-be-covered spans.
T? b ch ng shu  ,? ? ? liánhé zhèngf? , bìngqi? y u nénglì? guànchè .mùqián
He added that the coalition government carrying out the economic reform plancapable ofand
j?ngjì g igé  jìhuà?
is now in stable .
X1
condition
zhuàngkuàng w?ndìng 0      1                   2            3   4               5                    6                      7                                  8                         9   10                11        12              13                     14             15             16            17      18
(a)
Tàiguó shì  yào zhè b? qián xiàng j?ngjì zhùrù gèng du? .lìyòng
Thailand wants to circulating capital to the economyinject morethis money to
liúdòng z?j?n
utilize .
S 1 S 20               1          2              3                  4            5     6            7                 8             9               10           11         12                    13           14      15
(b)
Figure 3: Two Chinese-English sentence pairs from devset data in experiments. (a) Correct rule cannot be matched to [6,18],
our modifications match the rule to the first subspan [6,9] (b) LR-Hiero detects a wrong span for X
2
[12,15], we modify the
rule matching match X
2
to all subspans [12,13], [12,14] and [12,15], corresponding to 3 hypotheses.
hypotheses in the queue are popped (line 26) and
for each hypothesis its neighbours in the cube are
added to the priority queue (line 27). Decoding
finishes when stack S
n
has been filled.
The language model (LM) score violates the
hypotheses generation assumption of CP and can
cause search errors. In Figure 1, the topmost
and leftmost entry of the right cube has a score
worse than many hypotheses in the left cube due
to the LM score. This means the right cube
has hypotheses that are ignored. This type of
search error hurts LR-Hiero more than CKY-
Hiero, due to the fact that hypotheses scores in
LR-Hiero rely on a future cost, while CKY-Hiero
uses the inside score for each hypothesis. To
solve this issue for LR-Hiero we introduce the no-
tion of queue diversity which is the parameter d
in GetBestHypotheses((H,R),F , d). This pa-
rameter guarantees that each cube will produce at
least d candidate hypotheses for the priority queue.
d=1 in standard cube pruning for LR-Hiero (Siah-
bani et al., 2013). We apply the idea of diver-
sity at queue level, before generating K best hy-
pothesis, such that the GetBestHypotheses rou-
tine generates d best hypotheses from each cube
and all these hypotheses are pushed to the prior-
ity queue (line 22-23). We fill each stack differ-
ently from CKY-Hiero and so queue diversity is
different from lazy cube pruning (Pust and Knight,
2009) or cube growing (Huang and Chiang, 2007;
Vilar and Ney, 2009; Xu and Koehn, 2012).
3 Capturing Missing Alignments
Figure 3(a) and Figure 3(b) show two examples of
a common problem in LR-Hiero decoding. The
decoder steps for Figure 3(b) are shown in Fig-
ure 2. The problem occurs in Step 5 of Figure 2
where rule #5 is matched to span [7, 15]. Dur-
ing decoding LR-Hiero maintains a stack (last-
in-first-out) of yet-to-be-covered spans and tries
to translate the first uncovered span (span [7, 15]
in Step 5). LR-Hiero should match rule #5 to
span [7, 15], therefore X
2
is forced to match span
[12, 15] which leads to the translation of span [7, 9]
(corresponding to X
1
) being reordered around it
223
Corpus Train/Dev/Test
Cs-En Europarl(v7) + CzEng(v0.9); News
commentary(nc) 2008&2009; nc 2011
7.95M/3000/3003
De-En Europarl(v7); WMT2006; WMT2006 1.5M/2000/2000
Zh-En HK + GALE phase-1; MTC part 1&3;
MTC part 4
2.3M/1928/919
Table 1: Corpus statistics in number of sentences. Tuning and test sets for Chinese-English has 4 references.
Model Cs-En De-En Zh-En
Hiero 20.77 25.72 27.65
LR-Hiero (Watanabe et al., 2006) 20.72 25.10 25.99
LR-Hiero+CP (Siahbani et al., 2013) 20.15 24.83 -
LR-Hiero+CP (QD=1) 20.68 25.14 24.44
LR-Hiero+CP (QD=15) - - 26.10
LR-Hiero+CP+(ab) 20.88 25.22 26.55
LR-Hiero+CP+(abc) 20.89 25.22 26.52
(a) BLEU scores for different baselines and modifications of this paper.
QD=15 for Zh-En in last three rows. (b) Average number of language model queries.
Table 2: (a) BLEU (b) LM calls
causing the incorrect translation in Step 9. If we
use the same set of rules for translation in Hi-
ero (CKY-based decoder), the decoder is able to
generate the correct translation for span [7, 14] (it
works bottom-up and generate best translation for
each source span). Then it combines translation of
[7, 14] with translation of spans [0, 7] and [14, 15]
using glue rules (monotonic combination).
In Figure 3(a) monotonic translations after span
[6, 9] are out of reach of the LR-Hiero decoder
which has to use the non-terminals to support
the reordering within span [6, 9]. In this exam-
ple the first few phrases are translated monoton-
ically, then for span [6, 18] we have to apply rule
?muqian X
1
wending, is now in stable X
1
? to ob-
tain the correct translation. But this rule cannot
be matched to span [6, 18] and the decoder fails
to generate the correct translation. While CKY-
Hiero can apply this rule to span [6, 9], generate
correct translation for this span and monotonically
combine it with translation of other spans ([0, 6],
[9, 18]).
In both these cases, CKY-Hiero has no diffi-
culty in reaching the target sentence with the same
GNF rules. The fact that we have to process spans
as they appear in the stack in LR-Hiero means
that we cannot combine arbitrary adjacent spans
to deal with such cases. So purely bottom-up de-
coders such as CKY-Hiero can capture the align-
ments in Figure 3 but LR-Hiero cannot.
We extend the LR-Hiero decoder to handle such
cases by making the GNF grammar more expres-
sive. Rules are partitioned to three types based on
the right boundary in the source and target side.
The rhs after the? shows the new rules we create
within the decoder using a new non-terminal X
r
to match the right boundary.
(a) ??a¯,
¯
b?? ? ??a¯X
r
,
¯
b?X
r
?
(b) ??X
n
,
¯
b?X
n
? ? ??X
n
X
r
,
¯
b?X
n
X
r
?
(c) ??X
n
,
¯
b?X
m
? ? ??X
n
X
r
,
¯
b?X
m
X
r
?
(1)
where ? is a string of terminals and non-terminals,
a¯ and
¯
b are terminal sequences of source and tar-
get respectively, ? is a possibly empty sequence
of non-terminals and X
n
and X
m
are different
non-terminals distinct from X
r
3
. The extra non-
terminal X
r
lets us add a new yet-to-be-covered
span to the bottom of the stack at each rule appli-
cation which lets us match any two adjacent spans
just as in CKY-Hiero. This captures the missing
alignments that could not be previously captured
in the LR-Hiero decoder
4
.
In Table 4 we translated devset sentences using
forced decoding to show that our modifications to
LR-Hiero in this section improves the alignment
coverage when compared to CKY-Hiero.
4 Experiments
We evaluate our modifications to LR-Hiero de-
coder on three language pairs (Table 1): German-
English (De-En), Czech-English (Cs-En) and
Chinese-English (Zh-En).
3
In rule type (c) X
n
will be in ? and X
m
will be in ?.
4
For the sake of simplicity, in rule type (b) we can merge
X
n
and X
r
as they are in the same order on both source and
target side.
224
We use a 5-gram LM trained on the Gigaword
corpus and use KenLM (Heafield, 2011). We
tune weights by minimizing BLEU loss on the dev
set through MERT (Och, 2003) and report BLEU
scores on the test set. Pop limit for Hiero and LR-
Hiero+CP is 500 and beam size LR-Hiero is 500.
Other extraction and decoder settings such as max-
imum phrase length, etc. were identical across set-
tings. To make the results comparable we use the
same feature set for all baselines, Hiero as well
(including new features proposed by (Siahbani et
al., 2013)).
We use 3 baselines: (i) our implementation of
(Watanabe et al., 2006): LR-Hiero with beam
search (LR-Hiero) and (ii) LR-Hiero with cube
pruning (Siahbani et al., 2013): (LR-Hiero+CP);
and (iii) Kriya, an open-source implementation of
Hiero in Python, which performs comparably to
other open-source Hiero systems (Sankaran et al.,
2012).
Table 3 shows model sizes for LR-Hiero (GNF)
and Hiero (SCFG). Typical Hiero rule extraction
excludes phrase-pairs with unaligned words on
boundaries (loose phrases). We use similar rule
extraction as Hiero, except that exclude non-GNF
rules and include loose phrase-pairs as terminal
rules.
Table 2a shows the translation quality of dif-
ferent systems in terms of BLEU score. Row
3 is from (Siahbani et al., 2013)
5
. As we dis-
cussed in Section 2, LR-Hiero+CP suffers from
severe search errors on Zh-En (1.5 BLEU) but us-
ing queue diversity (QD=15) we fill this gap. We
use the same QD(=15) in next rows for Zh-en.
For Cs-En and De-En we use regular cube prun-
ing (QD=1), as it works as well as beam search
(compare rows 4 and 2).
We measure the benefit of the new modified
rules from Section 3: (ab): adding modifications
for rules type (a) and (b); (abc): modification
of all rules. We can see that for all language
pairs (ab) constantly improves performance of LR-
Hiero, significantly better than LR-Hiero+CP and
LR-Hiero (p-value<0.05) on Cs-En and Zh-En,
evaluated by MultEval (Clark et al., 2011). But
modifying rule type (c) does not show any im-
provement due to spurious ambiguity created by
5
We report results on Cs-En and De-En in (Siahbani et
al., 2013). Row 4 is the same translation system as row 3
(LR-Hiero+CP). We achieve better results than our previous
work (Siahbani et al., 2013) (row 4 vs. row 3) due to bug
corrections and adding loose phrases as terminal rules.
Model Cs-En De-En Zh-En
Hiero 1,961.6 858.5 471.9
LR-Hiero 266.5 116.0 100.9
Table 3: Model sizes (millions of rules).
Model Cs-En De-En Zh-En
Hiero 318 351 187
LR-Hiero 278 300 132
LR-Hiero+(abc) 338 361 174
Table 4: No. of sentence covered in forced decoding of a sam-
ple of sentences from the devset. We improve the coverage
by 31% for Chinese-English and more than 20% for the other
two language pairs.
type (c) rules.
Figure 2b shows the results in terms of average
number of language model queries on a sample set
of 50 sentences from test sets. All of the base-
lines use the same wrapper to KenLM (Heafield,
2011) to query the language model, and we have
instrumented the wrapper to count the statistics.
In (Siahbani et al., 2013) we discuss that LR-Hiero
with beam search (Watanabe et al., 2006) does not
perform at the same level of state-of-the-art Hi-
ero (more LM calls and less translation quality).
As we can see in this figure, adding new mod-
ified rules slightly increases the number of lan-
guage model queries on Cs-En and De-En so that
LR-Hiero+CP still works 2 to 3 times faster than
Hiero. On Zh-En, LR-Hiero+CP applies queue
diversity (QD=15) which reduces search errors
and improves translation quality but increases the
number of hypothesis generation as well. LR-
Hiero+CP with our modifications works substan-
tially faster than LR-Hiero while obtain signifi-
cantly better translation quality on Zh-En.
Comparing Table 2a with Figure 2b we can see
that overall our modifications to LR-Hiero decoder
significantly improves the BLEU scores compared
to previous LR decoders for Hiero. We obtain
comparable results to CKY-Hiero for Cs-En and
De-En and remarkably improve results on Zh-En,
while at the same time making 2 to 3 times less
LM calls on Cs-En and De-En compared to CKY-
Hiero.
Acknowledgments
This research was partially supported by NSERC,
Canada RGPIN: 262313 and RGPAS: 446348
grants to the second author. The authors wish to
thank Baskaran Sankaran for his valuable discus-
sions and the anonymous reviewers for their help-
ful comments.
225
References
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing for
statistical machine translation: controlling for opti-
mizer instability. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies: short pa-
pers - Volume 2, HLT ’11, pages 176–181, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Jay Earley. 1970. An efficient context-free parsing al-
gorithm. Commun. ACM, 13(2):94–102, February.
Yang Feng, Yang Liu, Qun Liu, and Trevor Cohn.
2012. Left-to-right tree-to-string decoding with pre-
diction. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, EMNLP-CoNLL ’12, pages 1191–1200,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Michel Galley and Christopher D. Manning. 2010.
Accurate non-hierarchical phrase-based translation.
In Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter
of the Association for Computational Linguistics,
pages 966–974, Los Angeles, California, June. As-
sociation for Computational Linguistics.
Kenneth Heafield, Hieu Hoang, Philipp Koehn, Tet-
suo Kiso, and Marcello Federico. 2011. Left lan-
guage model state for syntactic machine translation.
In Proceedings of the International Workshop on
Spoken Language Translation, pages 183–190, San
Francisco, California, USA, 12.
Kenneth Heafield, Philipp Koehn, and Alon Lavie.
2013. Grouping language model boundary words
to speed K-Best extraction from hypergraphs. In
Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Atlanta, Georgia, USA, 6.
Kenneth Heafield. 2011. KenLM: Faster and smaller
language model queries. In In Proc. of the Sixth
Workshop on Statistical Machine Translation.
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. In In ACL 07.
Liang Huang and Haitao Mi. 2010. Efficient incre-
mental decoding for tree-to-string translation. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages
273–283, Cambridge, MA, October. Association for
Computational Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond?rej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 177–180, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Philipp Koehn. 2004. Pharaoh: A beam search de-
coder for phrase-based statistical machine transla-
tion models. In AMTA, pages 115–124.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ’03, pages 160–
167, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Michael Pust and Kevin Knight. 2009. Faster mt
decoding through pervasive laziness. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
Companion Volume: Short Papers, pages 141–144,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Baskaran Sankaran, Majid Razmara, and Anoop
Sarkar. 2012. Kriya - an end-to-end hierarchi-
cal phrase-based mt system. The Prague Bulletin
of Mathematical Linguistics (PBML), 97(97):83–98,
apr.
Maryam Siahbani, Baskaran Sankaran, and Anoop
Sarkar. 2013. Efficient left-to-right hierarchical
phrase-based translation with improved reordering.
In Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, Seattle,
USA, October. Association for Computational Lin-
guistics.
David Vilar and Hermann Ney. 2009. On lm heuris-
tics for the cube growing algorithm. In Annual Con-
ference of the European Association for Machine
Translation, pages 242–249, Barcelona, Spain, may.
Taro Watanabe, Hajime Tsukada, and Hideki Isozaki.
2006. Left-to-right target generation for hierarchical
phrase-based translation. In Proc. of ACL.
Wenduan Xu and Philipp Koehn. 2012. Extending hi-
ero decoding in moses with cube growing. Prague
Bull. Math. Linguistics, 98:133–.
226
