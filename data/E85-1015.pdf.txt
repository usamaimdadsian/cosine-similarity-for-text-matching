LANGUAGE-BASED ENVIRONMENT FOR NATURAL LANGUAGE PARSING 
Lehtola, A., J~ppinen, H., Nelimarkka, E. 
sirra Foundation (*) and 
Helsinki University of Technology 
Helsinki, Finland 
ABSTRACT 
This paper introduces a special 
programming environment for the definit ion 
of grammars and for the implementation of 
corresponding parsers. In natural 
language processing systems it is 
advantageous to have l inguistic knowledge 
and processing mechanisms separated. Our 
environment accepts grammars consist ing of 
binary dependency relations and 
grammatical  functions. Well - formed 
expressions of functions and relations 
provide constituent surroundings for 
syntactic categories in the form of 
two-way automata. These relations, 
functions, and automata are described in a 
special definit ion language. 
In focusing on high level descr ipt ions a 
l inguist may ignore computational  detai ls 
of the parsing process. He writes the 
grammar into a DPL-descr ipt ion and a 
compiler translates it into eff ic ient 
LISP-code. The environment has also a 
tracing facil ity for the parsing process, 
grammar-sensit ive lexical maintenance 
programs, and routines for the interactive 
graphic display of parse trees and grammar 
definitions. Translator routines are also 
available for the transport of compiled 
code between various LISP-dialects. The 
environment itself exists currently in 
INTERLISP and FRANZLISP. This paper 
focuses on knowledge engineering issues 
and does not enter l inguistic 
argumentation. 
INTRODUCTION 
Our objective has been to build a parser 
for Finnish to work as a practical tool in 
real production applications. In the 
beginning of our work we were faced with 
two major problems. First, so far there 
was no formal descript ion of the Finnish 
grammar. Second dif f iculty was that 
Finnish differs by its structure greatly 
from the Indoeuropean languages. Finnish 
has relatively free word order and 
syntact ico-semantic knowledge in a 
sentence is often expressed in the 
inflections of the words. Therefore 
exist ing parsing methods for Indoeuropean 
languages (eg. ATN, DCG, LFG etc.) did 
not seem to grasp the idiosyncracies of 
Finnish. 
The parser system we have developed is 
based on functional dependency. Grammar 
is specified by a family of two-way finite 
automata and by dependency function and 
relat ion definit ions. Each automaton 
expresses the valid dependency context of 
one const ituent type. In abstract sense 
the working storage of the parser consists 
of two const ituent stacks and of a 
register which holds the current 
const ituent (Figure I). 
The register of 
the current 
constituent 
LI 
L2 
L3 
RI 
R2 
R3 
The left The righ 
constituent constituent 
stack stack 
Figure I. The working storage 
of DPL-parsers 
(*) SITRA Foundation 
P.O. Box 329, SF-00121 Helsinki, 
Finland 
98 
<-Phrase Adverbial )<+Phrase Adverbial 
IILD PHRASE 
ON RIGHT 
~*Phrase Subject~ ~ophrase 
Phrase \] I 
L Adverbial 
! *Phrase 
IAdverbial  
IILO PHRASE 
ON RIGHT 
~Phrase 
Phrase  
Sublet1 
ILO PHRASE 
ON RIGHT 
• - -Nomina 
empty le f t -  
hand side 
BUILD PXRA: 
ON RIGHT 
= ,Nominal  
- +Nominal 
~nd of inpul @ 
FIND REGENT 
ON RIGHT 
Notations: 
On the left  is I On the left  is a state transit ion 
the state node ?X  with priority, conditions for 
of the automaton {cond$ . . . .  the dependent candidate (if not 
Toncllon) otherwised stated) and k The question mark I 
indicates the direction 4, connection function indicated. 
Double circles are used 
to denote entrees and 
exits of an automaton•  
Inside is expressed the 
manner  of operation. 
Figure 2. A two-way automaton for Finnish verbs 
The two stacks hold the right and left 
contexts of the current constituent. The 
parsing process is always directed by the 
expectations of the current constituent. 
Dynamic local control is realized by 
permitt ing the automata to activate one 
another. The basic decision for the 
automaton associated with the current 
constituent is to accept or reject a 
neighbor via a valid syntact ico-semantic 
subordinate relation. Acceptance 
subordinates the neighbor, and it 
disappears from the stack. The structure 
an input sentence receives is an annotated 
tree of such binary relations. 
An automaton for verbs is described in 
Figure 2. When a verb becomes the current 
constituent for the first time it will 
enter the automaton through the START 
node. The automaton expects to find a 
dependent from the left (?V). If the left 
neighbor has the constituent feature 
+Phrase, it wil l  be tested first for 
Subject and then for Object. When a 
function test succeeds, the neighbor will 
be subord inated  and the verb advances to 
the state indicated by arcs. The double 
circle states denote entry and exit points 
of the automaton. 
~f completed const ituents do not exist as 
neighbors, an automaton may defer 
decision. In the Figure 2 states labelled 
"BUILD PHRASE ON RIGHT" and "FIND REGENT 
ON RIGHT" push the verb to the left stack 
and pop the right stack for the current 
constituent. When the verb is activated 
later on, the control flow will continue 
from the state expressed in the 
deact ivat ion command. 
There are two dist inct search strategies 
involved. If a single parse is 
sufficient, the graphs (i.e. the 
automata) are searched depth first 
fol lowing the priority numbering. A full 
search is also possible. 
99 
The functions, relations and automata are 
expressed in a special conditional 
expression formalism DPL (for Dependency 
Parser Language). We believe that DPL 
might find applications in other 
inflectional languages as well. 
DPL-DESCRIPTIONS 
The main object in DPL is a constituent. 
A grammar specification opens with the 
structural descriptions of constituents 
and the allowed property names and 
property values. User may specify simple 
properties, features or categories. The 
structures of the lexical entries are also 
defined at the beginning. The syntax of 
these declarations can be seen in Figure 
3. 
All properties of constituents may be 
referred in a uniform manner using their 
values straight. The system automatically 
takes into account the computational 
details associated to property types. For 
example, the system is automatically tuned 
to notice the inheritance of properties in 
their hierarchies. Extensive support to 
multidimensional analysis has been one of 
the central objectives in the design of 
the DPL-formalism. Patterning can be done 
in multiple dimensions and the property 
set associated to constituents can easily 
be extended. 
An example of a constituent structure and 
its property definitions is given in 
Figure 4. The description states first 
that each constituent contains Function, 
Role, ConstFeat, PropOfLexeme and 
MorphChar. The next two following 
definitions further specify ConstFeat and 
PropOfLexeme. In the last part the 
definition of a category tree SemCat is 
given. This tree has sets of property 
values associated with nodes. The 
DPL-system automatically takes care of 
their inheritances. Thus for a 
constituent that belongs to the semantic 
category Human the system automatically 
associates feature values +Hum, +Anim, 
+Countable, and +Concr. 
The binary grammatical functions and 
relations are defined using the syntax in 
Figure 5. A DPL-function returns as its 
value the binary construct built from the 
~urrent constituent (C) and its dependent 
candidate (D), or it returns NIL. 
DPL-relations return as their values the 
pairs of C and D constituents that have 
passed the associated predicate filter. 
By choosing operators a user may vary a 
predication between simple equality (=) 
and equality with ambiguity elimination 
(=:=). Operators := and :- denote 
replacement and insertion, respectively. 
In predicate expressions angle brackets 
signal the scope of an implicit 
OR-operator and parentheses that of an 
<const i tuent  s t ruc ture> : :=  ( CONSTITUENT: 
<subtree o~ const i tuent>: := ( SUBTREE: 
< l i s t  of  p roper t ies> 
<proper ty  name> 
<type name> 
<glue node name> 
<glue node> 
<l i s t  of  p roper t ies>. .  ) 
<glue node> 
<l i s t  of  p roper t ies> ) : 
( LEXICON-ENTRY: <glue node> 
<l i s t  of  p roper t ies> ) 
: :=  ( < l i s t  of p roper t ies>. .  ) 
( <proper ty  name>.. ) 
: :=  <type name> : <glue node name> 
: :=  <unique l i sp  atom> 
: :=  <unique l i sp  atom> 
: :=  <glue node name in  upper level-> 
<proper ty  dec la ra t ion> 
<poss ib le  values> 
<defau l t  va lue  > 
<node de f in i t ion> 
<node name> 
<feature  set> 
<father  node> 
<empty> 
: :=  ( PROPERTY: <type name> <poss ib le  values> ) : 
( FEATURE: <type name> <poss ib le  values> ) 
( CATEGORY: <type name> < <node de f in i t ion>. .  > ) 
: :=  < <defau l t  va lue> <unique l i sp  atom>.. > 
: :=  NoDefault  : <unique l i sp  atom> 
: :=  ( <node name> <feature  set> <father  node> ) 
: :=  <unique l i sp  atom> 
: :=  ( <feature  va lue> ) : <empty> 
: :=  / <name of an a l ready  de f ined  node> : <empty> 
: :=  
Figure 3. The syntax of constituent structure 
and property definitions 
100 
(CONSTITUENT: 
(LEXICON-ENTRY: 
(SUBTREE: 
(CATEGORY: 
(Funct ion  Ro le  ConstFeat  PropOgLexeme Morphchar ) )  
PropOfLexeme 
( (SyntCat  SyntFeat )  
(SemCat SemFeat) 
(FrameCat LexFrame) 
AKO )) 
MorphChar 
( Po la r  Vo ice  Modal Tense Comparison 
Number Case PersonN PersonP C l i t l  C l i t2 ) )  
SemCat 
< ( Ent i ty  ) 
( Concrete  ( +Concr ) / Ent i ty  ) 
( Animate ( +Anim +Countab le  ) / Concrete  ) 
( Human ( +Hum ) / Animate ) 
( An imals  / Animate ) 
( NonAnim / Concrete  ) 
( Mat ter  ( -Countab le  ) / NonAnim ) 
( Th ing ( +Countab le  ) / NonAnim ) > 
Figure 4. An example of a const i tuent  s t ructure  spec i f i ca t ion  
and the def in i t ion  of an category  tree 
impl ic i t  AND-operator .  An arrow tr iggers 
defau l ts  on: the e lements  of express ions  
to the r ight of an arrow are in the 
OR- re la t ion  and those to the left of it 
are in the AND-re lat ion.  Two kinds of 
arrows are in use. A s imple arrow (->) 
per forms all operat ions  on the right and a 
double arrow (=>) terminates  the execut ion 
at the first successfu l  operat ion.  
In F igure 6 is an example of how one may 
def ine Subject.  If the re lat ion RecSubj 
holds between the regent and the dependent  
cand idate  the latter wi l l  be label led 
Subject  and subord inated to the former. 
The re lat iona l  express ion  RecSubj def ines  
the proper ty  pat terns  the const i tuents  
should match. 
A grammar def in i t ion  ends with the context  
spec i f i ca t ions  of const i tuents  expressed 
as two-way automata.  The automata are 
descr ibed  using the notat ion shown in 
somewhat  s impl i f ied form in Figure 7. An 
automaton  can refer up to three 
const i tuents  to the r ight or left using 
indexed names: LI, L2, L3, RI, R2 or R3. 
<~unct ion> : :=  ( FUNCTION: <~unct ion  name> <operat ion  expr> ) 
<re la t ion> : :=  ( RELATION: <re la t ion  name> <operat ion  expr> ) 
<operat ion  expr> : :=  ( <pred icate  e~pr>. .  < imply  <operat ion  e×pr>. .  ) 
<pred icate  expr> 
<re la t ion  name> : 
( DEL <const i tuent  labe l> ) 
<pred icate  expr> : :=  < <pred icate  expr> > I 
( <pred icate  expr> ) 
( <const i tuent  po in ter> <operator> <va lue  expr>)  
<impl> : :=  -> I => 
<const i tuent  labe l>: := C I D 
<operator> ::= = I := I :-- I =:= 
<value expr> ::= < <va lue  expr>.. > : 
( <value expr>.. ) : 
<va lue  o~ some proper ty> I 
'<lexeme> I 
( <proper ty  name> <const i tuent  label> ) 
F igure 5. The syntax of DPL- funct ions  and DPL- re la t ions  
101 
(FUNCTION: 
) 
(RELATION: 
Sub jec t  
( RecSubj ->  (D := Sub jec t ) )  
RecSubj 
((C = Act  < Ind Cond Pot Imper >) (D = -Sentence  +Nominal) 
->  ((D = Nom) 
-> (D = PersPron (PersonP C) (PersonN C)) 
((D = Noun) (C = 3P) -> ((C = S) (D = SG)) 
( (C  = P )  (D  = PL) ) ) )  
( (D  = Par t )  (C  = S 3P)  
->  ( (C  = "OLLA)  
=> (C : -  +Ex is tence) )  
((C = -T rans i t i ve  +Ex is tence) ) ) )  
Figure 6. A realisation of Subject 
<state  in  autom.>: := ( STATE: <state  name> <di rec t ion> <state  expr>. .  ) 
<d i rec t ion> : :=  LEFT | RIGHT 
<state  expr> : :=  ( < lhs  o f  s.  expr> <impl> <state  expr>. .  ) 
( < lhs  o f  s.  expr> <impl> <state  change> ) 
< lhs  o f  s.  expr> : :=  <funct ion  name> ~ <pred icate  expr>. .  
<state  change> : :=  ( C := <name o f  next  s ta te> ) : 
( FIND-REG-ON <d i rec t ion> <sstate  oh .> ) 
( BUILD-PHRASE-ON <d i rec t ion> <sstate  oh .> ) 
( PARSED ) 
<state  change> : :=  <work sp. manip°> <state  change> 
<sstate  ch .> : :=  ( C := <name o f  re turn  s ta te> ) 
<work sp. man ip°>: := ( DEL <const i tuent  labe l> ) 
( TRANSPOSE <const i tuent  labe l> 
<const i tuent  labe l> ) 
Figure 7. Simplified syntax of state specifications 
( STATE: V? RIGHT 
((D = +Phrase) ->  (Sub jec t  ->  (C := VS?)) 
(Ob jec t  -> (C := VO?)) 
(Adverb ia l  -> (C := V?))  
(T => (C := ?VF ina l ) ) )  
((D = -Phrase)  -> (BUILD-PHRASE-ON RIGHT (C :=  V?) ) )  
Figure 8. The expression of V? in Figure 2. 
102 
The direction of a state (see Figure 2.) 
selects the dependent candidate normally 
as L1 or R1. A switch of state takes 
place by an assignment in the same way as 
l inguistic properties are assigned. As an 
example the node V? of Figure 2 is 
defined formally in Figure 8. 
More l inguist ical ly oriented 
argumentation of the DPL-formal ism appears 
elsewhere (Nelimarkka, 1984a, and 
Nelimarkka, 1984b). 
THE ARCHITECTURE OF THE DPL-ENVIRONMENT 
The architecture of the DPL-environment is 
described schematical ly in Figure 9. The 
main parts are highlighted by heavy lines. 
Single arrows represent data transfer; 
double arrows indicate the production of 
data structures. All modules have been 
implemented in LISP. The realisations do 
not rely on specifics of underlying 
LISP-environments. 
The DPL-compiler 
A compilat ion results in executable code 
of a parser. The compiler produces highly 
optimized code (Lehtola, 1984). 
Internal ly data structures are only partly 
dynamic for the reason of fast information 
fetch. Ambiguit ies are expressed locally 
to minimize redundant search. The 
principle of structure sharing is followed 
whenever new data structures are built. 
In the manipulat ion of const ituent 
structures there exists a special service 
routine for each combination of property 
and predicat ion types. These routines 
take special care of time and memory 
consumption. For instance with regard 
replacements and insertions the copying 
includes physical ly only the path from the 
root of the list structure to the changed 
sublist. The logically shared parts will 
• be shared also physically. This 
st ipulation minimizes memory usage. 
In the state transit ion network level the 
search is done depth first. To handle 
ambiquit ies DPL-funct ions and -relations 
process all alternative interpretations in 
parallel. In fact the alternatives are 
stored in the stacks and in the C-register 
as trees of alternants. 
In the first version of the DPL-compiler 
the generation rules were intermixed with 
the compiler code. The maintenance of the 
compiler grew harder when we experimented 
with new computational  features. We 
parser  facility 
lexicon 
maintenance 
information 
extraction system 
with 
graphic output 
Figure 9. The architecture of the DPL-environment 
103 
therefore started to develop a 
metacompi ler  in which compi lat ion is 
defined by rules. At moment we are 
testing it and soon it will be in everyday 
use. The amount of LISP-code has greatly 
reduced with the rule based approach, and 
we are now planning to install the 
DPL-environment into IBM PC. 
Our parsers were aimed to be practical 
tools in real product ion applications. It 
was hence important to make the produced 
programs transferable. As of now we have 
a rule-based translator which converts 
parsers between LISP dialects. The 
translator accepts currently INTERLISP, 
FranzLISP and Common Lisp. 
Lexicon and its Maintenance 
The environment has a special maintenance 
program for lexicons. The program uses 
video graphics to ease updating and it 
performs various checks to guarantee the 
consistency of the lexical entries. It 
also co-operates with the information 
extract ion system to help the user in the 
select ion of properties. 
The Tracing Faci l i ty 
The tracing faci l ity is a convenient tool 
for grammar debugging. For example, in 
Figure I0 appears the trace of the parsing 
of the sentence "Poikani tuli i l lal la 
kent~it~ heitt~m~st~ kiekkoa." (= "My son 
(T  POIKANI TULI ILLALLA KENT~LT~ HEITT~M~ST~ KIEKKOA .) 
~8~ ¢c~ses  
• 03 seconds 
0 .0  seconds, garbage co l lec t ion  t ime 
PARSED 
_PRTH ( ) 
=> (POIKA)  (TULJ.A) ( I LTA)  (KENTT~) (HE ITT~)  (KIE\]<KO) ?N 
(POIKA)  <= (TULLA)  ( I LTA)  (KENTT~) (HE ITT~)  (K IEKKO)  N? 
=> (POIKA)  (TULLA)  ( I LTA)  (KENTT~) (HE ITT~)  (K IEKKO)  ?NF ina l  
(##)  (POIKA)  (TULLA)  ( I LTA)  (KENTT~) (HE ITT~)  (K IEKKO)  NIL 
(POIKA)  => (TULLA) (ILTA) (KENTT~) (HE ITT~)  (K IEKKO)  ?V. 
,=> ( (POIKA)  TULLA) (ILTA) (KENTT~) (HEITT~) (KIEKKO) ?VS 
((POIKA) TULLA) <= (~LTA) (KENTT~) (HEITT~&) (KIEKKO) VS? 
((POIKA) TULLA) => (ILTA) (KENTT~) (HEITT~&~) (KIEKKO) ?N 
( (POIKA)  TULLA) ( I LTA)  <= (KENTT~) (HE ITT~)  (K IEKKO) N? 
((POIKA) TULLA) => "(ILTA) (KENTT~) (HEITT~) (KIEKKO) ?NFinal 
((POIKA) TULLA) <= (ILTA) (KENTT~) (HEITT~) (KIEKKO) VS? 
((POIKA) TULLA (ILTA)) <= (KENTT~) (HEITTYdl) (KIEKKO) VS? 
((POIKA) TULLA (ILTA)) => (KENTT&) (HEITT~) (KIEKKO) ?N 
((POIKA) TULLA (ILTA)) (KENTT~) <= (HEITT~) (KIEKKO) N? 
((POIKA) TULLA (ILTA)) => (KENTT~) (HEITT~) (KIEKKO) ?NFinal 
((POIKA) TULLA (ILTA)) <= (KENTT&) (HEITT~) (KIEKKO) VS? 
( (POLKA)  TULLA ( I LTA)  (KENTT~))  <= (HE ITT~)  (K IEKKO) VS? 
((POIKA) TULLA (ILTA) (KENTT~)) => (HEITT~i) (KIEKKO) .9%/ 
((POIKA) TULLA (ILTA) (KENTT~)) (HEITT~) <= (KIEKKO) V? 
((POIKA) TULLA (ILTA) (KENTT~)) (HEITT~dl) => (KIEKKO) ?N 
((POIKA) TULLA (ILTA) (KENTT~)) (HEITT~) (KIEKKO) <= N? 
((POIKA) TULLA (ILTA) (KENTT~)) (HEITT&~) => (KIEKKO) ?NFinal 
((POIKA) TULLA (ILTA) (KENTT~)) (HEITT~) <= (KIEKKO) V? 
((POIKA) TULLA (ILTA) (KENTT&)) (HEITT~ (KIEKKO)) <= VO? 
((POIKA) TULLA (ILTA) (KENTT~)) => (HEITT~ (KIEKKO)) ?VFinal 
((POIKA) TULLA (ILTA) (KENTT~)) <= (HEITT&~ (KIEKKO)) VS? 
((POIKA) TULLA (ILTA) (KENTT~) (HEITT~ (KIEKKO))) <= VS? 
=> ((POIKA) TULLA (ILTA) (KENTT~) (HEITT~ (KIEKKO))) ?VFinal 
((POIKA) TULLA (ILTA) (KENTT~) (HEITT~ (KIEKKO))) <= MainSent? 
((POIKA) TULLA (ILTA) (KENTT~) (HEITT&& (KIEKKO))) <= MainSent? OK 
DONE 
Figure I0. A trace of parsing process 
104 
came back in the evening from the stadium 
where he had been throwing the discus."). 
Each row represents a state of the parser 
before the control enters the state 
mentioned on the right-hand column. The 
thus-far found constituents are shown by 
the parenthesis. An arrow head points 
from a dependent candidate (one which is 
subjected to dependency tests) towards the 
current constituent. 
The tracing facil ity gives also the 
consumed CPU-time and two qual ity 
indicators: search eff ic iency and 
connection efficiency. Search eff iciency 
is 100%, if no useless state transit ions 
took place in the search. This figure is 
meaningless when the system is 
parameterized to full search because then 
all transit ions are tried. 
Connection eff ic iency is the ratio of the 
number of connections remaining in a 
result to the total number of connections 
attempted for it during the search. We 
are currently developing other measuring 
tools to extract statist ical information, 
eg. about the frequency distr ibut ion of 
di f ferent constructs. Under development 
is also automatic book-keeping of all 
sentence~ input to the system. These will 
be divided into two groups: parsed and 
not parsed. The first group const i tutes 
growing test material  to ensure monotonic 
improvement of grammars: after a non 
trivial change is done in the grammar, a 
new compiled parser runs all test 
sentences and the results are compared to 
the previous ones. 
Information Extraction System 
In an actual working situation there may 
be thousands of l inguistic symbols in the 
work space. To make such a complex 
manageable, we have implemented an 
information system that for a given symbol 
pretty-pr ints all information associated 
with it. 
The environment has routines for the 
graphic display of parsing results. A 
user can select information by pointing 
with the cursor. The example in Figure Ii 
demonstrates the use of this facility. 
The command SHOW() inquires the results of 
_SHOW ( ) 
(PO IKANI )  (TUL I )  ( IL J .RLLR)  (K I~&I .T&)  ( HE I TT31 I ' I~X ) (K IEK~)  STRRT 
( (P I \ ] IKA)  TULLA ( I LTA\ ]~KENTT~)  (HE ITT  xx  (K IEKKO)) )  ! 
TULLA 
I 
I 
! 
i 
SubJect 
' oa t ive  Neutra l )  
, i 
! ! 
ILTA KENTTX 
Adverb ia l  Adverb ia l  
TiaeIPred Ab la t ive  
Funct ion Sub Jec t  
Role (Ergat ive  Neutra l  )
FrameFeat  (N IL )  
Po la r  (Pos )  
IVo ice  (N IL )  
!Modal (N IL )  
Tense (N IL )  
Comparison (N i lCo lpar )  
Number (SG) 
Case  (Nee)  
PersonN (S) 
P~sonP  ( IP )  
Cl i t l  (N IL )  
Cl i t2  (N IL )  
, e 
HEITT~U~ 
Adverbial 
S 
! 
KIEKKO 
Ob jec t  
Neutra l  
ConstFeat i s  a l ingu is t i c  feature  type. 
Defau l t  valuen -Phrase 
Associated va lues :  (+Dec larat ive  -Dec larat ive  +Main -Main +Nominal 
-Nominal +Phrase -Phrase +Pred icat ive  -P red icat ive  +Re la t ive  -Re la t ive  
+Sentence -Sentence)  
Associated ~unct i  onsl 
(C~nstFeat / INIT  ConstFeat/FN CenstFeat l= ConstFeat /=:= ConstFeat / : -  
ConstFeat / , - /C  CanstFeat / := ConstFeat/:=/C) 
Figure ii. An example of information extraction uti l it ies 
105 
the parsing process described in Figure i0. 
The system replies by first printing the 
start state and then the found result(s) 
in compressed Eorm. The cursor has been 
moved on top of this parse and CTRL-G has 
been typed. The system now draws the 
picture of the tree structure. 
Subsequently one of the nodes has been 
opened. The properties of the node POIKA 
appear pretty-printed. The user has 
furthermore asked information about the 
property type ConstFeat. All these 
operations are general; they do not use 
the special features of any part icular 
terminal. 
CONCLUSION 
The parsing strategy applied for the 
DPL-formal ism was original ly viewed as a 
cognit ive model. It has proved to result 
practical  and eff icient parsers as well. 
Experiments with a non-tr ivial  set of 
Finnish sentence structures have been 
performed both on DEC-2060 and on 
VAX-I I /780 systems. The analysis of an 
eight word sentence, for instance, takes 
between 20 and 600 ms of DEC CPU-time in 
the INTERLISP-version depending on whether 
one wants only the first or, through 
complete search, all parses for 
structural ly ambiguous sentences. The 
MacLISP-vers ion of the parser runs  about 
20 % faster on the same computer. The 
NIL-version (Common Lisp compatible) is 
about 5 times slower on VAX. The whole 
environment has been transferred also to 
FranzLISP on VAX. We have not yet focused 
on optimality issues in grammar 
descriptions. We believe that by 
rearranging the orderings of expectations 
in the automata improvement in eff ic iency 
ensues. 
REFERENCES 
i. Lehtola, A., Compilat ion and 
Implementat ion of 2-way Tree Automata for 
the Parsing of Finnish. M.So Thesis, 
~elsinki University of Technology, 
Department of Physics, 1984, 120 p. (in 
Finnish) 
2° Nelimarkka, E°, J~ppinen, H. and 
Lehtola A., Two-way Finite Automata and 
Dependency Theory: A Parsing Method for 
Inf lectional Free Word Order Languages. 
Proc. COLING84/ACL, Stanford, 1984a, pp. 
389-392. 
3° Nelimarkka, E., J~ppinen, H. and 
Lehtola A., Parsing an Inf lectional Free 
Word Order Language with Two-way Finite 
Automata° Proc. of the 6th European 
Conference on Art i f ic ial  Intel l igence, 
Pisa, 1984b, pp. 167-176. 
4. Winograd, To, Language as a Cognit ive 
Process. Volume I: Syntax, 
Addison-Wesley Publishing Company, 
Reading, 1983, 640 p. 
106 
